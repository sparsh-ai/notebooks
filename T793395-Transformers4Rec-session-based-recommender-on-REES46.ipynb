{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T793395 | Transformers4Rec session-based recommender on REES46","provenance":[],"collapsed_sections":["qDsU-44pE-bz","1Ufoo58oE-b7","Yho5LkXrE-b9","YlU41Xs6FgSy","mzHE1FEDFgS-","pq-ivc1PFgTE","qhLlRxTSFgTF","br8Yv6cMFgTI","bgQ675fqFgTJ","jbHfTea4FgTR","85BpF7YjGkUa","d08dfc19","a8e7be36","68b323f3","dbd88fe6","d8ca3850","b7a1426f","9ff98ee9","3f217071","85047d3a","f5293026","2c63913c","8dab45a7","08de0ba3","26cdec77","184fca87","a512b632","04b7b077","3ee17c91","b72e5aef","43341500","77d36393","43dc14a8","07499907","72c90e93","0adbbbf2","fe1debc7","2f2e07dc","6224a7fe","496bdf04"],"toc_visible":true,"authorship_tag":"ABX9TyNJAIMpbsc83TUQCg2SRtkB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wOOL7LCXEWQz"},"source":["# Transformers4Rec session-based recommender on REES46"]},{"cell_type":"markdown","metadata":{"id":"Z3Ea3xXkEgCX"},"source":["Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals. Session-based recommenders provide relevant and personalized recommendations even when prior user history is not available or their tastes change over time. They recently gained popularity due to their ability to capture short-term or contextual user preferences towards items."]},{"cell_type":"markdown","metadata":{"id":"Qx_02_Z3EgTU"},"source":["## Learning Objectives\n","In this tutorial, we will learn:\n","- the main concepts and algorithms for session-based recommendation\n","- implementation of preprocessing and feature engineering techniques for session-based recommendation model on GPU with NVTabular\n","- how to build, train and evaluate a session-based recommendation model based on RNN and Transformer architectures with Transformers4Rec library\n","- how to deploy a trained model to the Triton Inference Server\n","- Preprocessing with cuDF and NVTabular\n","- Feature engineering with NVTabular\n","- Introduction to Transformers4Rec\n","- Introduction to session-based recommendation\n","- Accelerated dataloaders for PyTorch\n","- Traning and evaluating an RNN-based session based recommendation model for next item prediction task\n","- Traning and evaluating Transformer architecture based session-based recommendation model next item prediction task\n","- Using side information (additional features) to improve the accuracy of a model\n","- Deploying to inference with Triton"]},{"cell_type":"markdown","metadata":{"id":"WyqP2RTYE-bf"},"source":["## Import the required libraries"]},{"cell_type":"code","metadata":{"id":"NVYfsPmqE-bg"},"source":["import os\n","import numpy as np \n","import gc\n","import shutil\n","import glob\n","\n","import cudf\n","import cupy as cp\n","import nvtabular as nvt\n","from nvtabular import ColumnSelector\n","\n","import transformers4rec.torch as tr\n","from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBgPdlr1E-bX"},"source":["## Read and Process E-Commerce data"]},{"cell_type":"markdown","metadata":{"id":"jIHSWbBjE-bb"},"source":["In this section, we are going to use a subset of a publicly available [eCommerce dataset](https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store). The full dataset contains 7 months data (from October 2019 to April 2020) from a large multi-category online store. Each row in the file represents an event. All events are related to products and users. Each event is like many-to-many relation between products and users.\n","Data collected by Open CDP project and the source of the dataset is [REES46 Marketing Platform](https://rees46.com/)."]},{"cell_type":"markdown","metadata":{"id":"LPHsMoXxE-bd"},"source":["We use only `2019-Oct.csv` file for training our models, so you can visit this site and download the csv file: https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store."]},{"cell_type":"markdown","metadata":{"id":"AojjHH9NE-bi"},"source":["## Read Data via cuDF from CSV"]},{"cell_type":"markdown","metadata":{"id":"P_uW4DuYE-bk"},"source":["At this point we expect that you have already downloaded the `2019-Oct.csv` dataset and stored it in the `INPUT_DATA_DIR` as defined below. It is worth mentioning that the raw dataset is ~ 6 GB, therefore a single GPU with 16 GB or less memory might run out of memory."]},{"cell_type":"code","metadata":{"id":"DB3xflW4E-bm"},"source":["# define some information about where to get our data\n","INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYHVpXf2E-bo","outputId":"6ba40ec4-72d0-4019-b86e-3f0be4e8bcd5"},"source":["%%time\n","raw_df = cudf.read_csv(os.path.join(INPUT_DATA_DIR, '2019-Oct.csv')) \n","raw_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 3.2 s, sys: 1.5 s, total: 4.69 s\n","Wall time: 5.32 s\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>event_time</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>user_session</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2019-10-01 00:00:00 UTC</td>\n","      <td>view</td>\n","      <td>44600062</td>\n","      <td>2103807459595387724</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>shiseido</td>\n","      <td>35.79</td>\n","      <td>541312140</td>\n","      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2019-10-01 00:00:00 UTC</td>\n","      <td>view</td>\n","      <td>3900821</td>\n","      <td>2053013552326770905</td>\n","      <td>appliances.environment.water_heater</td>\n","      <td>aqua</td>\n","      <td>33.20</td>\n","      <td>554748717</td>\n","      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019-10-01 00:00:01 UTC</td>\n","      <td>view</td>\n","      <td>17200506</td>\n","      <td>2053013559792632471</td>\n","      <td>furniture.living_room.sofa</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>543.10</td>\n","      <td>519107250</td>\n","      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2019-10-01 00:00:01 UTC</td>\n","      <td>view</td>\n","      <td>1307067</td>\n","      <td>2053013558920217191</td>\n","      <td>computers.notebook</td>\n","      <td>lenovo</td>\n","      <td>251.74</td>\n","      <td>550050854</td>\n","      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2019-10-01 00:00:04 UTC</td>\n","      <td>view</td>\n","      <td>1004237</td>\n","      <td>2053013555631882655</td>\n","      <td>electronics.smartphone</td>\n","      <td>apple</td>\n","      <td>1081.98</td>\n","      <td>535871217</td>\n","      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                event_time event_type  product_id          category_id  \\\n","0  2019-10-01 00:00:00 UTC       view    44600062  2103807459595387724   \n","1  2019-10-01 00:00:00 UTC       view     3900821  2053013552326770905   \n","2  2019-10-01 00:00:01 UTC       view    17200506  2053013559792632471   \n","3  2019-10-01 00:00:01 UTC       view     1307067  2053013558920217191   \n","4  2019-10-01 00:00:04 UTC       view     1004237  2053013555631882655   \n","\n","                         category_code     brand    price    user_id  \\\n","0                                 <NA>  shiseido    35.79  541312140   \n","1  appliances.environment.water_heater      aqua    33.20  554748717   \n","2           furniture.living_room.sofa      <NA>   543.10  519107250   \n","3                   computers.notebook    lenovo   251.74  550050854   \n","4               electronics.smartphone     apple  1081.98  535871217   \n","\n","                           user_session  \n","0  72d76fde-8bb3-4e00-8c23-a032dfed738c  \n","1  9333dfbd-b87a-4708-9857-6336556b0fcc  \n","2  566511c2-e2e3-422b-b695-cf8e6e792ca8  \n","3  7c90fc70-0e80-4590-96f3-13c02c18c713  \n","4  c6bd7419-2748-4c56-95b4-8cec9ff8b80d  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Lz998es4E-br","outputId":"2f78ee1e-b7d2-4712-c7b0-d922fc00241e"},"source":["raw_df.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(42448764, 9)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"6Si2x7muE-bs"},"source":["## Convert timestamp from datetime"]},{"cell_type":"code","metadata":{"id":"Rx30B89IE-bt","outputId":"1bdab8cc-24ae-494c-c005-6d54b5d221a2"},"source":["raw_df['event_time_dt'] = raw_df['event_time'].astype('datetime64[s]')\n","raw_df['event_time_ts']= raw_df['event_time_dt'].astype('int')\n","raw_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>event_time</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>user_session</th>\n","      <th>event_time_dt</th>\n","      <th>event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2019-10-01 00:00:00 UTC</td>\n","      <td>view</td>\n","      <td>44600062</td>\n","      <td>2103807459595387724</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>shiseido</td>\n","      <td>35.79</td>\n","      <td>541312140</td>\n","      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>\n","      <td>2019-10-01 00:00:00</td>\n","      <td>1569888000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2019-10-01 00:00:00 UTC</td>\n","      <td>view</td>\n","      <td>3900821</td>\n","      <td>2053013552326770905</td>\n","      <td>appliances.environment.water_heater</td>\n","      <td>aqua</td>\n","      <td>33.20</td>\n","      <td>554748717</td>\n","      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>\n","      <td>2019-10-01 00:00:00</td>\n","      <td>1569888000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019-10-01 00:00:01 UTC</td>\n","      <td>view</td>\n","      <td>17200506</td>\n","      <td>2053013559792632471</td>\n","      <td>furniture.living_room.sofa</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>543.10</td>\n","      <td>519107250</td>\n","      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>\n","      <td>2019-10-01 00:00:01</td>\n","      <td>1569888001</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2019-10-01 00:00:01 UTC</td>\n","      <td>view</td>\n","      <td>1307067</td>\n","      <td>2053013558920217191</td>\n","      <td>computers.notebook</td>\n","      <td>lenovo</td>\n","      <td>251.74</td>\n","      <td>550050854</td>\n","      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>\n","      <td>2019-10-01 00:00:01</td>\n","      <td>1569888001</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2019-10-01 00:00:04 UTC</td>\n","      <td>view</td>\n","      <td>1004237</td>\n","      <td>2053013555631882655</td>\n","      <td>electronics.smartphone</td>\n","      <td>apple</td>\n","      <td>1081.98</td>\n","      <td>535871217</td>\n","      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>\n","      <td>2019-10-01 00:00:04</td>\n","      <td>1569888004</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                event_time event_type  product_id          category_id  \\\n","0  2019-10-01 00:00:00 UTC       view    44600062  2103807459595387724   \n","1  2019-10-01 00:00:00 UTC       view     3900821  2053013552326770905   \n","2  2019-10-01 00:00:01 UTC       view    17200506  2053013559792632471   \n","3  2019-10-01 00:00:01 UTC       view     1307067  2053013558920217191   \n","4  2019-10-01 00:00:04 UTC       view     1004237  2053013555631882655   \n","\n","                         category_code     brand    price    user_id  \\\n","0                                 <NA>  shiseido    35.79  541312140   \n","1  appliances.environment.water_heater      aqua    33.20  554748717   \n","2           furniture.living_room.sofa      <NA>   543.10  519107250   \n","3                   computers.notebook    lenovo   251.74  550050854   \n","4               electronics.smartphone     apple  1081.98  535871217   \n","\n","                           user_session       event_time_dt  event_time_ts  \n","0  72d76fde-8bb3-4e00-8c23-a032dfed738c 2019-10-01 00:00:00     1569888000  \n","1  9333dfbd-b87a-4708-9857-6336556b0fcc 2019-10-01 00:00:00     1569888000  \n","2  566511c2-e2e3-422b-b695-cf8e6e792ca8 2019-10-01 00:00:01     1569888001  \n","3  7c90fc70-0e80-4590-96f3-13c02c18c713 2019-10-01 00:00:01     1569888001  \n","4  c6bd7419-2748-4c56-95b4-8cec9ff8b80d 2019-10-01 00:00:04     1569888004  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"PThaWmIiE-bv","outputId":"afaa993d-e789-4cfc-8593-d78267160131"},"source":["# check out the columns with nulls\n","raw_df.isnull().any()"],"execution_count":null,"outputs":[{"data":{"text/plain":["event_time       False\n","event_type       False\n","product_id       False\n","category_id      False\n","category_code     True\n","brand             True\n","price            False\n","user_id          False\n","user_session      True\n","event_time_dt    False\n","event_time_ts    False\n","dtype: bool"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"z2yjt_nCE-bx","outputId":"0130b474-adba-401e-ab88-0eb16ba5008c"},"source":["# Remove rows where `user_session` is null.\n","raw_df = raw_df[raw_df['user_session'].isnull()==False]\n","len(raw_df)"],"execution_count":null,"outputs":[{"data":{"text/plain":["42448762"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"--qT8qvmE-by"},"source":["We no longer need `event_time` column."]},{"cell_type":"code","metadata":{"id":"qaUO-tRUE-bz"},"source":["raw_df = raw_df.drop(['event_time'],  axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDsU-44pE-bz"},"source":["## Categorify `user_session` column\n","Although `user_session` is not used as an input feature for the model, it is useful to convert those raw long string to int values to avoid potential failures when grouping interactions by `user_session` in the next section."]},{"cell_type":"code","metadata":{"id":"u-5hxU0XE-b0","outputId":"ad46a69b-b288-40e3-cbf6-a726f4254795"},"source":["cols = list(raw_df.columns)\n","cols.remove('user_session')\n","cols"],"execution_count":null,"outputs":[{"data":{"text/plain":["['event_type',\n"," 'product_id',\n"," 'category_id',\n"," 'category_code',\n"," 'brand',\n"," 'price',\n"," 'user_id',\n"," 'event_time_dt',\n"," 'event_time_ts']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"qX_yH9nvE-b1"},"source":["# load data \n","df_event = nvt.Dataset(raw_df) \n","\n","# categorify user_session \n","cat_feats = ['user_session'] >> nvt.ops.Categorify()\n","\n","workflow = nvt.Workflow(cols + cat_feats)\n","workflow.fit(df_event)\n","df = workflow.transform(df_event).to_ddf().compute()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d582q3NXE-b2","outputId":"7468d8e9-acfa-43bd-ac3a-0b44a4385b7d"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>event_time_dt</th>\n","      <th>event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5126085</td>\n","      <td>view</td>\n","      <td>44600062</td>\n","      <td>2103807459595387724</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>shiseido</td>\n","      <td>35.79</td>\n","      <td>541312140</td>\n","      <td>2019-10-01 00:00:00</td>\n","      <td>1569888000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7854470</td>\n","      <td>view</td>\n","      <td>3900821</td>\n","      <td>2053013552326770905</td>\n","      <td>appliances.environment.water_heater</td>\n","      <td>aqua</td>\n","      <td>33.20</td>\n","      <td>554748717</td>\n","      <td>2019-10-01 00:00:00</td>\n","      <td>1569888000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>730655</td>\n","      <td>view</td>\n","      <td>17200506</td>\n","      <td>2053013559792632471</td>\n","      <td>furniture.living_room.sofa</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>543.10</td>\n","      <td>519107250</td>\n","      <td>2019-10-01 00:00:01</td>\n","      <td>1569888001</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1637332</td>\n","      <td>view</td>\n","      <td>1307067</td>\n","      <td>2053013558920217191</td>\n","      <td>computers.notebook</td>\n","      <td>lenovo</td>\n","      <td>251.74</td>\n","      <td>550050854</td>\n","      <td>2019-10-01 00:00:01</td>\n","      <td>1569888001</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4202155</td>\n","      <td>view</td>\n","      <td>1004237</td>\n","      <td>2053013555631882655</td>\n","      <td>electronics.smartphone</td>\n","      <td>apple</td>\n","      <td>1081.98</td>\n","      <td>535871217</td>\n","      <td>2019-10-01 00:00:04</td>\n","      <td>1569888004</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_session event_type  product_id          category_id  \\\n","0       5126085       view    44600062  2103807459595387724   \n","1       7854470       view     3900821  2053013552326770905   \n","2        730655       view    17200506  2053013559792632471   \n","3       1637332       view     1307067  2053013558920217191   \n","4       4202155       view     1004237  2053013555631882655   \n","\n","                         category_code     brand    price    user_id  \\\n","0                                 <NA>  shiseido    35.79  541312140   \n","1  appliances.environment.water_heater      aqua    33.20  554748717   \n","2           furniture.living_room.sofa      <NA>   543.10  519107250   \n","3                   computers.notebook    lenovo   251.74  550050854   \n","4               electronics.smartphone     apple  1081.98  535871217   \n","\n","        event_time_dt  event_time_ts  \n","0 2019-10-01 00:00:00     1569888000  \n","1 2019-10-01 00:00:00     1569888000  \n","2 2019-10-01 00:00:01     1569888001  \n","3 2019-10-01 00:00:01     1569888001  \n","4 2019-10-01 00:00:04     1569888004  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"mkvU4w_mE-b4"},"source":["raw_df = None\n","del(raw_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjTswg3QE-b5","outputId":"0cc8bf62-247a-47c9-fd10-98bfbf15dd81"},"source":["gc.collect()"],"execution_count":null,"outputs":[{"data":{"text/plain":["145"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"1Ufoo58oE-b7"},"source":["## Removing consecutive repeated (user, item) interactions"]},{"cell_type":"markdown","metadata":{"id":"C159Al0wE-b7"},"source":["We keep repeated interactions on the same items, removing only consecutive interactions, because it might be due to browser tab refreshes or different interaction types (e.g. click, add-to-card, purchase)"]},{"cell_type":"code","metadata":{"id":"KvJPNGpbE-b8","outputId":"040ca1bb-82ac-4d94-d047-5ce9abe0473f"},"source":["%%time\n","df = df.sort_values(['user_session', 'event_time_ts']).reset_index(drop=True)\n","\n","print(\"Count with in-session repeated interactions: {}\".format(len(df)))\n","# Sorts the dataframe by session and timestamp, to remove consecutive repetitions\n","df['product_id_past'] = df['product_id'].shift(1).fillna(0)\n","df['session_id_past'] = df['user_session'].shift(1).fillna(0)\n","#Keeping only no consecutive repeated in session interactions\n","df = df[~((df['user_session'] == df['session_id_past']) & \\\n","             (df['product_id'] == df['product_id_past']))]\n","print(\"Count after removed in-session repeated interactions: {}\".format(len(df)))\n","del(df['product_id_past'])\n","del(df['session_id_past'])\n","\n","gc.collect()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Count with in-session repeated interactions: 42448762\n","Count after removed in-session repeated interactions: 30733301\n","CPU times: user 789 ms, sys: 120 ms, total: 909 ms\n","Wall time: 1.16 s\n"]},{"data":{"text/plain":["0"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"Yho5LkXrE-b9"},"source":["## Include the item first time seen feature (for recency calculation)"]},{"cell_type":"markdown","metadata":{"id":"HN0elKgCE-b-"},"source":["We create `prod_first_event_time_ts` column which indicates the timestamp that an item was seen first time."]},{"cell_type":"code","metadata":{"id":"Rho7eH5dE-b_","outputId":"cedd5778-c4a7-46f7-c65c-1424fc28215f"},"source":["item_first_interaction_df = df.groupby('product_id').agg({'event_time_ts': 'min'}) \\\n","            .reset_index().rename(columns={'event_time_ts': 'prod_first_event_time_ts'})\n","item_first_interaction_df.head()\n","gc.collect()"],"execution_count":null,"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"xBfuAk3vE-b_"},"source":["df = df.merge(item_first_interaction_df, on=['product_id'], how='left').reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGRPz0pqE-cA","outputId":"cb01ffc8-ebdd-47c7-a2f7-2a33c1d3beda"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>event_time_dt</th>\n","      <th>event_time_ts</th>\n","      <th>prod_first_event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>94</td>\n","      <td>view</td>\n","      <td>26202560</td>\n","      <td>2053013563693335403</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>388.49</td>\n","      <td>512892706</td>\n","      <td>2019-10-15 17:21:59</td>\n","      <td>1571160119</td>\n","      <td>1569925682</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>94</td>\n","      <td>view</td>\n","      <td>26203994</td>\n","      <td>2053013563693335403</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>157.79</td>\n","      <td>512892706</td>\n","      <td>2019-10-15 17:22:17</td>\n","      <td>1571160137</td>\n","      <td>1569941460</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>94</td>\n","      <td>view</td>\n","      <td>26204036</td>\n","      <td>2053013563693335403</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>sokolov</td>\n","      <td>471.70</td>\n","      <td>512892706</td>\n","      <td>2019-10-15 17:22:29</td>\n","      <td>1571160149</td>\n","      <td>1569897265</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>94</td>\n","      <td>view</td>\n","      <td>26203994</td>\n","      <td>2053013563693335403</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>157.79</td>\n","      <td>512892706</td>\n","      <td>2019-10-15 17:22:58</td>\n","      <td>1571160178</td>\n","      <td>1569941460</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>94</td>\n","      <td>view</td>\n","      <td>26203727</td>\n","      <td>2053013563693335403</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>lucente</td>\n","      <td>317.38</td>\n","      <td>512892706</td>\n","      <td>2019-10-15 17:23:19</td>\n","      <td>1571160199</td>\n","      <td>1569901056</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_session event_type  product_id          category_id category_code  \\\n","0            94       view    26202560  2053013563693335403          <NA>   \n","1            94       view    26203994  2053013563693335403          <NA>   \n","2            94       view    26204036  2053013563693335403          <NA>   \n","3            94       view    26203994  2053013563693335403          <NA>   \n","4            94       view    26203727  2053013563693335403          <NA>   \n","\n","     brand   price    user_id       event_time_dt  event_time_ts  \\\n","0     <NA>  388.49  512892706 2019-10-15 17:21:59     1571160119   \n","1     <NA>  157.79  512892706 2019-10-15 17:22:17     1571160137   \n","2  sokolov  471.70  512892706 2019-10-15 17:22:29     1571160149   \n","3     <NA>  157.79  512892706 2019-10-15 17:22:58     1571160178   \n","4  lucente  317.38  512892706 2019-10-15 17:23:19     1571160199   \n","\n","   prod_first_event_time_ts  \n","0                1569925682  \n","1                1569941460  \n","2                1569897265  \n","3                1569941460  \n","4                1569901056  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"tzLFbQG1E-cB","outputId":"24cde00a-fabf-42eb-e0a0-b91e80b862f0"},"source":["del(item_first_interaction_df)\n","item_first_interaction_df=None\n","gc.collect()"],"execution_count":null,"outputs":[{"data":{"text/plain":["0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"WiE2JuncE-cC"},"source":["In this tutorial, we only use one week of data from Oct 2019 dataset."]},{"cell_type":"code","metadata":{"id":"SoV0lsUTE-cC","outputId":"95fc4898-cf68-4ed3-87cf-45cb5e09eec6"},"source":["# check the min date\n","df['event_time_dt'].min()"],"execution_count":null,"outputs":[{"data":{"text/plain":["numpy.datetime64('2019-10-01T00:00:00')"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"1PdlgOiUE-cD"},"source":["# Filters only the first week of the data.\n","df = df[df['event_time_dt'] < np.datetime64('2019-10-08')].reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ePNRj5fE-cD"},"source":["We verify that we only have the first week of Oct-2019 dataset."]},{"cell_type":"code","metadata":{"id":"WRKAYLk8E-cE","outputId":"a9752c5d-2ac7-4397-e89a-31c75f507269"},"source":["df['event_time_dt'].max()"],"execution_count":null,"outputs":[{"data":{"text/plain":["numpy.datetime64('2019-10-07T23:59:59')"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"9p8s8iRaE-cE"},"source":["We drop `event_time_dt` column as it will not be used anymore."]},{"cell_type":"code","metadata":{"id":"UGjYRVEbE-cF"},"source":["df = df.drop(['event_time_dt'],  axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIUUcjyaE-cF","outputId":"e68ecd23-e613-450a-d3f1-450d725c7cd6"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>event_time_ts</th>\n","      <th>prod_first_event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300797</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>panasonic</td>\n","      <td>39.90</td>\n","      <td>513903572</td>\n","      <td>1570460611</td>\n","      <td>1569948287</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300798</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>panasonic</td>\n","      <td>32.18</td>\n","      <td>513903572</td>\n","      <td>1570460616</td>\n","      <td>1569934097</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300284</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>rowenta</td>\n","      <td>30.86</td>\n","      <td>513903572</td>\n","      <td>1570460621</td>\n","      <td>1569927253</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300382</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>remington</td>\n","      <td>28.22</td>\n","      <td>513903572</td>\n","      <td>1570460636</td>\n","      <td>1570026747</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300366</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>polaris</td>\n","      <td>26.46</td>\n","      <td>513903572</td>\n","      <td>1570460650</td>\n","      <td>1570097085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_session event_type  product_id          category_id category_code  \\\n","0            43       view     5300797  2053013563173241677          <NA>   \n","1            43       view     5300798  2053013563173241677          <NA>   \n","2            43       view     5300284  2053013563173241677          <NA>   \n","3            43       view     5300382  2053013563173241677          <NA>   \n","4            43       view     5300366  2053013563173241677          <NA>   \n","\n","       brand  price    user_id  event_time_ts  prod_first_event_time_ts  \n","0  panasonic  39.90  513903572     1570460611                1569948287  \n","1  panasonic  32.18  513903572     1570460616                1569934097  \n","2    rowenta  30.86  513903572     1570460621                1569927253  \n","3  remington  28.22  513903572     1570460636                1570026747  \n","4    polaris  26.46  513903572     1570460650                1570097085  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"obYUFiImE-cG"},"source":["Save the data as a single parquet file to be used in the ETL section."]},{"cell_type":"code","metadata":{"id":"Hn0AAqHoE-cG"},"source":["# save df as parquet files on disk\n","df.to_parquet(os.path.join(INPUT_DATA_DIR, 'Oct-2019.parquet'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YlU41Xs6FgSy"},"source":["## ETL with NVTabular"]},{"cell_type":"markdown","metadata":{"id":"rdbomPTRFgS0"},"source":["In this section, we will create a preprocessing and feature engineering pipeline with [Rapids cuDF](https://github.com/rapidsai/cudf) and [Merlin NVTabular](https://github.com/NVIDIA/NVTabular) libraries to prepare our dataset for session-based recommendation model training. \n","\n","NVTabular is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides high-level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS Dask-cuDF library, and is designed to be interoperable with both PyTorch and TensorFlow using dataloaders that have been developed as extensions of native framework code.\n","\n","Our main goal is to create sequential features. In order to do that, we are going to perform the following:\n","\n","- Categorify categorical features with `Categorify()` op\n","- Create temporal features with a `user-defined custom` op and `Lambda` op\n","- Transform continuous features using `Log` and `Normalize` ops\n","- Group all these features together at the session level sorting the interactions by time with `Groupby`\n","- Finally export the preprocessed datasets to parquet files by hive-partitioning."]},{"cell_type":"code","metadata":{"id":"XTEGEg3bFgS8"},"source":["# define data path about where to get our data\n","INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data/\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzHE1FEDFgS-"},"source":["## Read the Input Parquet file"]},{"cell_type":"markdown","metadata":{"id":"xqq-E0sVFgS-"},"source":["We already performed certain preprocessing steps on the first month (Oct-2019) of the raw dataset : <br>\n","\n","- we created `event_time_ts` column from `event_time` column which shows the time when event happened at (in UTC).\n","- we created `prod_first_event_time_ts` column which indicates the timestamp that an item was seen first time.\n","- we removed the rows where the `user_session` is Null. As a result, 2 rows were removed.\n","- we categorified the `user_session` column, so that it now has only integer values.\n","- we removed consequetively repeated (user, item) interactions. For example, an original session with `[1, 2, 4, 1, 2, 2, 3, 3, 3]` product interactions has become `[1, 2, 4, 1, 2, 3]` after removing the repeated interactions on the same item within the same session."]},{"cell_type":"markdown","metadata":{"id":"hsav2LH9FgS_"},"source":["Even though the original dataset contains 7 months data files, we are going to use the first seven days of the `Oct-2019.csv` ecommerce dataset. We use cuDF to read the parquet file. "]},{"cell_type":"code","metadata":{"id":"ZP_DOjBbFgTA","outputId":"86c5792d-339d-4fbc-f70d-15ba398d1652"},"source":["%%time\n","df = cudf.read_parquet(os.path.join(INPUT_DATA_DIR, 'Oct-2019.parquet'))  \n","df.head(5)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 665 ms, sys: 330 ms, total: 995 ms\n","Wall time: 999 ms\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>event_time_ts</th>\n","      <th>prod_first_event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300797</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>panasonic</td>\n","      <td>39.90</td>\n","      <td>513903572</td>\n","      <td>1570460611</td>\n","      <td>1569948287</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300798</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>panasonic</td>\n","      <td>32.18</td>\n","      <td>513903572</td>\n","      <td>1570460616</td>\n","      <td>1569934097</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300284</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>rowenta</td>\n","      <td>30.86</td>\n","      <td>513903572</td>\n","      <td>1570460621</td>\n","      <td>1569927253</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300382</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>remington</td>\n","      <td>28.22</td>\n","      <td>513903572</td>\n","      <td>1570460636</td>\n","      <td>1570026747</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>43</td>\n","      <td>view</td>\n","      <td>5300366</td>\n","      <td>2053013563173241677</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>polaris</td>\n","      <td>26.46</td>\n","      <td>513903572</td>\n","      <td>1570460650</td>\n","      <td>1570097085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_session event_type  product_id          category_id category_code  \\\n","0            43       view     5300797  2053013563173241677          <NA>   \n","1            43       view     5300798  2053013563173241677          <NA>   \n","2            43       view     5300284  2053013563173241677          <NA>   \n","3            43       view     5300382  2053013563173241677          <NA>   \n","4            43       view     5300366  2053013563173241677          <NA>   \n","\n","       brand  price    user_id  event_time_ts  prod_first_event_time_ts  \n","0  panasonic  39.90  513903572     1570460611                1569948287  \n","1  panasonic  32.18  513903572     1570460616                1569934097  \n","2    rowenta  30.86  513903572     1570460621                1569927253  \n","3  remington  28.22  513903572     1570460636                1570026747  \n","4    polaris  26.46  513903572     1570460650                1570097085  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"PGPAp5YxFgTB","outputId":"0192cff4-27b9-4a71-aa40-1a50701b90ab"},"source":["df.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(6390928, 10)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"lcn9L1PDFgTC"},"source":["Let's check if there is any column with nulls."]},{"cell_type":"code","metadata":{"id":"-xLmJ8LGFgTD","outputId":"84a5c0e4-a11e-4a6a-8d27-f3fc0d519439"},"source":["df.isnull().any()"],"execution_count":null,"outputs":[{"data":{"text/plain":["user_session                False\n","event_type                  False\n","product_id                  False\n","category_id                 False\n","category_code                True\n","brand                        True\n","price                       False\n","user_id                     False\n","event_time_ts               False\n","prod_first_event_time_ts    False\n","dtype: bool"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"9wXtQcIWFgTD"},"source":["We see that `'category_code'` and `'brand'` columns have null values, and in the following cell we are going to fill these nulls with via categorify op, and then all categorical columns will be encoded to continuous integers. Note that we add `start_index=1` in the `Categorify op` for the categorical columns, the reason for that we want the encoded null values to start from `1` instead of `0` because we reserve `0` for padding the sequence features."]},{"cell_type":"markdown","metadata":{"id":"pq-ivc1PFgTE"},"source":["## Initialize NVTabular Workflow\n","\n","### Categorical Features Encoding"]},{"cell_type":"code","metadata":{"id":"rJSahDvGFgTE"},"source":["# categorify features \n","cat_feats = ['user_session', 'category_code', 'brand', 'user_id', 'product_id', 'category_id', 'event_type'] >> nvt.ops.Categorify(start_index=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhLlRxTSFgTF"},"source":["### Extract Temporal Features"]},{"cell_type":"code","metadata":{"id":"bU4fd7EwFgTF"},"source":["# create time features\n","session_ts = ['event_time_ts']\n","\n","session_time = (\n","    session_ts >> \n","    nvt.ops.LambdaOp(lambda col: cudf.to_datetime(col, unit='s')) >> \n","    nvt.ops.Rename(name = 'event_time_dt')\n",")\n","\n","sessiontime_weekday = (\n","    session_time >> \n","    nvt.ops.LambdaOp(lambda col: col.dt.weekday) >> \n","    nvt.ops.Rename(name ='et_dayofweek')\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vy8iqoiDFgTF"},"source":["Now let's create cycling features from the `sessiontime_weekday` column. We would like to use the temporal features (hour, day of week, month, etc.) that have inherently cyclical characteristic. We represent the day of week as a cycling feature (sine and cosine), so that it can be represented in a continuous space. That way, the difference between the representation of two different days is the same, in other words, with cyclical features we can convey closeness between data. You can read more about it [here](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/)."]},{"cell_type":"code","metadata":{"id":"Afiq11p_FgTG"},"source":["def get_cycled_feature_value_sin(col, max_value):\n","    value_scaled = (col + 0.000001) / max_value\n","    value_sin = np.sin(2*np.pi*value_scaled)\n","    return value_sin\n","\n","def get_cycled_feature_value_cos(col, max_value):\n","    value_scaled = (col + 0.000001) / max_value\n","    value_cos = np.cos(2*np.pi*value_scaled)\n","    return value_cos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4gqz2X7FgTG"},"source":["weekday_sin = sessiontime_weekday >> (lambda col: get_cycled_feature_value_sin(col+1, 7)) >> nvt.ops.Rename(name = 'et_dayofweek_sin')\n","weekday_cos= sessiontime_weekday >> (lambda col: get_cycled_feature_value_cos(col+1, 7)) >> nvt.ops.Rename(name = 'et_dayofweek_cos')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BcirHkJgFgTH"},"source":["**Add Product Recency feature**"]},{"cell_type":"markdown","metadata":{"id":"BEUI-kTwFgTH"},"source":["- Let's define a custom op to calculate product recency in days"]},{"cell_type":"code","metadata":{"id":"rMTSXhwFFgTH"},"source":["from nvtabular.ops import Operator\n","\n","class ItemRecency(Operator):\n","    def transform(self, columns, gdf):\n","        for column in columns.names:\n","            col = gdf[column]\n","            item_first_timestamp = gdf['prod_first_event_time_ts']\n","            delta_days = (col - item_first_timestamp) / (60*60*24)\n","            gdf[column + \"_age_days\"] = delta_days * (delta_days >=0)\n","        return gdf\n","            \n","    def output_column_names(self, columns):\n","        return ColumnSelector([column + \"_age_days\" for column in columns.names])\n","\n","    def dependencies(self):\n","        return [\"prod_first_event_time_ts\"]\n","    \n","    \n","recency_features = ['event_time_ts'] >> ItemRecency() \n","recency_features_norm = recency_features >> nvt.ops.LogOp() >> nvt.ops.Normalize() >> nvt.ops.Rename(name='product_recency_days_log_norm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvemsATWFgTI"},"source":["time_features = (\n","    session_time +\n","    sessiontime_weekday +\n","    weekday_sin +\n","    weekday_cos +\n","    recency_features_norm\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"br8Yv6cMFgTI"},"source":["### Normalize Continuous Features"]},{"cell_type":"code","metadata":{"id":"-ygRxgYuFgTI"},"source":["# Smoothing price long-tailed distribution and applying standardization\n","price_log = ['price'] >> nvt.ops.LogOp() >> nvt.ops.Normalize() >> nvt.ops.Rename(name='price_log_norm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EyoOLlqkFgTJ"},"source":["# Relative price to the average price for the category_id\n","def relative_price_to_avg_categ(col, gdf):\n","    epsilon = 1e-5\n","    col = ((gdf['price'] - col) / (col + epsilon)) * (col > 0).astype(int)\n","    return col\n","    \n","avg_category_id_pr = ['category_id'] >> nvt.ops.JoinGroupby(cont_cols =['price'], stats=[\"mean\"]) >> nvt.ops.Rename(name='avg_category_id_price')\n","relative_price_to_avg_category = avg_category_id_pr >> nvt.ops.LambdaOp(relative_price_to_avg_categ, dependency=['price']) >> nvt.ops.Rename(name=\"relative_price_to_avg_categ_id\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgQ675fqFgTJ"},"source":["### Grouping interactions into sessions"]},{"cell_type":"markdown","metadata":{"id":"rZ4dLmgUFgTJ"},"source":["**Aggregate by session id and creates the sequential features**"]},{"cell_type":"code","metadata":{"id":"J_G1YzfqFgTK"},"source":["groupby_feats = ['event_time_ts', 'user_session'] + cat_feats + time_features + price_log + relative_price_to_avg_category"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtSyScspFgTK"},"source":["# Define Groupby Workflow\n","groupby_features = groupby_feats >> nvt.ops.Groupby(\n","    groupby_cols=[\"user_session\"], \n","    sort_cols=[\"event_time_ts\"],\n","    aggs={\n","        'user_id': ['first'],\n","        'product_id': [\"list\", \"count\"],\n","        'category_code': [\"list\"],  \n","        'event_type': [\"list\"], \n","        'brand': [\"list\"], \n","        'category_id': [\"list\"], \n","        'event_time_ts': [\"first\"],\n","        'event_time_dt': [\"first\"],\n","        'et_dayofweek_sin': [\"list\"],\n","        'et_dayofweek_cos': [\"list\"],\n","        'price_log_norm': [\"list\"],\n","        'relative_price_to_avg_categ_id': [\"list\"],\n","        'product_recency_days_log_norm': [\"list\"]\n","        },\n","    name_sep=\"-\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVtitxs7FgTK"},"source":["- Select columns which are list"]},{"cell_type":"code","metadata":{"id":"8jkZsNNvFgTL"},"source":["groupby_features_list = groupby_features['product_id-list',\n","        'category_code-list',  \n","        'event_type-list', \n","        'brand-list', \n","        'category_id-list', \n","        'et_dayofweek_sin-list',\n","        'et_dayofweek_cos-list',\n","        'price_log_norm-list',\n","        'relative_price_to_avg_categ_id-list',\n","        'product_recency_days_log_norm-list']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zz4wa_TFgTL"},"source":["SESSIONS_MAX_LENGTH = 20 \n","MINIMUM_SESSION_LENGTH = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kk9up4feFgTM"},"source":["We truncate the sequence features in length according to sessions_max_length param, which is set as 20 in our example."]},{"cell_type":"code","metadata":{"id":"NYwTLjSyFgTM"},"source":["groupby_features_trim = groupby_features_list >> nvt.ops.ListSlice(0,SESSIONS_MAX_LENGTH) >> nvt.ops.Rename(postfix = '_seq')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrTG8oPOFgTM"},"source":["- Create a `day_index` column in order to partition sessions by day when saving the parquet files."]},{"cell_type":"code","metadata":{"id":"RdeUzUyiFgTN"},"source":["# calculate session day index based on 'timestamp-first' column\n","day_index = ((groupby_features['event_time_dt-first'])  >> \n","    nvt.ops.LambdaOp(lambda col: (col - col.min()).dt.days +1) >> \n","    nvt.ops.Rename(f = lambda col: \"day_index\")\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ZhdHSbkFgTN"},"source":["- Select certain columns to be used in model training"]},{"cell_type":"code","metadata":{"id":"YpMnwY3lFgTO"},"source":["selected_features = groupby_features['user_session', 'product_id-count'] + groupby_features_trim + day_index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nvOhA3FPFgTO"},"source":["- Filter out the session that have less than 2 interactions."]},{"cell_type":"code","metadata":{"id":"4IMUckPnFgTO"},"source":["filtered_sessions = selected_features >> nvt.ops.Filter(f=lambda df: df[\"product_id-count\"] >= MINIMUM_SESSION_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaF2xzSlFgTO"},"source":["# avoid numba warnings\n","from numba import config\n","config.CUDA_LOW_OCCUPANCY_WARNINGS = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vB-GJ2SSFgTP"},"source":["- Initialize the NVTabular dataset object and workflow graph."]},{"cell_type":"markdown","metadata":{"id":"q4ioP3jDFgTP"},"source":["NVTabular's preprocessing and feature engineering workflows are directed graphs of operators. When we initialize a Workflow with our pipeline, workflow organizes the input and output columns."]},{"cell_type":"code","metadata":{"id":"4C61VMBNFgTP"},"source":["dataset = nvt.Dataset(df)\n","\n","workflow = nvt.Workflow(filtered_sessions)\n","workflow.fit(dataset)\n","sessions_gdf = workflow.transform(dataset).to_ddf()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TFSyYeV5FgTQ"},"source":["Above, we created an NVTabular Dataset object using our input dataset. Then, we calculate statistics for this workflow on the input dataset, i.e. on our training set, using the `workflow.fit()` method so that our Workflow can use these stats to transform any given input."]},{"cell_type":"markdown","metadata":{"id":"_r_nHCIUFgTQ"},"source":["Let's print the head of our preprocessed dataset. You can notice that now each example (row) is a session and the sequential features with respect to user interactions were converted to lists with matching length."]},{"cell_type":"code","metadata":{"id":"277HZkLWFgTQ","outputId":"df51cf64-5032-4b2a-95e5-780212988b70"},"source":["sessions_gdf.head(3)"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>product_id-count</th>\n","      <th>product_id-list_seq</th>\n","      <th>category_code-list_seq</th>\n","      <th>event_type-list_seq</th>\n","      <th>brand-list_seq</th>\n","      <th>category_id-list_seq</th>\n","      <th>et_dayofweek_sin-list_seq</th>\n","      <th>et_dayofweek_cos-list_seq</th>\n","      <th>price_log_norm-list_seq</th>\n","      <th>relative_price_to_avg_categ_id-list_seq</th>\n","      <th>product_recency_days_log_norm-list_seq</th>\n","      <th>day_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>779</td>\n","      <td>[19064, 52057, 13290, 11446, 15835, 879, 633, ...</td>\n","      <td>[1, 1, 1, 1, 1, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n","      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n","      <td>[171, 120, 231, 392, 562, 20, 9, 20, 295, 143,...</td>\n","      <td>[3, 3, 3, 3, 3, 17, 17, 17, 17, 17, 17, 17, 17...</td>\n","      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>\n","      <td>[-0.22252177, -0.22252177, -0.22252177, -0.222...</td>\n","      <td>[-0.6063043, -0.5922227, -0.58657265, -0.95319...</td>\n","      <td>[0.03519271796785072, 0.05391070768135458, 0.0...</td>\n","      <td>[-2.2660856, -2.2660856, -2.2657654, -2.266085...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>316</td>\n","      <td>[252, 2801, 5399, 1074, 252, 355, 327, 319, 34...</td>\n","      <td>[1, 17, 17, 15, 1, 1, 17, 31, 17, 17, 17, 17, ...</td>\n","      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n","      <td>[1, 1, 1, 1, 1, 50, 1, 1, 36, 1, 1, 36, 50, 1,...</td>\n","      <td>[234, 36, 36, 30, 234, 52, 36, 48, 36, 36, 36,...</td>\n","      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>\n","      <td>[-0.90096927, -0.90096927, -0.90096927, -0.900...</td>\n","      <td>[0.76379955, 0.40693888, 0.2585879, 0.01305802...</td>\n","      <td>[0.0006990395296891112, -0.04875344158592035, ...</td>\n","      <td>[-0.8581507, -0.9379308, -1.0066843, -0.936325...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>277</td>\n","      <td>[765, 353, 1360, 1965, 2204, 3129, 726, 861, 9...</td>\n","      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n","      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n","      <td>[448, 114, 1, 20, 20, 72, 114, 143, 20, 141, 7...</td>\n","      <td>[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 1...</td>\n","      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>\n","      <td>[-0.90096927, -0.90096927, -0.90096927, -0.900...</td>\n","      <td>[-1.7807854, -0.5645747, -0.04535069, -0.43499...</td>\n","      <td>[-0.832720989925482, -0.19123240368025274, 0.5...</td>\n","      <td>[-0.7992506, -0.78641737, -0.8228414, -0.79577...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_session  product_id-count  \\\n","0             2               779   \n","1             3               316   \n","2             4               277   \n","\n","                                 product_id-list_seq  \\\n","0  [19064, 52057, 13290, 11446, 15835, 879, 633, ...   \n","1  [252, 2801, 5399, 1074, 252, 355, 327, 319, 34...   \n","2  [765, 353, 1360, 1965, 2204, 3129, 726, 861, 9...   \n","\n","                              category_code-list_seq  \\\n","0  [1, 1, 1, 1, 1, 12, 12, 12, 12, 12, 12, 12, 12...   \n","1  [1, 17, 17, 15, 1, 1, 17, 31, 17, 17, 17, 17, ...   \n","2  [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...   \n","\n","                                 event_type-list_seq  \\\n","0  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n","1  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n","2  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n","\n","                                      brand-list_seq  \\\n","0  [171, 120, 231, 392, 562, 20, 9, 20, 295, 143,...   \n","1  [1, 1, 1, 1, 1, 50, 1, 1, 36, 1, 1, 36, 50, 1,...   \n","2  [448, 114, 1, 20, 20, 72, 114, 143, 20, 141, 7...   \n","\n","                                category_id-list_seq  \\\n","0  [3, 3, 3, 3, 3, 17, 17, 17, 17, 17, 17, 17, 17...   \n","1  [234, 36, 36, 30, 234, 52, 36, 48, 36, 36, 36,...   \n","2  [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 1...   \n","\n","                           et_dayofweek_sin-list_seq  \\\n","0  [0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...   \n","1  [0.43388295, 0.43388295, 0.43388295, 0.4338829...   \n","2  [0.43388295, 0.43388295, 0.43388295, 0.4338829...   \n","\n","                           et_dayofweek_cos-list_seq  \\\n","0  [-0.22252177, -0.22252177, -0.22252177, -0.222...   \n","1  [-0.90096927, -0.90096927, -0.90096927, -0.900...   \n","2  [-0.90096927, -0.90096927, -0.90096927, -0.900...   \n","\n","                             price_log_norm-list_seq  \\\n","0  [-0.6063043, -0.5922227, -0.58657265, -0.95319...   \n","1  [0.76379955, 0.40693888, 0.2585879, 0.01305802...   \n","2  [-1.7807854, -0.5645747, -0.04535069, -0.43499...   \n","\n","             relative_price_to_avg_categ_id-list_seq  \\\n","0  [0.03519271796785072, 0.05391070768135458, 0.0...   \n","1  [0.0006990395296891112, -0.04875344158592035, ...   \n","2  [-0.832720989925482, -0.19123240368025274, 0.5...   \n","\n","              product_recency_days_log_norm-list_seq  day_index  \n","0  [-2.2660856, -2.2660856, -2.2657654, -2.266085...          1  \n","1  [-0.8581507, -0.9379308, -1.0066843, -0.936325...          2  \n","2  [-0.7992506, -0.78641737, -0.8228414, -0.79577...          2  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"vnFFkk8XFgTQ","outputId":"ba1aa575-7857-4159-9e70-a33a23eb1399"},"source":["workflow.output_schema.column_names"],"execution_count":null,"outputs":[{"data":{"text/plain":["['user_session',\n"," 'product_id-count',\n"," 'product_id-list_seq',\n"," 'category_code-list_seq',\n"," 'event_type-list_seq',\n"," 'brand-list_seq',\n"," 'category_id-list_seq',\n"," 'et_dayofweek_sin-list_seq',\n"," 'et_dayofweek_cos-list_seq',\n"," 'price_log_norm-list_seq',\n"," 'relative_price_to_avg_categ_id-list_seq',\n"," 'product_recency_days_log_norm-list_seq',\n"," 'day_index']"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"bJcnPhNBFgTR"},"source":["- Save NVTabular workflow to load at the inference step."]},{"cell_type":"code","metadata":{"id":"VCsSnQXMFgTR"},"source":["workflow_path = os.path.join(INPUT_DATA_DIR, 'workflow_etl')\n","workflow.save(workflow_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbHfTea4FgTR"},"source":["## Exporting data"]},{"cell_type":"markdown","metadata":{"id":"6mKC6NmQFgTR"},"source":["We export dataset to parquet partioned by the session `day_index` column."]},{"cell_type":"code","metadata":{"id":"lFzVEYsKFgTS"},"source":["# define partition column\n","PARTITION_COL = 'day_index'\n","\n","# define output_folder to store the partitioned parquet files\n","OUTPUT_FOLDER = os.environ.get(\"OUTPUT_FOLDER\", INPUT_DATA_DIR + \"sessions_by_day\")\n","!mkdir -p $OUTPUT_FOLDER"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJmTyfkzFgTS"},"source":["In this section we are going to create a folder structure as shown below. As we explained above, this is just to structure parquet files so that it would be easier to do incremental training and evaluation."]},{"cell_type":"markdown","metadata":{"id":"Zok2k9DWFgTS"},"source":["```\n","/sessions_by_day/\n","|-- 1\n","|   |-- train.parquet\n","|   |-- valid.parquet\n","|   |-- test.parquet\n","\n","|-- 2\n","|   |-- train.parquet\n","|   |-- valid.parquet\n","|   |-- test.parquet\n","```"]},{"cell_type":"markdown","metadata":{"id":"K-fCUKlrFgTS"},"source":["`gpu_preprocessing` function converts the process df to a Dataset object and write out hive-partitioned data to disk."]},{"cell_type":"code","metadata":{"id":"JV6k0dsMFgTS","outputId":"1cdd4770-8c22-4021-faed-9a2194eae823"},"source":["from transformers4rec.data.preprocessing import save_time_based_splits\n","save_time_based_splits(data=nvt.Dataset(sessions_gdf),\n","                       output_dir= OUTPUT_FOLDER,\n","                       partition_col=PARTITION_COL,\n","                       timestamp_col='user_session', \n","                      )"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Creating time-based splits: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.63it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"txYDB2f5FgTT","outputId":"ae9db4f2-747d-484b-c247-4ad072f57585"},"source":["# check out the OUTPUT_FOLDER\n","!ls $OUTPUT_FOLDER"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1  2  3  4  5  6  7\n"]}]},{"cell_type":"code","metadata":{"id":"f2d1e30c"},"source":["# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85BpF7YjGkUa"},"source":["## Session-based recommendation with Transformers4Rec"]},{"cell_type":"markdown","metadata":{"id":"b7ec3b1b"},"source":["In the previous section we went through our ETL pipeline with NVTabular library, and created sequential features to be used for training a session-based recommendation model. In this section we will learn:\n","\n","- Accelerating data loading of parquet files multiple features on PyTorch using NVTabular library\n","- Training and evaluating an RNN-based (GRU) session-based recommendation model \n","- Training and evaluating a Transformer architecture (XLNET) for session-based recommendation model\n","- Integrate side information (additional features) into transformer architectures in order to improve recommendation accuracy"]},{"cell_type":"markdown","metadata":{"id":"a9193ebc"},"source":["Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals, where most users either browse anonymously or may have very distinct interests for different sessions. Session-Based Recommender Systems (SBRS) have\n","been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term and contextual user preferences towards items.\n","\n","\n","Many methods have been proposed to leverage the sequence of interactions that occur during a session, including session-based k-NN algorithms like V-SkNN [1] and neural approaches like GRU4Rec [2]. In addition,  state of the art NLP approaches have inspired RecSys practitioners and researchers to leverage the self-attention mechanism and the Transformer-based architectures for sequential [3] and session-based recommendation [4]."]},{"cell_type":"markdown","metadata":{"id":"0147de64"},"source":["In this tutorial, we introduce the [Transformers4Rec](https://github.com/NVIDIA-Merlin/Transformers4Rec) open-source library for sequential and session-based recommendation task.\n","\n","With Transformers4Rec we import from the HF Transformers NLP library the transformer architectures and their configuration classes. \n","\n","In addition, Transformers4Rec provides additional blocks necessary for recommendation, e.g., input features normalization and aggregation, and heads for recommendation and sequence classification/prediction. We also extend their Trainer class to allow for the evaluation with RecSys metrics.\n","\n","Here are some of the most important modules:\n","\n","- [TabularSequenceFeatures](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.TabularSequenceFeatures) is the input block for sequential features. Based on a `Schema` and options set by the user, it dynamically creates all the necessary layers (e.g. embedding layers) to encode, normalize, and aggregate categorical and continuous features. It also allows to set the `masking` training approach (e.g. Causal LM, Masked LM).\n","- [TransformerBlock](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.TransformerBlock) class is the bridge that adapts HuggingFace Transformers for session-based and sequential-based recommendation models.\n","- [SequentialBlock](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.SequentialBlock) allows the definition of a model body as as sequence of layer (similarly to [torch.nn.sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)). It is designed to define our model as a sequence of layers and automatically setting the input shape of a layer from the output shape of the previous one.\n","- [Head](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.Head) class defines the head of a model.\n","- [NextItemPredictionTask](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.NextItemPredictionTask) is the class to support next item prediction task, combining a model body with a head.\n","- [Trainer](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.Trainer) extends the `Trainer` class from HF transformers and manages the model training and evaluation.\n","\n","You can check the [full documentation](https://nvidia-merlin.github.io/Transformers4Rec/main/index.html) of Transformers4Rec if needed."]},{"cell_type":"markdown","metadata":{"id":"c5a9886d"},"source":["In the following Figure, we present a reference architecture that we are going to build with Transformers4Rec PyTorch API in this section. We are going to start using only `product-id` as input feature, but as you can notice in the figure, we can add additional categorical and numerical features later to improve recommendation accuracy."]},{"cell_type":"markdown","metadata":{"id":"16e6d8c7"},"source":["<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/360a24b7-5d3f-41bc-bafc-e6f7a50b8a90/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T112731Z&X-Amz-Expires=86400&X-Amz-Signature=2127778c75a954ad2b20a01cbb06aa9774a935b18af8875d784d0250dc999f93&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'>\n","<p><center>Figure 1. Transformers4Rec meta-architecture.</center></p>"]},{"cell_type":"markdown","metadata":{"id":"d08dfc19"},"source":["## Training an RNN-based Session-based Recommendation Model"]},{"cell_type":"markdown","metadata":{"id":"6fddb668"},"source":["In this section, we use a type of Recurrent Neural Networks (RNN) - the Gated Recurrent Unit (GRU)[5] - to do next-item prediction using a sequence of events (e.g., click, view, or purchase) per user in a given session. There is obviously some sequential patterns that we want to capture to provide more relevant recommendations. In our case, the input of the GRU layer is a representation of the user interaction, the internal GRU hidden state encodes a representation of the session based on past interactions and the outputs are the next-item predictions. Basically, for each item in a given session, we generate the output as the predicted preference of the items, i.e. the likelihood of being the next."]},{"cell_type":"markdown","metadata":{"id":"49750806"},"source":["Figure 2 illustrates the logic of predicting next item in a given session. First, the product ids are embedded and fed as a sequence to a GRU layer, which outputs a representation than can be used to predict the next item. For the sake of simplicity, we treat the recommendation as a multi-class classification problem and use cross-entropy loss. In our first example, we use a GRU block instead of `Transformer block` (shown in the Figure 1)."]},{"cell_type":"markdown","metadata":{"id":"bfda5ba7"},"source":["<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72275c7e-3e6c-4399-adb0-406c1bd36863/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T112939Z&X-Amz-Expires=86400&X-Amz-Signature=19668197b543d096cd1b1e9ed1579dfca46c9329d70edd4b4b937902209ef0e4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 2. Next item prediction with RNN.</center></p>"]},{"cell_type":"markdown","metadata":{"id":"a8e7be36"},"source":["### Instantiates Schema object from a `schema` file."]},{"cell_type":"code","metadata":{"id":"a64c3082"},"source":["from merlin_standard_lib import Schema\n","# Define schema object to pass it to the TabularSequenceFeatures class\n","SCHEMA_PATH = 'schema_tutorial.pb'\n","schema = Schema().from_proto_text(SCHEMA_PATH)\n","schema = schema.select_by_name(['product_id-list_seq'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9a4493de"},"source":["Transformers4Rec library relies on `Schema` object in `TabularSequenceFeatures` that takes the input features as input and create all the necessary layers to process and aggregate them. As you can see below, the `schema.pb` is a protobuf text file contains features metadata, including statistics about features such as cardinality, min and max values and also tags based on their characteristics and dtypes (e.g., `categorical`, `continuous`, `list`, `item_id`). We can tag our target column and even add the prediction task such as `binary`, `regression` or `multiclass` as tags for the target column in the `schema.pb` file. The `Schema` provides a standard representation for metadata that is useful when training machine learning or deep learning models.\n","\n","The metadata information loaded from `Schema` and their tags are used to automatically set the parameters of Transformers4rec models. Certain Transformers4rec modules have a `from_schema()` method to instantiate their parameters and layers from protobuf text file respectively. \n","\n","Although in this tutorial we are defining the `Schema` manually, the next NVTabular release is going to generate the schema with appropriate types and tags automatically from the preprocessing workflow, allowing the user to set additional feaure tags if needed."]},{"cell_type":"markdown","metadata":{"id":"81225a6d"},"source":["Let's inspect the first lines of `schema.pb`"]},{"cell_type":"code","metadata":{"id":"33ab76ed","outputId":"f39ee485-acf9-4a6c-e056-c86f06914ef0"},"source":["!head -30 $SCHEMA_PATH"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["feature {\n","  name: \"user_session\"\n","  type: INT\n","  int_domain {\n","    name: \"user_session\"\n","    min: 1\n","    max: 1877365\n","    is_categorical: false\n","  }\n","  annotation {\n","    tag: \"groupby_col\"\n","  }\n","}\n","feature {\n","  name: \"category_id-list_seq\"\n","  value_count {\n","    min: 2\n","    max: 20\n","  }\n","  type: INT\n","  int_domain {\n","    name: \"category_id-list_seq\"\n","    min: 1\n","    max: 566\n","    is_categorical: true\n","  }\n","  annotation {\n","    tag: \"list\"\n","    tag: \"categorical\"\n","    tag: \"item\"\n"]}]},{"cell_type":"markdown","metadata":{"id":"68b323f3"},"source":["### Defining the input block: `TabularSequenceFeatures`"]},{"cell_type":"markdown","metadata":{"id":"14f277f5"},"source":["We define our input block using `TabularSequenceFeatures` class. The `from_schema()` method directly parses the schema and accepts sequential and non-sequential features. Based on the `Schema` and some user-defined options, the categorical features are represented by embeddings and numerical features can be represented as continuous scalars or by a technique named Soft One-Hot embeddings (more info in our [paper's online appendix](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md)). \n","\n","The embedding features can optionally be normalized (`layer_norm=True`). Data augmentation methods like \"Stochastic Swap Noise\" (`pre=\"stochastic-swap-noise\"`) and `aggregation` opptions (like `concat` and `elementwise-sum`) are also available. The continuous features can also be combined and projected by MLP layers by setting `continuous_projection=[dim]`. Finally, the `max_sequence_length` argument defines the maximum sequence length of our sequential input.\n","\n","Another important argument is the `masking` method, which sets the training approach. See Section 3.2.2 for details on this."]},{"cell_type":"code","metadata":{"id":"1d10f641"},"source":["sequence_length = 20\n","inputs = tr.TabularSequenceFeatures.from_schema(\n","        schema,\n","        max_sequence_length= sequence_length,\n","        masking = 'causal',\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dbd88fe6"},"source":["### Connecting the blocks with `SequentialBlock`\n","\n","The `SequentialBlock` creates a pipeline by connecting the building blocks in a serial way, so that the input shape of one block is inferred from the output of the previus block. In this example, the `TabularSequenceFeatures` object is followed by an MLP projection layer, which feeds data to a GRU block."]},{"cell_type":"code","metadata":{"id":"31aafb08"},"source":["d_model = 128\n","body = tr.SequentialBlock(\n","        inputs,\n","        tr.MLPBlock([d_model]),\n","        tr.Block(torch.nn.GRU(input_size=d_model, hidden_size=d_model, num_layers=1), [None, 20, d_model])\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8ca3850"},"source":["### Item Prediction head and tying embeddings"]},{"cell_type":"markdown","metadata":{"id":"8bdf2e4a"},"source":["In our experiments published in our [ACM RecSys'21 paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf) [8], we used the next item prediction head, which projects the output of the RNN/Transformer block to the items space, followed by a softmax layer to produce the relevance scores over all items. For the output layer we provide the `Tying Embeddings` technique (`weight_tying`). It was proposed originally by the NLP community to tie the weights of the input (item id) embedding matrix with the output projection layer, showed to be a very effective technique in extensive experimentation for competitions and empirical analysis (for more details see our [paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf) and its online [appendix](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md)). In practice, such technique helps the network to learn faster item embeddings even for rare items, reduces the number of parameters for large item cardinalities and enables Approximate Nearest Neighbours (ANN) search on inference, as the predictions can be obtained by a dot product between the model output and the item embeddings."]},{"cell_type":"markdown","metadata":{"id":"c7116b15"},"source":["Next, we link the transformer-body to the inputs and the prediction tasks to get the final PyTorch `Model` class."]},{"cell_type":"code","metadata":{"id":"89060b5d","outputId":"adcaaec1-bf9b-412d-fa98-e2a3c6d4aeb0"},"source":["head = tr.Head(\n","    body,\n","    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n","                              metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n","                                       RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",")\n","model = tr.Model(head)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '128' to be equal to the item-id embedding dimension '64'\n"]}]},{"cell_type":"markdown","metadata":{"id":"b7a1426f"},"source":["### Define a Dataloader function from schema"]},{"cell_type":"markdown","metadata":{"id":"29075a9e"},"source":["We use optimized NVTabular PyTorch Dataloader which has the following benefits:\n","- removing bottlenecks from dataloading by processing large chunks of data at a time instead iterating by row\n","- processing datasets that don’t fit within the GPU or CPU memory by streaming from the disk\n","- reading data directly into the GPU memory and removing CPU-GPU communication\n","- preparing batch asynchronously into the GPU to avoid CPU-GPU communication\n","- supporting commonly used formats such as parquet\n","- having native support to sparse sequential features"]},{"cell_type":"code","metadata":{"id":"a1baaf30"},"source":["# import NVTabular dependencies\n","from transformers4rec.torch.utils.data_utils import NVTabularDataLoader\n","\n","x_cat_names, x_cont_names = ['product_id-list_seq'], []\n","\n","# dictionary representing max sequence length for column\n","sparse_features_max = {\n","    fname: sequence_length\n","    for fname in x_cat_names + x_cont_names\n","}\n","\n","# Define a `get_dataloader` function to call in the training loop\n","def get_dataloader(path, batch_size=32):\n","\n","    return NVTabularDataLoader.from_schema(\n","        schema,\n","        path, \n","        batch_size,\n","        max_sequence_length=sequence_length,\n","        sparse_names=x_cat_names + x_cont_names,\n","        sparse_max=sparse_features_max,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ff98ee9"},"source":["### Daily Fine-Tuning: Training over a time window"]},{"cell_type":"markdown","metadata":{"id":"825efe4a"},"source":["Now that the model is defined, we are going to launch training. For that, Transfromers4rec extends the HF Transformers `Trainer` class to adapt the evaluation loop for session-based recommendation task and the calculation of ranking metrics. \n","The original HF `Trainer.train()` method is not overloaded, meaning that we leverage the efficient training implementation from HF transformers library, which manages for example half-precision (FP16) training."]},{"cell_type":"markdown","metadata":{"id":"3f217071"},"source":["### Set training arguments"]},{"cell_type":"code","metadata":{"id":"a112d8ed"},"source":["from transformers4rec.config.trainer import T4RecTrainingArguments\n","from transformers4rec.torch import Trainer\n","\n","#Set arguments for training \n","train_args = T4RecTrainingArguments(local_rank = -1, \n","                                    dataloader_drop_last = False,\n","                                    report_to = [],   #set empy list to avoig logging metrics to Weights&Biases\n","                                    gradient_accumulation_steps = 1,\n","                                    per_device_train_batch_size = 256, \n","                                    per_device_eval_batch_size = 32,\n","                                    output_dir = \"./tmp\", \n","                                    max_sequence_length=sequence_length,\n","                                    learning_rate=0.00071,\n","                                    num_train_epochs=3,\n","                                    logging_steps=200,\n","                                   )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85047d3a"},"source":["### Instantiate the Trainer"]},{"cell_type":"code","metadata":{"id":"5aca4e84"},"source":["# Instantiate the T4Rec Trainer, which manages training and evaluation\n","trainer = Trainer(\n","    model=model,\n","    args=train_args,\n","    schema=schema,\n","    compute_metrics=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fcf86a74"},"source":["Define the output folder of the processed parquet files"]},{"cell_type":"code","metadata":{"id":"fc64a1f4"},"source":["OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/sessions_by_day\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f5293026"},"source":["### Model finetuning and incremental evaluation\n","Training models incrementally, e.g. fine-tuning pre-trained models with new data over time is a common practice in industry to scale to the large streaming data been generated every data. Furthermore, it is common to evaluate recommendation models on data that came after the one used to train the models, for a more realistic evaluation.\n","\n","Here, we use a loop that to conduct a time-based finetuning, by iteratively training and evaluating using a sliding time window as follows: At each iteration, we use training data of a specific time index <i>t</i> to train the model then we evaluate on the validation data of next index <i>t + 1</i>. We set the start time to 1 and end time to 4."]},{"cell_type":"code","metadata":{"id":"3e48f16f","outputId":"f0763043-ea27-423e-b647-2d1c5853562d"},"source":["%%time\n","start_time_window_index = 1\n","final_time_window_index = 4\n","for time_index in range(start_time_window_index, final_time_window_index):\n","    # Set data \n","    time_index_train = time_index\n","    time_index_eval = time_index + 1\n","    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n","    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n","    \n","    # Initialize dataloaders\n","    trainer.train_dataloader = get_dataloader(train_paths, train_args.per_device_train_batch_size)\n","    trainer.eval_dataloader = get_dataloader(eval_paths, train_args.per_device_eval_batch_size)\n","    \n","    # Train on day related to time_index \n","    print('*'*20)\n","    print(\"Launch training for day %s are:\" %time_index)\n","    print('*'*20 + '\\n')\n","    trainer.reset_lr_scheduler()\n","    trainer.train()\n","    trainer.state.global_step +=1\n","    \n","    # Evaluate on the following day\n","    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n","    print('*'*20)\n","    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n","    print('\\n' + '*'*20 + '\\n')\n","    for key in sorted(train_metrics.keys()):\n","        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n","    trainer.wipe_memory()"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 112128\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1314\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Launch training for day 1 are:\n","********************\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1314/1314 00:51, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>9.975300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>9.218200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.972500</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.898600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.804800</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>8.801400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [415/415 01:55]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 2 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.881314277648926\n"," eval/next-item/ndcg_at_10 = 0.036112383008003235\n"," eval/next-item/ndcg_at_20 = 0.04597809165716171\n"," eval/next-item/recall_at_10 = 0.06884850561618805\n"," eval/next-item/recall_at_20 = 0.10798582434654236\n"," eval_runtime = 6.3241\n"," eval_samples_per_second = 2099.891\n"," eval_steps_per_second = 65.622\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 106240\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1245\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Launch training for day 2 are:\n","********************\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1245/1245 00:48, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.992400</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.859700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.636400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.524400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.396200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>8.369100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 3 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.505434036254883\n"," eval/next-item/ndcg_at_10 = 0.05683322995901108\n"," eval/next-item/ndcg_at_20 = 0.0703873336315155\n"," eval/next-item/recall_at_10 = 0.10895449668169022\n"," eval/next-item/recall_at_20 = 0.16269777715206146\n"," eval_runtime = 5.949\n"," eval_samples_per_second = 2065.548\n"," eval_steps_per_second = 64.548\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 97792\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1146\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Launch training for day 3 are:\n","********************\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1146/1146 00:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.581200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.463000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.274700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.186600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.055800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 4 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.123461723327637\n"," eval/next-item/ndcg_at_10 = 0.07151895016431808\n"," eval/next-item/ndcg_at_20 = 0.08768121898174286\n"," eval/next-item/recall_at_10 = 0.1361762434244156\n"," eval/next-item/recall_at_20 = 0.20020613074302673\n"," eval_runtime = 7.5055\n"," eval_samples_per_second = 2072.086\n"," eval_steps_per_second = 64.753\n","CPU times: user 2min 18s, sys: 30.2 s, total: 2min 49s\n","Wall time: 2min 48s\n"]}]},{"cell_type":"markdown","metadata":{"id":"ee3a0dab"},"source":["Let's write out model evaluation accuracy results to a text file to compare model at the end"]},{"cell_type":"code","metadata":{"id":"bc41e5c5"},"source":["with open(\"results.txt\", 'w') as f: \n","    f.write('GRU accuracy results:')\n","    f.write('\\n')\n","    for key, value in  model.compute_metrics().items(): \n","        f.write('%s:%s\\n' % (key, value.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"2c63913c"},"source":["### Metrics"]},{"cell_type":"markdown","metadata":{"id":"d062ec1a"},"source":["We have extended the HuggingFace transformers Trainer class (PyTorch only) to support evaluation of RecSys metrics. The following information\n","retrieval metrics are used to compute the Top-20 accuracy of recommendation lists containing all items: <br> \n","- **Normalized Discounted Cumulative Gain (NDCG@20):** NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n","\n","- **Hit Rate (HR@20)**: Also known as `Recall@n` when there is only one relevant item in the recommendation list. HR just verifies whether the relevant item is among the top-n items."]},{"cell_type":"markdown","metadata":{"id":"8dab45a7"},"source":["### Restart the kernel to free our GPU memory"]},{"cell_type":"code","metadata":{"id":"e2138cba","outputId":"7d63ad79-8255-4623-9eb2-f260c45437c2"},"source":["import IPython\n","app = IPython.Application.instance()\n","app.kernel.do_shutdown(True)"],"execution_count":null,"outputs":[{"data":{"text/plain":["{'status': 'ok', 'restart': True}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"6b21fd3b"},"source":["At this stage if the kernel does not restart automatically, we expect you to manually restart the kernel to free GPU memory so that you can move on to the next session-based model training with a SOTA deep learning Transformer-based model, [XLNet](https://arxiv.org/pdf/1906.08237.pdf)."]},{"cell_type":"markdown","metadata":{"id":"08de0ba3"},"source":["## Training a Transformer-based Session-based Recommendation Model"]},{"cell_type":"markdown","metadata":{"id":"26cdec77"},"source":["### What's Transformers?"]},{"cell_type":"markdown","metadata":{"id":"cbac868e"},"source":["The Transformer is a competitive alternative to the models using Recurrent Neural Networks (RNNs) for a range of sequence modeling tasks. The Transformer architecture [6] was introduced as a novel architecture in NLP domain that aims to solve sequence-to-sequence tasks relying entirely on self-attention mechanism to compute representations of its input and output. Hence, the Transformer overperforms RNNs with their three mechanisms: \n","\n","- Non-sequential: Transformers network is parallelized where as RNN computations are inherently sequential. That resulted in significant speed-up in the training time.\n","- Self-attention mechanisms: Transformers rely entirely on self-attention mechanisms that directly model relationships between all item-ids in a sequence.  \n","- Positional encodings: A representation of the location or “position” of items in a sequence which is used to give the order context to the model architecture."]},{"cell_type":"markdown","metadata":{"id":"06235f16"},"source":["<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5a89728b-f767-43f9-a04b-249ac5148c2a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113310Z&X-Amz-Expires=86400&X-Amz-Signature=ae0e7ad7c947f6e916c5e809d2779079c81ebd16d9dc2eca17604c5fcca04d02&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 3. Transformer vs vanilla RNN.</center></p>"]},{"cell_type":"markdown","metadata":{"id":"3988fdc6"},"source":["Figure 4 illustrates the differences of Transformer (self-attention based) and a vanilla RNN architecture. As we see, RNN cannot be parallelized because it uses sequential processing over time (notice the sequential path from previous cells to the current one). On the other hand, the Transformer is a more powerful architecture because the self-attention mechanism is capable of representing dependencies within the sequence of tokens, favors parallel processing and handle longer sequences.\n","\n","As illustrated in the [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) paper, the original transformer model is made up of an encoder and decoder where each is a stack we can call a transformer block. In Transformers4Rec architectures we use the encoder block of transformer architecture."]},{"cell_type":"markdown","metadata":{"id":"6727e272"},"source":["<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f0b9e980-ad4e-452b-8936-68fbac8fccd7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113407Z&X-Amz-Expires=86400&X-Amz-Signature=263317ed25284a919e276c6d552bc032ab9100106730663b6d2d8dc5fcc77c95&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 4. Encoder block of the Transformer Architecture.</center></p>"]},{"cell_type":"markdown","metadata":{"id":"184fca87"},"source":["### XLNet"]},{"cell_type":"markdown","metadata":{"id":"da6da733"},"source":["Here, we use XLNet [10] as the Transformer block in our architecture. It was originally proposed to be trained with the *Permutation Language Modeling (PLM)*  technique, that combines the advantages of autoregressive (Causal LM) and autoencoding (Masked LM). Although, we found out in our [paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf) [8] that the *Masked Language Model (MLM)* approach worked better than PLM for the small sequences in session-based recommendation, thus we use MLM for this example. MLM was introduced in *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding* paper [8]. \n","\n","Figure 5 illustrates the causal language modeling (LM) and masked LM. In this example, we use in causal LM for RNN masked LM for XLNet. Causal LM is the task of predicting the token following a sequence of tokens, where the model only attends to the left context, i.e. models the probability of a token given the previous tokens in a sentence [7]. On the other hand, the MLM randomly masks some of the tokens from the input sequence, and the objective is to predict the original vocabulary id of the masked word based only on its bi-directional context. When we train with MLM, the Transformer layer is also allowed to use positions on the right (future information) during training. During inference, all past items are visible for the Transformer layer, which tries to predict the next item. It performs a type of data augmentation, by masking different positions of the sequences in each training epoch."]},{"cell_type":"markdown","metadata":{"id":"26638655"},"source":["<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/35f985e3-b874-4aba-9420-7ee6fa0b8e7e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113457Z&X-Amz-Expires=86400&X-Amz-Signature=4e1a1639f829054317666ff74fc10dbff4411c150405bec184f5b3cbd2127977&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 5. Causal and Masked Language Model masking methods.</center></p>"]},{"cell_type":"markdown","metadata":{"id":"a512b632"},"source":["### Train XLNET for Next Item Prediction"]},{"cell_type":"markdown","metadata":{"id":"b7b45ea4"},"source":["Now we are going to define an architecture for next-item prediction using the XLNET architecture."]},{"cell_type":"code","metadata":{"id":"4a12d605"},"source":["import os\n","import glob\n","\n","import torch \n","import transformers4rec.torch as tr\n","\n","from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69c6542b"},"source":["As we did above, we start with defining our schema object and selecting only the `product_id` feature for training."]},{"cell_type":"code","metadata":{"id":"e04d30d5"},"source":["from merlin_standard_lib import Schema\n","\n","# Define schema object to pass it to the TabularSequenceFeatures class\n","SCHEMA_PATH = 'schema_tutorial.pb'\n","schema = Schema().from_proto_text(SCHEMA_PATH)\n","\n","# Create a sub-schema only with the selected features\n","schema = schema.select_by_name(['product_id-list_seq'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"04b7b077"},"source":["### Define Input block\n","Here we instantiate `TabularSequenceFeatures` from the feature schema and set `masking=\"mlm\"` to use MLM as training method."]},{"cell_type":"code","metadata":{"id":"db863122"},"source":["#Input \n","sequence_length, d_model = 20, 192\n","# Define input module to process tabular input-features and to prepare masked inputs\n","inputs= tr.TabularSequenceFeatures.from_schema(\n","    schema,\n","    max_sequence_length=sequence_length,\n","    d_output=d_model,\n","    masking=\"mlm\",\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8a611eed"},"source":["We have inherited the original `XLNetConfig` class of HF transformers with some default arguments in the `build()` method. Here we use it to instantiate an XLNET model according to the arguments (`d_model`, `n_head`, etc.), defining the model architecture.\n","\n","The `TransformerBlock` class supports HF Transformers for session-based and sequential-based recommendation models. `NextItemPredictionTask` is the class to support next item prediction task, encapsulating the corresponding heads and loss."]},{"cell_type":"code","metadata":{"id":"d589d961","outputId":"e676e74b-4659-413e-8253-d03a3e588435"},"source":["# Define XLNetConfig class and set default parameters for HF XLNet config  \n","transformer_config = tr.XLNetConfig.build(\n","    d_model=d_model, n_head=4, n_layer=2, total_seq_length=sequence_length\n",")\n","# Define the model block including: inputs, masking, projection and transformer block.\n","body = tr.SequentialBlock(\n","    inputs, tr.MLPBlock([192]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",")\n","\n","# Define the head for to next item prediction task \n","head = tr.Head(\n","    body,\n","    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n","                              metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n","                                       RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",")\n","\n","# Get the end-to-end Model class \n","model = tr.Model(head)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '64'\n"]}]},{"cell_type":"markdown","metadata":{"id":"f55e1bd0"},"source":["**Set training arguments**"]},{"cell_type":"markdown","metadata":{"id":"1cae8fe6"},"source":["Among the training arguments you can set the `data_loader_engine` to automatically instantiate the dataloader based on the schema, rather than instantiating the data loader manually like we did for the RNN example. The default value is `\"nvtabular\"` for optimized GPU-based data-loading. Optionally the PyarrowDataLoader (`\"pyarrow\"`) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded into CPU memory."]},{"cell_type":"code","metadata":{"id":"848baadc","outputId":"4b5b29b8-2358-47f5-df68-e1bb98ca090d"},"source":["from transformers4rec.config.trainer import T4RecTrainingArguments\n","from transformers4rec.torch import Trainer\n","\n","#Set arguments for training \n","training_args = T4RecTrainingArguments(\n","            output_dir=\"./tmp\",\n","            max_sequence_length=20,\n","            data_loader_engine='nvtabular',\n","            num_train_epochs=3, \n","            dataloader_drop_last=False,\n","            per_device_train_batch_size = 256,\n","            per_device_eval_batch_size = 32,\n","            gradient_accumulation_steps = 1,\n","            learning_rate=0.000666,\n","            report_to = [],\n","            logging_steps=200,\n","        )"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n"]}]},{"cell_type":"markdown","metadata":{"id":"fc4bd782"},"source":["**Instantiate the trainer**"]},{"cell_type":"code","metadata":{"id":"3192fa33"},"source":["# Instantiate the T4Rec Trainer, which manages training and evaluation\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    schema=schema,\n","    compute_metrics=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8b383d2"},"source":["Define the output folder of the processed parquet files"]},{"cell_type":"code","metadata":{"id":"c3b6ae2e"},"source":["OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/sessions_by_day\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99663319"},"source":["Now, we do time-based fine-tuning the model by iteratively training and evaluating using a sliding time window, like we did for the RNN example."]},{"cell_type":"code","metadata":{"id":"813c00c4","outputId":"65b29789-087f-43cf-ddd2-19a3069e12a5"},"source":["%%time\n","start_time_window_index = 1\n","final_time_window_index = 4\n","for time_index in range(start_time_window_index, final_time_window_index):\n","    # Set data \n","    time_index_train = time_index\n","    time_index_eval = time_index + 1\n","    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n","    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n","    # Train on day related to time_index \n","    print('*'*20)\n","    print(\"Launch training for day %s are:\" %time_index)\n","    print('*'*20 + '\\n')\n","    trainer.train_dataset_or_path = train_paths\n","    trainer.reset_lr_scheduler()\n","    trainer.train()\n","    trainer.state.global_step +=1\n","    # Evaluate on the following day\n","    trainer.eval_dataset_or_path = eval_paths\n","    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n","    print('*'*20)\n","    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n","    print('\\n' + '*'*20 + '\\n')\n","    for key in sorted(train_metrics.keys()):\n","        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n","    trainer.wipe_memory()"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 112128\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1314\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Launch training for day 1 are:\n","********************\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1314/1314 00:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>9.927000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>9.046400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.779300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.635800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.539400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>8.507000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [415/415 01:48]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 2 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.753535270690918\n"," eval/next-item/ndcg_at_10 = 0.049175068736076355\n"," eval/next-item/ndcg_at_20 = 0.06000332161784172\n"," eval/next-item/recall_at_10 = 0.09177286922931671\n"," eval/next-item/recall_at_20 = 0.1346806436777115\n"," eval_runtime = 7.0703\n"," eval_samples_per_second = 1878.271\n"," eval_steps_per_second = 58.696\n","********************\n","Launch training for day 2 are:\n","********************\n","\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 106240\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1245\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1245/1245 00:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.635100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.523100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.375600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.322400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.232100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>8.209900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 3 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.421579360961914\n"," eval/next-item/ndcg_at_10 = 0.061416078358888626\n"," eval/next-item/ndcg_at_20 = 0.07491344213485718\n"," eval/next-item/recall_at_10 = 0.11719132959842682\n"," eval/next-item/recall_at_20 = 0.17060838639736176\n"," eval_runtime = 7.0074\n"," eval_samples_per_second = 1753.564\n"," eval_steps_per_second = 54.799\n","********************\n","Launch training for day 3 are:\n","********************\n","\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 97792\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1146\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1146/1146 00:40, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.312100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.226900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.095400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.065600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>7.965600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 4 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.107558250427246\n"," eval/next-item/ndcg_at_10 = 0.07384572923183441\n"," eval/next-item/ndcg_at_20 = 0.08944202959537506\n"," eval/next-item/recall_at_10 = 0.13939706981182098\n"," eval/next-item/recall_at_20 = 0.20175212621688843\n"," eval_runtime = 8.9372\n"," eval_samples_per_second = 1740.144\n"," eval_steps_per_second = 54.38\n","CPU times: user 6min 57s, sys: 14.3 s, total: 7min 11s\n","Wall time: 2min 35s\n"]}]},{"cell_type":"markdown","metadata":{"id":"1cda4321"},"source":["Add eval accuracy metric results to the existing resuls.txt file."]},{"cell_type":"code","metadata":{"id":"cc3203b5"},"source":["with open(\"results.txt\", 'a') as f:\n","    f.write('\\n')\n","    f.write('XLNet-MLM accuracy results:')\n","    f.write('\\n')\n","    for key, value in  model.compute_metrics().items(): \n","        f.write('%s:%s\\n' % (key, value.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fbf1aff"},"source":["**Restart the kernel to free our GPU memory**"]},{"cell_type":"code","metadata":{"id":"b3e2ceae","outputId":"98a348c2-0e95-4d04-9130-8f2bdd84fd2d"},"source":["import IPython\n","app = IPython.Application.instance()\n","app.kernel.do_shutdown(True)"],"execution_count":null,"outputs":[{"data":{"text/plain":["{'status': 'ok', 'restart': True}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"54e6c70f"},"source":["At this stage if the kernel does not restart automatically, we expect you to manually restart the kernel to free GPU memory so that you can move on to the next session-based model training with XLNet using side information."]},{"cell_type":"markdown","metadata":{"id":"3ee17c91"},"source":["### Train XLNET with Side Information for Next Item Prediction"]},{"cell_type":"markdown","metadata":{"id":"4f82f8a9"},"source":["It is a common practice in RecSys to leverage additional tabular features of item (product) metadata and user context, providing the model more\n","information for meaningful predictions. With that motivation, in this section, we will use additional features to train our XLNET architecture. We already checked our `schema.pb`, saw that it includes features and their tags. Now it is time to use these additional features that we created earlier."]},{"cell_type":"code","metadata":{"id":"3aefd29c"},"source":["import os\n","import glob\n","import nvtabular as nvt\n","\n","import torch \n","import transformers4rec.torch as tr\n","\n","from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1389b745"},"source":["# Define categorical and continuous columns to fed to training model\n","x_cat_names = ['product_id-list_seq', 'category_id-list_seq', 'brand-list_seq']\n","x_cont_names = ['product_recency_days_log_norm-list_seq', 'et_dayofweek_sin-list_seq', 'et_dayofweek_cos-list_seq', \n","                'price_log_norm-list_seq', 'relative_price_to_avg_categ_id-list_seq']\n","\n","from merlin_standard_lib import Schema\n","\n","# Define schema object to pass it to the TabularSequenceFeatures class\n","SCHEMA_PATH ='schema_tutorial.pb'\n","schema = Schema().from_proto_text(SCHEMA_PATH)\n","schema = schema.select_by_name(x_cat_names + x_cont_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9c1bcff"},"source":["Here we set `aggregation=\"concat\"`, so that all categorical and continuous features are concatenated to form an interaction representation."]},{"cell_type":"code","metadata":{"id":"1929fc23","outputId":"7ff55bf1-cbb6-4758-ccc7-11dfc4f41886"},"source":["# Define input block\n","sequence_length, d_model = 20, 192\n","# Define input module to process tabular input-features and to prepare masked inputs\n","inputs= tr.TabularSequenceFeatures.from_schema(\n","    schema,\n","    max_sequence_length=sequence_length,\n","    aggregation=\"concat\",\n","    d_output=d_model,\n","    masking=\"mlm\",\n",")\n","\n","# Define XLNetConfig class and set default parameters for HF XLNet config  \n","transformer_config = tr.XLNetConfig.build(\n","    d_model=d_model, n_head=4, n_layer=2, total_seq_length=sequence_length\n",")\n","# Define the model block including: inputs, masking, projection and transformer block.\n","body = tr.SequentialBlock(\n","    inputs, tr.MLPBlock([192]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",")\n","\n","# Define the head related to next item prediction task \n","head = tr.Head(\n","    body,\n","    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n","                                     metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n","                                              RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",")\n","\n","# Get the end-to-end Model class \n","model = tr.Model(head)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '64'\n"]}]},{"cell_type":"markdown","metadata":{"id":"b72e5aef"},"source":["### Training and Evaluation"]},{"cell_type":"code","metadata":{"id":"103b3a99"},"source":["from transformers4rec.config.trainer import T4RecTrainingArguments\n","from transformers4rec.torch import Trainer\n","\n","#Set arguments for training \n","training_args = T4RecTrainingArguments(\n","            output_dir=\"./tmp\",\n","            max_sequence_length=20,\n","            data_loader_engine='nvtabular',\n","            num_train_epochs=3, \n","            dataloader_drop_last=False,\n","            per_device_train_batch_size = 256,\n","            per_device_eval_batch_size = 32,\n","            gradient_accumulation_steps = 1,\n","            learning_rate=0.000666,\n","            report_to = [],\n","            logging_steps=200,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"35398982"},"source":["# Instantiate the T4Rec Trainer, which manages training and evaluation\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    schema=schema,\n","    compute_metrics=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d72bd497"},"source":["Define the output folder of the processed parquet files"]},{"cell_type":"code","metadata":{"id":"254c744a"},"source":["OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/sessions_by_day\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec86fada","outputId":"05b466fa-f091-409b-c790-5d805b22d10c"},"source":["%%time\n","start_time_window_index = 1\n","final_time_window_index = 4\n","for time_index in range(start_time_window_index, final_time_window_index):\n","    # Set data \n","    time_index_train = time_index\n","    time_index_eval = time_index + 1\n","    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n","    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n","    # Train on day related to time_index \n","    print('*'*20)\n","    print(\"Launch training for day %s are:\" %time_index)\n","    print('*'*20 + '\\n')\n","    trainer.train_dataset_or_path = train_paths\n","    trainer.reset_lr_scheduler()\n","    trainer.train()\n","    trainer.state.global_step +=1\n","    # Evaluate on the following day\n","    trainer.eval_dataset_or_path = eval_paths\n","    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n","    print('*'*20)\n","    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n","    print('\\n' + '*'*20 + '\\n')\n","    for key in sorted(train_metrics.keys()):\n","        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n","    trainer.wipe_memory()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["********************\n","Launch training for day 1 are:\n","********************\n","\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 112128\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1314\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1314/1314 00:51, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>9.836900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.937700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.665200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.518700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.411900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>8.371200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [415/415 02:11]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 2 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.605655670166016\n"," eval/next-item/ndcg_at_10 = 0.0545700266957283\n"," eval/next-item/ndcg_at_20 = 0.06626961380243301\n"," eval/next-item/recall_at_10 = 0.10270718485116959\n"," eval/next-item/recall_at_20 = 0.14915919303894043\n"," eval_runtime = 9.5026\n"," eval_samples_per_second = 1397.507\n"," eval_steps_per_second = 43.672\n","********************\n","Launch training for day 2 are:\n","********************\n","\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 106240\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1245\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1245/1245 00:50, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.466200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>8.315800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>8.120000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>8.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>7.920700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>7.883900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 3 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 8.162181854248047\n"," eval/next-item/ndcg_at_10 = 0.0733010321855545\n"," eval/next-item/ndcg_at_20 = 0.08980806171894073\n"," eval/next-item/recall_at_10 = 0.13904747366905212\n"," eval/next-item/recall_at_20 = 0.20428968966007233\n"," eval_runtime = 9.1126\n"," eval_samples_per_second = 1348.468\n"," eval_steps_per_second = 42.14\n","********************\n","Launch training for day 3 are:\n","********************\n","\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 97792\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 256\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1146\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1146/1146 00:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>8.016800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>7.900500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>7.740200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>7.691500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>7.583600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./tmp/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to ./tmp/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["********************\n","Eval results for day 4 are:\t\n","\n","********************\n","\n"," epoch = 3.0\n"," eval/loss = 7.774728775024414\n"," eval/next-item/ndcg_at_10 = 0.09089759737253189\n"," eval/next-item/ndcg_at_20 = 0.10928591340780258\n"," eval/next-item/recall_at_10 = 0.16947951912879944\n"," eval/next-item/recall_at_20 = 0.24214120209217072\n"," eval_runtime = 11.8897\n"," eval_samples_per_second = 1308.02\n"," eval_steps_per_second = 40.876\n","CPU times: user 7min 29s, sys: 16.9 s, total: 7min 45s\n","Wall time: 3min 10s\n"]}]},{"cell_type":"markdown","metadata":{"id":"e6978124"},"source":["Add XLNet-MLM with side information accuracy results to the `results.txt`"]},{"cell_type":"code","metadata":{"id":"d7998f38"},"source":["with open(\"results.txt\", 'a') as f:\n","    f.write('\\n')\n","    f.write('XLNet-MLM with side information accuracy results:')\n","    f.write('\\n')\n","    for key, value in  model.compute_metrics().items(): \n","        f.write('%s %s\\n' % (key, value.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0657768a"},"source":["After model training and evaluation is completed we can save our trained model in the next section. "]},{"cell_type":"markdown","metadata":{"id":"43341500"},"source":["## Exporting the preprocessing workflow and model for deployment to Triton server"]},{"cell_type":"markdown","metadata":{"id":"70927a43"},"source":["Load the preproc workflow that we saved in the ETL section."]},{"cell_type":"code","metadata":{"id":"8fe450c4"},"source":["import nvtabular as nvt\n","\n","# define data path about where to get our data\n","INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data/\")\n","workflow_path = os.path.join(INPUT_DATA_DIR, 'workflow_etl')\n","workflow = nvt.Workflow.load(workflow_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4af4431c","outputId":"6041333c-6693-4bc2-c57f-dec5e47b0045"},"source":["# dictionary representing max sequence length for the sequential (list) columns\n","sparse_features_max = {\n","    fname: sequence_length\n","    for fname in x_cat_names + x_cont_names\n","}\n","\n","sparse_features_max"],"execution_count":null,"outputs":[{"data":{"text/plain":["{'product_id-list_seq': 20,\n"," 'category_id-list_seq': 20,\n"," 'brand-list_seq': 20,\n"," 'product_recency_days_log_norm-list_seq': 20,\n"," 'et_dayofweek_sin-list_seq': 20,\n"," 'et_dayofweek_cos-list_seq': 20,\n"," 'price_log_norm-list_seq': 20,\n"," 'relative_price_to_avg_categ_id-list_seq': 20}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"e6839f8c"},"source":["It is time to export the proc workflow and model in the format required by Triton Inference Server, by using the NVTabular’s `export_pytorch_ensemble()` function."]},{"cell_type":"code","metadata":{"id":"d2b9e84c"},"source":["from nvtabular.inference.triton import export_pytorch_ensemble\n","export_pytorch_ensemble(\n","    model,\n","    workflow,\n","    sparse_max=sparse_features_max,\n","    name= \"t4r_pytorch\",\n","    model_path= \"/workspace/models\",\n","    label_columns =[],\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbfb8213"},"source":["Before we move on to the next section, let's print out our results.txt file. "]},{"cell_type":"code","metadata":{"id":"54a92609","outputId":"ed0a674a-eddb-4ee2-a2ef-9badac3ccd86"},"source":["!cat results.txt"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["GRU accuracy results:\n","next-item/ndcg_at_10:0.07151895016431808\n","next-item/ndcg_at_20:0.08768121898174286\n","next-item/recall_at_10:0.1361762434244156\n","next-item/recall_at_20:0.20020613074302673\n","\n","XLNet-MLM accuracy results:\n","next-item/ndcg_at_10:0.07384572923183441\n","next-item/ndcg_at_20:0.08944202959537506\n","next-item/recall_at_10:0.13939706981182098\n","next-item/recall_at_20:0.20175212621688843\n","\n","XLNet-MLM with side information accuracy results:\n","next-item/ndcg_at_10:0.08558817952871323\n","next-item/ndcg_at_20:0.10371016710996628\n","next-item/recall_at_10:0.1605256348848343\n","next-item/recall_at_20:0.2324143350124359"]}]},{"cell_type":"markdown","metadata":{"id":"146af29e"},"source":["Let's plot bar charts to visualize and compare the accuracy results using `visuals` util function."]},{"cell_type":"code","metadata":{"id":"c66e3f39","outputId":"3c244ec6-52fb-4ab4-dc49-3ba01794f025"},"source":["from visuals import create_bar_chart\n","create_bar_chart('results.txt')"],"execution_count":null,"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"77d36393"},"source":["## Triton for Recommender Systems"]},{"cell_type":"markdown","metadata":{"id":"172f9e15"},"source":["NVIDIA [Triton Inference Server (TIS)](https://github.com/triton-inference-server/server) simplifies the deployment of AI models at scale in production. The Triton Inference Server allows us to deploy and serve our model for inference. It supports a number of different machine learning frameworks such as TensorFlow and PyTorch.\n","\n","The last step of machine learning (ML)/deep learning (DL) pipeline is to deploy the ETL workflow and saved model to production. In the production setting, we want to transform the input data as done during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the DL model for a prediction. Therefore, we deploy the NVTabular workflow with the PyTorch model as an ensemble model to Triton Inference. The ensemble model guarantees that the same transformation is applied to the raw inputs."]},{"cell_type":"markdown","metadata":{"id":"ae645daa"},"source":["<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/55f95680-f556-45b4-93b3-a3f5eaf715f7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T114013Z&X-Amz-Expires=86400&X-Amz-Signature=3229c6eb93dda4a077bae72a876dcaa5da46602d1cdc28193ae42c540ff67944&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'>"]},{"cell_type":"markdown","metadata":{"id":"6f85f45d"},"source":["**Objectives:**\n","\n","Learn how to deploy a model to Triton\n","1. Deploy saved NVTabular and PyTorch models to Triton Inference Server\n","2. Sent requests for predictions"]},{"cell_type":"markdown","metadata":{"id":"43dc14a8"},"source":["## Pull and start Inference docker container"]},{"cell_type":"markdown","metadata":{"id":"f22667d0"},"source":["At this point, before connecing to the Triton Server, we launch the inference docker container and then load the exported ensemble `t4r_pytorch` to the inference server. This is done with the scripts below:\n","\n","**Launch the docker container:**\n","```\n","docker run -it --gpus device=0 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v <path_to_saved_models>:/workspace/models/ nvcr.io/nvidia/merlin/merlin-inference:21.09\n","```\n","\n","This script will mount your local model-repository folder that includes your saved models from the previous cell to `/workspace/models` directory in the merlin-inference docker container.\n","\n","**Start triton server**\n","After you started the merlin-inference container, you can start triton server with the command below. You need to provide correct path of the models folder.\n","```\n","tritonserver --model-repository=<path_to_models> --model-control-mode=explicit\n","```\n","Note: The model-repository path for our example is `/workspace/models`. The models haven't been loaded, yet. Below, we will request the Triton server to load the saved ensemble model."]},{"cell_type":"markdown","metadata":{"id":"07499907"},"source":["## Deploy PyTorch and NVTabular Model to Triton Inference Server"]},{"cell_type":"markdown","metadata":{"id":"6b61ed1a"},"source":["Our Triton server has already been launched and is ready to make requests. Remember we already exported the saved PyTorch model in the previous section, and generated the config files for Triton Inference Server."]},{"cell_type":"code","metadata":{"id":"6645e40e"},"source":["# Import dependencies\n","import os\n","from time import time\n","\n","import argparse\n","import numpy as np\n","import pandas as pd\n","import sys\n","import cudf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72c90e93"},"source":["## Review exported files"]},{"cell_type":"markdown","metadata":{"id":"6b8b7a4c"},"source":["Triton expects a specific directory structure for our models as the following format:"]},{"cell_type":"markdown","metadata":{"id":"d34dcb28"},"source":["```\n","<model-name>/\n","[config.pbtxt]\n","<version-name>/\n","  [model.savedmodel]/\n","    <pytorch_saved_model_files>/\n","      ...\n","```"]},{"cell_type":"markdown","metadata":{"id":"9d7d3156"},"source":["Let's check out our model repository layout. You can install tree library with `apt-get install tree`, and then run `!tree /workspace/models/` to print out the model repository layout as below:\n","\n","```\n","├── t4r_pytorch\n","│   ├── 1\n","│   └── config.pbtxt\n","├── t4r_pytorch_nvt\n","│   ├── 1\n","│   │   ├── model.py\n","│   │   ├── __pycache__\n","│   │   │   └── model.cpython-38.pyc\n","│   │   └── workflow\n","│   │       ├── categories\n","│   │       │   ├── cat_stats.category_id.parquet\n","│   │       │   ├── unique.brand.parquet\n","│   │       │   ├── unique.category_code.parquet\n","│   │       │   ├── unique.category_id.parquet\n","│   │       │   ├── unique.event_type.parquet\n","│   │       │   ├── unique.product_id.parquet\n","│   │       │   ├── unique.user_id.parquet\n","│   │       │   └── unique.user_session.parquet\n","│   │       ├── metadata.json\n","│   │       └── workflow.pkl\n","│   └── config.pbtxt\n","└── t4r_pytorch_pt\n","    ├── 1\n","    │   ├── model_info.json\n","    │   ├── model.pkl\n","    │   ├── model.pth\n","    │   ├── model.py\n","    │   └── __pycache__\n","    │       └── model.cpython-38.pyc\n","    └── config.pbtxt\n","```"]},{"cell_type":"markdown","metadata":{"id":"79b1036b"},"source":["Triton needs a [config file](https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md) to understand how to interpret the model. Let's look at the generated config file. It defines the input columns with datatype and dimensions and the output layer. Manually creating this config file can be complicated and NVTabular generates it with the `export_pytorch_ensemble()` function, which we used in the previous section.\n","\n","The [config file](https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md) needs the following information:\n","* `name`: The name of our model. Must be the same name as the parent folder.\n","* `platform`: The type of framework serving the model.\n","* `input`: The input our model expects.\n","  * `name`: Should correspond with the model input name.\n","  * `data_type`: Should correspond to the input's data type.\n","  * `dims`: The dimensions of the *request* for the input. For models that support input and output tensors with variable-size dimensions, those dimensions can be listed as -1 in the input and output configuration.\n","* `output`: The output parameters of our model.\n","  * `name`: Should correspond with the model output name.\n","  * `data_type`: Should correspond to the output's data type.\n","  * `dims`: The dimensions of the output."]},{"cell_type":"markdown","metadata":{"id":"0adbbbf2"},"source":["## Loading Model"]},{"cell_type":"markdown","metadata":{"id":"276a0e31"},"source":["Next, let's build a client to connect to our server. The `InferenceServerClient` object is what we'll be using to talk to Triton."]},{"cell_type":"code","metadata":{"id":"b1e8ac0f","outputId":"d860e2b2-893c-4209-c1cd-3cee1a4f3164"},"source":["import tritonhttpclient\n","\n","try:\n","    triton_client = tritonhttpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n","    print(\"client created.\")\n","except Exception as e:\n","    print(\"channel creation failed: \" + str(e))\n","triton_client.is_server_live()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["client created.\n","GET /v2/health/live, headers None\n","<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"]},{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"f61231d8","outputId":"c3489c5e-d903-4fc0-f011-4e1d8bb92bad"},"source":["triton_client.get_model_repository_index()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["POST /v2/repository/index, headers None\n","\n","<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '201'}>\n","bytearray(b'[{\"name\":\"t4r_pytorch\",\"version\":\"1\",\"state\":\"UNAVAILABLE\",\"reason\":\"unloaded\"},{\"name\":\"t4r_pytorch_nvt\",\"version\":\"1\",\"state\":\"UNLOADING\"},{\"name\":\"t4r_pytorch_pt\",\"version\":\"1\",\"state\":\"UNLOADING\"}]')\n"]},{"data":{"text/plain":["[{'name': 't4r_pytorch',\n","  'version': '1',\n","  'state': 'UNAVAILABLE',\n","  'reason': 'unloaded'},\n"," {'name': 't4r_pytorch_nvt', 'version': '1', 'state': 'UNLOADING'},\n"," {'name': 't4r_pytorch_pt', 'version': '1', 'state': 'UNLOADING'}]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3d091905"},"source":["We load the ensemble model"]},{"cell_type":"code","metadata":{"id":"260d063d","outputId":"ce8e8aa4-3388-4bd7-a588-c4ff17203289"},"source":["model_name = \"t4r_pytorch\"\n","triton_client.load_model(model_name=model_name)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["POST /v2/repository/models/t4r_pytorch/load, headers None\n","\n","<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n","Loaded model 't4r_pytorch'\n"]}]},{"cell_type":"markdown","metadata":{"id":"26345f7d"},"source":["If all models are loaded succesfully, you should be seeing successfully loaded status next to each model name on your terminal."]},{"cell_type":"markdown","metadata":{"id":"fe1debc7"},"source":["## Sent Requests for Predictions"]},{"cell_type":"markdown","metadata":{"id":"2b2cc71a"},"source":["Load raw data for inference: We select the first 50 interactions and filter out sessions with less than 2 interactions. For this tutorial, just as an example we use the `Oct-2019` dataset that we used for model training."]},{"cell_type":"code","metadata":{"id":"5309a22e"},"source":["INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data/\")\n","df= cudf.read_parquet(os.path.join(INPUT_DATA_DIR, 'Oct-2019.parquet'))\n","df=df.sort_values('event_time_ts')\n","batch = df.iloc[:50,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"592aad96"},"source":["sessions_to_use = batch.user_session.value_counts()\n","filtered_batch = batch[batch.user_session.isin(sessions_to_use[sessions_to_use.values>1].index.values)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b860b31c","outputId":"d5d6d2af-a47d-472f-8a1e-7a53b6e8cf3e"},"source":["filtered_batch.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_session</th>\n","      <th>event_type</th>\n","      <th>product_id</th>\n","      <th>category_id</th>\n","      <th>category_code</th>\n","      <th>brand</th>\n","      <th>price</th>\n","      <th>user_id</th>\n","      <th>event_time_ts</th>\n","      <th>prod_first_event_time_ts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3562914</th>\n","      <td>1637332</td>\n","      <td>view</td>\n","      <td>1307067</td>\n","      <td>2053013558920217191</td>\n","      <td>computers.notebook</td>\n","      <td>lenovo</td>\n","      <td>251.74</td>\n","      <td>550050854</td>\n","      <td>1569888001</td>\n","      <td>1569888001</td>\n","    </tr>\n","    <tr>\n","      <th>5173328</th>\n","      <td>4202155</td>\n","      <td>view</td>\n","      <td>1004237</td>\n","      <td>2053013555631882655</td>\n","      <td>electronics.smartphone</td>\n","      <td>apple</td>\n","      <td>1081.98</td>\n","      <td>535871217</td>\n","      <td>1569888004</td>\n","      <td>1569888004</td>\n","    </tr>\n","    <tr>\n","      <th>3741261</th>\n","      <td>1808164</td>\n","      <td>view</td>\n","      <td>1480613</td>\n","      <td>2053013561092866779</td>\n","      <td>computers.desktop</td>\n","      <td>pulser</td>\n","      <td>908.62</td>\n","      <td>512742880</td>\n","      <td>1569888005</td>\n","      <td>1569888005</td>\n","    </tr>\n","    <tr>\n","      <th>4996937</th>\n","      <td>3794756</td>\n","      <td>view</td>\n","      <td>31500053</td>\n","      <td>2053013558031024687</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>luminarc</td>\n","      <td>41.16</td>\n","      <td>550978835</td>\n","      <td>1569888008</td>\n","      <td>1569888008</td>\n","    </tr>\n","    <tr>\n","      <th>5589259</th>\n","      <td>5470852</td>\n","      <td>view</td>\n","      <td>28719074</td>\n","      <td>2053013565480109009</td>\n","      <td>apparel.shoes.keds</td>\n","      <td>baden</td>\n","      <td>102.71</td>\n","      <td>520571932</td>\n","      <td>1569888010</td>\n","      <td>1569888010</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         user_session event_type  product_id          category_id  \\\n","3562914       1637332       view     1307067  2053013558920217191   \n","5173328       4202155       view     1004237  2053013555631882655   \n","3741261       1808164       view     1480613  2053013561092866779   \n","4996937       3794756       view    31500053  2053013558031024687   \n","5589259       5470852       view    28719074  2053013565480109009   \n","\n","                  category_code     brand    price    user_id  event_time_ts  \\\n","3562914      computers.notebook    lenovo   251.74  550050854     1569888001   \n","5173328  electronics.smartphone     apple  1081.98  535871217     1569888004   \n","3741261       computers.desktop    pulser   908.62  512742880     1569888005   \n","4996937                    <NA>  luminarc    41.16  550978835     1569888008   \n","5589259      apparel.shoes.keds     baden   102.71  520571932     1569888010   \n","\n","         prod_first_event_time_ts  \n","3562914                1569888001  \n","5173328                1569888004  \n","3741261                1569888005  \n","4996937                1569888008  \n","5589259                1569888010  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"b40c3922","outputId":"97faa931-c7bb-485d-c8cc-d24e283032d9"},"source":["import nvtabular.inference.triton as nvt_triton\n","import tritonclient.grpc as grpcclient\n","\n","inputs = nvt_triton.convert_df_to_triton_input(filtered_batch.columns, filtered_batch, grpcclient.InferInput)\n","\n","output_names = [\"output\"]\n","\n","outputs = []\n","for col in output_names:\n","    outputs.append(grpcclient.InferRequestedOutput(col))\n","    \n","MODEL_NAME_NVT = \"t4r_pytorch\"\n","\n","with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n","    response = client.infer(MODEL_NAME_NVT, inputs)\n","    print(col, ':\\n', response.as_numpy(col))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["output :\n"," [[-12.86381   -13.449438   -9.572359  ... -12.689846  -13.033402\n","  -13.294905 ]\n"," [-24.320768  -26.130745   -4.3342614 ... -24.07727   -25.470228\n","  -26.27378  ]\n"," [-22.867298  -24.897617   -6.6269407 ... -23.640343  -23.620872\n","  -24.977371 ]\n"," [-21.455946  -22.92965    -4.8912797 ... -21.020473  -22.514032\n","  -22.958193 ]\n"," [-24.569319  -26.149971   -4.223791  ... -24.316437  -25.649946\n","  -26.920403 ]\n"," [-14.218529  -14.833358   -8.438756  ... -14.013732  -14.700138\n","  -14.71361  ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"2f2e07dc"},"source":["## Visualise top-k predictions"]},{"cell_type":"code","metadata":{"id":"45c64075","outputId":"9fad59ae-4234-41f9-c15d-fecdb3b5b565"},"source":["from transformers4rec.torch.utils.examples_utils import visualize_response\n","visualize_response(filtered_batch, response, top_k=5, session_col='user_session')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["- Top-5 predictions for session `1167651`: 1045 || 229 || 233 || 1085 || 10\n","\n","- Top-5 predictions for session `1637332`: 11 || 7 || 4 || 2 || 3\n","\n","- Top-5 predictions for session `1808164`: 162 || 142 || 226 || 80 || 200\n","\n","- Top-5 predictions for session `3794756`: 3 || 2 || 26 || 364 || 10\n","\n","- Top-5 predictions for session `4202155`: 2 || 57 || 36 || 38 || 10\n","\n","- Top-5 predictions for session `5470852`: 1710 || 233 || 805 || 555 || 10\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"1619777f"},"source":["As you see we first got prediction results (logits) from the trained model head, and then by using a handy util function `visualize_response` we extracted top-k encoded item-ids from logits. Basically, we  generated recommended items for a given session.\n","\n","This is the end of the tutorial. You successfully ...\n","1. performed feature engineering with NVTabular\n","2. trained transformer architecture based session-based recommendation models with Transformers4Rec \n","3. deployed a trained model to Triton Inference Server, sent request and got responses from the server."]},{"cell_type":"markdown","metadata":{"id":"6224a7fe"},"source":["## Unload models and shut down the kernel"]},{"cell_type":"code","metadata":{"id":"f481d47f","outputId":"f86accf1-6809-4b7d-8719-55149a125f16"},"source":["triton_client.unload_model(model_name=\"t4r_pytorch\")\n","triton_client.unload_model(model_name=\"t4r_pytorch_nvt\")\n","triton_client.unload_model(model_name=\"t4r_pytorch_pt\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["POST /v2/repository/models/t4r_pytorch/unload, headers None\n","{\"parameters\":{\"unload_dependents\":false}}\n","<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n","Loaded model 't4r_pytorch'\n","POST /v2/repository/models/t4r_pytorch_nvt/unload, headers None\n","{\"parameters\":{\"unload_dependents\":false}}\n","<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n","Loaded model 't4r_pytorch_nvt'\n","POST /v2/repository/models/t4r_pytorch_pt/unload, headers None\n","{\"parameters\":{\"unload_dependents\":false}}\n","<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n","Loaded model 't4r_pytorch_pt'\n"]}]},{"cell_type":"markdown","metadata":{"id":"496bdf04"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"66f2a8e5"},"source":["[1] Malte Ludewig and Dietmar Jannach. 2018. Evaluation of session-based recommendation algorithms. User Modeling and User-Adapted Interaction 28, 4-5 (2018), 331–390.<br>\n","[2] Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACMinternational conference on information and knowledge management. 843–852.<br>\n","[3] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441–1450.\n","[4] Shiming Sun, Yuanhe Tang, Zemei Dai, and Fu Zhou. 2019. Self-attention network for session-based recommendation with streaming data input. IEEE Access 7 (2019), 110499–110509.  \n","[5] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).  \n","[6] Vaswani, A., et al. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).  \n","[7] Lample, Guillaume, and Alexis Conneau. \"Cross-lingual language model pretraining.\" arXiv preprint arXiv:1901.07291  \n","[8] Gabriel De Souza P. Moreira, et al. (2021). Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. RecSys'21.  \n","[9] Understanding XLNet, BorealisAI. Online available: https://www.borealisai.com/en/blog/understanding-xlnet/  \n","[10] Yang, Zhilin, et al. \"Xlnet: Generalized autoregressive pretraining for language understanding.\" Advances in neural information processing systems 32 (2019)."]}]}