{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_name = \"reco-tut-sor\"; branch = \"main\"; account = \"sparsh-ai\"\n",
    "project_path = os.path.join('/content', project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(project_path):\n",
    "    !cp /content/drive/MyDrive/mykeys.py /content\n",
    "    import mykeys\n",
    "    !rm /content/mykeys.py\n",
    "    path = \"/content/\" + project_name; \n",
    "    !mkdir \"{path}\"\n",
    "    %cd \"{path}\"\n",
    "    import sys; sys.path.append(path)\n",
    "    !git config --global user.email \"recotut@recohut.com\"\n",
    "    !git config --global user.name  \"reco-tut\"\n",
    "    !git init\n",
    "    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n",
    "    !git pull origin \"{branch}\"\n",
    "    !git checkout main\n",
    "else:\n",
    "    %cd \"{project_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add . && git commit -m 'commit' && git push origin \"{branch}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/silver/userdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "        df[col] = df[col].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_categorical(df, ['id', 'offer_id', 'event'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation matrix is very similar to embeddings. So we will leverage this and will train embedding along the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding sizes\n",
    "N = len(df['id'].unique())\n",
    "M = len(df['offer_id'].unique())\n",
    "\n",
    "# Set embedding dimension\n",
    "D = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_specs = ['difficulty', 'duration', 'reward', 'web',\n",
    "       'email', 'mobile', 'social', 'bogo', 'discount', 'informational']\n",
    "user_specs = ['age', 'became_member_on', 'gender', 'income', 'memberdays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network that takes additional continuous paramets\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_cont_user, n_cont_offer, embed_dim, output_dim, layers=[1024], p=0.4):\n",
    "        super(Model, self).__init__()\n",
    "        self.N = n_users\n",
    "        self.M = n_items\n",
    "        self.D = embed_dim\n",
    "        self.bn_cont_u = nn.BatchNorm1d(n_cont_user)\n",
    "        self.bn_cont_o = nn.BatchNorm1d(n_cont_offer)\n",
    "        self.u_emb = nn.Embedding(self.N, self.D)\n",
    "        self.m_emb = nn.Embedding(self.M, self.D)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_in = 2 * self.D + n_cont_user + n_cont_offer\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            \n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            layerlist.append(nn.ReLU())\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],output_dim))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.layers[0].weight)\n",
    "        nn.init.zeros_(self.layers[0].bias)\n",
    "        nn.init.xavier_uniform_(self.layers[-1].weight)\n",
    "        nn.init.zeros_(self.layers[-1].bias)\n",
    "\n",
    "    def forward(self, user, offer, user_details, offer_details):\n",
    "        u = self.u_emb(user) # output is (num_samples, D)\n",
    "        m = self.m_emb(offer) # output is (num_samples, D)\n",
    "\n",
    "        # merge\n",
    "        out = torch.cat((u, m), 1) # output is (num_samples, 2D)\n",
    "        u_cont = self.bn_cont_u(user_details)\n",
    "        o_cont = self.bn_cont_o(offer_details)\n",
    "        out = torch.cat([out, u_cont, o_cont], 1)\n",
    "        x = self.layers(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "layers = [1024, 1024, 512, 256, 128]\n",
    "model = Model(N, M, \n",
    "              n_cont_user=df[user_specs].shape[1], \n",
    "              n_cont_offer=df[offer_specs].shape[1],\n",
    "              embed_dim=D, \n",
    "              output_dim=df['event'].nunique(), \n",
    "              layers=layers)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.04, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create additional user and offer details tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "# Make datasets\n",
    "# We name events as rating for give better insight on the target value\n",
    "# and ease of comparison to other similar models\n",
    "\n",
    "user_ids_t = torch.from_numpy(df['id'].values).long()\n",
    "offer_ids_t = torch.from_numpy(df['offer_id'].values).long()\n",
    "ratings_t = torch.from_numpy(df['event'].values).long()\n",
    "\n",
    "user_params_t = torch.from_numpy(df[user_specs].values).float()\n",
    "offer_params_t = torch.from_numpy(df[offer_specs].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "N_train = int(0.8 * len(df['event'].values))\n",
    "N_test = 1000\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    user_ids_t[:N_train],\n",
    "    offer_ids_t[:N_train],\n",
    "    user_params_t[:N_train],\n",
    "    offer_params_t[:N_train],\n",
    "    ratings_t[:N_train],\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    user_ids_t[N_train:-N_test],\n",
    "    offer_ids_t[N_train:-N_test],\n",
    "    user_params_t[N_train:-N_test],\n",
    "    offer_params_t[N_train:-N_test],\n",
    "    ratings_t[N_train:-N_test],\n",
    "    \n",
    ")\n",
    "test_df = df[-N_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(model, criterion, optimizer, train_iter, test_iter, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    val_losses = np.zeros(epochs)\n",
    "    acc_list = []\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for users, offers, u_params, o_params, targets in train_loader:\n",
    "            \n",
    "\n",
    "            # move data to GPU\n",
    "            users, offers, u_params, o_params, targets = users.to(device), offers.to(device),  u_params.to(device), o_params.to(device), targets.to(device)\n",
    "            #targets = targets.view(-1, 1).long()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(users, offers, u_params, o_params)\n",
    "            \n",
    "            loss = criterion(outputs, targets.squeeze())\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # Track the accuracy\n",
    "            total = targets.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == targets).sum().item()\n",
    "            acc = correct / total\n",
    "            acc_list.append(acc)\n",
    "\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "        \n",
    "        val_loss = []\n",
    "        \n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            for users, offers, u_params, o_params, targets in validation_loader:\n",
    "                users, offers, u_params, o_params, targets = users.to(device), offers.to(device),  u_params.to(device), o_params.to(device), targets.to(device)\n",
    "                #targets = targets.view(-1, 1).long()\n",
    "                outputs = model(users, offers, u_params, o_params)\n",
    "                loss = criterion(outputs, targets.squeeze())\n",
    "                val_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = np.mean(val_loss)\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, '\n",
    "              f'Validations Loss: {val_loss:.4f}, Accuracy: {acc:.4f}, Duration: {dt}')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, train_loader, validation_loader, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train loss and test loss per iteration\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ix = 0\n",
    "end_ix = -1\n",
    "test_X =  torch.from_numpy(test_df.iloc[start_ix:end_ix]['id'].values).long()\n",
    "test_y = torch.from_numpy(test_df.iloc[start_ix:end_ix]['event'].values).long()\n",
    "user_params_t = torch.from_numpy(test_df.iloc[start_ix:end_ix][user_specs].values).float()\n",
    "offer_params_t = torch.from_numpy(test_df.iloc[start_ix:end_ix][offer_specs].values).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred = model(test_X.to(device), test_y.to(device), user_params_t.to(device), offer_params_t.to(device))\n",
    "    #print(pred)\n",
    "    \n",
    "_, predicted = torch.max(pred.data, 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          save=False,\n",
    "                          figname='cm.png'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if save:\n",
    "        plt.savefig(figname, dpi=fig.dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot confusion matrix and baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors should be copied back to cpu using tensor.cpu()\n",
    "test_y = test_y.cpu()\n",
    "predicted = predicted.cpu()\n",
    "cm = confusion_matrix(test_y, predicted)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes, save=True, figname='./outputs/RecommendationEngine-cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy so far: \" + str(100*accuracy_score(test_y, predicted))+ \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are decent so far and almost twice better than random quessing.\n",
    "\n",
    "#### Show some predicted examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ix = 10\n",
    "end_ix = 30\n",
    "data = test_df.iloc[start_ix:end_ix][['age', 'became_member_on', 'gender', 'id', 'income', 'memberdays', 'event']]#['offer_id'].values\n",
    "pred_values = pd.DataFrame(predicted[start_ix:end_ix], columns=['predicted'], index=data.index)\n",
    "results = pd.concat([data, pred_values], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we see that for randomly selected 10 users model was inaccurate twice, but was able to predict user positive actions on offer.\n",
    "\n",
    "Mislassifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.event != results.predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, model_info):\n",
    "    # Save the parameters used to construct the model\n",
    "    with open(model_name, 'wb') as f:\n",
    "        torch.save(model_info, f)\n",
    "\n",
    "    # Save the model parameters\n",
    "    \n",
    "    with open(model_name, 'wb') as f:\n",
    "        torch.save(model.cpu().state_dict(), f)\n",
    "\n",
    "model_info = {    \n",
    "          'n_users': M, \n",
    "          'n_items': N, \n",
    "          'n_cont_user': df[user_specs].shape[1], \n",
    "          'n_cont_offer': df[offer_specs].shape[1],\n",
    "          'embed_dim': D, \n",
    "          'output_dim': df['event'].nunique(), \n",
    "          'layers': layers, \n",
    "          'p': 0.4\n",
    "    }\n",
    "save_model(model, './artifacts/models/RecommendationModel2.pth', model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's additionally check another metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [1024, 1024, 512, 256, 128]\n",
    "model2 = Model(N, M, \n",
    "              n_cont_user=df[user_specs].shape[1], \n",
    "              n_cont_offer=df[offer_specs].shape[1],\n",
    "              embed_dim=D, \n",
    "              output_dim=df['event'].nunique(), \n",
    "              layers=layers)\n",
    "\n",
    "model2.load_state_dict(torch.load('./artifacts/models/RecommendationModel2.pth'));\n",
    "model2.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ix = 0\n",
    "end_ix = -1\n",
    "test_X =  torch.from_numpy(test_df.iloc[start_ix:end_ix]['id'].values).long()\n",
    "test_y = torch.from_numpy(test_df.iloc[start_ix:end_ix]['event'].values).long()\n",
    "user_params_t = torch.from_numpy(test_df.iloc[start_ix:end_ix][user_specs].values).float()\n",
    "offer_params_t = torch.from_numpy(test_df.iloc[start_ix:end_ix][offer_specs].values).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model2.eval()\n",
    "    pred = model2(test_X.to(device), test_y.to(device), user_params_t.to(device), offer_params_t.to(device))\n",
    "    #print(pred)\n",
    "_, predicted = torch.max(pred.data, 1)\n",
    "#print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors should be copied back to cpu using tensor.cpu()\n",
    "test_y = test_y.cpu()\n",
    "predicted = predicted.cpu()\n",
    "cm = confusion_matrix(test_y, predicted)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy so far: \" + str(100*accuracy_score(test_y, predicted))+ \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score for the model: \" + str(f1_score(test_y, predicted, average='weighted')))\n",
    "print(\"Recall score for the model: \" + str(recall_score(test_y, predicted, average='weighted')))\n",
    "print(\"Precision score for the model: \" + str(precision_score(test_y, predicted, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOkbY6ZCvzdOQh+WJHPhe7+",
   "collapsed_sections": [],
   "mount_file_id": "1Cz_Ni1c9WfFwG3xiThlgmAtNwRxonYft",
   "name": "reco-tut-sor-02-recommender-model.ipynb",
   "provenance": [
    {
     "file_id": "1UuUa25pOjIh93SeHhRVnsmZgeohAt_qD",
     "timestamp": 1628780642971
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
