{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T665264 | GCN on CORA in PyTorch","provenance":[{"file_id":"1VLG33XWDO08FrRSayyJbVqEMbQhjhBek","timestamp":1638106806149},{"file_id":"1MLa8I6LkNp7yMC9h7Tt6tiNWJsg6Q9Ls","timestamp":1638106054440}],"collapsed_sections":[],"mount_file_id":"1MLa8I6LkNp7yMC9h7Tt6tiNWJsg6Q9Ls","authorship_tag":"ABX9TyMLH/5kLbKW8XJrmtiXxrY9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NfkGGOZ0xpLG"},"source":["# GCN on CORA in PyTorch"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8S8VFwCjxNZa","executionInfo":{"status":"ok","timestamp":1638106724565,"user_tz":-330,"elapsed":6245,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a1a43f7f-b20b-4e2c-9551-8b5c73e68d59"},"source":["!pip install -q dgl"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.4 MB 8.0 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8_VhUsDYzLE","executionInfo":{"status":"ok","timestamp":1638106767240,"user_tz":-330,"elapsed":702,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c12b7b04-08d7-4651-e9f8-fa71294e79fa"},"source":["import numpy as np\n","import pandas as pd\n","import random\n","import os, sys, pickle\n","import random, math, gc\n","\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import dgl\n","from dgl.data import CoraGraphDataset"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}]},{"cell_type":"code","metadata":{"id":"VxRBHd8aZYEL"},"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmZ_eW-vZGHK"},"source":["class GCNDataset(Dataset):\n","    def __init__(self, graph, is_train):\n","        super(GCNDataset, self).__init__()\n","        self.graph = graph\n","        self.mask = graph.ndata['train_mask'] if is_train else graph.ndata['test_mask']\n","        self.label = graph.ndata['label']\n","        self.node = graph.nodes()\n","        self.feat = graph.ndata['feat'].float()\n","\n","    def __len__(self):\n","        return self.graph.num_nodes()\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'node': self.node[idx],\n","            'y': self.label[idx],\n","            'mask': self.mask[idx],\n","            'x': self.feat[idx]\n","        }\n","\n","def get_A_mat(graph, config):\n","    A = np.zeros((graph.num_nodes(), graph.num_nodes()))\n","    for src, dst in zip(graph.edges()[0].numpy(), graph.edges()[1].numpy()):\n","        A[src, dst] += 1\n","    A = A + np.identity(graph.num_nodes())\n","    D = np.sum(A, axis=1)\n","    D = np.diag(np.power(D, -0.5))\n","    Ahat = np.dot(D, A).dot(D)\n","    return torch.tensor(Ahat).float().to(config.device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcUJ5zCWZS-W"},"source":["class GCNLayer(nn.Module):\n","    def __init__(self, input, output, dropout):\n","        super(GCNLayer, self).__init__()\n","        self.input = input\n","        self.output = output\n","        self.W = nn.Linear(input, output)\n","        self.dropout = nn.Dropout(dropout)\n","        # torch.nn.init.uniform_(self.W.weight, -1/math.sqrt(output), 1/math.sqrt(output))\n","        torch.nn.init.uniform_(self.W.weight)        \n","    \n","    def forward(self, x, adj):\n","        output = torch.spmm(adj, x)\n","        output = self.dropout(output)\n","        output = self.W(output)\n","        return output\n","\n","class GCN(nn.Module):\n","    def __init__(self, config):\n","        super(GCN, self).__init__()\n","        self.gcn1 = GCNLayer(config.input_dim, config.hidden_dim, dropout=0.1) \n","        self.gcn2 = GCNLayer(config.hidden_dim, config.output_dim, dropout=0.1) \n","        \n","    def forward(self, batch_data, A):\n","        label, data, mask = batch_data['y'], batch_data['x'], batch_data['mask']\n","        data = F.relu(self.gcn1(data, A))\n","        data = self.gcn2(data, A)\n","        return data[mask], label[mask]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rU1R_3VSYxGn","executionInfo":{"status":"ok","timestamp":1630651560310,"user_tz":-330,"elapsed":143233,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"387dcde0-a501-4618-c22b-ec56d0403e4e"},"source":["class Config:\n","    learning_rate = 0.01\n","    weight_decay = 5e-4\n","    hidden_dim = 16\n","    epochs = 200\n","    early_stopping_round = None\n","    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","    seed = 1995\n","\n","config = Config()\n","\n","dataset = CoraGraphDataset()\n","graph = dataset[0]\n","config.batch_size = graph.num_nodes()\n","config.input_dim = graph.ndata['feat'].shape[1]\n","config.output_dim = graph.ndata['label'].unique().shape[0]\n","\n","seed_everything(config.seed)\n","train_set = GCNDataset(graph, True)\n","valid_set = GCNDataset(graph, False)\n","train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=False)\n","valid_loader = DataLoader(valid_set, batch_size=config.batch_size, shuffle=False)\n","\n","A = get_A_mat(graph, config)\n","model = GCN(config)\n","model = model.to(config.device)\n","optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n","loss_fn = nn.CrossEntropyLoss()\n","history = defaultdict(list)\n","\n","start = datetime.now()\n","best_loss, early_step, best_epoch = 0, 0, 0\n","for epoch in range(config.epochs):\n","    model.train()\n","    for batch_data in train_loader:\n","        optimizer.zero_grad()\n","        batch_data = {k:v.to(config.device) for k,v in batch_data.items()}\n","        output, true = model(batch_data, A)\n","        acc_tr = torch.sum(true == torch.argmax(output, axis=1)) / len(true)\n","        loss = loss_fn(output, true)\n","        loss.backward()\n","        optimizer.step()\n","\n","    history['train_loss'].append(loss.item())\n","    history['train_acc'].append(acc_tr)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_data in valid_loader:\n","            batch_data = {k:v.to(config.device) for k,v in batch_data.items()}\n","            output, true = model(batch_data, A)\n","            acc = torch.sum(true == torch.argmax(output, axis=1)) / len(true)\n","            loss = loss_fn(output, true)\n","\n","    history['valid_loss'].append(loss.item())\n","    history['valid_acc'].append(acc)\n","\n","    if epoch == 0 or epoch == config.epochs-1 or (epoch+1)%10 == 0:\n","        print(f'EPOCH {epoch+1} : TRAINING loss {history[\"train_loss\"][-1]:.3f}, TRAINING ACC {history[\"train_acc\"][-1]:.3f}, VALID loss {history[\"valid_loss\"][-1]:.3f}, VALID ACC {history[\"valid_acc\"][-1]:.3f}')\n","    \n","    if history['valid_acc'][-1] > best_loss:\n","        best_loss = history['valid_acc'][-1]\n","        best_epoch = epoch\n","\n","    elif(config.early_stopping_round is not None):\n","        \n","        early_step += 1\n","        if (early_step >= config.early_stopping_round):\n","            break\n","end = datetime.now()\n","print(end-start)\n","print(f'At EPOCH {best_epoch + 1}, We have Best Acc {best_loss}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n","Extracting file to /root/.dgl/cora_v2\n","Finished data loading and preprocessing.\n","  NumNodes: 2708\n","  NumEdges: 10556\n","  NumFeats: 1433\n","  NumClasses: 7\n","  NumTrainingSamples: 140\n","  NumValidationSamples: 500\n","  NumTestSamples: 1000\n","Done saving data into cached files.\n","EPOCH 1 : TRAINING loss 2.322, TRAINING ACC 0.143, VALID loss 2.266, VALID ACC 0.091\n","EPOCH 10 : TRAINING loss 1.946, TRAINING ACC 0.193, VALID loss 1.947, VALID ACC 0.148\n","EPOCH 20 : TRAINING loss 1.872, TRAINING ACC 0.229, VALID loss 1.923, VALID ACC 0.146\n","EPOCH 30 : TRAINING loss 1.829, TRAINING ACC 0.486, VALID loss 1.884, VALID ACC 0.350\n","EPOCH 40 : TRAINING loss 1.765, TRAINING ACC 0.736, VALID loss 1.846, VALID ACC 0.684\n","EPOCH 50 : TRAINING loss 1.687, TRAINING ACC 0.757, VALID loss 1.801, VALID ACC 0.663\n","EPOCH 60 : TRAINING loss 1.589, TRAINING ACC 0.793, VALID loss 1.732, VALID ACC 0.734\n","EPOCH 70 : TRAINING loss 1.433, TRAINING ACC 0.864, VALID loss 1.646, VALID ACC 0.761\n","EPOCH 80 : TRAINING loss 1.312, TRAINING ACC 0.871, VALID loss 1.539, VALID ACC 0.778\n","EPOCH 90 : TRAINING loss 1.140, TRAINING ACC 0.907, VALID loss 1.436, VALID ACC 0.793\n","EPOCH 100 : TRAINING loss 1.007, TRAINING ACC 0.914, VALID loss 1.328, VALID ACC 0.803\n","EPOCH 110 : TRAINING loss 0.930, TRAINING ACC 0.900, VALID loss 1.235, VALID ACC 0.819\n","EPOCH 120 : TRAINING loss 0.799, TRAINING ACC 0.950, VALID loss 1.156, VALID ACC 0.819\n","EPOCH 130 : TRAINING loss 0.722, TRAINING ACC 0.950, VALID loss 1.096, VALID ACC 0.817\n","EPOCH 140 : TRAINING loss 0.650, TRAINING ACC 0.971, VALID loss 1.042, VALID ACC 0.815\n","EPOCH 150 : TRAINING loss 0.602, TRAINING ACC 0.929, VALID loss 1.000, VALID ACC 0.813\n","EPOCH 160 : TRAINING loss 0.580, TRAINING ACC 0.950, VALID loss 0.959, VALID ACC 0.820\n","EPOCH 170 : TRAINING loss 0.517, TRAINING ACC 0.957, VALID loss 0.933, VALID ACC 0.819\n","EPOCH 180 : TRAINING loss 0.479, TRAINING ACC 0.950, VALID loss 0.915, VALID ACC 0.810\n","EPOCH 190 : TRAINING loss 0.480, TRAINING ACC 0.957, VALID loss 0.887, VALID ACC 0.810\n","EPOCH 200 : TRAINING loss 0.451, TRAINING ACC 0.950, VALID loss 0.879, VALID ACC 0.808\n","0:02:18.900756\n","At EPOCH 155, We have Best Acc 0.8220000267028809\n"]}]},{"cell_type":"markdown","metadata":{"id":"EsFzSRvnxb3X"},"source":["---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKXM9U7sxb3Z","executionInfo":{"status":"ok","timestamp":1638106792273,"user_tz":-330,"elapsed":3002,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"729e3d64-42f2-4de7-9685-304a7dfbd0dc"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-11-28 13:39:52\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","numpy     : 1.19.5\n","sys       : 3.7.12 (default, Sep 10 2021, 00:21:48) \n","[GCC 7.5.0]\n","IPython   : 5.5.0\n","torch     : 1.10.0+cu111\n","networkx  : 2.6.3\n","dgl       : 0.6.1\n","pandas    : 1.1.5\n","matplotlib: 3.2.2\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"Bn4s9s_Axb3Z"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"jFXf3bKdxb3a"},"source":["**END**"]}]}