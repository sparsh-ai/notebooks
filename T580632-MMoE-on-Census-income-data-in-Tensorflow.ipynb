{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T580632 | MMoE on Census income data in Tensorflow","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMF3NIwUSHhD2ToJk3tuT7T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LYmYGbTFvezn"},"source":["# MMoE on Census income data in Tensorflow"]},{"cell_type":"markdown","metadata":{"id":"esrj1dEwvm7O"},"source":["## Installations"]},{"cell_type":"code","metadata":{"id":"uAAu8LPivIzh"},"source":["!pip install numpy==1.19.2\n","!pip install pandas==1.3.1\n","!pip install scikit-learn==0.24.2\n","!pip install tensorflow==2.5.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TtnPLkdPvixQ"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"Ams90NSpv0O9"},"source":["import random\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import metrics\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.initializers import VarianceScaling\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import activations, initializers, regularizers, constraints\n","from tensorflow.keras.layers import Layer, InputSpec\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import Callback\n","from sklearn.metrics import roc_auc_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hWzDpHYAwcEs"},"source":["## Params"]},{"cell_type":"code","metadata":{"id":"YGFxSdfqwdKU"},"source":["SEED = 1\n","\n","# Fix numpy seed for reproducibility\n","np.random.seed(SEED)\n","\n","# Fix random seed for reproducibility\n","random.seed(SEED)\n","\n","# Fix TensorFlow graph-level seed for reproducibility\n","tf.random.set_seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IJZbLNKNv0L3"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"b3saeSl5v0IR"},"source":["class MMoE(Layer):\n","    \"\"\"\n","    Multi-gate Mixture-of-Experts model.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 units,\n","                 num_experts,\n","                 num_tasks,\n","                 use_expert_bias=True,\n","                 use_gate_bias=True,\n","                 expert_activation='relu',\n","                 gate_activation='softmax',\n","                 expert_bias_initializer='zeros',\n","                 gate_bias_initializer='zeros',\n","                 expert_bias_regularizer=None,\n","                 gate_bias_regularizer=None,\n","                 expert_bias_constraint=None,\n","                 gate_bias_constraint=None,\n","                 expert_kernel_initializer='VarianceScaling',\n","                 gate_kernel_initializer='VarianceScaling',\n","                 expert_kernel_regularizer=None,\n","                 gate_kernel_regularizer=None,\n","                 expert_kernel_constraint=None,\n","                 gate_kernel_constraint=None,\n","                 activity_regularizer=None,\n","                 **kwargs):\n","        \"\"\"\n","         Method for instantiating MMoE layer.\n","        :param units: Number of hidden units\n","        :param num_experts: Number of experts\n","        :param num_tasks: Number of tasks\n","        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n","        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n","        :param expert_activation: Activation function of the expert weights\n","        :param gate_activation: Activation function of the gate weights\n","        :param expert_bias_initializer: Initializer for the expert bias\n","        :param gate_bias_initializer: Initializer for the gate bias\n","        :param expert_bias_regularizer: Regularizer for the expert bias\n","        :param gate_bias_regularizer: Regularizer for the gate bias\n","        :param expert_bias_constraint: Constraint for the expert bias\n","        :param gate_bias_constraint: Constraint for the gate bias\n","        :param expert_kernel_initializer: Initializer for the expert weights\n","        :param gate_kernel_initializer: Initializer for the gate weights\n","        :param expert_kernel_regularizer: Regularizer for the expert weights\n","        :param gate_kernel_regularizer: Regularizer for the gate weights\n","        :param expert_kernel_constraint: Constraint for the expert weights\n","        :param gate_kernel_constraint: Constraint for the gate weights\n","        :param activity_regularizer: Regularizer for the activity\n","        :param kwargs: Additional keyword arguments for the Layer class\n","        \"\"\"\n","        # Hidden nodes parameter\n","        self.units = units\n","        self.num_experts = num_experts\n","        self.num_tasks = num_tasks\n","\n","        # Weight parameter\n","        self.expert_kernels = None\n","        self.gate_kernels = None\n","        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n","        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n","        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n","        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n","        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n","        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n","\n","        # Activation parameter\n","        self.expert_activation = activations.get(expert_activation)\n","        self.gate_activation = activations.get(gate_activation)\n","\n","        # Bias parameter\n","        self.expert_bias = None\n","        self.gate_bias = None\n","        self.use_expert_bias = use_expert_bias\n","        self.use_gate_bias = use_gate_bias\n","        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n","        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n","        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n","        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n","        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n","        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n","\n","        # Activity parameter\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","\n","        # Keras parameter\n","        self.input_spec = InputSpec(min_ndim=2)\n","        self.supports_masking = True\n","\n","        super(MMoE, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        \"\"\"\n","        Method for creating the layer weights.\n","        :param input_shape: Keras tensor (future input to layer)\n","                            or list/tuple of Keras tensors to reference\n","                            for weight shape computations\n","        \"\"\"\n","        assert input_shape is not None and len(input_shape) >= 2\n","\n","        input_dimension = input_shape[-1]\n","\n","        # Initialize expert weights (number of input features * number of units per expert * number of experts)\n","        self.expert_kernels = self.add_weight(\n","            name='expert_kernel',\n","            shape=(input_dimension, self.units, self.num_experts),\n","            initializer=self.expert_kernel_initializer,\n","            regularizer=self.expert_kernel_regularizer,\n","            constraint=self.expert_kernel_constraint,\n","        )\n","\n","        # Initialize expert bias (number of units per expert * number of experts)\n","        if self.use_expert_bias:\n","            self.expert_bias = self.add_weight(\n","                name='expert_bias',\n","                shape=(self.units, self.num_experts),\n","                initializer=self.expert_bias_initializer,\n","                regularizer=self.expert_bias_regularizer,\n","                constraint=self.expert_bias_constraint,\n","            )\n","\n","        # Initialize gate weights (number of input features * number of experts * number of tasks)\n","        self.gate_kernels = [self.add_weight(\n","            name='gate_kernel_task_{}'.format(i),\n","            shape=(input_dimension, self.num_experts),\n","            initializer=self.gate_kernel_initializer,\n","            regularizer=self.gate_kernel_regularizer,\n","            constraint=self.gate_kernel_constraint\n","        ) for i in range(self.num_tasks)]\n","\n","        # Initialize gate bias (number of experts * number of tasks)\n","        if self.use_gate_bias:\n","            self.gate_bias = [self.add_weight(\n","                name='gate_bias_task_{}'.format(i),\n","                shape=(self.num_experts,),\n","                initializer=self.gate_bias_initializer,\n","                regularizer=self.gate_bias_regularizer,\n","                constraint=self.gate_bias_constraint\n","            ) for i in range(self.num_tasks)]\n","\n","        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n","\n","        super(MMoE, self).build(input_shape)\n","\n","    def call(self, inputs, **kwargs):\n","        \"\"\"\n","        Method for the forward function of the layer.\n","        :param inputs: Input tensor\n","        :param kwargs: Additional keyword arguments for the base method\n","        :return: A tensor\n","        \"\"\"\n","        gate_outputs = []\n","        final_outputs = []\n","\n","        # f_{i}(x) = activation(W_{i} * x + b), where activation is ReLU according to the paper\n","        expert_outputs = tf.tensordot(a=inputs, b=self.expert_kernels, axes=1)\n","        # Add the bias term to the expert weights if necessary\n","        if self.use_expert_bias:\n","            expert_outputs = K.bias_add(x=expert_outputs, bias=self.expert_bias)\n","        expert_outputs = self.expert_activation(expert_outputs)\n","\n","        # g^{k}(x) = activation(W_{gk} * x + b), where activation is softmax according to the paper\n","        for index, gate_kernel in enumerate(self.gate_kernels):\n","            gate_output = K.dot(x=inputs, y=gate_kernel)\n","            # Add the bias term to the gate weights if necessary\n","            if self.use_gate_bias:\n","                gate_output = K.bias_add(x=gate_output, bias=self.gate_bias[index])\n","            gate_output = self.gate_activation(gate_output)\n","            gate_outputs.append(gate_output)\n","\n","        # f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x))\n","        for gate_output in gate_outputs:\n","            expanded_gate_output = K.expand_dims(gate_output, axis=1)\n","            weighted_expert_output = expert_outputs * K.repeat_elements(expanded_gate_output, self.units, axis=1)\n","            final_outputs.append(K.sum(weighted_expert_output, axis=2))\n","\n","        return final_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\"\n","        Method for computing the output shape of the MMoE layer.\n","        :param input_shape: Shape tuple (tuple of integers)\n","        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n","        \"\"\"\n","        assert input_shape is not None and len(input_shape) >= 2\n","\n","        output_shape = list(input_shape)\n","        output_shape[-1] = self.units\n","        output_shape = tuple(output_shape)\n","\n","        return [output_shape for _ in range(self.num_tasks)]\n","\n","    def get_config(self):\n","        \"\"\"\n","        Method for returning the configuration of the MMoE layer.\n","        :return: Config dictionary\n","        \"\"\"\n","        config = {\n","            'units': self.units,\n","            'num_experts': self.num_experts,\n","            'num_tasks': self.num_tasks,\n","            'use_expert_bias': self.use_expert_bias,\n","            'use_gate_bias': self.use_gate_bias,\n","            'expert_activation': activations.serialize(self.expert_activation),\n","            'gate_activation': activations.serialize(self.gate_activation),\n","            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n","            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n","            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n","            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n","            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n","            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n","            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n","            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n","            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n","            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n","            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n","            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n","            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n","        }\n","        base_config = super(MMoE, self).get_config()\n","\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SKeCrlb1wJeK"},"source":["## Synthetic data"]},{"cell_type":"code","metadata":{"id":"0k_67dNwwKy9"},"source":["SEED = 1\n","\n","# Fix numpy seed for reproducibility\n","np.random.seed(SEED)\n","\n","# Fix random seed for reproducibility\n","random.seed(SEED)\n","\n","# Fix TensorFlow graph-level seed for reproducibility\n","tf.random.set_seed(SEED)\n","\n","def data_preparation():\n","    # Synthetic data parameters\n","    num_dimension = 100\n","    num_row = 12000\n","    c = 0.3\n","    rho = 0.8\n","    m = 5\n","\n","    # Initialize vectors u1, u2, w1, and w2 according to the paper\n","    mu1 = np.random.normal(size=num_dimension)\n","    mu1 = (mu1 - np.mean(mu1)) / (np.std(mu1) * np.sqrt(num_dimension))\n","    mu2 = np.random.normal(size=num_dimension)\n","    mu2 -= mu2.dot(mu1) * mu1\n","    mu2 /= np.linalg.norm(mu2)\n","    w1 = c * mu1\n","    w2 = c * (rho * mu1 + np.sqrt(1. - rho ** 2) * mu2)\n","\n","    # Feature and label generation\n","    alpha = np.random.normal(size=m)\n","    beta = np.random.normal(size=m)\n","    y0 = []\n","    y1 = []\n","    X = []\n","\n","    for i in range(num_row):\n","        x = np.random.normal(size=num_dimension)\n","        X.append(x)\n","        num1 = w1.dot(x)\n","        num2 = w2.dot(x)\n","        comp1, comp2 = 0.0, 0.0\n","\n","        for j in range(m):\n","            comp1 += np.sin(alpha[j] * num1 + beta[j])\n","            comp2 += np.sin(alpha[j] * num2 + beta[j])\n","\n","        y0.append(num1 + comp1 + np.random.normal(scale=0.1, size=1))\n","        y1.append(num2 + comp2 + np.random.normal(scale=0.1, size=1))\n","\n","    X = np.array(X)\n","    data = pd.DataFrame(\n","        data=X,\n","        index=range(X.shape[0]),\n","        columns=['x{}'.format(it) for it in range(X.shape[1])]\n","    )\n","\n","    train_data = data.iloc[0:10000]\n","    train_label = [y0[0:10000], y1[0:10000]]\n","    validation_data = data.iloc[10000:11000]\n","    validation_label = [y0[10000:11000], y1[10000:11000]]\n","    test_data = data.iloc[11000:]\n","    test_label = [y0[11000:], y1[11000:]]\n","\n","    return train_data, train_label, validation_data, validation_label, test_data, test_label\n","\n","\n","def main():\n","    # Load the data\n","    train_data, train_label, validation_data, validation_label, test_data, test_label = data_preparation()\n","    num_features = train_data.shape[1]\n","\n","    print('Training data shape = {}'.format(train_data.shape))\n","    print('Validation data shape = {}'.format(validation_data.shape))\n","    print('Test data shape = {}'.format(test_data.shape))\n","\n","    # Set up the input layer\n","    input_layer = Input(shape=(num_features,))\n","\n","    # Set up MMoE layer\n","    mmoe_layers = MMoE(\n","        units=16,\n","        num_experts=8,\n","        num_tasks=2\n","    )(input_layer)\n","\n","    output_layers = []\n","\n","    output_info = ['y0', 'y1']\n","\n","    # Build tower layer from MMoE layer\n","    for index, task_layer in enumerate(mmoe_layers):\n","        tower_layer = Dense(\n","            units=8,\n","            activation='relu',\n","            kernel_initializer=VarianceScaling())(task_layer)\n","        output_layer = Dense(\n","            units=1,\n","            name=output_info[index],\n","            activation='linear',\n","            kernel_initializer=VarianceScaling())(tower_layer)\n","        output_layers.append(output_layer)\n","\n","    # Compile model\n","    model = Model(inputs=[input_layer], outputs=output_layers)\n","    learning_rates = [1e-4, 1e-3, 1e-2]\n","    adam_optimizer = Adam(lr=learning_rates[0])\n","    model.compile(\n","        loss={'y0': 'mean_squared_error', 'y1': 'mean_squared_error'},\n","        optimizer=adam_optimizer,\n","        metrics=[metrics.mae]\n","    )\n","\n","    # Print out model architecture summary\n","    model.summary()\n","\n","    # Train the model\n","    model.fit(\n","        x=train_data,\n","        y=train_label,\n","        validation_data=(validation_data, validation_label),\n","        epochs=100\n","    )\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKJhejx-wHPf"},"source":["## Census data"]},{"cell_type":"code","metadata":{"id":"dc-6U8ZVvMBs"},"source":["# !wget -q --show-progress https://github.com/drawbridge/keras-mmoe/raw/master/data/census-income.data.gz\n","# !wget -q --show-progress https://github.com/drawbridge/keras-mmoe/raw/master/data/census-income.test.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAn9qjCyd5xH"},"source":["!git clone -q https://github.com/sparsh-ai/multiobjective-optimizations.git\n","!cp data/census-income.data.gz .\n","!cp data/census-income.test.gz ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEmzJim_woxb"},"source":["# Simple callback to print out ROC-AUC\n","class ROCCallback(Callback):\n","    def __init__(self, training_data, validation_data, test_data):\n","        self.train_X = training_data[0]\n","        self.train_Y = training_data[1]\n","        self.validation_X = validation_data[0]\n","        self.validation_Y = validation_data[1]\n","        self.test_X = test_data[0]\n","        self.test_Y = test_data[1]\n","\n","    def on_train_begin(self, logs={}):\n","        return\n","\n","    def on_train_end(self, logs={}):\n","        return\n","\n","    def on_epoch_begin(self, epoch, logs={}):\n","        return\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        train_prediction = self.model.predict(self.train_X)\n","        validation_prediction = self.model.predict(self.validation_X)\n","        test_prediction = self.model.predict(self.test_X)\n","\n","        # Iterate through each task and output their ROC-AUC across different datasets\n","        for index, output_name in enumerate(self.model.output_names):\n","            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n","            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n","            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n","            print(\n","                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n","                    output_name, round(train_roc_auc, 4),\n","                    output_name, round(validation_roc_auc, 4),\n","                    output_name, round(test_roc_auc, 4)\n","                )\n","            )\n","\n","        return\n","\n","    def on_batch_begin(self, batch, logs={}):\n","        return\n","\n","    def on_batch_end(self, batch, logs={}):\n","        return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrqhkN5BwvSv"},"source":["def data_preparation():\n","    # The column names are from\n","    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n","    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n","                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n","                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n","                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n","                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n","                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n","                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n","\n","    # Load the dataset in Pandas\n","    train_df = pd.read_csv(\n","        'census-income.data.gz',\n","        delimiter=',',\n","        header=None,\n","        index_col=None,\n","        names=column_names\n","    )\n","    other_df = pd.read_csv(\n","        'census-income.test.gz',\n","        delimiter=',',\n","        header=None,\n","        index_col=None,\n","        names=column_names\n","    )\n","\n","    # First group of tasks according to the paper\n","    label_columns = ['income_50k', 'marital_stat']\n","\n","    # One-hot encoding categorical columns\n","    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n","                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n","                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n","                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n","                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n","                           'vet_question']\n","    train_raw_labels = train_df[label_columns]\n","    other_raw_labels = other_df[label_columns]\n","    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n","    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n","\n","    # Filling the missing column in the other set\n","    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n","\n","    # One-hot encoding categorical labels\n","    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n","    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n","    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n","    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n","\n","    dict_outputs = {\n","        'income': train_income.shape[1],\n","        'marital': train_marital.shape[1]\n","    }\n","    dict_train_labels = {\n","        'income': train_income,\n","        'marital': train_marital\n","    }\n","    dict_other_labels = {\n","        'income': other_income,\n","        'marital': other_marital\n","    }\n","    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n","\n","    # Split the other dataset into 1:1 validation to test according to the paper\n","    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n","    test_indices = list(set(transformed_other.index) - set(validation_indices))\n","    validation_data = transformed_other.iloc[validation_indices]\n","    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n","    test_data = transformed_other.iloc[test_indices]\n","    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n","    train_data = transformed_train\n","    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n","\n","    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info\n","\n","\n","def main():\n","    # Load the data\n","    train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n","    num_features = train_data.shape[1]\n","\n","    print('Training data shape = {}'.format(train_data.shape))\n","    print('Validation data shape = {}'.format(validation_data.shape))\n","    print('Test data shape = {}'.format(test_data.shape))\n","\n","    # Set up the input layer\n","    input_layer = Input(shape=(num_features,))\n","\n","    # Set up MMoE layer\n","    mmoe_layers = MMoE(\n","        units=4,\n","        num_experts=8,\n","        num_tasks=2\n","    )(input_layer)\n","\n","    output_layers = []\n","\n","    # Build tower layer from MMoE layer\n","    for index, task_layer in enumerate(mmoe_layers):\n","        tower_layer = Dense(\n","            units=8,\n","            activation='relu',\n","            kernel_initializer=VarianceScaling())(task_layer)\n","        output_layer = Dense(\n","            units=output_info[index][0],\n","            name=output_info[index][1],\n","            activation='softmax',\n","            kernel_initializer=VarianceScaling())(tower_layer)\n","        output_layers.append(output_layer)\n","\n","    # Compile model\n","    model = Model(inputs=[input_layer], outputs=output_layers)\n","    adam_optimizer = Adam()\n","    model.compile(\n","        loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n","        optimizer=adam_optimizer,\n","        metrics=['accuracy']\n","    )\n","\n","    # Print out model architecture summary\n","    model.summary()\n","\n","    # Train the model\n","    model.fit(\n","        x=train_data,\n","        y=train_label,\n","        validation_data=(validation_data, validation_label),\n","        callbacks=[\n","            ROCCallback(\n","                training_data=(train_data, train_label),\n","                validation_data=(validation_data, validation_label),\n","                test_data=(test_data, test_label)\n","            )\n","        ],\n","        epochs=100\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQ0FYhPQwp2f","executionInfo":{"status":"ok","timestamp":1634552808576,"user_tz":-330,"elapsed":2971167,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"f6ca3231-685d-4080-9d63-3c07eabb94b5"},"source":["if __name__ == '__main__':\n","    main()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape = (199523, 499)\n","Validation data shape = (49881, 499)\n","Test data shape = (49881, 499)\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 499)]        0                                            \n","__________________________________________________________________________________________________\n","m_mo_e_1 (MMoE)                 [(None, 4), (None, 4 24000       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 8)            40          m_mo_e_1[0][0]                   \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 8)            40          m_mo_e_1[0][1]                   \n","__________________________________________________________________________________________________\n","income (Dense)                  (None, 2)            18          dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","marital (Dense)                 (None, 2)            18          dense_3[0][0]                    \n","==================================================================================================\n","Total params: 24,116\n","Trainable params: 24,116\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","6236/6236 [==============================] - 19s 3ms/step - loss: 0.4878 - income_loss: 0.1832 - marital_loss: 0.3046 - income_accuracy: 0.9378 - marital_accuracy: 0.8871 - val_loss: 0.4068 - val_income_loss: 0.1630 - val_marital_loss: 0.2438 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9153\n","ROC-AUC-income-Train: 0.9079 ROC-AUC-income-Validation: 0.9087 ROC-AUC-income-Test: 0.9081\n","ROC-AUC-marital-Train: 0.938 ROC-AUC-marital-Validation: 0.9257 ROC-AUC-marital-Test: 0.9257\n","Epoch 2/100\n","6236/6236 [==============================] - 22s 3ms/step - loss: 0.3325 - income_loss: 0.1530 - marital_loss: 0.1795 - income_accuracy: 0.9379 - marital_accuracy: 0.9366 - val_loss: 0.3608 - val_income_loss: 0.1497 - val_marital_loss: 0.2111 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9199\n","ROC-AUC-income-Train: 0.9162 ROC-AUC-income-Validation: 0.9146 ROC-AUC-income-Test: 0.9144\n","ROC-AUC-marital-Train: 0.9857 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9713\n","Epoch 3/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2844 - income_loss: 0.1500 - marital_loss: 0.1344 - income_accuracy: 0.9379 - marital_accuracy: 0.9448 - val_loss: 0.3743 - val_income_loss: 0.1830 - val_marital_loss: 0.1912 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9233\n","ROC-AUC-income-Train: 0.9172 ROC-AUC-income-Validation: 0.9157 ROC-AUC-income-Test: 0.913\n","ROC-AUC-marital-Train: 0.9896 ROC-AUC-marital-Validation: 0.9767 ROC-AUC-marital-Test: 0.9759\n","Epoch 4/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2738 - income_loss: 0.1468 - marital_loss: 0.1270 - income_accuracy: 0.9379 - marital_accuracy: 0.9466 - val_loss: 0.3629 - val_income_loss: 0.1506 - val_marital_loss: 0.2123 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9157\n","ROC-AUC-income-Train: 0.9141 ROC-AUC-income-Validation: 0.9132 ROC-AUC-income-Test: 0.9142\n","ROC-AUC-marital-Train: 0.9909 ROC-AUC-marital-Validation: 0.9764 ROC-AUC-marital-Test: 0.9755\n","Epoch 5/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2602 - income_loss: 0.1433 - marital_loss: 0.1169 - income_accuracy: 0.9379 - marital_accuracy: 0.9507 - val_loss: 0.4082 - val_income_loss: 0.1983 - val_marital_loss: 0.2099 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9169\n","ROC-AUC-income-Train: 0.9247 ROC-AUC-income-Validation: 0.9225 ROC-AUC-income-Test: 0.9201\n","ROC-AUC-marital-Train: 0.9918 ROC-AUC-marital-Validation: 0.9744 ROC-AUC-marital-Test: 0.9735\n","Epoch 6/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2583 - income_loss: 0.1427 - marital_loss: 0.1157 - income_accuracy: 0.9379 - marital_accuracy: 0.9510 - val_loss: 0.4272 - val_income_loss: 0.1736 - val_marital_loss: 0.2536 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9014\n","ROC-AUC-income-Train: 0.9242 ROC-AUC-income-Validation: 0.9219 ROC-AUC-income-Test: 0.9214\n","ROC-AUC-marital-Train: 0.9884 ROC-AUC-marital-Validation: 0.9643 ROC-AUC-marital-Test: 0.9638\n","Epoch 7/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2562 - income_loss: 0.1420 - marital_loss: 0.1143 - income_accuracy: 0.9379 - marital_accuracy: 0.9521 - val_loss: 0.3594 - val_income_loss: 0.1501 - val_marital_loss: 0.2093 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9161\n","ROC-AUC-income-Train: 0.9332 ROC-AUC-income-Validation: 0.9317 ROC-AUC-income-Test: 0.9313\n","ROC-AUC-marital-Train: 0.9929 ROC-AUC-marital-Validation: 0.9746 ROC-AUC-marital-Test: 0.9738\n","Epoch 8/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2547 - income_loss: 0.1417 - marital_loss: 0.1129 - income_accuracy: 0.9381 - marital_accuracy: 0.9513 - val_loss: 0.3981 - val_income_loss: 0.1691 - val_marital_loss: 0.2290 - val_income_accuracy: 0.9384 - val_marital_accuracy: 0.9093\n","ROC-AUC-income-Train: 0.9319 ROC-AUC-income-Validation: 0.9299 ROC-AUC-income-Test: 0.9297\n","ROC-AUC-marital-Train: 0.9916 ROC-AUC-marital-Validation: 0.9707 ROC-AUC-marital-Test: 0.97\n","Epoch 9/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2519 - income_loss: 0.1415 - marital_loss: 0.1104 - income_accuracy: 0.9379 - marital_accuracy: 0.9527 - val_loss: 0.3822 - val_income_loss: 0.1573 - val_marital_loss: 0.2249 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9142\n","ROC-AUC-income-Train: 0.929 ROC-AUC-income-Validation: 0.9244 ROC-AUC-income-Test: 0.923\n","ROC-AUC-marital-Train: 0.9932 ROC-AUC-marital-Validation: 0.9744 ROC-AUC-marital-Test: 0.9736\n","Epoch 10/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2526 - income_loss: 0.1399 - marital_loss: 0.1127 - income_accuracy: 0.9379 - marital_accuracy: 0.9528 - val_loss: 0.3936 - val_income_loss: 0.1452 - val_marital_loss: 0.2484 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9085\n","ROC-AUC-income-Train: 0.9306 ROC-AUC-income-Validation: 0.9308 ROC-AUC-income-Test: 0.9296\n","ROC-AUC-marital-Train: 0.9916 ROC-AUC-marital-Validation: 0.9702 ROC-AUC-marital-Test: 0.9697\n","Epoch 11/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2454 - income_loss: 0.1382 - marital_loss: 0.1073 - income_accuracy: 0.9393 - marital_accuracy: 0.9532 - val_loss: 0.4045 - val_income_loss: 0.1691 - val_marital_loss: 0.2353 - val_income_accuracy: 0.9352 - val_marital_accuracy: 0.9064\n","ROC-AUC-income-Train: 0.9326 ROC-AUC-income-Validation: 0.9297 ROC-AUC-income-Test: 0.9285\n","ROC-AUC-marital-Train: 0.9929 ROC-AUC-marital-Validation: 0.9714 ROC-AUC-marital-Test: 0.9709\n","Epoch 12/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2426 - income_loss: 0.1369 - marital_loss: 0.1057 - income_accuracy: 0.9397 - marital_accuracy: 0.9543 - val_loss: 0.4535 - val_income_loss: 0.2296 - val_marital_loss: 0.2238 - val_income_accuracy: 0.9315 - val_marital_accuracy: 0.9156\n","ROC-AUC-income-Train: 0.9 ROC-AUC-income-Validation: 0.8918 ROC-AUC-income-Test: 0.8949\n","ROC-AUC-marital-Train: 0.9926 ROC-AUC-marital-Validation: 0.9723 ROC-AUC-marital-Test: 0.9716\n","Epoch 13/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2426 - income_loss: 0.1364 - marital_loss: 0.1061 - income_accuracy: 0.9435 - marital_accuracy: 0.9540 - val_loss: 0.3841 - val_income_loss: 0.1415 - val_marital_loss: 0.2426 - val_income_accuracy: 0.9476 - val_marital_accuracy: 0.9075\n","ROC-AUC-income-Train: 0.9372 ROC-AUC-income-Validation: 0.9363 ROC-AUC-income-Test: 0.9349\n","ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9711 ROC-AUC-marital-Test: 0.9702\n","Epoch 14/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2395 - income_loss: 0.1351 - marital_loss: 0.1044 - income_accuracy: 0.9439 - marital_accuracy: 0.9547 - val_loss: 0.3808 - val_income_loss: 0.1649 - val_marital_loss: 0.2159 - val_income_accuracy: 0.9454 - val_marital_accuracy: 0.9155\n","ROC-AUC-income-Train: 0.9409 ROC-AUC-income-Validation: 0.9374 ROC-AUC-income-Test: 0.9361\n","ROC-AUC-marital-Train: 0.9933 ROC-AUC-marital-Validation: 0.9736 ROC-AUC-marital-Test: 0.9729\n","Epoch 15/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2399 - income_loss: 0.1358 - marital_loss: 0.1042 - income_accuracy: 0.9418 - marital_accuracy: 0.9550 - val_loss: 0.4345 - val_income_loss: 0.1799 - val_marital_loss: 0.2546 - val_income_accuracy: 0.9431 - val_marital_accuracy: 0.9055\n","ROC-AUC-income-Train: 0.9321 ROC-AUC-income-Validation: 0.9295 ROC-AUC-income-Test: 0.927\n","ROC-AUC-marital-Train: 0.9919 ROC-AUC-marital-Validation: 0.9698 ROC-AUC-marital-Test: 0.9691\n","Epoch 16/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2398 - income_loss: 0.1358 - marital_loss: 0.1041 - income_accuracy: 0.9430 - marital_accuracy: 0.9547 - val_loss: 0.4354 - val_income_loss: 0.1728 - val_marital_loss: 0.2625 - val_income_accuracy: 0.9439 - val_marital_accuracy: 0.9017\n","ROC-AUC-income-Train: 0.9371 ROC-AUC-income-Validation: 0.9348 ROC-AUC-income-Test: 0.9336\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9711 ROC-AUC-marital-Test: 0.9703\n","Epoch 17/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2360 - income_loss: 0.1344 - marital_loss: 0.1017 - income_accuracy: 0.9441 - marital_accuracy: 0.9556 - val_loss: 0.4007 - val_income_loss: 0.1494 - val_marital_loss: 0.2513 - val_income_accuracy: 0.9448 - val_marital_accuracy: 0.9126\n","ROC-AUC-income-Train: 0.9362 ROC-AUC-income-Validation: 0.9339 ROC-AUC-income-Test: 0.9329\n","ROC-AUC-marital-Train: 0.9927 ROC-AUC-marital-Validation: 0.9762 ROC-AUC-marital-Test: 0.9756\n","Epoch 18/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2366 - income_loss: 0.1343 - marital_loss: 0.1024 - income_accuracy: 0.9445 - marital_accuracy: 0.9556 - val_loss: 0.3909 - val_income_loss: 0.1675 - val_marital_loss: 0.2234 - val_income_accuracy: 0.9442 - val_marital_accuracy: 0.9141\n","ROC-AUC-income-Train: 0.9394 ROC-AUC-income-Validation: 0.9359 ROC-AUC-income-Test: 0.935\n","ROC-AUC-marital-Train: 0.9912 ROC-AUC-marital-Validation: 0.9725 ROC-AUC-marital-Test: 0.9717\n","Epoch 19/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2388 - income_loss: 0.1333 - marital_loss: 0.1055 - income_accuracy: 0.9449 - marital_accuracy: 0.9551 - val_loss: 0.4076 - val_income_loss: 0.1660 - val_marital_loss: 0.2416 - val_income_accuracy: 0.9463 - val_marital_accuracy: 0.9047\n","ROC-AUC-income-Train: 0.9406 ROC-AUC-income-Validation: 0.9386 ROC-AUC-income-Test: 0.9372\n","ROC-AUC-marital-Train: 0.9936 ROC-AUC-marital-Validation: 0.9718 ROC-AUC-marital-Test: 0.971\n","Epoch 20/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2359 - income_loss: 0.1332 - marital_loss: 0.1027 - income_accuracy: 0.9451 - marital_accuracy: 0.9555 - val_loss: 0.4299 - val_income_loss: 0.1784 - val_marital_loss: 0.2515 - val_income_accuracy: 0.9447 - val_marital_accuracy: 0.9004\n","ROC-AUC-income-Train: 0.9433 ROC-AUC-income-Validation: 0.9404 ROC-AUC-income-Test: 0.9393\n","ROC-AUC-marital-Train: 0.9936 ROC-AUC-marital-Validation: 0.9683 ROC-AUC-marital-Test: 0.9675\n","Epoch 21/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2354 - income_loss: 0.1330 - marital_loss: 0.1024 - income_accuracy: 0.9470 - marital_accuracy: 0.9559 - val_loss: 0.4072 - val_income_loss: 0.1631 - val_marital_loss: 0.2441 - val_income_accuracy: 0.9406 - val_marital_accuracy: 0.9023\n","ROC-AUC-income-Train: 0.9363 ROC-AUC-income-Validation: 0.9323 ROC-AUC-income-Test: 0.9313\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9711 ROC-AUC-marital-Test: 0.9702\n","Epoch 22/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2372 - income_loss: 0.1329 - marital_loss: 0.1043 - income_accuracy: 0.9473 - marital_accuracy: 0.9553 - val_loss: 0.4273 - val_income_loss: 0.1670 - val_marital_loss: 0.2603 - val_income_accuracy: 0.9383 - val_marital_accuracy: 0.9073\n","ROC-AUC-income-Train: 0.9339 ROC-AUC-income-Validation: 0.9285 ROC-AUC-income-Test: 0.9258\n","ROC-AUC-marital-Train: 0.9934 ROC-AUC-marital-Validation: 0.9694 ROC-AUC-marital-Test: 0.9683\n","Epoch 23/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2414 - income_loss: 0.1336 - marital_loss: 0.1077 - income_accuracy: 0.9472 - marital_accuracy: 0.9552 - val_loss: 0.4415 - val_income_loss: 0.1976 - val_marital_loss: 0.2439 - val_income_accuracy: 0.9428 - val_marital_accuracy: 0.9133\n","ROC-AUC-income-Train: 0.941 ROC-AUC-income-Validation: 0.9377 ROC-AUC-income-Test: 0.9364\n","ROC-AUC-marital-Train: 0.9926 ROC-AUC-marital-Validation: 0.9736 ROC-AUC-marital-Test: 0.9726\n","Epoch 24/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2361 - income_loss: 0.1331 - marital_loss: 0.1030 - income_accuracy: 0.9460 - marital_accuracy: 0.9549 - val_loss: 0.4271 - val_income_loss: 0.1911 - val_marital_loss: 0.2360 - val_income_accuracy: 0.9422 - val_marital_accuracy: 0.9101\n","ROC-AUC-income-Train: 0.9431 ROC-AUC-income-Validation: 0.9395 ROC-AUC-income-Test: 0.938\n","ROC-AUC-marital-Train: 0.9933 ROC-AUC-marital-Validation: 0.9714 ROC-AUC-marital-Test: 0.9703\n","Epoch 25/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2346 - income_loss: 0.1314 - marital_loss: 0.1031 - income_accuracy: 0.9476 - marital_accuracy: 0.9550 - val_loss: 0.4053 - val_income_loss: 0.1684 - val_marital_loss: 0.2369 - val_income_accuracy: 0.9451 - val_marital_accuracy: 0.9126\n","ROC-AUC-income-Train: 0.9442 ROC-AUC-income-Validation: 0.941 ROC-AUC-income-Test: 0.9399\n","ROC-AUC-marital-Train: 0.9927 ROC-AUC-marital-Validation: 0.9735 ROC-AUC-marital-Test: 0.9728\n","Epoch 26/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2343 - income_loss: 0.1316 - marital_loss: 0.1027 - income_accuracy: 0.9481 - marital_accuracy: 0.9550 - val_loss: 0.4045 - val_income_loss: 0.1808 - val_marital_loss: 0.2238 - val_income_accuracy: 0.9448 - val_marital_accuracy: 0.9117\n","ROC-AUC-income-Train: 0.9423 ROC-AUC-income-Validation: 0.939 ROC-AUC-income-Test: 0.9378\n","ROC-AUC-marital-Train: 0.9938 ROC-AUC-marital-Validation: 0.9738 ROC-AUC-marital-Test: 0.9729\n","Epoch 27/100\n","6236/6236 [==============================] - 21s 3ms/step - loss: 0.2341 - income_loss: 0.1312 - marital_loss: 0.1029 - income_accuracy: 0.9491 - marital_accuracy: 0.9549 - val_loss: 0.4414 - val_income_loss: 0.1712 - val_marital_loss: 0.2702 - val_income_accuracy: 0.9445 - val_marital_accuracy: 0.9091\n","ROC-AUC-income-Train: 0.9395 ROC-AUC-income-Validation: 0.9362 ROC-AUC-income-Test: 0.9345\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9721 ROC-AUC-marital-Test: 0.9713\n","Epoch 28/100\n","6236/6236 [==============================] - 25s 4ms/step - loss: 0.2324 - income_loss: 0.1303 - marital_loss: 0.1021 - income_accuracy: 0.9490 - marital_accuracy: 0.9554 - val_loss: 0.4315 - val_income_loss: 0.1675 - val_marital_loss: 0.2640 - val_income_accuracy: 0.9467 - val_marital_accuracy: 0.8931\n","ROC-AUC-income-Train: 0.9441 ROC-AUC-income-Validation: 0.9405 ROC-AUC-income-Test: 0.939\n","ROC-AUC-marital-Train: 0.9909 ROC-AUC-marital-Validation: 0.9646 ROC-AUC-marital-Test: 0.964\n","Epoch 29/100\n","6236/6236 [==============================] - 23s 4ms/step - loss: 0.2341 - income_loss: 0.1319 - marital_loss: 0.1022 - income_accuracy: 0.9468 - marital_accuracy: 0.9556 - val_loss: 0.4096 - val_income_loss: 0.1656 - val_marital_loss: 0.2440 - val_income_accuracy: 0.9440 - val_marital_accuracy: 0.9120\n","ROC-AUC-income-Train: 0.9402 ROC-AUC-income-Validation: 0.936 ROC-AUC-income-Test: 0.935\n","ROC-AUC-marital-Train: 0.9927 ROC-AUC-marital-Validation: 0.9725 ROC-AUC-marital-Test: 0.9716\n","Epoch 30/100\n","6236/6236 [==============================] - 23s 4ms/step - loss: 0.2330 - income_loss: 0.1310 - marital_loss: 0.1019 - income_accuracy: 0.9494 - marital_accuracy: 0.9555 - val_loss: 0.4374 - val_income_loss: 0.1822 - val_marital_loss: 0.2552 - val_income_accuracy: 0.9412 - val_marital_accuracy: 0.9118\n","ROC-AUC-income-Train: 0.9416 ROC-AUC-income-Validation: 0.9364 ROC-AUC-income-Test: 0.9363\n","ROC-AUC-marital-Train: 0.9932 ROC-AUC-marital-Validation: 0.9728 ROC-AUC-marital-Test: 0.9723\n","Epoch 31/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2318 - income_loss: 0.1315 - marital_loss: 0.1003 - income_accuracy: 0.9498 - marital_accuracy: 0.9559 - val_loss: 0.4398 - val_income_loss: 0.1761 - val_marital_loss: 0.2637 - val_income_accuracy: 0.9446 - val_marital_accuracy: 0.9093\n","ROC-AUC-income-Train: 0.9434 ROC-AUC-income-Validation: 0.9383 ROC-AUC-income-Test: 0.9371\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9721 ROC-AUC-marital-Test: 0.9711\n","Epoch 32/100\n","6236/6236 [==============================] - 19s 3ms/step - loss: 0.2321 - income_loss: 0.1299 - marital_loss: 0.1022 - income_accuracy: 0.9486 - marital_accuracy: 0.9556 - val_loss: 0.4243 - val_income_loss: 0.1635 - val_marital_loss: 0.2608 - val_income_accuracy: 0.9466 - val_marital_accuracy: 0.9036\n","ROC-AUC-income-Train: 0.9409 ROC-AUC-income-Validation: 0.9371 ROC-AUC-income-Test: 0.9356\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9708 ROC-AUC-marital-Test: 0.9697\n","Epoch 33/100\n","6236/6236 [==============================] - 19s 3ms/step - loss: 0.2318 - income_loss: 0.1313 - marital_loss: 0.1005 - income_accuracy: 0.9490 - marital_accuracy: 0.9559 - val_loss: 0.3851 - val_income_loss: 0.1589 - val_marital_loss: 0.2262 - val_income_accuracy: 0.9461 - val_marital_accuracy: 0.9136\n","ROC-AUC-income-Train: 0.942 ROC-AUC-income-Validation: 0.9382 ROC-AUC-income-Test: 0.937\n","ROC-AUC-marital-Train: 0.9929 ROC-AUC-marital-Validation: 0.9718 ROC-AUC-marital-Test: 0.9711\n","Epoch 34/100\n","6236/6236 [==============================] - 16s 2ms/step - loss: 0.2322 - income_loss: 0.1315 - marital_loss: 0.1007 - income_accuracy: 0.9494 - marital_accuracy: 0.9555 - val_loss: 0.4588 - val_income_loss: 0.2103 - val_marital_loss: 0.2485 - val_income_accuracy: 0.9449 - val_marital_accuracy: 0.9063\n","ROC-AUC-income-Train: 0.9024 ROC-AUC-income-Validation: 0.8959 ROC-AUC-income-Test: 0.8977\n","ROC-AUC-marital-Train: 0.9933 ROC-AUC-marital-Validation: 0.9695 ROC-AUC-marital-Test: 0.9687\n","Epoch 35/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2327 - income_loss: 0.1316 - marital_loss: 0.1011 - income_accuracy: 0.9493 - marital_accuracy: 0.9562 - val_loss: 0.3952 - val_income_loss: 0.1719 - val_marital_loss: 0.2234 - val_income_accuracy: 0.9435 - val_marital_accuracy: 0.9151\n","ROC-AUC-income-Train: 0.937 ROC-AUC-income-Validation: 0.9323 ROC-AUC-income-Test: 0.9316\n","ROC-AUC-marital-Train: 0.9932 ROC-AUC-marital-Validation: 0.9748 ROC-AUC-marital-Test: 0.9738\n","Epoch 36/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2300 - income_loss: 0.1293 - marital_loss: 0.1006 - income_accuracy: 0.9492 - marital_accuracy: 0.9559 - val_loss: 0.4054 - val_income_loss: 0.1813 - val_marital_loss: 0.2241 - val_income_accuracy: 0.9396 - val_marital_accuracy: 0.9091\n","ROC-AUC-income-Train: 0.9154 ROC-AUC-income-Validation: 0.9077 ROC-AUC-income-Test: 0.9088\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9726 ROC-AUC-marital-Test: 0.9716\n","Epoch 37/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2319 - income_loss: 0.1315 - marital_loss: 0.1004 - income_accuracy: 0.9496 - marital_accuracy: 0.9557 - val_loss: 0.4367 - val_income_loss: 0.2053 - val_marital_loss: 0.2314 - val_income_accuracy: 0.9422 - val_marital_accuracy: 0.9143\n","ROC-AUC-income-Train: 0.9443 ROC-AUC-income-Validation: 0.9395 ROC-AUC-income-Test: 0.938\n","ROC-AUC-marital-Train: 0.9937 ROC-AUC-marital-Validation: 0.9731 ROC-AUC-marital-Test: 0.9723\n","Epoch 38/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2314 - income_loss: 0.1318 - marital_loss: 0.0996 - income_accuracy: 0.9492 - marital_accuracy: 0.9556 - val_loss: 0.4146 - val_income_loss: 0.1687 - val_marital_loss: 0.2459 - val_income_accuracy: 0.9466 - val_marital_accuracy: 0.9108\n","ROC-AUC-income-Train: 0.944 ROC-AUC-income-Validation: 0.9374 ROC-AUC-income-Test: 0.9363\n","ROC-AUC-marital-Train: 0.9934 ROC-AUC-marital-Validation: 0.9715 ROC-AUC-marital-Test: 0.9706\n","Epoch 39/100\n","6236/6236 [==============================] - 20s 3ms/step - loss: 0.2302 - income_loss: 0.1304 - marital_loss: 0.0998 - income_accuracy: 0.9501 - marital_accuracy: 0.9563 - val_loss: 0.4248 - val_income_loss: 0.1821 - val_marital_loss: 0.2428 - val_income_accuracy: 0.9441 - val_marital_accuracy: 0.9094\n","ROC-AUC-income-Train: 0.9439 ROC-AUC-income-Validation: 0.9394 ROC-AUC-income-Test: 0.9383\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9708\n","Epoch 40/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2289 - income_loss: 0.1298 - marital_loss: 0.0991 - income_accuracy: 0.9487 - marital_accuracy: 0.9559 - val_loss: 0.4881 - val_income_loss: 0.2320 - val_marital_loss: 0.2561 - val_income_accuracy: 0.9404 - val_marital_accuracy: 0.9103\n","ROC-AUC-income-Train: 0.9411 ROC-AUC-income-Validation: 0.9346 ROC-AUC-income-Test: 0.9342\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.9717 ROC-AUC-marital-Test: 0.9708\n","Epoch 41/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2314 - income_loss: 0.1315 - marital_loss: 0.0999 - income_accuracy: 0.9486 - marital_accuracy: 0.9564 - val_loss: 0.4375 - val_income_loss: 0.1841 - val_marital_loss: 0.2534 - val_income_accuracy: 0.9424 - val_marital_accuracy: 0.9090\n","ROC-AUC-income-Train: 0.9402 ROC-AUC-income-Validation: 0.935 ROC-AUC-income-Test: 0.9343\n","ROC-AUC-marital-Train: 0.9932 ROC-AUC-marital-Validation: 0.9704 ROC-AUC-marital-Test: 0.9697\n","Epoch 42/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2293 - income_loss: 0.1310 - marital_loss: 0.0983 - income_accuracy: 0.9475 - marital_accuracy: 0.9563 - val_loss: 0.4033 - val_income_loss: 0.1869 - val_marital_loss: 0.2164 - val_income_accuracy: 0.9418 - val_marital_accuracy: 0.9142\n","ROC-AUC-income-Train: 0.9383 ROC-AUC-income-Validation: 0.9336 ROC-AUC-income-Test: 0.9326\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9738 ROC-AUC-marital-Test: 0.9727\n","Epoch 43/100\n","6236/6236 [==============================] - 16s 2ms/step - loss: 0.2311 - income_loss: 0.1307 - marital_loss: 0.1004 - income_accuracy: 0.9481 - marital_accuracy: 0.9563 - val_loss: 0.4265 - val_income_loss: 0.1820 - val_marital_loss: 0.2446 - val_income_accuracy: 0.9435 - val_marital_accuracy: 0.9107\n","ROC-AUC-income-Train: 0.9446 ROC-AUC-income-Validation: 0.9398 ROC-AUC-income-Test: 0.9389\n","ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9707 ROC-AUC-marital-Test: 0.9699\n","Epoch 44/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2296 - income_loss: 0.1314 - marital_loss: 0.0982 - income_accuracy: 0.9496 - marital_accuracy: 0.9569 - val_loss: 0.4512 - val_income_loss: 0.1911 - val_marital_loss: 0.2601 - val_income_accuracy: 0.9459 - val_marital_accuracy: 0.9119\n","ROC-AUC-income-Train: 0.9413 ROC-AUC-income-Validation: 0.9364 ROC-AUC-income-Test: 0.9353\n","ROC-AUC-marital-Train: 0.993 ROC-AUC-marital-Validation: 0.97 ROC-AUC-marital-Test: 0.9694\n","Epoch 45/100\n","6236/6236 [==============================] - 16s 2ms/step - loss: 0.2283 - income_loss: 0.1298 - marital_loss: 0.0984 - income_accuracy: 0.9480 - marital_accuracy: 0.9564 - val_loss: 0.4141 - val_income_loss: 0.1790 - val_marital_loss: 0.2351 - val_income_accuracy: 0.9424 - val_marital_accuracy: 0.9112\n","ROC-AUC-income-Train: 0.9434 ROC-AUC-income-Validation: 0.9379 ROC-AUC-income-Test: 0.9379\n","ROC-AUC-marital-Train: 0.9934 ROC-AUC-marital-Validation: 0.9734 ROC-AUC-marital-Test: 0.9726\n","Epoch 46/100\n","6236/6236 [==============================] - 15s 2ms/step - loss: 0.2276 - income_loss: 0.1292 - marital_loss: 0.0984 - income_accuracy: 0.9494 - marital_accuracy: 0.9565 - val_loss: 0.4280 - val_income_loss: 0.1889 - val_marital_loss: 0.2391 - val_income_accuracy: 0.9452 - val_marital_accuracy: 0.9097\n","ROC-AUC-income-Train: 0.9441 ROC-AUC-income-Validation: 0.9398 ROC-AUC-income-Test: 0.9387\n","ROC-AUC-marital-Train: 0.9934 ROC-AUC-marital-Validation: 0.9712 ROC-AUC-marital-Test: 0.9704\n","Epoch 47/100\n","6236/6236 [==============================] - 21s 3ms/step - loss: 0.2271 - income_loss: 0.1293 - marital_loss: 0.0978 - income_accuracy: 0.9492 - marital_accuracy: 0.9568 - val_loss: 0.4257 - val_income_loss: 0.1765 - val_marital_loss: 0.2492 - val_income_accuracy: 0.9444 - val_marital_accuracy: 0.9032\n","ROC-AUC-income-Train: 0.9444 ROC-AUC-income-Validation: 0.9394 ROC-AUC-income-Test: 0.9386\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.9707 ROC-AUC-marital-Test: 0.9698\n","Epoch 48/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2275 - income_loss: 0.1299 - marital_loss: 0.0976 - income_accuracy: 0.9492 - marital_accuracy: 0.9570 - val_loss: 0.4601 - val_income_loss: 0.1796 - val_marital_loss: 0.2805 - val_income_accuracy: 0.9455 - val_marital_accuracy: 0.9046\n","ROC-AUC-income-Train: 0.9369 ROC-AUC-income-Validation: 0.9322 ROC-AUC-income-Test: 0.9301\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.971 ROC-AUC-marital-Test: 0.97\n","Epoch 49/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2278 - income_loss: 0.1298 - marital_loss: 0.0980 - income_accuracy: 0.9489 - marital_accuracy: 0.9567 - val_loss: 0.4148 - val_income_loss: 0.1683 - val_marital_loss: 0.2465 - val_income_accuracy: 0.9458 - val_marital_accuracy: 0.9078\n","ROC-AUC-income-Train: 0.9399 ROC-AUC-income-Validation: 0.9361 ROC-AUC-income-Test: 0.935\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9707\n","Epoch 50/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2282 - income_loss: 0.1305 - marital_loss: 0.0978 - income_accuracy: 0.9491 - marital_accuracy: 0.9570 - val_loss: 0.4584 - val_income_loss: 0.1842 - val_marital_loss: 0.2742 - val_income_accuracy: 0.9440 - val_marital_accuracy: 0.9028\n","ROC-AUC-income-Train: 0.9429 ROC-AUC-income-Validation: 0.9373 ROC-AUC-income-Test: 0.9364\n","ROC-AUC-marital-Train: 0.993 ROC-AUC-marital-Validation: 0.97 ROC-AUC-marital-Test: 0.969\n","Epoch 51/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2285 - income_loss: 0.1300 - marital_loss: 0.0985 - income_accuracy: 0.9503 - marital_accuracy: 0.9566 - val_loss: 0.4055 - val_income_loss: 0.1864 - val_marital_loss: 0.2191 - val_income_accuracy: 0.9449 - val_marital_accuracy: 0.9139\n","ROC-AUC-income-Train: 0.9433 ROC-AUC-income-Validation: 0.9383 ROC-AUC-income-Test: 0.9375\n","ROC-AUC-marital-Train: 0.9937 ROC-AUC-marital-Validation: 0.9742 ROC-AUC-marital-Test: 0.9731\n","Epoch 52/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2268 - income_loss: 0.1286 - marital_loss: 0.0982 - income_accuracy: 0.9504 - marital_accuracy: 0.9570 - val_loss: 0.4449 - val_income_loss: 0.1879 - val_marital_loss: 0.2570 - val_income_accuracy: 0.9420 - val_marital_accuracy: 0.9010\n","ROC-AUC-income-Train: 0.9387 ROC-AUC-income-Validation: 0.9336 ROC-AUC-income-Test: 0.9332\n","ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.97 ROC-AUC-marital-Test: 0.9691\n","Epoch 53/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2259 - income_loss: 0.1281 - marital_loss: 0.0978 - income_accuracy: 0.9503 - marital_accuracy: 0.9567 - val_loss: 0.4288 - val_income_loss: 0.1821 - val_marital_loss: 0.2468 - val_income_accuracy: 0.9456 - val_marital_accuracy: 0.8988\n","ROC-AUC-income-Train: 0.9436 ROC-AUC-income-Validation: 0.9376 ROC-AUC-income-Test: 0.9369\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9702 ROC-AUC-marital-Test: 0.9692\n","Epoch 54/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2252 - income_loss: 0.1282 - marital_loss: 0.0970 - income_accuracy: 0.9496 - marital_accuracy: 0.9575 - val_loss: 0.4368 - val_income_loss: 0.1865 - val_marital_loss: 0.2503 - val_income_accuracy: 0.9440 - val_marital_accuracy: 0.9059\n","ROC-AUC-income-Train: 0.9423 ROC-AUC-income-Validation: 0.9363 ROC-AUC-income-Test: 0.9357\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.9713 ROC-AUC-marital-Test: 0.9702\n","Epoch 55/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2272 - income_loss: 0.1298 - marital_loss: 0.0974 - income_accuracy: 0.9500 - marital_accuracy: 0.9569 - val_loss: 0.4551 - val_income_loss: 0.1843 - val_marital_loss: 0.2707 - val_income_accuracy: 0.9439 - val_marital_accuracy: 0.9024\n","ROC-AUC-income-Train: 0.9408 ROC-AUC-income-Validation: 0.9338 ROC-AUC-income-Test: 0.9333\n","ROC-AUC-marital-Train: 0.9937 ROC-AUC-marital-Validation: 0.9694 ROC-AUC-marital-Test: 0.9684\n","Epoch 56/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2266 - income_loss: 0.1287 - marital_loss: 0.0979 - income_accuracy: 0.9511 - marital_accuracy: 0.9570 - val_loss: 0.4020 - val_income_loss: 0.1608 - val_marital_loss: 0.2412 - val_income_accuracy: 0.9445 - val_marital_accuracy: 0.9107\n","ROC-AUC-income-Train: 0.9443 ROC-AUC-income-Validation: 0.9391 ROC-AUC-income-Test: 0.9383\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9743 ROC-AUC-marital-Test: 0.9734\n","Epoch 57/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2224 - income_loss: 0.1266 - marital_loss: 0.0957 - income_accuracy: 0.9513 - marital_accuracy: 0.9571 - val_loss: 0.4548 - val_income_loss: 0.2151 - val_marital_loss: 0.2398 - val_income_accuracy: 0.9447 - val_marital_accuracy: 0.9109\n","ROC-AUC-income-Train: 0.9403 ROC-AUC-income-Validation: 0.9351 ROC-AUC-income-Test: 0.9331\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9742 ROC-AUC-marital-Test: 0.9735\n","Epoch 58/100\n","6236/6236 [==============================] - 16s 2ms/step - loss: 0.2247 - income_loss: 0.1275 - marital_loss: 0.0972 - income_accuracy: 0.9507 - marital_accuracy: 0.9574 - val_loss: 0.4973 - val_income_loss: 0.2313 - val_marital_loss: 0.2660 - val_income_accuracy: 0.9394 - val_marital_accuracy: 0.9059\n","ROC-AUC-income-Train: 0.9415 ROC-AUC-income-Validation: 0.9336 ROC-AUC-income-Test: 0.9342\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.972 ROC-AUC-marital-Test: 0.9707\n","Epoch 59/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2241 - income_loss: 0.1273 - marital_loss: 0.0968 - income_accuracy: 0.9505 - marital_accuracy: 0.9571 - val_loss: 0.4732 - val_income_loss: 0.1971 - val_marital_loss: 0.2761 - val_income_accuracy: 0.9450 - val_marital_accuracy: 0.9098\n","ROC-AUC-income-Train: 0.941 ROC-AUC-income-Validation: 0.9358 ROC-AUC-income-Test: 0.9347\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9742 ROC-AUC-marital-Test: 0.9734\n","Epoch 60/100\n","6236/6236 [==============================] - 16s 2ms/step - loss: 0.2245 - income_loss: 0.1277 - marital_loss: 0.0968 - income_accuracy: 0.9499 - marital_accuracy: 0.9571 - val_loss: 0.4431 - val_income_loss: 0.1711 - val_marital_loss: 0.2719 - val_income_accuracy: 0.9419 - val_marital_accuracy: 0.9069\n","ROC-AUC-income-Train: 0.9421 ROC-AUC-income-Validation: 0.9355 ROC-AUC-income-Test: 0.9355\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9722 ROC-AUC-marital-Test: 0.9711\n","Epoch 61/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2257 - income_loss: 0.1284 - marital_loss: 0.0973 - income_accuracy: 0.9499 - marital_accuracy: 0.9575 - val_loss: 0.4493 - val_income_loss: 0.1729 - val_marital_loss: 0.2764 - val_income_accuracy: 0.9441 - val_marital_accuracy: 0.9108\n","ROC-AUC-income-Train: 0.9441 ROC-AUC-income-Validation: 0.9383 ROC-AUC-income-Test: 0.937\n","ROC-AUC-marital-Train: 0.9938 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9708\n","Epoch 62/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2251 - income_loss: 0.1279 - marital_loss: 0.0972 - income_accuracy: 0.9505 - marital_accuracy: 0.9571 - val_loss: 0.4082 - val_income_loss: 0.1659 - val_marital_loss: 0.2423 - val_income_accuracy: 0.9457 - val_marital_accuracy: 0.9125\n","ROC-AUC-income-Train: 0.9442 ROC-AUC-income-Validation: 0.938 ROC-AUC-income-Test: 0.937\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9738 ROC-AUC-marital-Test: 0.973\n","Epoch 63/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2256 - income_loss: 0.1289 - marital_loss: 0.0967 - income_accuracy: 0.9504 - marital_accuracy: 0.9573 - val_loss: 0.4234 - val_income_loss: 0.2002 - val_marital_loss: 0.2232 - val_income_accuracy: 0.9430 - val_marital_accuracy: 0.9140\n","ROC-AUC-income-Train: 0.9441 ROC-AUC-income-Validation: 0.9364 ROC-AUC-income-Test: 0.9359\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9776 ROC-AUC-marital-Test: 0.9768\n","Epoch 64/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2243 - income_loss: 0.1273 - marital_loss: 0.0970 - income_accuracy: 0.9509 - marital_accuracy: 0.9572 - val_loss: 0.4273 - val_income_loss: 0.1714 - val_marital_loss: 0.2559 - val_income_accuracy: 0.9444 - val_marital_accuracy: 0.9061\n","ROC-AUC-income-Train: 0.944 ROC-AUC-income-Validation: 0.9382 ROC-AUC-income-Test: 0.9374\n","ROC-AUC-marital-Train: 0.9936 ROC-AUC-marital-Validation: 0.9714 ROC-AUC-marital-Test: 0.9703\n","Epoch 65/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2237 - income_loss: 0.1268 - marital_loss: 0.0969 - income_accuracy: 0.9513 - marital_accuracy: 0.9573 - val_loss: 0.4625 - val_income_loss: 0.1973 - val_marital_loss: 0.2653 - val_income_accuracy: 0.9441 - val_marital_accuracy: 0.9086\n","ROC-AUC-income-Train: 0.9456 ROC-AUC-income-Validation: 0.9394 ROC-AUC-income-Test: 0.9387\n","ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9714 ROC-AUC-marital-Test: 0.9706\n","Epoch 66/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2243 - income_loss: 0.1271 - marital_loss: 0.0971 - income_accuracy: 0.9505 - marital_accuracy: 0.9571 - val_loss: 0.4533 - val_income_loss: 0.1905 - val_marital_loss: 0.2629 - val_income_accuracy: 0.9456 - val_marital_accuracy: 0.9096\n","ROC-AUC-income-Train: 0.9443 ROC-AUC-income-Validation: 0.9385 ROC-AUC-income-Test: 0.9376\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9736 ROC-AUC-marital-Test: 0.9728\n","Epoch 67/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2251 - income_loss: 0.1285 - marital_loss: 0.0966 - income_accuracy: 0.9506 - marital_accuracy: 0.9575 - val_loss: 0.4970 - val_income_loss: 0.2239 - val_marital_loss: 0.2731 - val_income_accuracy: 0.9420 - val_marital_accuracy: 0.9091\n","ROC-AUC-income-Train: 0.9145 ROC-AUC-income-Validation: 0.9053 ROC-AUC-income-Test: 0.907\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.9745 ROC-AUC-marital-Test: 0.9738\n","Epoch 68/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2245 - income_loss: 0.1286 - marital_loss: 0.0959 - income_accuracy: 0.9506 - marital_accuracy: 0.9572 - val_loss: 0.4594 - val_income_loss: 0.1832 - val_marital_loss: 0.2762 - val_income_accuracy: 0.9437 - val_marital_accuracy: 0.9099\n","ROC-AUC-income-Train: 0.9452 ROC-AUC-income-Validation: 0.938 ROC-AUC-income-Test: 0.9379\n","ROC-AUC-marital-Train: 0.9937 ROC-AUC-marital-Validation: 0.9724 ROC-AUC-marital-Test: 0.9718\n","Epoch 69/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2249 - income_loss: 0.1294 - marital_loss: 0.0955 - income_accuracy: 0.9512 - marital_accuracy: 0.9577 - val_loss: 0.4537 - val_income_loss: 0.1891 - val_marital_loss: 0.2646 - val_income_accuracy: 0.9437 - val_marital_accuracy: 0.9096\n","ROC-AUC-income-Train: 0.9446 ROC-AUC-income-Validation: 0.9374 ROC-AUC-income-Test: 0.9381\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9737 ROC-AUC-marital-Test: 0.973\n","Epoch 70/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2231 - income_loss: 0.1270 - marital_loss: 0.0961 - income_accuracy: 0.9507 - marital_accuracy: 0.9575 - val_loss: 0.4000 - val_income_loss: 0.1827 - val_marital_loss: 0.2174 - val_income_accuracy: 0.9460 - val_marital_accuracy: 0.9150\n","ROC-AUC-income-Train: 0.9446 ROC-AUC-income-Validation: 0.9384 ROC-AUC-income-Test: 0.9389\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9764 ROC-AUC-marital-Test: 0.9756\n","Epoch 71/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2240 - income_loss: 0.1280 - marital_loss: 0.0960 - income_accuracy: 0.9506 - marital_accuracy: 0.9575 - val_loss: 0.3929 - val_income_loss: 0.1731 - val_marital_loss: 0.2198 - val_income_accuracy: 0.9442 - val_marital_accuracy: 0.9126\n","ROC-AUC-income-Train: 0.9432 ROC-AUC-income-Validation: 0.9374 ROC-AUC-income-Test: 0.9385\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9753 ROC-AUC-marital-Test: 0.9745\n","Epoch 72/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2217 - income_loss: 0.1264 - marital_loss: 0.0953 - income_accuracy: 0.9516 - marital_accuracy: 0.9575 - val_loss: 0.4115 - val_income_loss: 0.1841 - val_marital_loss: 0.2274 - val_income_accuracy: 0.9458 - val_marital_accuracy: 0.9146\n","ROC-AUC-income-Train: 0.9449 ROC-AUC-income-Validation: 0.9382 ROC-AUC-income-Test: 0.9385\n","ROC-AUC-marital-Train: 0.9938 ROC-AUC-marital-Validation: 0.9774 ROC-AUC-marital-Test: 0.9767\n","Epoch 73/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2212 - income_loss: 0.1261 - marital_loss: 0.0951 - income_accuracy: 0.9513 - marital_accuracy: 0.9579 - val_loss: 0.4839 - val_income_loss: 0.1827 - val_marital_loss: 0.3013 - val_income_accuracy: 0.9416 - val_marital_accuracy: 0.9058\n","ROC-AUC-income-Train: 0.9406 ROC-AUC-income-Validation: 0.935 ROC-AUC-income-Test: 0.9354\n","ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9713 ROC-AUC-marital-Test: 0.9706\n","Epoch 74/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2234 - income_loss: 0.1282 - marital_loss: 0.0953 - income_accuracy: 0.9486 - marital_accuracy: 0.9578 - val_loss: 0.4546 - val_income_loss: 0.1955 - val_marital_loss: 0.2591 - val_income_accuracy: 0.9451 - val_marital_accuracy: 0.9091\n","ROC-AUC-income-Train: 0.9462 ROC-AUC-income-Validation: 0.9403 ROC-AUC-income-Test: 0.9403\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.9722 ROC-AUC-marital-Test: 0.9714\n","Epoch 75/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2219 - income_loss: 0.1263 - marital_loss: 0.0957 - income_accuracy: 0.9514 - marital_accuracy: 0.9576 - val_loss: 0.4874 - val_income_loss: 0.2557 - val_marital_loss: 0.2317 - val_income_accuracy: 0.9389 - val_marital_accuracy: 0.9118\n","ROC-AUC-income-Train: 0.8883 ROC-AUC-income-Validation: 0.8805 ROC-AUC-income-Test: 0.8777\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9743 ROC-AUC-marital-Test: 0.9737\n","Epoch 76/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2221 - income_loss: 0.1266 - marital_loss: 0.0955 - income_accuracy: 0.9505 - marital_accuracy: 0.9579 - val_loss: 0.4567 - val_income_loss: 0.1727 - val_marital_loss: 0.2840 - val_income_accuracy: 0.9428 - val_marital_accuracy: 0.8972\n","ROC-AUC-income-Train: 0.9395 ROC-AUC-income-Validation: 0.9327 ROC-AUC-income-Test: 0.9335\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9678 ROC-AUC-marital-Test: 0.967\n","Epoch 77/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2252 - income_loss: 0.1295 - marital_loss: 0.0957 - income_accuracy: 0.9508 - marital_accuracy: 0.9575 - val_loss: 0.6249 - val_income_loss: 0.1956 - val_marital_loss: 0.4293 - val_income_accuracy: 0.9458 - val_marital_accuracy: 0.8717\n","ROC-AUC-income-Train: 0.9448 ROC-AUC-income-Validation: 0.9362 ROC-AUC-income-Test: 0.937\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.9504 ROC-AUC-marital-Test: 0.95\n","Epoch 78/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2209 - income_loss: 0.1260 - marital_loss: 0.0949 - income_accuracy: 0.9510 - marital_accuracy: 0.9578 - val_loss: 0.5312 - val_income_loss: 0.1982 - val_marital_loss: 0.3330 - val_income_accuracy: 0.9418 - val_marital_accuracy: 0.8913\n","ROC-AUC-income-Train: 0.9402 ROC-AUC-income-Validation: 0.9335 ROC-AUC-income-Test: 0.9341\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9643 ROC-AUC-marital-Test: 0.9637\n","Epoch 79/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2252 - income_loss: 0.1300 - marital_loss: 0.0952 - income_accuracy: 0.9501 - marital_accuracy: 0.9580 - val_loss: 0.5868 - val_income_loss: 0.1801 - val_marital_loss: 0.4068 - val_income_accuracy: 0.9452 - val_marital_accuracy: 0.8755\n","ROC-AUC-income-Train: 0.9409 ROC-AUC-income-Validation: 0.9255 ROC-AUC-income-Test: 0.9254\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.9527 ROC-AUC-marital-Test: 0.9522\n","Epoch 80/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2219 - income_loss: 0.1265 - marital_loss: 0.0954 - income_accuracy: 0.9511 - marital_accuracy: 0.9577 - val_loss: 0.5189 - val_income_loss: 0.1854 - val_marital_loss: 0.3335 - val_income_accuracy: 0.9449 - val_marital_accuracy: 0.9072\n","ROC-AUC-income-Train: 0.9464 ROC-AUC-income-Validation: 0.9397 ROC-AUC-income-Test: 0.9398\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9714 ROC-AUC-marital-Test: 0.9707\n","Epoch 81/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2213 - income_loss: 0.1265 - marital_loss: 0.0947 - income_accuracy: 0.9500 - marital_accuracy: 0.9580 - val_loss: 0.4432 - val_income_loss: 0.1736 - val_marital_loss: 0.2696 - val_income_accuracy: 0.9443 - val_marital_accuracy: 0.9097\n","ROC-AUC-income-Train: 0.9408 ROC-AUC-income-Validation: 0.9354 ROC-AUC-income-Test: 0.9353\n","ROC-AUC-marital-Train: 0.9945 ROC-AUC-marital-Validation: 0.9748 ROC-AUC-marital-Test: 0.9741\n","Epoch 82/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2214 - income_loss: 0.1264 - marital_loss: 0.0950 - income_accuracy: 0.9511 - marital_accuracy: 0.9580 - val_loss: 0.4064 - val_income_loss: 0.1753 - val_marital_loss: 0.2311 - val_income_accuracy: 0.9453 - val_marital_accuracy: 0.9149\n","ROC-AUC-income-Train: 0.9454 ROC-AUC-income-Validation: 0.9379 ROC-AUC-income-Test: 0.9392\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9771 ROC-AUC-marital-Test: 0.9763\n","Epoch 83/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2198 - income_loss: 0.1251 - marital_loss: 0.0947 - income_accuracy: 0.9516 - marital_accuracy: 0.9580 - val_loss: 0.4988 - val_income_loss: 0.2002 - val_marital_loss: 0.2987 - val_income_accuracy: 0.9446 - val_marital_accuracy: 0.9018\n","ROC-AUC-income-Train: 0.946 ROC-AUC-income-Validation: 0.9389 ROC-AUC-income-Test: 0.939\n","ROC-AUC-marital-Train: 0.9939 ROC-AUC-marital-Validation: 0.9692 ROC-AUC-marital-Test: 0.9686\n","Epoch 84/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2221 - income_loss: 0.1273 - marital_loss: 0.0949 - income_accuracy: 0.9508 - marital_accuracy: 0.9581 - val_loss: 0.4383 - val_income_loss: 0.1786 - val_marital_loss: 0.2598 - val_income_accuracy: 0.9426 - val_marital_accuracy: 0.9091\n","ROC-AUC-income-Train: 0.9436 ROC-AUC-income-Validation: 0.9356 ROC-AUC-income-Test: 0.9366\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.974 ROC-AUC-marital-Test: 0.9733\n","Epoch 85/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2215 - income_loss: 0.1271 - marital_loss: 0.0944 - income_accuracy: 0.9503 - marital_accuracy: 0.9583 - val_loss: 0.5437 - val_income_loss: 0.2258 - val_marital_loss: 0.3179 - val_income_accuracy: 0.9406 - val_marital_accuracy: 0.9001\n","ROC-AUC-income-Train: 0.9462 ROC-AUC-income-Validation: 0.9386 ROC-AUC-income-Test: 0.9392\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9687 ROC-AUC-marital-Test: 0.9681\n","Epoch 86/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2221 - income_loss: 0.1271 - marital_loss: 0.0950 - income_accuracy: 0.9510 - marital_accuracy: 0.9579 - val_loss: 0.4784 - val_income_loss: 0.1979 - val_marital_loss: 0.2805 - val_income_accuracy: 0.9451 - val_marital_accuracy: 0.9053\n","ROC-AUC-income-Train: 0.9447 ROC-AUC-income-Validation: 0.9386 ROC-AUC-income-Test: 0.9388\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.971 ROC-AUC-marital-Test: 0.9705\n","Epoch 87/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2205 - income_loss: 0.1260 - marital_loss: 0.0945 - income_accuracy: 0.9503 - marital_accuracy: 0.9580 - val_loss: 0.5688 - val_income_loss: 0.1889 - val_marital_loss: 0.3799 - val_income_accuracy: 0.9447 - val_marital_accuracy: 0.8845\n","ROC-AUC-income-Train: 0.9436 ROC-AUC-income-Validation: 0.937 ROC-AUC-income-Test: 0.937\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.96 ROC-AUC-marital-Test: 0.9596\n","Epoch 88/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2211 - income_loss: 0.1267 - marital_loss: 0.0944 - income_accuracy: 0.9508 - marital_accuracy: 0.9579 - val_loss: 0.4672 - val_income_loss: 0.1937 - val_marital_loss: 0.2735 - val_income_accuracy: 0.9417 - val_marital_accuracy: 0.9098\n","ROC-AUC-income-Train: 0.9455 ROC-AUC-income-Validation: 0.9382 ROC-AUC-income-Test: 0.9385\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9753 ROC-AUC-marital-Test: 0.9747\n","Epoch 89/100\n","6236/6236 [==============================] - 16s 3ms/step - loss: 0.2211 - income_loss: 0.1269 - marital_loss: 0.0943 - income_accuracy: 0.9504 - marital_accuracy: 0.9583 - val_loss: 0.4627 - val_income_loss: 0.1747 - val_marital_loss: 0.2879 - val_income_accuracy: 0.9432 - val_marital_accuracy: 0.9064\n","ROC-AUC-income-Train: 0.9459 ROC-AUC-income-Validation: 0.9383 ROC-AUC-income-Test: 0.9388\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9722 ROC-AUC-marital-Test: 0.9716\n","Epoch 90/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2227 - income_loss: 0.1281 - marital_loss: 0.0946 - income_accuracy: 0.9506 - marital_accuracy: 0.9579 - val_loss: 0.6135 - val_income_loss: 0.1877 - val_marital_loss: 0.4258 - val_income_accuracy: 0.9456 - val_marital_accuracy: 0.8738\n","ROC-AUC-income-Train: 0.9437 ROC-AUC-income-Validation: 0.9357 ROC-AUC-income-Test: 0.9364\n","ROC-AUC-marital-Train: 0.9937 ROC-AUC-marital-Validation: 0.9509 ROC-AUC-marital-Test: 0.9505\n","Epoch 91/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2235 - income_loss: 0.1276 - marital_loss: 0.0959 - income_accuracy: 0.9486 - marital_accuracy: 0.9582 - val_loss: 0.4589 - val_income_loss: 0.1812 - val_marital_loss: 0.2777 - val_income_accuracy: 0.9442 - val_marital_accuracy: 0.9038\n","ROC-AUC-income-Train: 0.9429 ROC-AUC-income-Validation: 0.9361 ROC-AUC-income-Test: 0.9366\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9704 ROC-AUC-marital-Test: 0.9698\n","Epoch 92/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2209 - income_loss: 0.1264 - marital_loss: 0.0945 - income_accuracy: 0.9506 - marital_accuracy: 0.9580 - val_loss: 0.5161 - val_income_loss: 0.1894 - val_marital_loss: 0.3267 - val_income_accuracy: 0.9458 - val_marital_accuracy: 0.8963\n","ROC-AUC-income-Train: 0.9443 ROC-AUC-income-Validation: 0.9371 ROC-AUC-income-Test: 0.9376\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9648 ROC-AUC-marital-Test: 0.9641\n","Epoch 93/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2205 - income_loss: 0.1256 - marital_loss: 0.0949 - income_accuracy: 0.9511 - marital_accuracy: 0.9579 - val_loss: 0.4910 - val_income_loss: 0.1938 - val_marital_loss: 0.2973 - val_income_accuracy: 0.9409 - val_marital_accuracy: 0.9028\n","ROC-AUC-income-Train: 0.9457 ROC-AUC-income-Validation: 0.9361 ROC-AUC-income-Test: 0.9374\n","ROC-AUC-marital-Train: 0.994 ROC-AUC-marital-Validation: 0.97 ROC-AUC-marital-Test: 0.9694\n","Epoch 94/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2205 - income_loss: 0.1262 - marital_loss: 0.0942 - income_accuracy: 0.9507 - marital_accuracy: 0.9580 - val_loss: 0.6300 - val_income_loss: 0.1877 - val_marital_loss: 0.4424 - val_income_accuracy: 0.9459 - val_marital_accuracy: 0.8671\n","ROC-AUC-income-Train: 0.9452 ROC-AUC-income-Validation: 0.9384 ROC-AUC-income-Test: 0.9386\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.9495 ROC-AUC-marital-Test: 0.9494\n","Epoch 95/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2218 - income_loss: 0.1269 - marital_loss: 0.0949 - income_accuracy: 0.9494 - marital_accuracy: 0.9579 - val_loss: 0.7888 - val_income_loss: 0.2005 - val_marital_loss: 0.5884 - val_income_accuracy: 0.9438 - val_marital_accuracy: 0.8629\n","ROC-AUC-income-Train: 0.9433 ROC-AUC-income-Validation: 0.9358 ROC-AUC-income-Test: 0.9367\n","ROC-AUC-marital-Train: 0.9941 ROC-AUC-marital-Validation: 0.9453 ROC-AUC-marital-Test: 0.9455\n","Epoch 96/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2210 - income_loss: 0.1266 - marital_loss: 0.0945 - income_accuracy: 0.9515 - marital_accuracy: 0.9582 - val_loss: 0.5288 - val_income_loss: 0.1797 - val_marital_loss: 0.3491 - val_income_accuracy: 0.9429 - val_marital_accuracy: 0.8932\n","ROC-AUC-income-Train: 0.9452 ROC-AUC-income-Validation: 0.9348 ROC-AUC-income-Test: 0.9354\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.9633 ROC-AUC-marital-Test: 0.9626\n","Epoch 97/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2192 - income_loss: 0.1249 - marital_loss: 0.0944 - income_accuracy: 0.9519 - marital_accuracy: 0.9584 - val_loss: 0.5172 - val_income_loss: 0.1925 - val_marital_loss: 0.3247 - val_income_accuracy: 0.9437 - val_marital_accuracy: 0.9008\n","ROC-AUC-income-Train: 0.9465 ROC-AUC-income-Validation: 0.9394 ROC-AUC-income-Test: 0.9393\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.9689 ROC-AUC-marital-Test: 0.9684\n","Epoch 98/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2210 - income_loss: 0.1268 - marital_loss: 0.0942 - income_accuracy: 0.9499 - marital_accuracy: 0.9585 - val_loss: 0.4602 - val_income_loss: 0.1786 - val_marital_loss: 0.2816 - val_income_accuracy: 0.9421 - val_marital_accuracy: 0.9060\n","ROC-AUC-income-Train: 0.9451 ROC-AUC-income-Validation: 0.9381 ROC-AUC-income-Test: 0.9385\n","ROC-AUC-marital-Train: 0.9944 ROC-AUC-marital-Validation: 0.972 ROC-AUC-marital-Test: 0.9714\n","Epoch 99/100\n","6236/6236 [==============================] - 18s 3ms/step - loss: 0.2237 - income_loss: 0.1289 - marital_loss: 0.0948 - income_accuracy: 0.9509 - marital_accuracy: 0.9580 - val_loss: 0.4398 - val_income_loss: 0.2055 - val_marital_loss: 0.2343 - val_income_accuracy: 0.9442 - val_marital_accuracy: 0.9140\n","ROC-AUC-income-Train: 0.9455 ROC-AUC-income-Validation: 0.9351 ROC-AUC-income-Test: 0.9359\n","ROC-AUC-marital-Train: 0.9943 ROC-AUC-marital-Validation: 0.9769 ROC-AUC-marital-Test: 0.9762\n","Epoch 100/100\n","6236/6236 [==============================] - 17s 3ms/step - loss: 0.2205 - income_loss: 0.1269 - marital_loss: 0.0936 - income_accuracy: 0.9502 - marital_accuracy: 0.9581 - val_loss: 0.5826 - val_income_loss: 0.1929 - val_marital_loss: 0.3898 - val_income_accuracy: 0.9454 - val_marital_accuracy: 0.8891\n","ROC-AUC-income-Train: 0.9452 ROC-AUC-income-Validation: 0.9372 ROC-AUC-income-Test: 0.9374\n","ROC-AUC-marital-Train: 0.9942 ROC-AUC-marital-Validation: 0.9598 ROC-AUC-marital-Test: 0.9592\n"]}]}]}