{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-14-grouprec.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/P969119%20%7C%20Group%20Playlist%20Recommendations%20on%20Million%20Songs%20Dataset%20using%20Surprise%20SVD%20and%20NMF%20Model.ipynb","timestamp":1644613911928}],"collapsed_sections":[],"authorship_tag":"ABX9TyP/tCElCcRAxH9xRNJHMTI9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Group Playlist Recommendations on Million Songs Dataset using Surprise SVD and NMF Model"],"metadata":{"id":"ZUoCyO0flQrk"}},{"cell_type":"markdown","source":["In many social situations, like parties and road trips, groups of people with different music tastes will listen to music together. It's hard to please everyone, and it's even harder if you don't know what each person likes. There are multiple ways to synthesize the preferences of a group. Should you average their preferences? Should you try to make sure that no one hates the choices at the cost of excluding someone's favorites? We explore these questions by first generating a music profile for each person, and then applying different strategies to combine their preferences into a single playlist."],"metadata":{"id":"d8Ri9-RalZW-"}},{"cell_type":"markdown","source":["## Process flow\n","\n","![](https://github.com/RecoHut-Stanzas/S165806/raw/main/images/process_flow.svg)"],"metadata":{"id":"kBinCWPysd11"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"slYewA7ifkoN"}},{"cell_type":"code","source":["!pip install -q surprise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zk2Bk6rOe9dZ","executionInfo":{"status":"ok","timestamp":1639024944693,"user_tz":-330,"elapsed":39259,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d44af4d8-6409-45a2-c08c-3b90f29d75e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 11.8 MB 4.4 MB/s \n","\u001b[?25h  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import logging\n","import sys\n","import argparse\n","import csv\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import rcParams\n","import seaborn as sns\n","\n","from surprise import SVD, SlopeOne, NMF, KNNBaseline\n","from surprise.prediction_algorithms.co_clustering import CoClustering\n","from surprise.prediction_algorithms.baseline_only import BaselineOnly\n","from surprise.prediction_algorithms.random_pred import NormalPredictor\n","from surprise import Dataset\n","from surprise import Reader\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","warnings.filterwarnings(\"ignore\")\n","rcParams.update({'font.size': 18})"],"metadata":{"id":"ODeRVyzqfLm-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data loading"],"metadata":{"id":"DE1QNejkfiOm"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jy5L1ULq-oVP","executionInfo":{"status":"ok","timestamp":1639024689835,"user_tz":-330,"elapsed":4964,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"225cfea3-bc41-4a3c-d132-11695f249a7b"},"source":["!wget http://millionsongdataset.com/sites/default/files/challenge/train_triplets.txt.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-09 04:38:13--  http://millionsongdataset.com/sites/default/files/challenge/train_triplets.txt.zip\n","Resolving millionsongdataset.com (millionsongdataset.com)... 172.104.14.177\n","Connecting to millionsongdataset.com (millionsongdataset.com)|172.104.14.177|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 512137572 (488M) [application/zip]\n","Saving to: ‘train_triplets.txt.zip’\n","\n","train_triplets.txt. 100%[===================>] 488.41M   116MB/s    in 4.2s    \n","\n","2021-12-09 04:38:17 (115 MB/s) - ‘train_triplets.txt.zip’ saved [512137572/512137572]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8_9u34G-2qw","executionInfo":{"status":"ok","timestamp":1639024739772,"user_tz":-330,"elapsed":49942,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c26731ce-7c4c-4b7b-9ab5-961c534915d5"},"source":["!unzip train_triplets.txt.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  train_triplets.txt.zip\n","  inflating: train_triplets.txt      \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2whKJ5lB-6UL","executionInfo":{"status":"ok","timestamp":1639024744157,"user_tz":-330,"elapsed":4394,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"e810b2b4-695c-4479-a91a-8b27e00ffd05"},"source":["!head train_triplets.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOAKIMP12A8C130995\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOAPDEY12A81C210A9\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBBMDR12A8C13253B\t2\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBFNSP12AF72A0E22\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBFOVM12A58A7D494\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBNZDC12A6D4FC103\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBSUJE12A6D4F8CF5\t2\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBVFZR12A6D4F8AE3\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBXALG12A8C13C108\t1\n","b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBXHDL12A81C204C0\t1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbzLnhJ5_LJe","executionInfo":{"status":"ok","timestamp":1639024744158,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c3b498ca-9e8e-482b-f45f-4bf3ed121484"},"source":["!du train_triplets.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2931312\ttrain_triplets.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"MwvSv1xu_YSC","executionInfo":{"status":"ok","timestamp":1639024791236,"user_tz":-330,"elapsed":47086,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"56f3ddbf-0a48-4c3a-f2fe-db34fc3071e8"},"source":["# df = pd.read_csv('train_triplets.txt', sep='\\t', header=None)\n","df.columns = ['user_id','song_id','play_counts']\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>song_id</th>\n","      <th>play_counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n","      <td>SOAKIMP12A8C130995</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n","      <td>SOAPDEY12A81C210A9</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n","      <td>SOBBMDR12A8C13253B</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n","      <td>SOBFNSP12AF72A0E22</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n","      <td>SOBFOVM12A58A7D494</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    user_id             song_id  play_counts\n","0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995            1\n","1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9            1\n","2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B            2\n","3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22            1\n","4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494            1"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"UxeOW-cn_fFy","executionInfo":{"status":"ok","timestamp":1639024830657,"user_tz":-330,"elapsed":39428,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"be73ee8c-c1a4-4f9e-f69a-2f03846f1be7"},"source":["df.describe(include='all')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>song_id</th>\n","      <th>play_counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>48373586</td>\n","      <td>48373586</td>\n","      <td>4.837359e+07</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>1019318</td>\n","      <td>384546</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>ec6dfcf19485cb011e0b22637075037aae34cf26</td>\n","      <td>SOFRQTD12A81C233C0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>4400</td>\n","      <td>110479</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.866859e+00</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6.437725e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.667000e+03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         user_id  ...   play_counts\n","count                                   48373586  ...  4.837359e+07\n","unique                                   1019318  ...           NaN\n","top     ec6dfcf19485cb011e0b22637075037aae34cf26  ...           NaN\n","freq                                        4400  ...           NaN\n","mean                                         NaN  ...  2.866859e+00\n","std                                          NaN  ...  6.437725e+00\n","min                                          NaN  ...  1.000000e+00\n","25%                                          NaN  ...  1.000000e+00\n","50%                                          NaN  ...  1.000000e+00\n","75%                                          NaN  ...  3.000000e+00\n","max                                          NaN  ...  9.667000e+03\n","\n","[11 rows x 3 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"gy6m4w_IANJR"},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le_user = LabelEncoder()\n","df.loc[:, 'user_id'] = le_user.fit_transform(df['user_id'].values)\n","\n","le_item = LabelEncoder()\n","df.loc[:, 'song_id'] = le_item.fit_transform(df['song_id'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xz1mbvfrCTdY","executionInfo":{"status":"ok","timestamp":1639024905443,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"9a042078-bf20-4ace-c19a-93a392207eb6"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>song_id</th>\n","      <th>play_counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>732659</td>\n","      <td>6347</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>732659</td>\n","      <td>9365</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>732659</td>\n","      <td>16962</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>732659</td>\n","      <td>19513</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>732659</td>\n","      <td>19536</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  song_id  play_counts\n","0   732659     6347            1\n","1   732659     9365            1\n","2   732659    16962            2\n","3   732659    19513            1\n","4   732659    19536            1"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mC9rB-IjC48l","executionInfo":{"status":"ok","timestamp":1639024905444,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"24a95967-e5bb-40ec-bae8-b21dcc74e037"},"source":["df.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["user_id        int64\n","song_id        int64\n","play_counts    int64\n","dtype: object"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# sampling for testing/prototyping and saving some time therefore\n","data = df.head(1000).copy()\n","data.columns = ['user_id', 'track_id','plays']\n","data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipX9tcdoecbP","executionInfo":{"status":"ok","timestamp":1639024985425,"user_tz":-330,"elapsed":805,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"e1a128eb-7cbd-40a4-d74c-464f538dc882"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count  Dtype\n","---  ------    --------------  -----\n"," 0   user_id   1000 non-null   int64\n"," 1   track_id  1000 non-null   int64\n"," 2   plays     1000 non-null   int64\n","dtypes: int64(3)\n","memory usage: 23.6 KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"Cy985iL8gNQq"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"OojYxl_JTXlh"},"source":["def tt_preprocess(tt):\n","    # Saturate top 1% of plays, where 24 is 99th percentile of plays\n","    tt.plays = tt.plays.transform(lambda x: 24 if x > 24 else x)\n","    # Create 'rating' column based on log(plays/max_plays) transformed to 1-5 scale\n","    tt['rating'] = np.log10(tt.plays)/np.log10(tt['plays'].max())*5+1\n","    # Include only top 250 tracks (11% of total data, ~4.8 millions entries)\n","    top_tracks = tt['track_id'].value_counts()[:250].index.tolist()\n","    tt = tt[tt['track_id'].isin(top_tracks)]\n","    # Drop plays\n","    tt = tt.drop(columns='plays')\n","    # Create dummy column, timestamp, to fit Surprise format\n","    tt['timestamp'] = 0\n","    return tt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN6ASKtjVzVt"},"source":["# load preprocessed tt data\n","data = tt_preprocess(data)\n","\n","# Split into train/validation data \n","frac = 0.8\n","train = data.sample(frac=frac,random_state=0)\n","test = data.drop(train.index)\n","# test = test.set_index('user_id')\n","\n","# saving train and test dataframes\n","train.to_parquet('train.parquet.snappy', compression='snappy')\n","test.to_parquet('test.parquet.snappy', compression='snappy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hw35zEjIg8Ws"},"source":["## User Profile Recommender"]},{"cell_type":"code","metadata":{"id":"TYN96WOCUNps"},"source":["class SongRecommender():\n","    \"\"\"Basic song recommender system.\"\"\"\n","    \n","    def __init__(self, model_name='svd'):\n","        \"\"\"Constructs a SongRecommender\"\"\"\n","        self.logger = logging.getLogger('reco-cs')\n","        self.model_name = model_name\n","\n","    def fit(self, ratings):\n","        \"\"\"\n","        Trains the recommender on a given set of ratings.\n","        Parameters\n","        ----------\n","        ratings : pandas dataframe, shape = (n_ratings, 4)\n","                  with columns 'user_id', 'track_id', 'likes', 'timestamp'\n","        Returns\n","        -------\n","        self : object\n","            Returns self.\n","        \"\"\"\n","        self.logger.debug(\"starting fit\")\n","        # processing for Surprise\n","        ratings = ratings.sample(frac=1)\n","        ratings = Dataset.load_from_df(ratings[['user_id', 'track_id', 'rating']],\n","                                       reader=Reader(rating_scale = (1,5)))\n","        self.trainset = ratings.build_full_trainset()\n","        # Choose model class based on model_name\n","        if self.model_name == 'svd':\n","            self.algo = SVD(lr_all=0.001,n_epochs=125)\n","        elif self.model_name == 'slopeone':\n","            self.algo = SlopeOne()\n","        elif self.model_name == 'nmf':\n","            self.algo = NMF()\n","        elif self.model_name == 'knnbaseline':\n","            self.algo = KNNBaseline() \n","        elif self.model_name == 'cocluster':\n","            self.algo = CoClustering() \n","        elif self.model_name == 'baseline':\n","            self.algo = BaselineOnly()\n","        elif self.model_name == 'normal':\n","            self.algo = NormalPredictor()            \n","        self.algo.fit(self.trainset)\n","        self.logger.debug(\"finishing fit\")\n","        return(self)\n","\n","    def transform(self, requests):\n","        \"\"\"\n","        Predicts the ratings for a given set of requests.\n","        Parameters\n","        ----------\n","        requests : pandas dataframe, shape = (n_ratings, 4)\n","                  with columns 'user_id', 'track_id', 'rating', 'timestamp'\n","        Returns\n","        -------\n","        dataframe : a pandas dataframe with columns 'user_id', 'track_id', 'rating'\n","                    column 'rating' contains the predicted rating\n","        \"\"\"\n","        self.logger.debug(\"starting predict\")\n","        self.logger.debug(\"request count: {}\".format(requests.shape[0]))\n","        testset = Dataset(reader=Reader()).construct_testset(raw_testset = requests.values)\n","        predictions = self.algo.test(testset)\n","        pred_base = [(pred.uid,pred.iid,pred.est) for pred in predictions]\n","        predictions = pd.DataFrame(pred_base,columns=['user_id', 'track_id', 'rating'])\n","        self.logger.debug(\"finishing predict\")\n","        return(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_-zAIB8hBtV"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"id":"i1-0EG54cYhq"},"source":["# set list of models to train\n","model_name_ = [\"svd\", \"cocluster\", \"nmf\"]\n","\n","for model_name in model_name_:\n","    # Creating an instance of your recommender with the right parameters\n","    reco = SongRecommender(model_name)\n","    # fits on training data, returns a SongRecommender object\n","    model = reco.fit(train)\n","    # save model to pickle file\n","    pickle.dump(model, open(f\"model_{model_name}.p\", \"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tXJpsjxYigko"},"source":["## Model Inference"]},{"cell_type":"code","metadata":{"id":"7AP6ZAOpXqaS"},"source":["result_path_ = \"model_result_ensemble.csv\"\n","\n","model_paths_ = ['model_cocluster.p',\n","                'model_svd.p',\n","                'model_nmf.p']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDKSkHY9Uplo"},"source":["# Reading REQUEST SET from input file into pandas\n","request_data = test.copy()\n","\n","if model_paths_ == 'default':\n","    global_mean = train_data['rating'].mean()\n","    result_data = request_data.drop(columns=['timestamp'])\n","    result_data['rating'] = global_mean\n","else:\n","    # Creating an instance of your recommender with the right parameters\n","    # reco_instance = SongRecommender(model_paths_)\n","    if len(model_paths_)>1:\n","        result_dfs = []\n","        for path in model_paths_:\n","            model = pickle.load(open(path, \"rb\"))\n","            result_dfs.append(model.transform(request_data))\n","        # Designate weights based on val set RMSE relative to\n","        # global mean RMSE, and normalize\n","        global_mean_rmse = 1.3706\n","        cocluster_weight = 1.3706 - 1.255\n","        nmf_weight = 1.3706 - 1.2716\n","        svd_weight = 1.3706 - 1.1934\n","        result_dfs[0]['rating'] = \\\n","            (result_dfs[0]['rating']*cocluster_weight + \\\n","                result_dfs[1]['rating']*nmf_weight + \\\n","                    result_dfs[2]['rating']*svd_weight)/ \\\n","                        (cocluster_weight + nmf_weight + svd_weight)\n","        result_data = result_dfs[0]\n","    else:\n","        # load the model\n","        model = pickle.load(open(model_paths_[0], \"rb\"))\n","        # apply predict on request_data, returns a dataframe\n","        result_data = model.transform(request_data)\n","\n","result_data.to_csv(result_path_, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fs4Og2Fowe6Z","executionInfo":{"status":"ok","timestamp":1639025246237,"user_tz":-330,"elapsed":650,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"986e945b-73e0-4abd-cf1f-d38783c91f77"},"source":["result_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>track_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>732659.0</td>\n","      <td>29262.0</td>\n","      <td>1.881562</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>732659.0</td>\n","      <td>168500.0</td>\n","      <td>1.881562</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>732659.0</td>\n","      <td>268948.0</td>\n","      <td>1.881562</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>532471.0</td>\n","      <td>227930.0</td>\n","      <td>2.021035</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>753546.0</td>\n","      <td>18343.0</td>\n","      <td>1.987814</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    user_id  track_id    rating\n","0  732659.0   29262.0  1.881562\n","1  732659.0  168500.0  1.881562\n","2  732659.0  268948.0  1.881562\n","3  532471.0  227930.0  2.021035\n","4  753546.0   18343.0  1.987814"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"_bJMtJwFf-12"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"v_SeDs2Uiyy5"},"source":["def compute_score(predictions, actual):\n","    \"\"\"Look at 5% of most highly predicted songs for each user.\n","    Return the average actual rating of those songs.\n","    \"\"\"\n","    actual.drop(columns=['timestamp'],inplace=True)\n","    df = pd.merge(predictions, actual.rename(columns={'rating':'actualrating'}), on=['user_id','track_id']).fillna(1.0)\n","    # for each user\n","    g = df.groupby('user_id')\n","    # detect the top 5% songs as predicted by your algorithm\n","    top_5 = g.rating.transform(\n","        lambda x: x >= x.quantile(.95))\n","    # return the mean of the actual score on those\n","    return df.actualrating[top_5==1].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"an-9RrKEiz5V"},"source":["def compute_rmse(predictions, actual):\n","    # RMSE between predictions and actual ratings\n","    rmse = ((predictions.rating - actual.rating) ** 2).mean() ** .5\n","    return rmse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Igm2YT3HjgWS"},"source":["result_path_ = \"model_result_ensemble.csv\" # predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAOT7lthf8j9","executionInfo":{"status":"ok","timestamp":1639025318549,"user_tz":-330,"elapsed":699,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3ee5a06b-98c0-4c6c-a2db-a3d8f78ae6c6"},"source":["# Load predictions data\n","prediction_data = pd.read_csv(result_path_)\n","\n","# Load actual validation data\n","actual_data = test.copy()\n","\n","# Compute score based on mean of top 5% of each users song rankings\n","score = compute_score(prediction_data, actual_data)\n","print(score)\n","\n","# Compute RMSE between prediction and actual data\n","rmse = compute_rmse(prediction_data, actual_data)\n","print(rmse)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.749794250070545\n","2.515609839014444\n"]}]},{"cell_type":"code","metadata":{"id":"IB4dlyq61UmV"},"source":["# Save results to csv file\n","fields=[result_path_,round(score,4),round(rmse,4)]\n","with open(r'eval_results.csv', 'a') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(fields)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trxJL3Mej_R5"},"source":["## Results Figure"]},{"cell_type":"code","metadata":{"id":"XaJPGMQ7kAnG"},"source":["# # Load results.csv file\n","# results = pd.read_csv('results.csv')\n","\n","# # If hyperparameters = True, generate SVD hyperparameters bar plot\n","# # If hyperparameters = False, generate model comparison bar plot\n","# hyperparameters = False\n","\n","# if hyperparameters == False:\n","#     model_labels = ['SVD', 'NMF','KNN',\n","#                         'Co-cluster','ALS Base','Normal','Global Mean']\n","\n","#     models_names = results.name[results.name.str.contains(\n","#         'svd_default|nmf|knn|cocluster|baseline|normal|global_mean')]\n","\n","#     xlabel = 'Model Name'\n","    \n","#     comparison = results[results.name.isin(models_names)]\n","\n","#     comparison['label'] = model_labels\n","#     comparison.sort_values(by='rmse',ascending=False,inplace=True)\n","\n","#     fig,ax = plt.subplots(figsize=(13,6))\n","#     plt.bar(comparison['label'],comparison['rmse'],color = sns.color_palette(\"husl\", 7))\n","#     plt.xlabel('Model Type')\n","#     plt.ylabel('RMSE')\n","\n","#     plt.show(block=False)\n","#     plt.savefig('rmse_comparison_no_ensemble.jpg')\n","#     plt.close('all')\n","\n","#     # comparison = comparison.iloc[:,[3,2]]\n","#     # comparison.to_csv('data/results/comparison_results.csv',index=False)\n","# else:\n","#     hyp_names = results.name[results.name.str.contains(\n","#         'svd|pred.csv')]\n","    \n","#     hyp_df = results[results.name.isin(hyp_names)]\n","    \n","#     hyp_df.drop(index=[9,10],inplace=True)\n","    \n","#     hyp_df['lr'] = [.01, .005, .001, .001, .001, .001, .005, .005, .005, .005]\n","#     hyp_df['epochs'] = [20, 20, 20, 50, 75, 125, 10, 50, 125, 75]\n","    \n","#     print(hyp_df)\n","\n","#     fig,ax = plt.subplots(figsize=(8,5))\n","#     plt.scatter(x=hyp_df['lr'], y=hyp_df['epochs'], s=400, \n","#                 c=hyp_df['rmse'], cmap=sns.color_palette('plasma', as_cmap=True))\n","#     plt.xlabel('Learning Rate')\n","#     plt.ylabel('Number of Epochs')\n","\n","#     cb = plt.colorbar()\n","#     cb.ax.set_title('RMSE')\n","    \n","#     fig.tight_layout()\n","#     plt.show(block=False)\n","#     plt.savefig('rmse_svd_hyp.jpg')\n","#     plt.close('all')\n","\n","#     hyp_df = hyp_df.iloc[:,[3,4,2]]\n","#     hyp_df.to_csv('hyp_results.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_n6lr7Rf5-b"},"source":["## Group Recommender"]},{"cell_type":"code","metadata":{"id":"Vucf-bjlRdh5"},"source":["class GroupRecommender():\n","    \"\"\"Playlist recommender system for groups.\"\"\"\n","\n","    def __init__(self,user_ids,num_songs=5,ensemble=True):\n","        \"\"\"Constructs a GroupRecommender\"\"\"\n","        self.user_ids = user_ids\n","        self.num_songs = num_songs\n","        self.ensemble = ensemble\n","\n","    def score_for_users(self,train_path):\n","        \"\"\"Loads a trained model and predicts ratings for all tracks for given users\n","        Args:\n","            train_path (str): path to training data csv file\n","        Returns:\n","            self: GroupRecommender class instance\n","        \"\"\"        \n","        self.train = pd.read_parquet(train_path)\n","        self.train.loc[:,'user_id'] = le_user.inverse_transform(self.train.user_id.values)\n","        \n","        track_list = self.train['track_id'].unique()\n","        \n","        df = pd.DataFrame(columns = self.user_ids, index = track_list).reset_index()\n","        \n","        request_data = pd.melt(df, id_vars = 'index', value_vars=self.user_ids)\n","        request_data.rename(columns={'index': 'track_id', 'variable': 'user_id', 'value': 'rating'},inplace=True)\n","        request_data = request_data[['user_id', 'track_id', 'rating']]\n","        request_data['timestamp'] = 0\n","        \n","        if self.ensemble:\n","            # Load ensemble of models for predictions\n","            model_paths = ['model_cocluster.p',\n","                           'model_svd.p',\n","                           'model_nmf.p']\n","            result_dfs = []\n","            for path in model_paths:\n","                model = pickle.load( open( path, \"rb\" ) )\n","                result_dfs.append(model.transform(request_data))\n","                \n","            global_mean_rmse = 1.3706\n","            cocluster_weight = global_mean_rmse - 1.255\n","            nmf_weight = global_mean_rmse - 1.2716\n","            svd_weight = global_mean_rmse - 1.1934\n","            result_dfs[0]['rating'] = \\\n","                (result_dfs[0]['rating']*cocluster_weight + \\\n","                    result_dfs[1]['rating']*nmf_weight + \\\n","                        result_dfs[2]['rating']*svd_weight)/ \\\n","                            (cocluster_weight + nmf_weight + svd_weight)\n","                            \n","            self.predictions = result_dfs[0]\n","        else:\n","            # Use best SVD model\n","            model = pickle.load(open(\"model_svd.p\", \"rb\"))\n","\n","            # Predict for request_data, returns a dataframe\n","            self.predictions = model.transform(request_data)\n","        \n","        return self\n","        \n","    def impute_knowns(self):\n","        \"\"\"Imputes actual ratings into prediction ratings for known entries\n","        Returns:\n","            self: GroupRecommender class instance\n","        \"\"\"        \n","        updated = self.predictions.merge(self.train, how='left', on=['user_id', 'track_id'],\n","                            suffixes=('', '_new'))\n","        # updated.drop(columns = ['Unnamed: 0','timestamp'],inplace=True)\n","\n","        updated['rating'] = np.where(pd.notnull(updated['rating_new']), updated['rating_new'], updated['rating'])\n","        # # # Modify here\n","        # updated['known'] = np.where(pd.notnull(updated['rating_new']), updated['rating_new'], updated['rating'])\n","        updated.drop('rating_new', axis=1, inplace=True)\n","        \n","        self.predictions = updated\n","        \n","        return self\n","        \n","    def create_rankings(self):\n","        \"\"\"For each user, sorts the ratings column, and replaces it with indices\n","            indicating the ranking of the entries\n","        Returns:\n","            self: GroupRecommender class instance\n","        \"\"\"        \n","        dfs = []\n","        for idx, user_id in enumerate(self.user_ids):\n","            sorted_by_rating = self.predictions[self.predictions['user_id'] == user_id].sort_values(\n","                by='rating',ascending=False).reset_index().drop(\n","                columns=['user_id','index']).reset_index().set_index('track_id')\n","            dfs.append(sorted_by_rating.rename(columns={'index':'rank'},inplace=True))\n","            if idx == 0:\n","                rankings = sorted_by_rating\n","            else:\n","                rankings = rankings.join(sorted_by_rating,rsuffix=str(idx+1))\n","\n","        self.rankings = rankings\n","        \n","        return self\n","    \n","    # def track_artist_names(self,df):\n","    #     \"\"\"Extract song_title and artist_name for tracks in given DataFrame\n","    #     Args:\n","    #         df (pandas DataFrame): DataFrame of top recommended songs\n","    #     Returns:\n","    #         pandas DataFrame: Initial DataFrame with additional song_title, artist_name columns\n","    #     \"\"\"    \n","        \n","    #     # read in map of track_id to artist_name and song_title\n","    #     names = pd.read_csv('data/track_artist_names.txt',sep = '<SEP>',header=None)\n","        \n","    #     # drop unnecessary column and rename columns\n","    #     names.drop(columns = [0], inplace = True)\n","    #     names.rename(columns={1: \"track_id\", 2: \"artist_name\", 3: \"song_title\"},inplace=True)\n","        \n","    #     # Merge on track id to add new columns\n","    #     df = pd.merge(df, names, on = 'track_id',how='left')\n","        \n","    #     return df\n","\n","    def rec_group_playlist(self,strategy='lm'):\n","        \"\"\"Applies a strategy to generate group rankings using the individual rankings\n","        Args:\n","            strategy (str, optional): Name of group ranking strategy. Defaults to 'lm'.\n","        Returns:\n","            pandas DataFrame: DataFrame of recommended songs with rankings\n","        \"\"\"        \n","        rankings = self.rankings\n","        \n","        rank_cols = [col for col in rankings.columns if 'rank' in col]\n","\n","        if strategy == 'mp':\n","             # Most pleasure strategy\n","            rankings['best_rnk'] = rankings[rank_cols].min(axis=1)\n","            strat_col = 'best_rnk'\n","        elif strategy == 'avg':\n","            # Average rank strategy\n","            rankings['avg_rnk'] = rankings[rank_cols].mean(axis=1)\n","            strat_col = 'avg_rnk'\n","        else:\n","            # Least misery strategy\n","            rankings['worst_rnk'] = rankings[rank_cols].max(axis=1)\n","            strat_col = 'worst_rnk' # default is least misery strategy\n","        \n","        top_songs = rankings.sort_values(strat_col)[:self.num_songs]\n","        # top_songs = self.track_artist_names(top_songs)\n","        \n","        # Rearrange dataframe to be presentable\n","        # top_songs.insert(0, 'artist_name', top_songs.pop('artist_name'))\n","        # top_songs.insert(1, 'song_title', top_songs.pop('song_title'))\n","        # top_songs.drop(columns=['track_id'],inplace=True)\n","        # rating_cols = [col for col in rankings.columns if 'rating' in col]\n","        # top_songs.drop(columns=rating_cols,inplace=True)\n","        # char_lim = 30\n","        # top_songs['artist_name'] = top_songs['artist_name'].transform(lambda x: \n","        #             x[:char_lim] + '...' \n","        #             if len(x) > char_lim+1 else x)\n","        # top_songs['song_title'] = top_songs['song_title'].transform(lambda x: \n","        #             x[:char_lim] + '...' \n","        #             if len(x) > char_lim+1 else x)\n","        # print(top_songs)\n","        \n","        return top_songs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdJtaBwEjUkD"},"source":["# Initial parameters\n","user_ids = ['d1ca8b3e78811238cf94ee7caa1868d7ae9e908a',\n","        '621659a10f52dc4f8b50f205ab85b6d6b7d1b0dc',\n","        '257fc9ff00cd0ac79f53c7d65510b2ebba0c6b8e']\n","\n","num_songs = 5\n","train_path = 'train.parquet.snappy'\n","strategy = 'avg'\n","save_path = 'rankings_avg.csv'\n","ensemble = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkEKlobqOKOZ"},"source":["reco = GroupRecommender(user_ids,num_songs,ensemble)\n","reco.score_for_users(train_path)\n","reco.impute_knowns()\n","reco.create_rankings()\n","top_songs = reco.rec_group_playlist(strategy)\n","top_songs.to_csv(save_path,index='False')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_songs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"yPNOpEpIialD","executionInfo":{"status":"ok","timestamp":1639025586720,"user_tz":-330,"elapsed":634,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0e5e73ca-c6b0-4ed1-c535-66026111a34b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rank</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","      <th>rank2</th>\n","      <th>rating2</th>\n","      <th>timestamp2</th>\n","      <th>rank3</th>\n","      <th>rating3</th>\n","      <th>timestamp3</th>\n","      <th>avg_rnk</th>\n","    </tr>\n","    <tr>\n","      <th>track_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>256744</th>\n","      <td>0</td>\n","      <td>2.372764</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2.372764</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2.372764</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>172300</th>\n","      <td>1</td>\n","      <td>2.367906</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2.367906</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2.367906</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>338615</th>\n","      <td>2</td>\n","      <td>2.366546</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2.366546</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2.366546</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>25043</th>\n","      <td>3</td>\n","      <td>2.357708</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2.357708</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2.357708</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>320787</th>\n","      <td>4</td>\n","      <td>2.352594</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>2.352594</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>2.352594</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          rank    rating  timestamp  ...   rating3  timestamp3  avg_rnk\n","track_id                             ...                               \n","256744       0  2.372764        NaN  ...  2.372764         NaN      0.0\n","172300       1  2.367906        NaN  ...  2.367906         NaN      1.0\n","338615       2  2.366546        NaN  ...  2.366546         NaN      2.0\n","25043        3  2.357708        NaN  ...  2.357708         NaN      3.0\n","320787       4  2.352594        NaN  ...  2.352594         NaN      4.0\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"HdRM66_YOdo8"},"source":["## App"]},{"cell_type":"code","metadata":{"id":"I8Gvk7rpk-11"},"source":["# from flask import Flask, render_template, flash, request\n","# from wtforms import Form, TextField, TextAreaField, validators, StringField, SubmitField\n","# from group_rec import GroupRecommender\n","\n","# DEBUG = True\n","# app = Flask(__name__)\n","# app.config.from_object(__name__)\n","# app.config['SECRET_KEY'] = 'SjdnUends821Jsdlkvxh391ksdODnejdDw'\n","\n","# class ReusableForm(Form):\n","#     user1 = TextField('user1:', validators=[validators.required()])\n","#     user2 = TextField('user2:', validators=[validators.required()])\n","#     user3 = TextField('user3:', validators=[validators.required()])\n","\n","# @app.route(\"/\", methods=['GET', 'POST'])\n","# def hello():\n","#     # Generate playlist recommendations based on user ids\n","#     form = ReusableForm(request.form)\n","\n","#     if request.method == 'POST':\n","#         user1=request.form['user1']\n","#         user2=request.form['user2']\n","#         user3=request.form['user3']\n","\n","#         if form.validate():\n","#             flash('Generating playlist...')\n","#             user_ids = [user1,user2,user3]\n","        \n","#             num_songs = 5\n","#             train_path = 'data/train.csv'\n","#             strategy = 'lm'\n","\n","#             ensemble = False\n","            \n","#             reco = GroupRecommender(user_ids,num_songs,ensemble)\n","            \n","#             reco.score_for_users(train_path)\n","            \n","#             reco.impute_knowns()\n","\n","#             reco.create_rankings()\n","            \n","#             top_songs = reco.rec_group_playlist(strategy)\n","            \n","#             top_songs = top_songs.loc[:,['artist_name','song_title']]\n","            \n","#             top_songs.rename(columns = {'artist_name': 'Artist', \n","#                                         'song_title':'Song Title'},inplace=True)\n","            \n","#             top_songs['Track Number'] = range(1,6)\n","#             top_songs.set_index('Track Number', drop=True, inplace=True)\n","#             top_songs.index.name = None\n","            \n","#             return render_template('view.html',tables=[top_songs.to_html(classes='songs')],titles=[''])\n","#         else:\n","#             flash('Error: All Fields are Required')\n","\n","#     return render_template('index.html', form=form)\n","\n","# if __name__ == \"__main__\":\n","#     app.run()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## References\n","\n","1. [https://github.com/chrisshaffer/group-playlist-recommender](https://github.com/chrisshaffer/group-playlist-recommender) `code`\n","2. [Taste Profile Subset](http://millionsongdataset.com/tasteprofile/) `data`"],"metadata":{"id":"ShZvesMblfzC"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"FB6hw-Sqiq9F"}},{"cell_type":"code","source":["!apt-get -qq install tree\n","!rm -r sample_data"],"metadata":{"id":"Rz9Uwwytir7P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tree -h --du -C ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7tvBKvJiwcj","executionInfo":{"status":"ok","timestamp":1639025679266,"user_tz":-330,"elapsed":439,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"65fda5d5-3740-44f9-8f9e-cf75f2a9f5cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34m.\u001b[00m\n","├── [  41]  eval_results.csv\n","├── [ 16K]  model_cocluster.p\n","├── [ 39K]  model_nmf.p\n","├── [2.1K]  model_result_ensemble.csv\n","├── [184K]  model_svd.p\n","├── [ 467]  rankings_avg.csv\n","├── [5.0K]  test.parquet.snappy\n","├── [7.0K]  train.parquet.snappy\n","├── [2.8G]  train_triplets.txt\n","└── [488M]  \u001b[01;31mtrain_triplets.txt.zip\u001b[00m\n","\n"," 3.3G used in 0 directories, 10 files\n"]}]},{"cell_type":"code","source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p surprise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5n0IQLTtiq9F","executionInfo":{"status":"ok","timestamp":1639025839853,"user_tz":-330,"elapsed":3854,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"701ffb5d-bea1-43b2-a3e2-a1222b908669"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-12-09 04:57:27\n","\n","surprise: 0.1\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","sys       : 3.7.12 (default, Sep 10 2021, 00:21:48) \n","[GCC 7.5.0]\n","seaborn   : 0.11.2\n","matplotlib: 3.2.2\n","IPython   : 5.5.0\n","argparse  : 1.1\n","requests  : 2.23.0\n","csv       : 1.0\n","logging   : 0.5.1.2\n","pandas    : 1.1.5\n","numpy     : 1.19.5\n","\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"TDEJSi4tiq9G"}},{"cell_type":"markdown","source":["**END**"],"metadata":{"id":"pyXLTwibiq9G"}}]}