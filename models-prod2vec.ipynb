{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.prod2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prod2Vec\n",
    "> Implementation of Prod2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List\n",
    "\n",
    "import logging\n",
    "import gensim\n",
    "import numpy as np\n",
    "import os\n",
    "from abc import ABC\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prod2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Prod2Vec(object):\n",
    "    \"\"\"\n",
    "    Implementation of the Prod2Vec skipgram model from\n",
    "    Grbovic Mihajlo, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp.\n",
    "    \"E-commerce in your inbox: Product recommendations at scale.\"\n",
    "    In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\n",
    "    pp. 1809-1818. ACM, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    def __init__(self, min_count=2, negative=5, size=100, window=5, decay_alpha=0.9):\n",
    "        \"\"\"\n",
    "        :param min_count: (optional) the minimum item frequency. Items less frequent that min_count will be pruned\n",
    "        :param negative: (optional) the minimum negative samples\n",
    "        :param size: (optional) the size of the embeddings\n",
    "        :param window: (optional) the size of the context window\n",
    "        :param decay_alpha: (optional) the exponential decay factor used to discount the similarity scores for items\n",
    "                back in the user profile. Lower values mean higher discounting of past user interactions. Allows values in [0-1].\n",
    "        \"\"\"\n",
    "        super(Prod2Vec, self).__init__()\n",
    "        self.min_count = min_count\n",
    "        self.negative = negative\n",
    "        self.size = size\n",
    "        self.window = window\n",
    "        self.decay_alpha = decay_alpha\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Prod2Vec(min_count={min_count}, ' \\\n",
    "               'size={size}, ' \\\n",
    "               'window={window}, ' \\\n",
    "               'decay_alpha={decay_alpha})'.format(**self.__dict__)\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self.model = gensim.models.Word2Vec(train_data,\n",
    "                                            min_count=self.min_count,\n",
    "                                            negative=self.negative,\n",
    "                                            window=self.window,\n",
    "                                            hs=1,\n",
    "                                            size=self.size,\n",
    "                                            sg=1,\n",
    "                                            workers=-1)\n",
    "        self.model.train(train_data, total_examples = self.model.corpus_count, \n",
    "                         epochs=10, report_delay=1)\n",
    "        # As we do not plan to train the model any further, we are calling\n",
    "        # init_sims(), which will make the model much more memory-efficient\n",
    "        self.model.init_sims(replace=True)\n",
    "\n",
    "    def aggregate_vectors(self, products):\n",
    "        product_vec = []\n",
    "        for i in products:\n",
    "            try:\n",
    "                product_vec.append(self.model[i])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "        return np.mean(product_vec, axis=0)\n",
    "\n",
    "    def recommend(self, user_profile, topk=5):\n",
    "        \"\"\"\n",
    "        Given the user profile return a list of recommendation\n",
    "\n",
    "        Args:\n",
    "            user_profile: list of item ids visited/interacted by the user\n",
    "            topk: (optional) top-k recommendations\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        try:\n",
    "            vec = self.aggregate_vectors(user_profile)\n",
    "            # extract most similar products for the input vector\n",
    "            rec = self.model.wv.similar_by_vector(vec, topn= topk+1)[1:]\n",
    "        except KeyError:\n",
    "            rec = []\n",
    "\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Retail.xlsx  100%[===================>]  22.62M  10.7MB/s    in 2.1s    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!wget -q --show-progress https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\n",
    "\n",
    "df = pd.read_excel('Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67c3bc470394dbc9374345f69804966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99361b1142540848001669faaa0d38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert the StockCode to string datatype\n",
    "df['StockCode']= df['StockCode'].astype(str)\n",
    "\n",
    "# Check out the number of unique customers in our dataset\n",
    "customers = df[\"CustomerID\"].unique().tolist()\n",
    "\n",
    "# shuffle customer ID's\n",
    "import random\n",
    "random.shuffle(customers)\n",
    "\n",
    "# extract 90% of customer ID's\n",
    "customers_train = [customers[i] for i in range(round(0.9*len(customers)))]\n",
    "\n",
    "# split data into train and validation set\n",
    "train_df = df[df['CustomerID'].isin(customers_train)]\n",
    "validation_df = df[~df['CustomerID'].isin(customers_train)]\n",
    "\n",
    "# list to capture purchase history of the customers\n",
    "purchases_train = []\n",
    "\n",
    "# populate the list with the product codes\n",
    "from tqdm.notebook import tqdm\n",
    "for i in tqdm(customers_train):\n",
    "    temp = train_df[train_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
    "    purchases_train.append(temp)\n",
    "\n",
    "# list to capture purchase history of the customers\n",
    "purchases_val = []\n",
    "\n",
    "# populate the list with the product codes\n",
    "for i in tqdm(validation_df['CustomerID'].unique()):\n",
    "    temp = validation_df[validation_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
    "    purchases_val.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word2vec Embeddings for Products\n",
    "# train word2vec model\n",
    "model = Prod2Vec(window=10, negative=5, size=100, min_count=2)\n",
    "model.fit(purchases_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "products = train_df[[\"StockCode\", \"Description\"]]\n",
    "\n",
    "# remove duplicates\n",
    "products.drop_duplicates(inplace=True, subset='StockCode', keep=\"last\")\n",
    "\n",
    "# create product-ID and product-description dictionary\n",
    "products_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SET OF 3 BABUSHKA STACKING TINS']\n",
      " \n",
      "['EDWARDIAN HEART PHOTO FRAME', 0.3702189028263092]\n",
      "['SET OF 6 VINTAGE NOTELETS KIT', 0.34610092639923096]\n",
      "['FRENCH STYLE STORAGE JAR JAM', 0.3301945626735687]\n",
      "['BAG 500g SWIRLY MARBLES', 0.3177795708179474]\n",
      "['SPOTTY BUNTING', 0.30998745560646057]\n"
     ]
    }
   ],
   "source": [
    "random_sample = products.sample(1).values\n",
    "recommendations = [[products_dict[a][0], b] for a,b in model.recommend(user_profile=random_sample[:,0])]\n",
    "\n",
    "print(random_sample[:,1])\n",
    "print(' ')\n",
    "for rec in recommendations: print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SET OF 5 LUCKY CAT MAGNETS ' 'HEARTS GIFT TAPE'\n",
      " 'PAINTED YELLOW WOODEN DAISY' 'COLOURFUL FLOWER FRUIT BOWL'\n",
      " 'TUSCAN VILLA BIRD FEEDER']\n",
      " \n",
      "['PAINTED YELLOW WOODEN DAISY', 0.498282253742218]\n",
      "['HEARTS GIFT TAPE', 0.4829496443271637]\n",
      "['TUSCAN VILLA BIRD FEEDER', 0.34984883666038513]\n",
      "['STRAWBERRY RAFFIA FOOD COVER', 0.3352939486503601]\n",
      "['IVORY PAPER CUP CAKE CASES ', 0.3215782642364502]\n"
     ]
    }
   ],
   "source": [
    "random_sample = products.sample(5).values\n",
    "recommendations = [[products_dict[a][0], b] for a,b in model.recommend(user_profile=random_sample[:,0])]\n",
    "\n",
    "print(random_sample[:,1])\n",
    "print(' ')\n",
    "for rec in recommendations: print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prod2Vec_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Prod2Vec_v2(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, items, iterations=15):\n",
    "        # Get the item ID and rating for each item for each unique user\n",
    "        x_train = [[str((x[\"sid\"], x[\"rating\"])) for x in y] for y in items]\n",
    "        self._model = self.train_embeddings(x_train, iterations=iterations)\n",
    "\n",
    "    def train_embeddings(\n",
    "        self,\n",
    "        sessions: list,\n",
    "        min_c: int = 3,\n",
    "        size: int = 48,\n",
    "        window: int = 5,\n",
    "        iterations: int = 15,\n",
    "        ns_exponent: float = 0.75,\n",
    "        is_debug: bool = True):\n",
    "        \"\"\"\n",
    "        Train CBOW to get product embeddings with sensible defaults\n",
    "        (https://arxiv.org/abs/2007.14906).\n",
    "        \"\"\"\n",
    "        model = gensim.models.Word2Vec(min_count=min_c,\n",
    "                                    size=size,\n",
    "                                    window=window,\n",
    "                                    iter=iterations,\n",
    "                                    ns_exponent=ns_exponent)\n",
    "\n",
    "        model.build_vocab(sessions)\n",
    "        model.init_sims(replace=True)\n",
    "        \n",
    "        return model.wv\n",
    "\n",
    "    def predict(self, prediction_input, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Predicts the top 10 similar items recommended for each user according\n",
    "        to the items that they've interacted and the ratings that they've given\n",
    "        :param prediction_input: a list of lists containing a dictionary for\n",
    "                                 each item interacted by that user\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        all_predictions = []\n",
    "        for items in prediction_input:\n",
    "            predictions = []\n",
    "            emb_vecs = []\n",
    "            for item in items:\n",
    "                emb_vec = self.get_vector(item)\n",
    "                if emb_vec:\n",
    "                    emb_vecs.append(emb_vec)\n",
    "            if emb_vecs:\n",
    "                # Calculate the average of all the latent vectors representing\n",
    "                # the items interacted by the user as is done in https://arxiv.org/abs/2007.14906\n",
    "                avg_emb_vec = np.mean(emb_vecs, axis=0)\n",
    "                nn_products = self.model.similar_by_vector(avg_emb_vec, topn=10)\n",
    "                for elem in nn_products:\n",
    "                    elem = ast.literal_eval(elem[0])\n",
    "                    predictions.append({\"sid\": elem[0], \"rating\": elem[1]})\n",
    "            all_predictions.append(predictions)\n",
    "        return all_predictions\n",
    "\n",
    "    def get_vector(self, x):\n",
    "        \"\"\"\n",
    "        Returns the latent vector that corresponds to the item ID and the rating\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        item = str((x[\"sid\"], x[\"rating\"]))\n",
    "        try:\n",
    "            return list(self.model.get_vector(item))\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prod2Vec_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Prod2Vec_v3:\n",
    "    \"\"\"\n",
    "    Implementation of the Prod2Vec skipgram model from\n",
    "    Grbovic Mihajlo, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp.\n",
    "    \"E-commerce in your inbox: Product recommendations at scale.\"\n",
    "    In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\n",
    "    pp. 1809-1818. ACM, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_count=2, size=100, window=5, decay_alpha=0.9, workers=4):\n",
    "        \"\"\"\n",
    "        :param min_count: (optional) the minimum item frequency. Items less frequent that min_count will be pruned\n",
    "        :param size: (optional) the size of the embeddings\n",
    "        :param window: (optional) the size of the context window\n",
    "        :param decay_alpha: (optional) the exponential decay factor used to discount the similarity scores for items\n",
    "                back in the user profile. Lower values mean higher discounting of past user interactions. Allows values in [0-1].\n",
    "        :param workers: (optional) the number of threads used for training\n",
    "        \"\"\"\n",
    "        self.min_count = min_count\n",
    "        self.size = size\n",
    "        self.window = window\n",
    "        self.decay_alpha = decay_alpha\n",
    "        self.workers = workers\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Prod2VecRecommender(min_count={min_count}, ' \\\n",
    "               'size={size}, ' \\\n",
    "               'window={window}, ' \\\n",
    "               'decay_alpha={decay_alpha}, ' \\\n",
    "               'workers={workers})'.format(**self.__dict__)\n",
    "\n",
    "    def fit(self, train_data, seq_col='sequence'):\n",
    "        sequences = train_data[seq_col].values\n",
    "        self.model = gensim.models.Word2Vec(sequences,\n",
    "                                            min_count=self.min_count,\n",
    "                                            window=self.window,\n",
    "                                            hs=1,\n",
    "                                            size=self.size,\n",
    "                                            sg=1,\n",
    "                                            workers=self.workers)\n",
    "\n",
    "    def recommend(self, user_profile, user_id=None):\n",
    "        \"\"\"\n",
    "        Given the user profile return a list of recommendation\n",
    "        :param user_profile: the user profile as a list of item identifiers\n",
    "        :param user_id: (optional) the user id\n",
    "        :return: list of recommendations e.g. [([2], 0.875), ([6], 1.0)]\n",
    "        \"\"\"\n",
    "        user_profile = list(map(str, user_profile))\n",
    "        rec = []\n",
    "        try:\n",
    "            # iterate the user profile backwards\n",
    "            for i, item in enumerate(user_profile[::-1]):\n",
    "                ms = self.model.most_similar(positive=item)\n",
    "                # apply exponential decay to the similarity scores\n",
    "                decay = self.decay_alpha ** i\n",
    "                ms = [(x[0], decay * x[1]) for x in ms]\n",
    "                rec.extend(ms)\n",
    "            # sort items by similarity score\n",
    "            rec = sorted(rec, key=lambda x: -x[1])\n",
    "        except KeyError:\n",
    "            rec = []\n",
    "        return [([x[0]], x[1]) for x in rec]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_recommendation_list(recommendation):\n",
    "        return list(map(lambda x: x[0], recommendation))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_recommendation_confidence_list(recommendation):\n",
    "        return list(map(lambda x: x[1], recommendation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from recohut.utils.data import load_dataset\n",
    "from recohut.utils.filters import filter_by_time, filter_top_k\n",
    "from recohut.utils.splitting import split_last_session_out\n",
    "from recohut.models.itempop import ItemPop_v2\n",
    "from recohut.evaluation.sequences import eval_seqreveal, eval_staticprofile\n",
    "from recohut.evaluation.sequences import eval_reclength, eval_profilelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('music30_sample')\n",
    "df.columns = ['session_id', 'user_id', 'item_id', 'ts', 'playtime']\n",
    "df['ts'] = pd.to_datetime(df['ts'], unit='s')\n",
    "\n",
    "# let's keep only the top-1k most popular items in the last month\n",
    "df = filter_by_time(df, last_months=1, ts_col='ts')\n",
    "df = filter_top_k(df, topk=1000, user_col='user_id', item_col='item_id', sess_col='session_id', ts_col='ts')\n",
    "\n",
    "train, test = split_last_session_out(df, user_col='user_id', sess_col='session_id', seq_col='sequence', time_col='ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prod2Vec_v3()\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891 sequences available for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:18<00:00, 154.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GIVEN_K': 1,\n",
       " 'LOOK_AHEAD': 1,\n",
       " 'MRR@10': 0.09646700449978074,\n",
       " 'Model': 'Prod2VecRecommender',\n",
       " 'Precision@10': 0.023950388764308123,\n",
       " 'Recall@10': 0.23162620325011596,\n",
       " 'STEP': 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_seqreveal(train, test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891 sequences available for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:01<00:00, 2624.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GIVEN_K': 1,\n",
       " 'LOOK_AHEAD': 'all',\n",
       " 'MRR@10': 0.1987120675550286,\n",
       " 'Model': 'Prod2VecRecommender',\n",
       " 'Precision@10': 0.10162573503977833,\n",
       " 'Recall@10': 0.19535189892426655,\n",
       " 'STEP': 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_staticprofile(train, test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891 sequences available for evaluation\n",
      "Evaluating recommendation lists with length: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:18<00:00, 152.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommendation lists with length: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:18<00:00, 153.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommendation lists with length: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:20<00:00, 142.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommendation lists with length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:19<00:00, 148.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommendation lists with length: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:26<00:00, 109.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommendation lists with length: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:23<00:00, 122.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 360x360 with 1 Axes>,\n",
       " <Figure size 360x360 with 1 Axes>,\n",
       " <Figure size 360x360 with 1 Axes>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_reclength(train, test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164 sequences available for evaluation\n",
      "Evaluating profiles having length: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:00<00:00, 2759.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating profiles having length: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:00<00:00, 1442.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating profiles having length: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:01<00:00, 1114.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating profiles having length: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:01<00:00, 882.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 360x360 with 1 Axes>,\n",
       " <Figure size 360x360 with 1 Axes>,\n",
       " <Figure size 360x360 with 1 Axes>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_profilelength(train, test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> References\n",
    ">\n",
    "> 1. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-07-19-session-based-prod2vec-coveo.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-07-19-session-based-prod2vec-coveo.ipynb)\n",
    "> 2. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-06-11-recostep-session-based-recommender-using-word2vec.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-06-11-recostep-session-based-recommender-using-word2vec.ipynb)\n",
    "> 3. [https://github.com/mquad/sars_tutorial/blob/master/recommenders/Prod2VecRecommender.py](https://github.com/mquad/sars_tutorial/blob/master/recommenders/Prod2VecRecommender.py)\n",
    "> 4. [https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-04-24-rec-medium-word2vec.ipynb](https://nbviewer.org/github/sparsh-ai/stanza/blob/S543002/2021-04-24-rec-medium-word2vec.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2022-01-13 11:15:25\n",
      "\n",
      "recohut: 0.0.11\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.144+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "gensim    : 3.6.0\n",
      "IPython   : 5.5.0\n",
      "networkx  : 2.6.3\n",
      "json      : 2.0.9\n",
      "matplotlib: 3.2.2\n",
      "torch     : 1.10.0+cu111\n",
      "numpy     : 1.19.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
