{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T416527 | NCF on ML-1m in TF 2.x","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLQcwA8h/vF2uP66AZlscM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Zb6n1vfEJq7H"},"source":["!pip install tensorflow==2.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thzbCqzfKV75","executionInfo":{"status":"ok","timestamp":1637056355012,"user_tz":-330,"elapsed":3517,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"21d2e932-2b22-456b-cbf5-8f70b2f2befc"},"source":["!wget -q --show-progress https://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ml-1m.zip           100%[===================>]   5.64M  3.71MB/s    in 1.5s    \n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n"]}]},{"cell_type":"code","metadata":{"id":"oRYCBuX9KV4O","executionInfo":{"status":"ok","timestamp":1637056667294,"user_tz":-330,"elapsed":3014,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import random\n","from time import time\n","from tqdm.notebook import tqdm\n","from collections import defaultdict\n","\n","import tensorflow as tf\n","from tensorflow.keras import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Layer, Dense, Dropout, Embedding, Input"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqhuTZxZLVlH","executionInfo":{"status":"ok","timestamp":1637056667298,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","file = 'ml-1m/ratings.dat'\n","trans_score = 1\n","test_neg_num = 100\n","\n","embed_dim = 32\n","hidden_units = [256, 128, 64]\n","embed_reg = 1e-6  # 1e-6\n","activation = 'relu'\n","dropout = 0.2\n","K = 10\n","\n","learning_rate = 0.001\n","epochs = 20\n","batch_size = 512"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"XoIea7QCKVzb","executionInfo":{"status":"ok","timestamp":1637056671922,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def sparseFeature(feat, feat_num, embed_dim=4):\n","    \"\"\"\n","    create dictionary for sparse feature\n","    :param feat: feature name\n","    :param feat_num: the total number of sparse features that do not repeat\n","    :param embed_dim: embedding dimension\n","    :return:\n","    \"\"\"\n","    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dlHOlqgKKk6S","executionInfo":{"status":"ok","timestamp":1637056671926,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def create_ml_1m_dataset(file, trans_score=2, embed_dim=8, test_neg_num=100):\n","    \"\"\"\n","    :param file: A string. dataset path.\n","    :param trans_score: A scalar. Greater than it is 1, and less than it is 0.\n","    :param embed_dim: A scalar. latent factor.\n","    :param test_neg_num: A scalar. The number of test negative samples\n","    :return: user_num, item_num, train_df, test_df\n","    \"\"\"\n","    print('==========Data Preprocess Start=============')\n","    data_df = pd.read_csv(file, sep=\"::\", engine='python',\n","                          names=['user_id', 'item_id', 'label', 'Timestamp'])\n","    # filtering\n","    data_df['item_count'] = data_df.groupby('item_id')['item_id'].transform('count')\n","    data_df = data_df[data_df.item_count >= 5]\n","    # trans score\n","    data_df = data_df[data_df.label >= trans_score]\n","    # sort\n","    data_df = data_df.sort_values(by=['user_id', 'Timestamp'])\n","    # split dataset and negative sampling\n","    print('============Negative Sampling===============')\n","    train_data, val_data, test_data = defaultdict(list), defaultdict(list), defaultdict(list)\n","    item_id_max = data_df['item_id'].max()\n","    for user_id, df in tqdm(data_df[['user_id', 'item_id']].groupby('user_id')):\n","        pos_list = df['item_id'].tolist()\n","\n","        def gen_neg():\n","            neg = pos_list[0]\n","            while neg in set(pos_list):\n","                neg = random.randint(1, item_id_max)\n","            return neg\n","\n","        neg_list = [gen_neg() for i in range(len(pos_list) + test_neg_num)]\n","        for i in range(1, len(pos_list)):\n","            hist_i = pos_list[:i]\n","            if i == len(pos_list) - 1:\n","                test_data['user_id'].append(user_id)\n","                test_data['pos_id'].append(pos_list[i])\n","                test_data['neg_id'].append(neg_list[i:])\n","            elif i == len(pos_list) - 2:\n","                val_data['user_id'].append(user_id)\n","                val_data['pos_id'].append(pos_list[i])\n","                val_data['neg_id'].append(neg_list[i])\n","            else:\n","                train_data['user_id'].append(user_id)\n","                train_data['pos_id'].append(pos_list[i])\n","                train_data['neg_id'].append(neg_list[i])\n","    # feature columns\n","    user_num, item_num = data_df['user_id'].max() + 1, data_df['item_id'].max() + 1\n","    item_feat_col = [sparseFeature('user_id', user_num, embed_dim),\n","                       sparseFeature('item_id', item_num, embed_dim)]\n","    # shuffle\n","    random.shuffle(train_data)\n","    random.shuffle(val_data)\n","    train = [np.array(train_data['user_id']), np.array(train_data['pos_id']),\n","               np.array(train_data['neg_id'])]\n","    val = [np.array(val_data['user_id']), np.array(val_data['pos_id']),\n","             np.array(val_data['neg_id'])]\n","    test = [np.array(test_data['user_id']), np.array(test_data['pos_id']),\n","              np.array(test_data['neg_id'])]\n","    print('============Data Preprocess End=============')\n","    return item_feat_col, train, val, test"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-neX9Y0KuWv","executionInfo":{"status":"ok","timestamp":1637056671929,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class DNN(Layer):\n","\t\"\"\"\n","\tDeep part\n","\t\"\"\"\n","\tdef __init__(self, hidden_units, activation='relu', dnn_dropout=0., **kwargs):\n","\t\t\"\"\"\n","\t\tDNN part\n","\t\t:param hidden_units: A list. List of hidden layer units's numbers\n","\t\t:param activation: A string. Activation function\n","\t\t:param dnn_dropout: A scalar. dropout number\n","\t\t\"\"\"\n","\t\tsuper(DNN, self).__init__(**kwargs)\n","\t\tself.dnn_network = [Dense(units=unit, activation=activation) for unit in hidden_units]\n","\t\tself.dropout = Dropout(dnn_dropout)\n","\n","\tdef call(self, inputs, **kwargs):\n","\t\tx = inputs\n","\t\tfor dnn in self.dnn_network:\n","\t\t\tx = dnn(x)\n","\t\tx = self.dropout(x)\n","\t\treturn x"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HK9Sq1d8KuTg","executionInfo":{"status":"ok","timestamp":1637056673980,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class NCF(Model):\n","    def __init__(self, feature_columns, hidden_units=None, dropout=0.2, activation='relu', embed_reg=1e-6, **kwargs):\n","        \"\"\"\n","        NCF model\n","        :param feature_columns: A list. user feature columns + item feature columns\n","        :param hidden_units: A list.\n","        :param dropout: A scalar.\n","        :param activation: A string.\n","        :param embed_reg: A scalar. The regularizer of embedding.\n","        \"\"\"\n","        super(NCF, self).__init__(**kwargs)\n","        if hidden_units is None:\n","            hidden_units = [64, 32, 16, 8]\n","        # feature columns\n","        self.user_fea_col, self.item_fea_col = feature_columns\n","        # MF user embedding\n","        self.mf_user_embedding = Embedding(input_dim=self.user_fea_col['feat_num'],\n","                                           input_length=1,\n","                                           output_dim=self.user_fea_col['embed_dim'],\n","                                           embeddings_initializer='random_normal',\n","                                           embeddings_regularizer=l2(embed_reg))\n","        # MF item embedding\n","        self.mf_item_embedding = Embedding(input_dim=self.item_fea_col['feat_num'],\n","                                           input_length=1,\n","                                           output_dim=self.item_fea_col['embed_dim'],\n","                                           embeddings_initializer='random_normal',\n","                                           embeddings_regularizer=l2(embed_reg))\n","        # MLP user embedding\n","        self.mlp_user_embedding = Embedding(input_dim=self.user_fea_col['feat_num'],\n","                                            input_length=1,\n","                                            output_dim=self.user_fea_col['embed_dim'],\n","                                            embeddings_initializer='random_normal',\n","                                            embeddings_regularizer=l2(embed_reg))\n","        # MLP item embedding\n","        self.mlp_item_embedding = Embedding(input_dim=self.item_fea_col['feat_num'],\n","                                            input_length=1,\n","                                            output_dim=self.item_fea_col['embed_dim'],\n","                                            embeddings_initializer='random_normal',\n","                                            embeddings_regularizer=l2(embed_reg))\n","        # dnn\n","        self.dnn = DNN(hidden_units, activation=activation, dnn_dropout=dropout)\n","        self.dense = Dense(1, activation=None)\n","\n","    def call(self, inputs):\n","        user_inputs, pos_inputs, neg_inputs = inputs  # (None, 1), (None, 1), (None, 1/101)\n","        # user info\n","        mf_user_embed = self.mf_user_embedding(user_inputs)  # (None, 1, dim)\n","        mlp_user_embed = self.mlp_user_embedding(user_inputs)  # (None, 1, dim)\n","        # item\n","        mf_pos_embed = self.mf_item_embedding(pos_inputs)  # (None, 1, dim)\n","        mf_neg_embed = self.mf_item_embedding(neg_inputs)  # (None, 1/101, dim)\n","        mlp_pos_embed = self.mlp_item_embedding(pos_inputs)  # (None, 1, dim)\n","        mlp_neg_embed = self.mlp_item_embedding(neg_inputs)  # (None, 1/101, dim)\n","        # MF\n","        mf_pos_vector = tf.nn.sigmoid(tf.multiply(mf_user_embed, mf_pos_embed))  # (None, 1, dim)\n","        mf_neg_vector = tf.nn.sigmoid(tf.multiply(mf_user_embed, mf_neg_embed))  # (None, 1, dim)\n","        # MLP\n","        mlp_pos_vector = tf.concat([mlp_user_embed, mlp_pos_embed], axis=-1)  # (None, 1, 2 * dim)\n","        mlp_neg_vector = tf.concat([tf.tile(mlp_user_embed, multiples=[1, mlp_neg_embed.shape[1], 1]),\n","                                    mlp_neg_embed], axis=-1)  # (None, 1/101, 2 * dim)\n","        mlp_pos_vector = self.dnn(mlp_pos_vector)  # (None, 1, dim)\n","        mlp_neg_vector = self.dnn(mlp_neg_vector)  # (None, 1/101, dim)\n","        # concat\n","        pos_vector = tf.concat([mf_pos_vector, mlp_pos_vector], axis=-1)  # (None, 1, 2 * dim)\n","        neg_vector = tf.concat([mf_neg_vector, mlp_neg_vector], axis=-1)  # (None, 1/101, 2 * dim)\n","        # pos_vector = mlp_pos_vector\n","        # neg_vector = mlp_neg_vector\n","        # result\n","        pos_logits = tf.squeeze(self.dense(pos_vector), axis=-1)  # (None, 1)\n","        neg_logits = tf.squeeze(self.dense(neg_vector), axis=-1)  # (None, 1/101)\n","        # loss\n","        losses = tf.reduce_mean(- tf.math.log(tf.nn.sigmoid(pos_logits)) -\n","                                tf.math.log(1 - tf.nn.sigmoid(neg_logits))) / 2\n","        self.add_loss(losses)\n","        logits = tf.concat([pos_logits, neg_logits], axis=-1)\n","        return logits\n","\n","    def summary(self):\n","        user_inputs = Input(shape=(1,), dtype=tf.int32)\n","        pos_inputs = Input(shape=(1,), dtype=tf.int32)\n","        neg_inputs = Input(shape=(1,), dtype=tf.int32)\n","        Model(inputs=[user_inputs, pos_inputs, neg_inputs],\n","              outputs=self.call([user_inputs, pos_inputs, neg_inputs])).summary()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqnt9DihKuQG","executionInfo":{"status":"ok","timestamp":1637056673983,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def test_model():\n","    user_features = {'feat': 'user_id', 'feat_num': 100, 'embed_dim': 8}\n","    item_features = {'feat': 'item_id', 'feat_num': 100, 'embed_dim': 8}\n","    features = [user_features, item_features]\n","    model = NCF(features)\n","    model.summary()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qdc9Il1pKuMl","executionInfo":{"status":"ok","timestamp":1637056673985,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def evaluate_model(model, test, K):\n","    \"\"\"\n","    evaluate model\n","    :param model: model\n","    :param test: test set\n","    :param K: top K\n","    :return: hit rate, ndcg\n","    \"\"\"\n","    pred_y = - model.predict(test)\n","    rank = pred_y.argsort().argsort()[:, 0]\n","    hr, ndcg = 0.0, 0.0\n","    for r in rank:\n","        if r < K:\n","            hr += 1\n","            ndcg += 1 / np.log2(r + 2)\n","    return hr / len(rank), ndcg / len(rank)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNgKr7GoLK2W","executionInfo":{"status":"ok","timestamp":1637057570102,"user_tz":-330,"elapsed":851948,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c96b1407-5bbf-4a10-8f1e-99e6c3291967"},"source":["# ========================== Create dataset =======================\n","feature_columns, train, val, test = create_ml_1m_dataset(file, trans_score, embed_dim, test_neg_num)\n","\n","# ============================Build Model==========================\n","mirrored_strategy = tf.distribute.MirroredStrategy()\n","with mirrored_strategy.scope():\n","    model = NCF(feature_columns, hidden_units, dropout, activation, embed_reg)\n","    model.summary()\n","    # =========================Compile============================\n","    model.compile(optimizer=Adam(learning_rate=learning_rate))\n","\n","results = []\n","for epoch in range(1, epochs + 1):\n","    # ===========================Fit==============================\n","    t1 = time()\n","    model.fit(\n","        train,\n","        None,\n","        validation_data=(val, None),\n","        epochs=1,\n","        batch_size=batch_size,\n","    )\n","    # ===========================Test==============================\n","    t2 = time()\n","    if epoch % 2 == 0:\n","        hit_rate, ndcg = evaluate_model(model, test, K)\n","        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG = %.4f'\n","                % (epoch, t2 - t1, time() - t2, hit_rate, ndcg))\n","        results.append([epoch, t2 - t1, time() - t2, hit_rate, ndcg])\n","# ========================== Write Log ===========================\n","pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time', 'hit_rate', 'ndcg'])\\\n","    .to_csv('NCF_log_dim_{}__K_{}.csv'.format(embed_dim, K), index=False)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["==========Data Preprocess Start=============\n","============Negative Sampling===============\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6040/6040 [00:33<00:00, 179.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["============Data Preprocess End=============\n","WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1, 32)        193312      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1, 32)        193312      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 32)        126496      input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 1, 32)        126496      input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","tf.tile (TFOpLambda)            (None, 1, 32)        0           embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","tf.math.multiply (TFOpLambda)   (None, 1, 32)        0           embedding[0][0]                  \n","                                                                 embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","tf.concat (TFOpLambda)          (None, 1, 64)        0           embedding_2[0][0]                \n","                                                                 embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","tf.math.multiply_1 (TFOpLambda) (None, 1, 32)        0           embedding[0][0]                  \n","                                                                 embedding_1[1][0]                \n","__________________________________________________________________________________________________\n","tf.concat_1 (TFOpLambda)        (None, 1, 64)        0           tf.tile[0][0]                    \n","                                                                 embedding_3[1][0]                \n","__________________________________________________________________________________________________\n","tf.math.sigmoid (TFOpLambda)    (None, 1, 32)        0           tf.math.multiply[0][0]           \n","__________________________________________________________________________________________________\n","dnn (DNN)                       (None, 1, 64)        57792       tf.concat[0][0]                  \n","                                                                 tf.concat_1[0][0]                \n","__________________________________________________________________________________________________\n","tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 32)        0           tf.math.multiply_1[0][0]         \n","__________________________________________________________________________________________________\n","tf.concat_2 (TFOpLambda)        (None, 1, 96)        0           tf.math.sigmoid[0][0]            \n","                                                                 dnn[0][0]                        \n","__________________________________________________________________________________________________\n","tf.concat_3 (TFOpLambda)        (None, 1, 96)        0           tf.math.sigmoid_1[0][0]          \n","                                                                 dnn[1][0]                        \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1, 1)         97          tf.concat_2[0][0]                \n","                                                                 tf.concat_3[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze (TFOpLambd (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze_1 (TFOpLam (None, 1)            0           dense_3[1][0]                    \n","__________________________________________________________________________________________________\n","tf.concat_4 (TFOpLambda)        (None, 2)            0           tf.compat.v1.squeeze[0][0]       \n","                                                                 tf.compat.v1.squeeze_1[0][0]     \n","==================================================================================================\n","Total params: 697,505\n","Trainable params: 697,505\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","1917/1917 [==============================] - 39s 19ms/step - loss: 0.4642 - val_loss: 0.5138\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.4169 - val_loss: 0.4730\n","Iteration 2 Fit [41.1 s], Evaluate [4.1 s]: HR = 0.5331, NDCG = 0.2941\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.3761 - val_loss: 0.4443\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.3445 - val_loss: 0.4323\n","Iteration 4 Fit [41.1 s], Evaluate [2.3 s]: HR = 0.6132, NDCG = 0.3410\n","1917/1917 [==============================] - 37s 19ms/step - loss: 0.3263 - val_loss: 0.4301\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.3117 - val_loss: 0.4304\n","Iteration 6 Fit [41.1 s], Evaluate [2.7 s]: HR = 0.6177, NDCG = 0.3467\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2997 - val_loss: 0.4311\n","1917/1917 [==============================] - 37s 19ms/step - loss: 0.2893 - val_loss: 0.4477\n","Iteration 8 Fit [41.1 s], Evaluate [2.7 s]: HR = 0.6116, NDCG = 0.3385\n","1917/1917 [==============================] - 37s 19ms/step - loss: 0.2806 - val_loss: 0.4687\n","1917/1917 [==============================] - 37s 19ms/step - loss: 0.2729 - val_loss: 0.4969\n","Iteration 10 Fit [36.7 s], Evaluate [2.3 s]: HR = 0.6008, NDCG = 0.3328\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2661 - val_loss: 0.4972\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2600 - val_loss: 0.5226\n","Iteration 12 Fit [36.5 s], Evaluate [2.3 s]: HR = 0.5877, NDCG = 0.3214\n","1917/1917 [==============================] - 38s 20ms/step - loss: 0.2548 - val_loss: 0.5287\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2501 - val_loss: 0.5616\n","Iteration 14 Fit [36.4 s], Evaluate [2.2 s]: HR = 0.5921, NDCG = 0.3241\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2456 - val_loss: 0.5817\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2415 - val_loss: 0.6016\n","Iteration 16 Fit [36.4 s], Evaluate [2.7 s]: HR = 0.5806, NDCG = 0.3129\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2380 - val_loss: 0.6058\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2346 - val_loss: 0.6222\n","Iteration 18 Fit [41.1 s], Evaluate [2.7 s]: HR = 0.5750, NDCG = 0.3108\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2316 - val_loss: inf\n","1917/1917 [==============================] - 36s 19ms/step - loss: 0.2287 - val_loss: 0.6692\n","Iteration 20 Fit [36.4 s], Evaluate [2.2 s]: HR = 0.5631, NDCG = 0.3034\n"]}]}]}