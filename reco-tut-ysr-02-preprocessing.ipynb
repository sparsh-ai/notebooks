{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_name = \"reco-tut-ysr\"; branch = \"main\"; account = \"sparsh-ai\"\n",
    "project_path = os.path.join('/content', project_name)\n",
    "\n",
    "if not os.path.exists(project_path):\n",
    "    !cp /content/drive/MyDrive/mykeys.py /content\n",
    "    import mykeys\n",
    "    !rm /content/mykeys.py\n",
    "    path = \"/content/\" + project_name; \n",
    "    !mkdir \"{path}\"\n",
    "    %cd \"{path}\"\n",
    "    import sys; sys.path.append(path)\n",
    "    !git config --global user.email \"recotut@recohut.com\"\n",
    "    !git config --global user.name  \"reco-tut\"\n",
    "    !git init\n",
    "    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n",
    "    !git pull origin \"{branch}\"\n",
    "    !git checkout main\n",
    "else:\n",
    "    %cd \"{project_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add . && git commit -m 'commit' && git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTXT(filename, start_line=0, sep=None):\n",
    "    with open(filename) as file:\n",
    "        return [line.rstrip().split(sep) for line in file.readlines()[start_line:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('./data/bronze/song_hash.txt', sep = '\\t', header = None,\n",
    "                    names = ['song_id', 'title', 'artist'], index_col = 0)\n",
    "songs['artist - title'] = songs['artist'] + \" - \" + songs['title']\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = readTXT('./data/bronze/tags.txt')\n",
    "tags[7:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: # means the song doesn't have any tag. we can replace it with unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tags = dict(readTXT('./data/bronze/tag_hash.txt', sep = ', '))\n",
    "mapping_tags['#'] = \"unknown\"\n",
    "song_tags = pd.DataFrame({'tag_names': [list(map(lambda x: mapping_tags.get(x), t)) for t in tags]})\n",
    "song_tags.index.name = 'song_id'\n",
    "song_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider song tags as a feature of song, so will merge it in songs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.merge(left = songs, right = song_tags, how = 'left',\n",
    "                 left_index = True, right_index = True)\n",
    "songs.index = songs.index.astype('str')\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the unknown songs, which doesn't have title and artist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_songs = songs[(songs['artist'] == '-') | (songs['title'] == '-')]\n",
    "songs.drop(unknown_songs.index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = readTXT('./data/bronze/train.txt', start_line = 2) + readTXT('./data/bronze/test.txt', start_line = 2)\n",
    "print(f'Playlist Count: {len(playlist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"Playlist Idx. {i}: {len(playlist[i])} Songs\")\n",
    "    print(\"-------------------------\")\n",
    "    print(playlist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unknown songs from the playlist.\n",
    "playlist_wo_unknown = [[song_id for song_id in p if song_id not in unknown_songs.index]\n",
    "                       for p in playlist]\n",
    "\n",
    "# Remove playlist with zero or one song, since the model wouldn't capture any sequence in that list.\n",
    "clean_playlist = [p for p in playlist_wo_unknown if len(p) > 1]\n",
    "print(f\"Playlist Count After Cleansing: {len(clean_playlist)}\")\n",
    "\n",
    "# Remove song that doesn't exist in any playlist.\n",
    "unique_songs = set(itertools.chain.from_iterable(clean_playlist))\n",
    "song_id_not_exist = set(songs.index) - unique_songs\n",
    "songs.drop(song_id_not_exist, inplace = True)\n",
    "print(f\"Unique Songs After Cleansing: {songs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before there were 75262 unique songs and 15910 playlists. Now we are ready with 73448 unique songs and 15842 playlists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data/silver\n",
    "\n",
    "with open('./data/silver/songs.pickle', 'wb') as handle:\n",
    "    pickle.dump(songs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('./data/silver/clean_playlist.pickle', 'wb') as handle:\n",
    "    pickle.dump(clean_playlist, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPvyXDynG2QHXWOjYzdEhiy",
   "collapsed_sections": [],
   "mount_file_id": "1G94Q6DmPw-Aej_urldj-gh1dphDMoSLd",
   "name": "reco-tut-ysr-02-preprocessing.ipynb",
   "provenance": [
    {
     "file_id": "1wgDgPKtfzySg9rFbT4M8H36kkahsxW1n",
     "timestamp": 1628264393475
    },
    {
     "file_id": "124PTuL4mumw_H7RPbqvAanbcZeTUOmFw",
     "timestamp": 1628263838077
    },
    {
     "file_id": "1__XR5YNYSaozls0OLI_vUkTnOCZg_0Nf",
     "timestamp": 1628254696760
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
