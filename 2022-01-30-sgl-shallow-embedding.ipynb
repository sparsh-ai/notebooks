{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Graph Learning - Shallow Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.utils.validation import check_is_fitted, _deprecate_positional_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(G, node_names={}, nodes_label=[], node_size=900):\n",
    "    pos_nodes = nx.spring_layout(G)\n",
    "    \n",
    "    col = {0:\"steelblue\",1:\"red\",2:\"green\"}\n",
    "    \n",
    "    colors = [col[x] for x in nodes_label]\n",
    "    \n",
    "    nx.draw(G, pos_nodes, with_labels=True, node_color=colors, node_size=node_size, edge_color='gray', \n",
    "            arrowsize=30)\n",
    "    \n",
    "    pos_attrs = {}\n",
    "    for node, coords in pos_nodes.items():\n",
    "        pos_attrs[node] = (coords[0], coords[1] + 0.08)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    axis = plt.gca()\n",
    "    axis.set_xlim([1.2*x for x in axis.get_xlim()])\n",
    "    axis.set_ylim([1.2*y for y in axis.get_ylim()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label propagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label propagation algorithm is a well-known semi-supervised algorithm widely applied in data science and used to solve the node classification task. More precisely, the algorithm *propagates* the label of a given node to its neighbors or to nodes having a high probability of being reached from that node.\n",
    "\n",
    "The general idea behind this approach is quite simple: given a graph with a set of labeled and unlabeled nodes, the labeled nodes propagate their label to the nodes having the highest probability of being reached. In the following diagram, we can see an example of a graph having labeled and unlabeled nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barbell_graph(m1=3, m2=2)\n",
    "nodes_label = [0 for x in range(len(G.nodes()))]\n",
    "nodes_label[0] = 1\n",
    "nodes_label[6] = 2\n",
    "draw_graph(G, nodes_label=nodes_label, node_size=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the figure above, using the information of the labeled nodes (node 0 and 6), the algorithm will calculate the probability of moving to another unlabeled node. The nodes having the highest probability from a labeled node will get the label of that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [G.degree(n) for n in G.nodes()]\n",
    "D = np.diag(D)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = inv(D)*nx.to_numpy_matrix(G)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label propagation implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLabelPropagation(ClassifierMixin, BaseEstimator, metaclass=ABCMeta):\n",
    "    \"\"\"Graph label propagation module.\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_iter : int, default=30\n",
    "        Change maximum number of iterations allowed.\n",
    "    tol : float, default=1e-3\n",
    "        Convergence tolerance: threshold to consider the system at steady\n",
    "        state.\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, max_iter=30, tol=1e-3):\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs inductive inference across the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : A networkx array.\n",
    "            The data matrix.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            Predictions for input data.\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return self.classes_[np.argmax(probas, axis=1)].ravel()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probability for each possible outcome.\n",
    "        Compute the probability estimates for each single node in X\n",
    "        and each possible outcome seen during training (categorical\n",
    "        distribution).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : A networkx array.\n",
    "        Returns\n",
    "        -------\n",
    "        probabilities : ndarray of shape (n_samples, n_classes)\n",
    "            Normalized probability distributions across\n",
    "            class labels.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        return self.label_distributions_\n",
    "    \n",
    "    def _validate_data(self, X, y):\n",
    "        if not isinstance(X, nx.Graph):\n",
    "            raise ValueError(\"Input should be a networkX graph\")\n",
    "        if not len(y) == len(X.nodes()):\n",
    "            raise ValueError(\"Label data input shape should be equal to the number of nodes in the graph\")\n",
    "        return X, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_label(x,classes):\n",
    "        tmp = np.zeros((classes))\n",
    "        tmp[x] = 1\n",
    "        return tmp\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit a semi-supervised label propagation model based\n",
    "        on the input graph G and corresponding label matrix y with a dedicated marker value for\n",
    "        unlabeled samples.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : A networkX array.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            `n_labeled_samples` (unlabeled points are marked as -1)\n",
    "            All unlabeled samples will be transductively assigned labels.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        X, y = self._validate_data(X, y)\n",
    "        self.X_ = X\n",
    "        check_classification_targets(y)\n",
    "\n",
    "        D = [X.degree(n) for n in X.nodes()]\n",
    "        D = np.diag(D)\n",
    "        \n",
    "        # label construction\n",
    "        # construct a categorical distribution for classification only\n",
    "        unlabeled_index = np.where(y==-1)[0]\n",
    "        labeled_index = np.where(y!=-1)[0]\n",
    "        unique_classes = np.unique(y[labeled_index])\n",
    "        \n",
    "        self.classes_ = unique_classes\n",
    "        \n",
    "        Y0 = np.array([self.build_label(y[x], len(unique_classes)) \n",
    "                                 if x in labeled_index else np.zeros(len(unique_classes)) for x in range(len(y))])\n",
    "        \n",
    "        A = inv(D)*nx.to_numpy_matrix(G)\n",
    "        Y_prev = Y0\n",
    "        it = 0\n",
    "        c_tool = 10\n",
    "        \n",
    "        while it < self.max_iter & c_tool > self.tol:\n",
    "            Y = A*Y_prev\n",
    "            #force labeled nodes\n",
    "            Y[labeled_index] = Y0[labeled_index]\n",
    "            \n",
    "            it +=1\n",
    "            c_tol = np.sum(np.abs(Y-Y_prev))\n",
    "            \n",
    "            Y_prev = Y\n",
    "            \n",
    "        self.label_distributions_ = Y\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label propagation execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glp = GraphLabelPropagation()\n",
    "y = np.array([-1 for x in range(len(G.nodes()))])\n",
    "y[0] = 1\n",
    "y[6] = 0\n",
    "glp.fit(G,y)\n",
    "tmp = glp.predict(G)\n",
    "print(glp.predict_proba(G))\n",
    "\n",
    "draw_graph(G, nodes_label=tmp+1, node_size=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label spreading algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label spreading algorithm is another semi-supervised shallow embedding algorithm. It was built in order to overcome one big limitation of the label propagation method: the initial labeling. Indeed, according to the label propagation algorithm, the initial labels cannot be modified in the training process and, in each iteration, they are forced to be equal to their original value. This constraint could generate incorrect results when the initial labeling is affected by errors or noise. As a consequence, the error will be propagated in all nodes of the input graph.\n",
    "\n",
    "In order to solve this limitation, the label spreading algorithm tries to relax the constraint of the original labeled data, allowing the labeled input nodes to change their label during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barbell_graph(m1=3, m2=2)\n",
    "nodes_label = [0 for x in range(len(G.nodes()))]\n",
    "nodes_label[0] = 1\n",
    "nodes_label[6] = 2\n",
    "draw_graph(G, nodes_label=nodes_label, node_size=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [G.degree(n) for n in G.nodes()]\n",
    "D = np.diag(D)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized graph Laplacian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_inv = fractional_matrix_power(D, -0.5)\n",
    "L = D_inv*nx.to_numpy_matrix(G)*D_inv\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label spreading implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLabelSpreading(GraphLabelPropagation):\n",
    "    \"\"\"Graph label propagation module.\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_iter : int, default=30\n",
    "        Change maximum number of iterations allowed.\n",
    "    tol : float, default=1e-3\n",
    "        Convergence tolerance: threshold to consider the system at steady\n",
    "        state.\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, max_iter=30, tol=1e-3, alpha=0.6):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        super().__init__(max_iter, tol)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit a semi-supervised label propagation model based\n",
    "        on the input graph G and corresponding label matrix y with a dedicated marker value for\n",
    "        unlabeled samples.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : A networkX array.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            `n_labeled_samples` (unlabeled points are marked as -1)\n",
    "            All unlabeled samples will be transductively assigned labels.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        X, y = self._validate_data(X, y)\n",
    "        self.X_ = X\n",
    "        check_classification_targets(y)\n",
    "\n",
    "        D = [X.degree(n) for n in X.nodes()]\n",
    "        D = np.diag(D)\n",
    "        D_inv = np.matrix(fractional_matrix_power(D,-0.5))\n",
    "        L = D_inv*nx.to_numpy_matrix(G)*D_inv\n",
    "        \n",
    "        # label construction\n",
    "        # construct a categorical distribution for classification only\n",
    "        unlabeled_index = np.where(y==-1)[0]\n",
    "        labeled_index = np.where(y!=-1)[0]\n",
    "        unique_classes = np.unique(y[labeled_index])\n",
    "        \n",
    "        self.classes_ = unique_classes\n",
    "        \n",
    "        Y0 = np.array([self.build_label(y[x], len(unique_classes)) \n",
    "                                 if x in labeled_index else np.zeros(len(unique_classes)) for x in range(len(y))])\n",
    "        \n",
    "        Y_prev = Y0\n",
    "        it = 0\n",
    "        c_tool = 10\n",
    "        \n",
    "        while it < self.max_iter & c_tool > self.tol:\n",
    "            Y = self.alpha*(L*Y_prev)+((1-self.alpha)*Y0)\n",
    "\n",
    "            it +=1\n",
    "            c_tol = np.sum(np.abs(Y-Y_prev))\n",
    "            Y_prev = Y\n",
    "        self.label_distributions_ = Y\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label spreading execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls = GraphLabelSpreading(max_iter=1000)\n",
    "y = np.array([-1 for x in range(len(G.nodes()))])\n",
    "y[0] = 1\n",
    "y[6] = 0\n",
    "gls.fit(G,y)\n",
    "tmp = gls.predict(G)\n",
    "print(gls.predict_proba(G))\n",
    "draw_graph(G, nodes_label=tmp+1, node_size=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result visible in the diagram shown in Figure 4.8 looks similar to the one obtained using the label propagation algorithm. The main difference is related to the probability of label assignment. Indeed, in this case, it is possible to see how nodes 0 and 6 (the ones having an initial labeling) have a probability of 0.5, which is significantly lower compared to the probability of 1 obtained using the label propagation algorithm. This behavior is expected since the influence of the initial label assignment is weighted by the regularization parameter $\\alpha$."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/mUoppqS878DjOHjtWsxo",
   "collapsed_sections": [],
   "name": "rec-tut-gml-04-sgl-shallow-embedding-methods.ipynb",
   "provenance": [
    {
     "file_id": "1FlR0Nt00zRzrjciEpl46j51IIomB0K_p",
     "timestamp": 1627985656545
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
