{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T525949 | AttRec on ML-1m in TF 2.x","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOo+X3/PrziNmCUVodT6WYC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2e75547bbc7c4fffa0295e9eff296fda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ce22228654446e3804adccba9b581e0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42f32229d0284ba5b3c79220472f89f9","IPY_MODEL_89079249d29a4188ba2353eecdbcb0bb","IPY_MODEL_34820c17224e46cfb1f3c420229e250e"]}},"4ce22228654446e3804adccba9b581e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42f32229d0284ba5b3c79220472f89f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_37660610c37f4652980211bdb9196c2b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88e6dab0adf34266ad96b78178852802"}},"89079249d29a4188ba2353eecdbcb0bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_68f7a61b4ce84099b0bec68c3602e70e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":6040,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6040,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38333b66d8f74363a0cf45b10a4ff3fe"}},"34820c17224e46cfb1f3c420229e250e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1415bc028c6a476aad215c062bcc5a72","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6040/6040 [00:23&lt;00:00, 376.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71565e08392045f9aee9457de810096e"}},"37660610c37f4652980211bdb9196c2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"88e6dab0adf34266ad96b78178852802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68f7a61b4ce84099b0bec68c3602e70e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38333b66d8f74363a0cf45b10a4ff3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1415bc028c6a476aad215c062bcc5a72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71565e08392045f9aee9457de810096e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gr_exnbyFd9P"},"source":["!pip install tensorflow==2.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiIrgWPHA_sZ","executionInfo":{"status":"ok","timestamp":1637053914012,"user_tz":-330,"elapsed":2087,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"7ea8e7cd-ed25-4dde-99b3-79000be5aea4"},"source":["!wget -q --show-progress https://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ml-1m.zip           100%[===================>]   5.64M  6.15MB/s    in 0.9s    \n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n"]}]},{"cell_type":"code","metadata":{"id":"PruyIn0iAyRx","executionInfo":{"status":"ok","timestamp":1637055306678,"user_tz":-330,"elapsed":2559,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import random\n","from time import time\n","from tqdm.notebook import tqdm\n","from collections import defaultdict\n","\n","import tensorflow as tf\n","from tensorflow.keras import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Embedding, Input\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from tensorflow.keras.layers import Layer, Dense\n","from tensorflow.keras.losses import Loss"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LOSVVJUC6au"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -m -iv -u -t -d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vSaa-LDB4KO","executionInfo":{"status":"ok","timestamp":1637055307254,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","file = 'ml-1m/ratings.dat'\n","trans_score = 1\n","maxlen = 5\n","\n","embed_dim = 100\n","embed_reg = 1e-6  # 1e-6\n","gamma = 0.5\n","mode = 'inner'  # 'inner' or 'dist'\n","w = 0.5\n","K = 10\n","\n","learning_rate = 0.001\n","epochs = 40\n","batch_size = 1024"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YXVIHnhA0_B","executionInfo":{"status":"ok","timestamp":1637055309502,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def sparseFeature(feat, feat_num, embed_dim=4):\n","    \"\"\"\n","    create dictionary for sparse feature\n","    :param feat: feature name\n","    :param feat_num: the total number of sparse features that do not repeat\n","    :param embed_dim: embedding dimension\n","    :return:\n","    \"\"\"\n","    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDHSNwWoA3Lm","executionInfo":{"status":"ok","timestamp":1637055310302,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def create_implicit_ml_1m_dataset(file, trans_score=2, embed_dim=8, maxlen=40):\n","    \"\"\"\n","    :param file: A string. dataset path.\n","    :param trans_score: A scalar. Greater than it is 1, and less than it is 0.\n","    :param embed_dim: A scalar. latent factor.\n","    :param maxlen: A scalar. maxlen.\n","    :return: user_num, item_num, train_df, test_df\n","    \"\"\"\n","    print('==========Data Preprocess Start============')\n","    data_df = pd.read_csv(file, sep=\"::\", engine='python',\n","                     names=['user_id', 'item_id', 'label', 'Timestamp'])\n","    # implicit dataset\n","    data_df = data_df[data_df.label >= trans_score]\n","\n","    # sort\n","    data_df = data_df.sort_values(by=['user_id', 'Timestamp'])\n","\n","    train_data, val_data, test_data = [], [], []\n","\n","    item_id_max = data_df['item_id'].max()\n","    for user_id, df in tqdm(data_df[['user_id', 'item_id']].groupby('user_id')):\n","        pos_list = df['item_id'].tolist()\n","\n","        def gen_neg():\n","            neg = pos_list[0]\n","            while neg in pos_list:\n","                neg = random.randint(1, item_id_max)\n","            return neg\n","\n","        neg_list = [gen_neg() for i in range(len(pos_list) + 100)]\n","        for i in range(1, len(pos_list)):\n","            hist_i = pos_list[:i]\n","            if i == len(pos_list) - 1:\n","                for neg in neg_list[i:]:\n","                    test_data.append([user_id, hist_i, pos_list[i], neg])\n","            elif i == len(pos_list) - 2:\n","                val_data.append([user_id, hist_i, pos_list[i], neg_list[i]])\n","            else:\n","                train_data.append([user_id, hist_i, pos_list[i], neg_list[i]])\n","\n","    # feature columns\n","    user_num, item_num = data_df['user_id'].max() + 1, data_df['item_id'].max() + 1\n","    feature_columns = [sparseFeature('user_id', user_num, embed_dim),\n","                       sparseFeature('item_id', item_num, embed_dim)]\n","\n","    # shuffle\n","    random.shuffle(train_data)\n","    random.shuffle(val_data)\n","    random.shuffle(test_data)\n","\n","    # create dataframe\n","    train = pd.DataFrame(train_data, columns=['user_id', 'hist', 'pos_item', 'neg_item'])\n","    val = pd.DataFrame(val_data, columns=['user_id', 'hist', 'pos_item', 'neg_item'])\n","    test = pd.DataFrame(test_data, columns=['user_id', 'hist', 'pos_item', 'neg_item'])\n","    print('==================Padding===================')\n","\n","    # create dataset\n","    def df_to_list(data):\n","        return [data['user_id'].values, pad_sequences(data['hist'], maxlen=maxlen),\n","                data['pos_item'].values, data['neg_item'].values]\n","\n","    train_X = df_to_list(train)\n","    val_X = df_to_list(val)\n","    test_X = df_to_list(test)\n","    print('============Data Preprocess End=============')\n","    return feature_columns, train_X, val_X, test_X"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ADXVraJMEp0E","executionInfo":{"status":"ok","timestamp":1637055311466,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class SelfAttention_Layer(Layer):\n","    def __init__(self):\n","        super(SelfAttention_Layer, self).__init__()\n","\n","    def build(self, input_shape):\n","        self.dim = input_shape[0][-1]\n","        self.W = self.add_weight(shape=[self.dim, self.dim], name='weight', \n","            initializer='random_uniform')\n","\n","    def call(self, inputs, **kwargs):\n","        q, k, v, mask = inputs\n","        # pos encoding\n","        k += self.positional_encoding(k)\n","        q += self.positional_encoding(q)\n","        # Nonlinear transformation\n","        q = tf.nn.relu(tf.matmul(q, self.W))  # (None, seq_len, dim)\n","        k = tf.nn.relu(tf.matmul(k, self.W))  # (None, seq_len, dim)\n","        mat_qk = tf.matmul(q, k, transpose_b=True)  # (None, seq_len, seq_len)\n","        dk = tf.cast(self.dim, dtype=tf.float32)\n","        # Scaled\n","        scaled_att_logits = mat_qk / tf.sqrt(dk)\n","        # Mask\n","        mask = tf.tile(tf.expand_dims(mask, 1), [1, q.shape[1], 1])  # (None, seq_len, seq_len)\n","        paddings = tf.ones_like(scaled_att_logits) * (-2 ** 32 + 1)\n","        outputs = tf.where(tf.equal(mask, 0), paddings, scaled_att_logits)  # (None, seq_len, seq_len)\n","        # softmax\n","        outputs = tf.nn.softmax(logits=outputs, axis=-1)  # (None, seq_len, seq_len)\n","        # output\n","        outputs = tf.matmul(outputs, v)  # (None, seq_len, dim)\n","        outputs = tf.reduce_mean(outputs, axis=1)  # (None, dim)\n","        return outputs\n","\n","    @staticmethod\n","    def get_angles(pos, i, d_model):\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","        return pos * angle_rates\n","\n","    def positional_encoding(self, QK_input):\n","        angle_rads = self.get_angles(np.arange(QK_input.shape[1])[:, np.newaxis],\n","                                np.arange(self.dim)[np.newaxis, :], self.dim)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","\n","        return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rs0iTy3BhSF","executionInfo":{"status":"ok","timestamp":1637055312873,"user_tz":-330,"elapsed":633,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class AttRec(Model):\n","    def __init__(self, feature_columns, maxlen=40, mode='inner', gamma=0.5, w=0.5, embed_reg=1e-6, **kwargs):\n","        \"\"\"\n","        AttRec\n","        :param feature_columns: A feature columns list. user + seq\n","        :param maxlen: A scalar. In the paper, maxlen is L, the number of latest items.\n","        :param gamma: A scalar. if mode == 'dist', gamma is the margin.\n","        :param mode: A string. inner or dist.\n","        :param w: A scalar. The weight of short interest.\n","        :param embed_reg: A scalar. The regularizer of embedding.\n","        \"\"\"\n","        super(AttRec, self).__init__(**kwargs)\n","        # maxlen\n","        self.maxlen = maxlen\n","        # w\n","        self.w = w\n","        self.gamma = gamma\n","        self.mode = mode\n","        # feature columns\n","        self.user_fea_col, self.item_fea_col = feature_columns\n","        # embed_dim\n","        self.embed_dim = self.item_fea_col['embed_dim']\n","        # user embedding\n","        self.user_embedding = Embedding(input_dim=self.user_fea_col['feat_num'],\n","                                        input_length=1,\n","                                        output_dim=self.user_fea_col['embed_dim'],\n","                                        mask_zero=False,\n","                                        embeddings_initializer='random_normal',\n","                                        embeddings_regularizer=l2(embed_reg))\n","        # item embedding\n","        self.item_embedding = Embedding(input_dim=self.item_fea_col['feat_num'],\n","                                        input_length=1,\n","                                        output_dim=self.item_fea_col['embed_dim'],\n","                                        mask_zero=True,\n","                                        embeddings_initializer='random_normal',\n","                                        embeddings_regularizer=l2(embed_reg))\n","        # item2 embedding, not share embedding\n","        self.item2_embedding = Embedding(input_dim=self.item_fea_col['feat_num'],\n","                                        input_length=1,\n","                                        output_dim=self.item_fea_col['embed_dim'],\n","                                        mask_zero=True,\n","                                        embeddings_initializer='random_normal',\n","                                        embeddings_regularizer=l2(embed_reg))\n","        # self-attention\n","        self.self_attention = SelfAttention_Layer()\n","\n","    def call(self, inputs, **kwargs):\n","        # input\n","        user_inputs, seq_inputs, pos_inputs, neg_inputs = inputs\n","        # mask\n","        # mask = self.item_embedding.compute_mask(seq_inputs)\n","        mask = tf.cast(tf.not_equal(seq_inputs, 0), dtype=tf.float32)  # (None, maxlen)\n","        # user info\n","        user_embed = self.user_embedding(tf.squeeze(user_inputs, axis=-1))  # (None, dim)\n","        # seq info\n","        seq_embed = self.item_embedding(seq_inputs)  # (None, maxlen, dim)\n","        # item\n","        pos_embed = self.item_embedding(tf.squeeze(pos_inputs, axis=-1))  # (None, dim)\n","        neg_embed = self.item_embedding(tf.squeeze(neg_inputs, axis=-1))  # (None, dim)\n","        # item2 embed\n","        pos_embed2 = self.item2_embedding(tf.squeeze(pos_inputs, axis=-1))  # (None, dim)\n","        neg_embed2 = self.item2_embedding(tf.squeeze(neg_inputs, axis=-1))  # (None, dim)\n","\n","        # short-term interest\n","        short_interest = self.self_attention([seq_embed, seq_embed, seq_embed, mask])  # (None, dim)\n","\n","        # mode\n","        if self.mode == 'inner':\n","            # long-term interest, pos and neg\n","            pos_long_interest = tf.multiply(user_embed, pos_embed2)\n","            neg_long_interest = tf.multiply(user_embed, neg_embed2)\n","            # combine\n","            pos_scores = self.w * tf.reduce_sum(pos_long_interest, axis=-1, keepdims=True) \\\n","                         + (1 - self.w) * tf.reduce_sum(tf.multiply(short_interest, pos_embed), axis=-1, keepdims=True)\n","            neg_scores = self.w * tf.reduce_sum(neg_long_interest, axis=-1, keepdims=True) \\\n","                         + (1 - self.w) * tf.reduce_sum(tf.multiply(short_interest, neg_embed), axis=-1, keepdims=True)\n","            self.add_loss(tf.reduce_mean(-tf.math.log(tf.nn.sigmoid(pos_scores - neg_scores))))\n","        else:\n","            # clip by norm\n","            user_embed = tf.clip_by_norm(user_embed, 1, -1)\n","            pos_embed = tf.clip_by_norm(pos_embed, 1, -1)\n","            neg_embed = tf.clip_by_norm(neg_embed, 1, -1)\n","            pos_embed2 = tf.clip_by_norm(pos_embed2, 1, -1)\n","            neg_embed2 = tf.clip_by_norm(neg_embed2, 1, -1)\n","            # distance\n","            # long-term interest, pos and neg\n","            pos_long_interest = tf.square(user_embed - pos_embed2)  # (None, dim)\n","            neg_long_interest = tf.square(user_embed - neg_embed2)  # (None, dim)\n","            # combine. Here is a difference from the original paper.\n","            pos_scores = self.w * tf.reduce_sum(pos_long_interest, axis=-1, keepdims=True) + \\\n","                         (1 - self.w) * tf.reduce_sum(tf.square(short_interest - pos_embed), axis=-1, keepdims=True)\n","            neg_scores = self.w * tf.reduce_sum(neg_long_interest, axis=-1, keepdims=True) + \\\n","                         (1 - self.w) * tf.reduce_sum(tf.square(short_interest - neg_embed), axis=-1, keepdims=True)\n","            # minimize loss\n","            # self.add_loss(tf.reduce_sum(tf.maximum(pos_scores - neg_scores + self.gamma, 0)))\n","            self.add_loss(tf.reduce_sum(tf.nn.relu(pos_scores - neg_scores + self.gamma)))\n","        return pos_scores, neg_scores\n","\n","    def summary(self):\n","        seq_inputs = Input(shape=(self.maxlen,), dtype=tf.int32)\n","        user_inputs = Input(shape=(1, ), dtype=tf.int32)\n","        pos_inputs = Input(shape=(1, ), dtype=tf.int32)\n","        neg_inputs = Input(shape=(1, ), dtype=tf.int32)\n","        Model(inputs=[user_inputs, seq_inputs, pos_inputs, neg_inputs], \n","            outputs=self.call([user_inputs, seq_inputs, pos_inputs, neg_inputs])).summary()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FiecGHPuBjQT","executionInfo":{"status":"ok","timestamp":1637055318637,"user_tz":-330,"elapsed":621,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def test_model():\n","    user_features = {'feat': 'user_id', 'feat_num': 100, 'embed_dim': 8}\n","    seq_features = {'feat': 'item_id', 'feat_num': 100, 'embed_dim': 8}\n","    features = [user_features, seq_features]\n","    model = AttRec(features, mode='dist')\n","    model.summary()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYj86oraBrKR","executionInfo":{"status":"ok","timestamp":1637055319499,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def getHit(df):\n","    \"\"\"\n","    calculate hit rate\n","    :return:\n","    \"\"\"\n","    if sum(df['pred']) < _K:\n","        return 1\n","    else:\n","        return 0\n","\n","\n","def getNDCG(df):\n","    \"\"\"\n","    calculate NDCG\n","    :return:\n","    \"\"\"\n","    if sum(df['pred']) < _K:\n","        return 1 / np.log(sum(df['pred']) + 2)\n","    else:\n","        return 0.\n","\n","\n","def getMRR(df):\n","    \"\"\"\n","    calculate MRR\n","    :return:\n","    \"\"\"\n","    return 1 / (sum(df['pred']) + 1)\n","\n","\n","def evaluate_model(model, test, K):\n","    \"\"\"\n","    evaluate model\n","    :param model: model\n","    :param test: test set\n","    :param K: top K\n","    :return: hit rate, ndcg\n","    \"\"\"\n","    global _K\n","    _K = K\n","    test_X = test\n","    # predict\n","    pos_score, neg_score = model.predict(test_X)\n","    # create dataframe\n","    test_df = pd.DataFrame(test_X[0], columns=['user_id'])\n","    # if mode == 'inner', pos score < neg score, pred = 1\n","    if model.mode == 'inner':\n","        test_df['pred'] = (pos_score <= neg_score).astype(np.int32)\n","    else:\n","        test_df['pred'] = (pos_score >= neg_score).astype(np.int32)\n","    # groupby\n","    tg = test_df.groupby('user_id')\n","    # calculate hit\n","    hit_rate = tg.apply(getHit).mean()\n","    # calculate ndcg\n","    ndcg = tg.apply(getNDCG).mean()\n","    # calculate mrr\n","    mrr = tg.apply(getMRR).mean()\n","    return hit_rate, ndcg, mrr"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2e75547bbc7c4fffa0295e9eff296fda","4ce22228654446e3804adccba9b581e0","42f32229d0284ba5b3c79220472f89f9","89079249d29a4188ba2353eecdbcb0bb","34820c17224e46cfb1f3c420229e250e","37660610c37f4652980211bdb9196c2b","88e6dab0adf34266ad96b78178852802","68f7a61b4ce84099b0bec68c3602e70e","38333b66d8f74363a0cf45b10a4ff3fe","1415bc028c6a476aad215c062bcc5a72","71565e08392045f9aee9457de810096e"]},"id":"iTbYFKSzCE1I","executionInfo":{"status":"ok","timestamp":1637060785608,"user_tz":-330,"elapsed":5466124,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"fbc0c787-2b05-4351-e422-b3f2bbfc8432"},"source":["# ========================== Create dataset =======================\n","feature_columns, train, val, test = create_implicit_ml_1m_dataset(file, trans_score, embed_dim, maxlen)\n","train_X = train\n","val_X = val\n","\n","# ============================Build Model==========================\n","model = AttRec(feature_columns, maxlen, mode, gamma, w, embed_reg)\n","model.summary()\n","# =========================Compile============================\n","model.compile(optimizer=Adam(learning_rate=learning_rate))\n","\n","results = []\n","for epoch in range(1, epochs + 1):\n","    # ===========================Fit==============================\n","    t1 = time()\n","    model.fit(\n","        train_X,\n","        None,\n","        validation_data=(val_X, None),\n","        epochs=1,\n","        # callbacks=[tensorboard, checkpoint],\n","        batch_size=batch_size,\n","        )\n","    # ===========================Test==============================\n","    t2 = time()\n","    if epoch % 5 == 0:\n","        hit_rate, ndcg, mrr = evaluate_model(model, test, K)\n","        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG = %.4f, MRR = %.4f'\n","                % (epoch, t2 - t1, time() - t2, hit_rate, ndcg, mrr))\n","        results.append([epoch, t2 - t1, time() - t2, hit_rate, ndcg, mrr])\n","# ========================== Write Log ===========================\n","pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time',\n","                                'hit_rate', 'ndcg', 'mrr']).to_csv(\n","    'AttRec_log_maxlen_{}_dim_{}_K_{}_w_{}.csv'.format(maxlen, embed_dim, K, w), index=False)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["==========Data Preprocess Start============\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e75547bbc7c4fffa0295e9eff296fda","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/6040 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["==================Padding===================\n","============Data Preprocess End=============\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 5)]          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","tf.math.not_equal (TFOpLambda)  (None, 5)            0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze (TFOpLambd (None,)              0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze_3 (TFOpLam (None,)              0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         multiple             395300      input_1[0][0]                    \n","                                                                 tf.compat.v1.squeeze_1[0][0]     \n","                                                                 tf.compat.v1.squeeze_2[0][0]     \n","__________________________________________________________________________________________________\n","tf.cast (TFOpLambda)            (None, 5)            0           tf.math.not_equal[0][0]          \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze_1 (TFOpLam (None,)              0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze_4 (TFOpLam (None,)              0           input_4[0][0]                    \n","__________________________________________________________________________________________________\n","tf.compat.v1.squeeze_2 (TFOpLam (None,)              0           input_4[0][0]                    \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 100)          604100      tf.compat.v1.squeeze[0][0]       \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 100)          395300      tf.compat.v1.squeeze_3[0][0]     \n","                                                                 tf.compat.v1.squeeze_4[0][0]     \n","__________________________________________________________________________________________________\n","self_attention__layer (SelfAtte (None, 100)          10000       embedding_1[0][0]                \n","                                                                 embedding_1[0][0]                \n","                                                                 embedding_1[0][0]                \n","                                                                 tf.cast[0][0]                    \n","__________________________________________________________________________________________________\n","tf.math.multiply (TFOpLambda)   (None, 100)          0           embedding[0][0]                  \n","                                                                 embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","tf.math.multiply_3 (TFOpLambda) (None, 100)          0           self_attention__layer[0][0]      \n","                                                                 embedding_1[1][0]                \n","__________________________________________________________________________________________________\n","tf.math.multiply_1 (TFOpLambda) (None, 100)          0           embedding[0][0]                  \n","                                                                 embedding_2[1][0]                \n","__________________________________________________________________________________________________\n","tf.math.multiply_6 (TFOpLambda) (None, 100)          0           self_attention__layer[0][0]      \n","                                                                 embedding_1[2][0]                \n","__________________________________________________________________________________________________\n","tf.math.reduce_sum (TFOpLambda) (None, 1)            0           tf.math.multiply[0][0]           \n","__________________________________________________________________________________________________\n","tf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.math.multiply_3[0][0]         \n","__________________________________________________________________________________________________\n","tf.math.reduce_sum_2 (TFOpLambd (None, 1)            0           tf.math.multiply_1[0][0]         \n","__________________________________________________________________________________________________\n","tf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.math.multiply_6[0][0]         \n","__________________________________________________________________________________________________\n","tf.math.multiply_2 (TFOpLambda) (None, 1)            0           tf.math.reduce_sum[0][0]         \n","__________________________________________________________________________________________________\n","tf.math.multiply_4 (TFOpLambda) (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n","__________________________________________________________________________________________________\n","tf.math.multiply_5 (TFOpLambda) (None, 1)            0           tf.math.reduce_sum_2[0][0]       \n","__________________________________________________________________________________________________\n","tf.math.multiply_7 (TFOpLambda) (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n","__________________________________________________________________________________________________\n","tf.__operators__.add (TFOpLambd (None, 1)            0           tf.math.multiply_2[0][0]         \n","                                                                 tf.math.multiply_4[0][0]         \n","__________________________________________________________________________________________________\n","tf.__operators__.add_1 (TFOpLam (None, 1)            0           tf.math.multiply_5[0][0]         \n","                                                                 tf.math.multiply_7[0][0]         \n","==================================================================================================\n","Total params: 1,404,700\n","Trainable params: 1,404,700\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","960/960 [==============================] - 114s 118ms/step - loss: 0.3800 - val_loss: 0.3079\n","960/960 [==============================] - 113s 118ms/step - loss: 0.2363 - val_loss: 0.2730\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1982 - val_loss: 0.2413\n","960/960 [==============================] - 118s 122ms/step - loss: 0.1748 - val_loss: 0.2308\n","960/960 [==============================] - 117s 122ms/step - loss: 0.1622 - val_loss: 0.2245\n","Iteration 5 Fit [116.8 s], Evaluate [41.9 s]: HR = 0.7353, NDCG = 0.7026, MRR = 0.4226\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1541 - val_loss: 0.2236\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1484 - val_loss: 0.2228\n","960/960 [==============================] - 114s 118ms/step - loss: 0.1439 - val_loss: 0.2217\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1404 - val_loss: 0.2218\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1373 - val_loss: 0.2226\n","Iteration 10 Fit [142.0 s], Evaluate [41.8 s]: HR = 0.7666, NDCG = 0.7496, MRR = 0.4536\n","960/960 [==============================] - 114s 118ms/step - loss: 0.1348 - val_loss: 0.2239\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1326 - val_loss: 0.2250\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1308 - val_loss: 0.2260\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1292 - val_loss: 0.2268\n","960/960 [==============================] - 114s 118ms/step - loss: 0.1278 - val_loss: 0.2277\n","Iteration 15 Fit [113.7 s], Evaluate [41.8 s]: HR = 0.7719, NDCG = 0.7616, MRR = 0.4623\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1266 - val_loss: 0.2300\n","960/960 [==============================] - 112s 117ms/step - loss: 0.1256 - val_loss: 0.2299\n","960/960 [==============================] - 112s 117ms/step - loss: 0.1247 - val_loss: 0.2303\n","960/960 [==============================] - 112s 116ms/step - loss: 0.1241 - val_loss: 0.2319\n","960/960 [==============================] - 112s 116ms/step - loss: 0.1233 - val_loss: 0.2332\n","Iteration 20 Fit [142.0 s], Evaluate [26.8 s]: HR = 0.7674, NDCG = 0.7567, MRR = 0.4595\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1227 - val_loss: 0.2329\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1222 - val_loss: 0.2348\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1217 - val_loss: 0.2347\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1213 - val_loss: 0.2341\n","960/960 [==============================] - 113s 118ms/step - loss: 0.1209 - val_loss: 0.2345\n","Iteration 25 Fit [113.1 s], Evaluate [41.8 s]: HR = 0.7722, NDCG = 0.7607, MRR = 0.4613\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1205 - val_loss: 0.2353\n","960/960 [==============================] - 112s 117ms/step - loss: 0.1202 - val_loss: 0.2364\n","960/960 [==============================] - 112s 116ms/step - loss: 0.1199 - val_loss: 0.2354\n","960/960 [==============================] - 110s 115ms/step - loss: 0.1195 - val_loss: 0.2371\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1192 - val_loss: 0.2383\n","Iteration 30 Fit [142.0 s], Evaluate [28.0 s]: HR = 0.7699, NDCG = 0.7576, MRR = 0.4593\n","960/960 [==============================] - 114s 119ms/step - loss: 0.1190 - val_loss: 0.2382\n","960/960 [==============================] - 115s 120ms/step - loss: 0.1187 - val_loss: 0.2375\n","960/960 [==============================] - 119s 124ms/step - loss: 0.1184 - val_loss: 0.2382\n","960/960 [==============================] - 122s 127ms/step - loss: 0.1182 - val_loss: 0.2380\n","960/960 [==============================] - 122s 127ms/step - loss: 0.1180 - val_loss: 0.2380\n","Iteration 35 Fit [121.9 s], Evaluate [29.4 s]: HR = 0.7672, NDCG = 0.7568, MRR = 0.4595\n","960/960 [==============================] - 119s 124ms/step - loss: 0.1178 - val_loss: 0.2376\n","960/960 [==============================] - 118s 123ms/step - loss: 0.1176 - val_loss: 0.2383\n","960/960 [==============================] - 120s 125ms/step - loss: 0.1174 - val_loss: 0.2381\n","960/960 [==============================] - 125s 130ms/step - loss: 0.1172 - val_loss: 0.2385\n","960/960 [==============================] - 118s 123ms/step - loss: 0.1170 - val_loss: 0.2384\n","Iteration 40 Fit [142.0 s], Evaluate [41.8 s]: HR = 0.7680, NDCG = 0.7543, MRR = 0.4571\n"]}]}]}