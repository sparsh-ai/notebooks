{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T595874 | BERT4Rec on ML-25m in PyTorch Lightning","provenance":[{"file_id":"1RYK4m2Sn8UykvIX4rPzXqZ5TMZKFpvza","timestamp":1633079298537}],"collapsed_sections":["a2mxEHOOZGWr","ju9vFxseZHCK","V7u3_SyPZHrn"],"authorship_tag":"ABX9TyPHwG5ar5+KHqN6bKfUAxsI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KlNI72qJZnUv"},"source":["# BERT4Rec on ML-25m in PyTorch Lightning\n","\n","Implementing BERT4Rec model on Movielens 25m dataset in PyTorch."]},{"cell_type":"markdown","metadata":{"id":"6OZVcq6rYphR"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"sZaJrJ1q96Jf"},"source":["### Installations"]},{"cell_type":"code","metadata":{"id":"UPJ9X5rjXzwI"},"source":["%%sh\n","mkdir /content/_temp\n","cd /content/_temp\n","wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n","unzip ml-25m.zip\n","cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zqn_uGP6YuEe"},"source":["!pip install -q pytorch_lightning"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iM0d1bGcYhRV"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"7duH6OQ1YzZ4"},"source":["import random\n","import os\n","import numpy as np\n","import pandas as pd\n","from typing import Optional\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Linear\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.loggers import TensorBoardLogger"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ehDGA7GYse2"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"293b8dieYSoR"},"source":["class Args:\n","    PAD = 0\n","    MASK = 1\n","    CAP = 0\n","    SEED = 42\n","    RAW_DATA_PATH = '/content/_temp/ml-25m'\n","    VOCAB_SIZE = 10000\n","    CHANNELS = 128\n","    DROPOUT = 0.4\n","    LR = 1e-4\n","    HISTORY_SIZE = 120\n","    DEBUG_MODE = True\n","    DEBUG_LOAD = 1000\n","    LOG_DIR = '/content/recommender_logs'\n","    MODEL_DIR = '/content/recommender_models'\n","    BATCH_SIZE = 32\n","    EPOCHS = 2000\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oy459Dd2Yz0d"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"-ila65IcJaBf"},"source":["def map_column(df: pd.DataFrame, col_name: str):\n","    \"\"\"Maps column values to integers.\n","    \"\"\"\n","    values = sorted(list(df[col_name].unique()))\n","    mapping = {k: i + 2 for i, k in enumerate(values)}\n","    inverse_mapping = {v: k for k, v in mapping.items()}\n","    df[col_name + \"_mapped\"] = df[col_name].map(mapping)\n","    return df, mapping, inverse_mapping\n","\n","def get_context(df: pd.DataFrame, split: str, context_size: int = 120, val_context_size: int = 5, seed: int = 42):\n","    \"\"\"Create a training / validation samples.\n","    \"\"\"\n","    random.seed(seed)\n","    if split == \"train\":\n","        end_index = random.randint(10, df.shape[0] - val_context_size)\n","    elif split in [\"val\", \"test\"]:\n","        end_index = df.shape[0]\n","    else:\n","        raise ValueError\n","    start_index = max(0, end_index - context_size)\n","    context = df[start_index:end_index]\n","    return context\n","\n","def pad_arr(arr: np.ndarray, expected_size: int = 30):\n","    \"\"\"Pad top of array when there is not enough history.\n","    \"\"\"\n","    arr = np.pad(arr, [(expected_size - arr.shape[0], 0), (0, 0)], mode=\"edge\")\n","    return arr\n","\n","def pad_list(list_integers, history_size: int, pad_val: int = 0, mode=\"left\"):\n","    \"\"\"Pad list from left or right\n","    \"\"\"\n","    if len(list_integers) < history_size:\n","        if mode == \"left\":\n","            list_integers = [pad_val] * (history_size - len(list_integers)) + list_integers\n","        else:\n","            list_integers = list_integers + [pad_val] * (history_size - len(list_integers))\n","    return list_integers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAXCIhFBTQsN"},"source":["def masked_accuracy(y_pred: torch.Tensor, y_true: torch.Tensor, mask: torch.Tensor):\n","    _, predicted = torch.max(y_pred, 1)\n","    y_true = torch.masked_select(y_true, mask)\n","    predicted = torch.masked_select(predicted, mask)\n","    acc = (y_true == predicted).double().mean()\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Do_cLe-4YgRM"},"source":["def masked_ce(y_pred, y_true, mask):\n","    loss = F.cross_entropy(y_pred, y_true, reduction=\"none\")\n","    loss = loss * mask\n","    return loss.sum() / (mask.sum() + 1e-8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmX_49DMlumu"},"source":["def mask_list(l1, p=0.8):\n","    random.seed(args.SEED)\n","    l1 = [a if random.random() < p else args.MASK for a in l1]\n","    return l1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVIfejNVT_a0"},"source":["def mask_last_elements_list(l1, val_context_size: int = 5):\n","    l1 = l1[:-val_context_size] + mask_list(l1[-val_context_size:], p=0.5)\n","    return l1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-usSJNrHY66A"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"rKFEK03VZNTZ"},"source":["class ML25Dataset(torch.utils.data.Dataset):\n","    def __init__(self, args, split='train'):\n","        self.args = args\n","        self.grp_by = None\n","        self.groups = None\n","        self.split = split\n","        self.history_size = args.HISTORY_SIZE\n","        self.mapping = None\n","        self.inverse_mapping = None\n","        self.load_dataset()\n","\n","    def load_dataset(self):\n","        filepath = os.path.join(self.args.RAW_DATA_PATH, 'ratings.csv')\n","        if args.DEBUG_MODE:\n","            data = pd.read_csv(filepath, nrows=1000)\n","        else:\n","            data = pd.read_csv(filepath)\n","        data.sort_values(by=\"timestamp\", inplace=True)\n","        data, self.mapping, self.inverse_mapping = map_column(data, col_name=\"movieId\")\n","        self.grp_by = data.groupby(by=\"userId\")\n","        self.groups = list(self.grp_by.groups)\n","        \n","    def genome_mapping(self, genome):\n","        \"\"\"movie id to relevance mapping\n","        \"\"\"\n","        genome.sort_values(by=[\"movieId\", \"tagId\"], inplace=True)\n","        movie_genome = genome.groupby(\"movieId\")[\"relevance\"].agg(list).reset_index()\n","        movie_genome = {a: b for a, b in zip(movie_genome['movieId'], movie_genome['relevance'])}\n","        return movie_genome\n","\n","    def __len__(self):\n","        return len(self.groups)\n","\n","    def __getitem__(self, idx):\n","        group = self.groups[idx]\n","        df = self.grp_by.get_group(group)\n","        context = get_context(df, split=self.split, context_size=self.history_size)\n","        trg_items = context[\"movieId_mapped\"].tolist()\n","        if self.split == \"train\":\n","            src_items = mask_list(trg_items)\n","        else:\n","            src_items = mask_last_elements_list(trg_items)\n","        pad_mode = \"left\" if random.random() < 0.5 else \"right\"\n","        trg_items = pad_list(trg_items, history_size=self.history_size, mode=pad_mode)\n","        src_items = pad_list(src_items, history_size=self.history_size, mode=pad_mode)\n","        src_items = torch.tensor(src_items, dtype=torch.long)\n","        trg_items = torch.tensor(trg_items, dtype=torch.long)\n","        return src_items, trg_items"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2mxEHOOZGWr"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"7E0d-NsuZPTJ"},"source":["class BERT4Rec(pl.LightningModule):\n","    def __init__(self, args, vocab_size):\n","        super().__init__()\n","        self.cap = args.CAP\n","        self.mask = args.MASK\n","        self.lr = args.LR\n","        self.dropout = args.DROPOUT\n","        self.vocab_size = vocab_size\n","        self.channels = args.CHANNELS\n","\n","        self.item_embeddings = torch.nn.Embedding(\n","            self.vocab_size, embedding_dim=self.channels\n","        )\n","        self.input_pos_embedding = torch.nn.Embedding(512, embedding_dim=self.channels)\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=self.channels, nhead=4, dropout=self.dropout\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=6)\n","        self.linear_out = Linear(self.channels, self.vocab_size)\n","        self.do = nn.Dropout(p=self.dropout)\n","\n","    def encode_src(self, src_items):\n","        src_items = self.item_embeddings(src_items)\n","        batch_size, in_sequence_len = src_items.size(0), src_items.size(1)\n","        pos_encoder = (\n","            torch.arange(0, in_sequence_len, device=src_items.device)\n","            .unsqueeze(0)\n","            .repeat(batch_size, 1)\n","        )\n","        pos_encoder = self.input_pos_embedding(pos_encoder)\n","        src_items += pos_encoder\n","        src = src_items.permute(1, 0, 2)\n","        src = self.encoder(src)\n","        return src.permute(1, 0, 2)\n","\n","    def forward(self, src_items):\n","        src = self.encode_src(src_items)\n","        out = self.linear_out(src)\n","        return out\n","\n","    def training_step(self, batch, batch_idx):\n","        src_items, y_true = batch\n","        y_pred = self(src_items)\n","        y_pred = y_pred.view(-1, y_pred.size(2))\n","        y_true = y_true.view(-1)\n","        src_items = src_items.view(-1)\n","        mask = src_items == self.mask\n","        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n","        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n","        self.log(\"train_loss\", loss)\n","        self.log(\"train_accuracy\", accuracy)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        src_items, y_true = batch\n","        y_pred = self(src_items)\n","        y_pred = y_pred.view(-1, y_pred.size(2))\n","        y_true = y_true.view(-1)\n","        src_items = src_items.view(-1)\n","        mask = src_items == self.mask\n","        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n","        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n","        self.log(\"valid_loss\", loss)\n","        self.log(\"valid_accuracy\", accuracy)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        src_items, y_true = batch\n","        y_pred = self(src_items)\n","        y_pred = y_pred.view(-1, y_pred.size(2))\n","        y_true = y_true.view(-1)\n","        src_items = src_items.view(-1)\n","        mask = src_items == self.mask\n","        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n","        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n","        self.log(\"test_loss\", loss)\n","        self.log(\"test_accuracy\", accuracy)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, patience=10, factor=0.1\n","        )\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": scheduler,\n","            \"monitor\": \"valid_loss\",\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ju9vFxseZHCK"},"source":["## Trainer"]},{"cell_type":"code","metadata":{"id":"WJyXo8psZSIz"},"source":["args.DEBUG_MODE = True\n","args.DEBUG_LOAD = 10000\n","train_data = ML25Dataset(args, split='train')\n","val_data = ML25Dataset(args, split='val')\n","\n","train_loader = DataLoader(\n","    train_data,\n","    batch_size=args.BATCH_SIZE,\n","    num_workers=2,\n","    shuffle=True,\n",")\n","val_loader = DataLoader(\n","    val_data,\n","    batch_size=args.BATCH_SIZE,\n","    num_workers=2,\n","    shuffle=False,\n",")\n","\n","model = BERT4Rec(\n","    args, vocab_size=len(train_data.mapping) + 2)\n","\n","logger = TensorBoardLogger(\n","    save_dir=args.LOG_DIR,\n",")\n","\n","checkpoint_callback = ModelCheckpoint(\n","    monitor=\"valid_loss\",\n","    mode=\"min\",\n","    dirpath=args.MODEL_DIR,\n","    filename=\"recommender\",\n",")\n","\n","trainer = pl.Trainer(\n","    max_epochs=args.EPOCHS,\n","    gpus=1,\n","    logger=logger,\n","    callbacks=[checkpoint_callback],\n",")\n","trainer.fit(model, train_loader, val_loader)\n","\n","result_val = trainer.test(test_dataloaders=val_loader)\n","\n","output_json = {\n","    \"val_loss\": result_val[0][\"test_loss\"],\n","    \"best_model_path\": checkpoint_callback.best_model_path,\n","}\n","\n","print(output_json)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V7u3_SyPZHrn"},"source":["## Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"v_kL-604D95Y","executionInfo":{"status":"ok","timestamp":1632575167340,"user_tz":-330,"elapsed":1978,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0c61a357-c8b8-4905-a889-8b87e2260697"},"source":["movies_path = \"/content/ml-25m/movies.csv\"\n","movies = pd.read_csv(movies_path)\n","movies.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movieId  ...                                       genres\n","0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n","1        2  ...                   Adventure|Children|Fantasy\n","2        3  ...                               Comedy|Romance\n","3        4  ...                         Comedy|Drama|Romance\n","4        5  ...                                       Comedy\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwxX14ivC3Fe","executionInfo":{"status":"ok","timestamp":1632575262464,"user_tz":-330,"elapsed":1863,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3644ce8a-bc11-4781-9de4-4e398b0660d2"},"source":["args.DEBUG_MODE = True\n","args.DEBUG_LOAD = 10000\n","data = ML25Dataset(args, split='train')\n","\n","random.seed(args.SEED)\n","random.sample(list(data.grp_by.groups), k=2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 4]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"fOAsjdSSEqDY"},"source":["model = BERT4Rec(args, vocab_size=len(data.mapping) + 2)\n","model.eval()\n","\n","model_path = \"/content/recommender_models/recommender.ckpt\"\n","model.load_state_dict(torch.load(model_path)[\"state_dict\"])\n","movie_to_idx = {a: data.mapping[b] for a, b in zip(movies.title.tolist(), movies.movieId.tolist()) if b in data.mapping}\n","idx_to_movie = {v: k for k, v in movie_to_idx.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmc36T7q5OpM"},"source":["def predict(list_movies, model, movie_to_idx, idx_to_movie):\n","    ids = [args.PAD] * (120 - len(list_movies) - 1) + [movie_to_idx[a] for a in list_movies] + [args.MASK]\n","    src = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n","    with torch.no_grad():\n","        prediction = model(src)\n","    masked_pred = prediction[0, -1].numpy()\n","    sorted_predicted_ids = np.argsort(masked_pred).tolist()[::-1]\n","    sorted_predicted_ids = [a for a in sorted_predicted_ids if a not in ids]\n","    return [idx_to_movie[a] for a in sorted_predicted_ids[:30] if a in idx_to_movie]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLzE_aWE6JTQ","executionInfo":{"status":"ok","timestamp":1632575326058,"user_tz":-330,"elapsed":24,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c517192c-5914-40bf-caa9-8cc25c1493e0"},"source":["list_movies = [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\",\n","               \"Harry Potter and the Chamber of Secrets (2002)\",\n","               \"Harry Potter and the Prisoner of Azkaban (2004)\",\n","               \"Harry Potter and the Goblet of Fire (2005)\"]\n","\n","top_movie = predict(list_movies, model, movie_to_idx, idx_to_movie)\n","top_movie"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Pirates of the Caribbean: The Curse of the Black Pearl (2003)',\n"," 'Ratatouille (2007)',\n"," 'Pulp Fiction (1994)',\n"," 'Evolution (2001)',\n"," 'Jupiter Ascending (2015)',\n"," 'Kung Fu Panda 3 (2016)',\n"," 'Back to the Future (1985)',\n"," 'Neighbors (2014)',\n"," 'Bridge of Spies (2015)',\n"," \"Schindler's List (1993)\",\n"," 'Coraline (2009)',\n"," 'Spider-Man (2002)',\n"," 'X-Men (2000)',\n"," 'Watership Down (1978)',\n"," 'In the Mood For Love (Fa yeung nin wa) (2000)',\n"," 'Burn After Reading (2008)',\n"," 'Aladdin (1992)',\n"," 'Finding Nemo (2003)',\n"," 'RocknRolla (2008)',\n"," 'Last Castle, The (2001)',\n"," \"Before the Devil Knows You're Dead (2007)\",\n"," 'Through a Glass Darkly (Såsom i en spegel) (1961)',\n"," 'Looper (2012)',\n"," 'Hoosiers (a.k.a. Best Shot) (1986)',\n"," 'Kill Bill: Vol. 2 (2004)',\n"," 'Big Fish (2003)',\n"," 'Star Wars: Episode III - Revenge of the Sith (2005)',\n"," 'Clear and Present Danger (1994)',\n"," 'Flightplan (2005)',\n"," 'Wedding Crashers (2005)']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbSlRaGH6JQm","executionInfo":{"status":"ok","timestamp":1632575352677,"user_tz":-330,"elapsed":1238,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3d65c863-d065-4e9e-92eb-e767c53a7938"},"source":["list_movies = [\"Black Panther (2017)\",\n","               \"Avengers, The (2012)\",\n","               \"Avengers: Infinity War - Part I (2018)\",\n","               \"Logan (2017)\",\n","               \"Spider-Man (2002)\",\n","               \"Spider-Man 3 (2007)\"]\n","\n","top_movie = predict(list_movies, model, movie_to_idx, idx_to_movie)\n","top_movie"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Pirates of the Caribbean: The Curse of the Black Pearl (2003)',\n"," 'Ratatouille (2007)',\n"," 'Evolution (2001)',\n"," 'Pulp Fiction (1994)',\n"," 'Jupiter Ascending (2015)',\n"," 'Kung Fu Panda 3 (2016)',\n"," 'Neighbors (2014)',\n"," 'Back to the Future (1985)',\n"," 'In the Mood For Love (Fa yeung nin wa) (2000)',\n"," 'Bridge of Spies (2015)',\n"," \"Schindler's List (1993)\",\n"," 'Coraline (2009)',\n"," 'X-Men (2000)',\n"," 'Watership Down (1978)',\n"," 'Burn After Reading (2008)',\n"," 'RocknRolla (2008)',\n"," \"Before the Devil Knows You're Dead (2007)\",\n"," 'Aladdin (1992)',\n"," 'Last Castle, The (2001)',\n"," 'Finding Nemo (2003)',\n"," 'Wedding Crashers (2005)',\n"," 'Through a Glass Darkly (Såsom i en spegel) (1961)',\n"," 'Flightplan (2005)',\n"," 'Looper (2012)',\n"," 'Star Wars: Episode III - Revenge of the Sith (2005)',\n"," '2046 (2004)',\n"," 'Kill Bill: Vol. 2 (2004)',\n"," 'Clear and Present Danger (1994)',\n"," 'Port of Shadows (Quai des brumes) (1938)',\n"," 'Hoosiers (a.k.a. Best Shot) (1986)']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHmsGbxr6JNN","executionInfo":{"status":"ok","timestamp":1632575382501,"user_tz":-330,"elapsed":35,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ed4c67de-db0e-48ac-8789-f4e4acb80a49"},"source":["list_movies = [\"Toy Story 3 (2010)\",\n","               \"Finding Nemo (2003)\",\n","               \"Ratatouille (2007)\",\n","               \"The Lego Movie (2014)\",\n","               \"Ghostbusters (a.k.a. Ghost Busters) (1984)\"]\n","top_movie = predict(list_movies, model, movie_to_idx, idx_to_movie)\n","top_movie"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Pirates of the Caribbean: The Curse of the Black Pearl (2003)',\n"," 'Evolution (2001)',\n"," 'Pulp Fiction (1994)',\n"," 'Jupiter Ascending (2015)',\n"," 'Kung Fu Panda 3 (2016)',\n"," 'Back to the Future (1985)',\n"," 'Neighbors (2014)',\n"," 'Bridge of Spies (2015)',\n"," \"Schindler's List (1993)\",\n"," 'Coraline (2009)',\n"," 'Spider-Man (2002)',\n"," 'Watership Down (1978)',\n"," 'X-Men (2000)',\n"," 'In the Mood For Love (Fa yeung nin wa) (2000)',\n"," 'Burn After Reading (2008)',\n"," 'Aladdin (1992)',\n"," 'RocknRolla (2008)',\n"," \"Before the Devil Knows You're Dead (2007)\",\n"," 'Last Castle, The (2001)',\n"," 'Looper (2012)',\n"," 'Through a Glass Darkly (Såsom i en spegel) (1961)',\n"," 'Hoosiers (a.k.a. Best Shot) (1986)',\n"," 'Star Wars: Episode III - Revenge of the Sith (2005)',\n"," 'Wedding Crashers (2005)',\n"," 'Flightplan (2005)',\n"," 'Big Fish (2003)',\n"," '2046 (2004)',\n"," 'Kill Bill: Vol. 2 (2004)',\n"," 'Lost in Translation (2003)',\n"," 'Clear and Present Danger (1994)']"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"UljgDDKUZIYw"},"source":["## Unit Testing"]},{"cell_type":"code","metadata":{"id":"w_t_4MbCJ9Oh"},"source":["import unittest\n","from numpy.testing import assert_array_equal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezKBo6Q0J-gk"},"source":["class TestUtils(unittest.TestCase):\n","    def testColMapping(self):\n","        \"test the column mapping function\"\n","        df = pd.DataFrame(\n","            {'uid': [1,2,3,4],\n","             'sid': [1,3,5,7]}\n","        )\n","        df, _, _ = map_column(df, col_name='sid')\n","        assert_array_equal(df.sid_mapped.values,\n","                           [2, 3, 4, 5])\n","        \n","    def testSplit(self):\n","        \"test the train/test/val split\"\n","        SEED = 42\n","        df = pd.DataFrame(\n","            {'uid': list(np.arange(50)),\n","                'sid': list(np.arange(50))}\n","        )\n","        context = get_context(df, split='train', context_size=5, seed=SEED)\n","        assert_array_equal(context.sid.values,\n","                           [12, 13, 14, 15, 16])\n","        \n","    def testArrayPadding(self):\n","        \"test array padding function\"\n","        pad_output_1 = pad_arr(np.array([[1,2,3],[7,8,9]]), expected_size=5)\n","        pad_output_2 = pad_arr(np.array([[1,2,3]]), expected_size=3)\n","        assert_array_equal(pad_output_1,\n","                           [[1, 2, 3],\n","                            [1, 2, 3],\n","                            [1, 2, 3],\n","                            [1, 2, 3],\n","                            [7, 8, 9]])\n","        assert_array_equal(pad_output_2,\n","                           [[1, 2, 3],\n","                            [1, 2, 3],\n","                            [1, 2, 3]])\n","        \n","    def testListPadding(self):\n","        \"test list padding function\"\n","        pad_output_1 = pad_list([1,2,3], history_size=5, pad_val=0, mode='left')\n","        pad_output_2 = pad_list([1,2,3], history_size=6, pad_val=1, mode='right')\n","        assert_array_equal(pad_output_1,\n","                           [0, 0, 1, 2, 3])\n","        assert_array_equal(pad_output_2,\n","                           [1, 2, 3, 1, 1, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TfTrrQ19Q1F"},"source":["class TestML25Dataset(unittest.TestCase):\n","    def testRecordsCount(self):\n","        train_data = ML25Dataset(args, split='train')\n","        self.assertEqual(len(train_data), 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJbEQG5LiXi2"},"source":["class TestModelBERT4Rec(unittest.TestCase):\n","    def testBERT4Rec(self):\n","        n_items = 1000\n","        recommender = BERT4Rec(args, vocab_size=1000)\n","        src_items = torch.randint(low=0, high=n_items, size=(32, 30))\n","        src_items[:, 0] = 1\n","        trg_out = torch.randint(low=0, high=n_items, size=(32, 30))\n","        out = recommender(src_items)\n","        loss = recommender.training_step((src_items, trg_out), batch_idx=1)\n","        self.assertEqual(out.shape, torch.Size([32, 30, 1000]))\n","        self.assertIsInstance(loss, torch.Tensor)\n","        self.assertFalse(torch.isnan(loss).any())\n","        self.assertEqual(loss.size(),torch.Size([]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVmtbhoeWE3K"},"source":["class TestModelUtils(unittest.TestCase):\n","    def testMaskedAccuracy(self):\n","        \"test the masked accuracy\"\n","        output1 = masked_accuracy(torch.Tensor([[0,1,1,0]]),\n","                                torch.Tensor([[0,1,1,1]]),\n","                                torch.tensor([1,1,1,1], dtype=torch.bool))\n","\n","        output2 = masked_accuracy(torch.Tensor([[0,1,1,0]]),\n","                                torch.Tensor([[0,1,1,1]]),\n","                                torch.tensor([1,0,0,1], dtype=torch.bool))\n","\n","        self.assertEqual(output1, torch.tensor(0.75, dtype=torch.float64))\n","        self.assertEqual(output2, torch.tensor(0.5, dtype=torch.float64))\n","\n","    def testMaskedCrossEntropy(self):\n","        input = [[1.1049, 1.5729, 1.4864],\n","        [-1.8321, -0.3137, -0.3257]]\n","        target = [0,2]\n","\n","        output1 = masked_ce(torch.tensor(input),\n","                            torch.tensor(target),\n","                            torch.tensor([1,0], dtype=torch.bool))\n","\n","        output2 = masked_ce(torch.tensor(input), \n","                            torch.tensor(target),\n","                            torch.tensor([1,1], dtype=torch.bool))\n","        \n","        assert_array_equal(output1.numpy().round(4),\n","                           np.array(1.4015, dtype=np.float32))\n","        assert_array_equal(output2.numpy().round(4),\n","                           np.array(1.1026, dtype=np.float32))\n","        \n","    def testMaskList(self):\n","        args.SEED = 42\n","        assert_array_equal(mask_list([1,2,3,4,5,6,7,8]),\n","                           [1,2,3,4,5,6,1,8])\n","        args.SEED = 40\n","        assert_array_equal(mask_list([1,2,3,4,5,6,7,8]),\n","                           [1,1,3,4,1,6,7,8])\n","\n","    def testMaskListLastElement(self):\n","        args.SEED = 42\n","        output1 = mask_last_elements_list([1,2,3,4,5,6,7,8], val_context_size=5)\n","        output2 = mask_last_elements_list([1,2,3,4,5,6,7,8], val_context_size=3)\n","        assert_array_equal(output1, [1,2,3,1,5,6,7,1])\n","        assert_array_equal(output2, [1,2,3,4,5,1,7,8])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbqpEHhO-94V"},"source":["unittest.main(argv=[''], verbosity=2, exit=False)"],"execution_count":null,"outputs":[]}]}