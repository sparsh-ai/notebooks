{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.layers.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Layers\n",
    "> Implementation of encoding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import copy\n",
    "\n",
    "from recohut.models.layers.activation import gelu, swish\n",
    "from recohut.models.layers.attention import SelfAttention, DistSelfAttention, DistMeanSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": F.relu, \"swish\": swish}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Intermediate(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_act, hidden_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(hidden_size, hidden_size * 4)\n",
    "        if isinstance(hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = hidden_act\n",
    "\n",
    "        self.dense_2 = nn.Linear(hidden_size * 4, hidden_size)\n",
    "        self.layernorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        hidden_states = self.dense_1(input_tensor)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        hidden_states = self.dense_2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.layernorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "hidden_act = 'swish'\n",
    "hidden_dropout_prob = 0.5\n",
    "\n",
    "layer = Intermediate(hidden_size, hidden_act, hidden_dropout_prob)\n",
    "\n",
    "input_tensor = torch.rand(4,4)\n",
    "\n",
    "output = layer.forward(input_tensor)\n",
    "\n",
    "test_eq(output.shape.numel(), 16)\n",
    "test_eq(output.shape, [4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistIntermediate(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(hidden_size, hidden_size * 4)\n",
    "        self.intermediate_act_fn = nn.ELU()\n",
    "\n",
    "        self.dense_2 = nn.Linear(hidden_size * 4, hidden_size)\n",
    "        self.layernorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        hidden_states = self.dense_1(input_tensor)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        hidden_states = self.dense_2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.layernorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "hidden_dropout_prob = 0.5\n",
    "\n",
    "layer = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
    "\n",
    "input_tensor = torch.rand(4,4)\n",
    "\n",
    "output = layer.forward(input_tensor)\n",
    "\n",
    "test_eq(output.shape.numel(), 16)\n",
    "test_eq(output.shape, [4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_act, num_attention_heads, \n",
    "                 hidden_dropout_prob, attention_probs_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(hidden_size, num_attention_heads, \n",
    "                                       attention_probs_dropout_prob, hidden_dropout_prob)\n",
    "        self.intermediate = Intermediate(hidden_size, hidden_act, hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output, attention_scores = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        return intermediate_output, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "hidden_act = 'gelu'\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "\n",
    "layer = Layer(hidden_size, hidden_act, num_attention_heads, \n",
    "              hidden_dropout_prob, attention_probs_dropout_prob)\n",
    "\n",
    "hidden_states = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "hidden_states = torch.round(layer.forward(hidden_states, attention_mask)[0].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(hidden_states.shape.numel(), 32)\n",
    "test_eq(list(hidden_states.shape), [2, 4, 4])\n",
    "\n",
    "attention_probs = torch.round(layer.forward(hidden_states, attention_mask)[1].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(attention_probs.shape.numel(), 64)\n",
    "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                 attention_probs_dropout_prob, distance_metric='wasserstein'):\n",
    "        super().__init__()\n",
    "        self.attention = DistSelfAttention(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                                           attention_probs_dropout_prob, distance_metric)\n",
    "        self.mean_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
    "        self.cov_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
    "        self.activation_func = nn.ELU()\n",
    "\n",
    "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask):\n",
    "        mean_attention_output, cov_attention_output, attention_scores = self.attention(mean_hidden_states, cov_hidden_states, attention_mask)\n",
    "        mean_intermediate_output = self.mean_intermediate(mean_attention_output)\n",
    "        cov_intermediate_output = self.activation_func(self.cov_intermediate(cov_attention_output)) + 1\n",
    "        return mean_intermediate_output, cov_intermediate_output, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "\n",
    "layer = DistLayer(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
    "                  attention_probs_dropout_prob)\n",
    "\n",
    "input_tensor = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
    "\n",
    "mean_hidden_states = torch.round(output[0].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(mean_hidden_states.shape.numel(), 32)\n",
    "test_eq(list(mean_hidden_states.shape), [2, 4, 4])\n",
    "\n",
    "cov_hidden_states = torch.round(output[1].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(cov_hidden_states.shape.numel(), 32)\n",
    "test_eq(list(cov_hidden_states.shape), [2, 4, 4])\n",
    "\n",
    "attention_probs = torch.round(output[2].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(attention_probs.shape.numel(), 64)\n",
    "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistMeanSALayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                 attention_probs_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.attention = DistMeanSelfAttention(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                                               attention_probs_dropout_prob)\n",
    "        self.mean_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
    "        self.cov_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
    "        self.activation_func = nn.ELU()\n",
    "\n",
    "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask):\n",
    "        mean_attention_output, cov_attention_output, attention_scores = self.attention(mean_hidden_states, cov_hidden_states, attention_mask)\n",
    "        mean_intermediate_output = self.mean_intermediate(mean_attention_output)\n",
    "        cov_intermediate_output = self.activation_func(self.cov_intermediate(cov_attention_output)) + 1\n",
    "        return mean_intermediate_output, cov_intermediate_output, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "\n",
    "layer = DistMeanSALayer(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
    "                  attention_probs_dropout_prob)\n",
    "\n",
    "input_tensor = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
    "\n",
    "mean_hidden_states = torch.round(output[0].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(mean_hidden_states.shape.numel(), 32)\n",
    "test_eq(list(mean_hidden_states.shape), [2, 4, 4])\n",
    "\n",
    "cov_hidden_states = torch.round(output[1].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(cov_hidden_states.shape.numel(), 32)\n",
    "test_eq(list(cov_hidden_states.shape), [2, 4, 4])\n",
    "\n",
    "attention_probs = torch.round(output[2].detach()*1e4)/1e4\n",
    "\n",
    "test_eq(attention_probs.shape.numel(), 64)\n",
    "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistSAEncoder(nn.Module):               \n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                 attention_probs_dropout_prob, num_hidden_layers,\n",
    "                 distance_metric='wasserstein'):\n",
    "        super().__init__()\n",
    "        layer = DistLayer(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                          attention_probs_dropout_prob, distance_metric)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
    "                                    for _ in range(num_hidden_layers)])\n",
    "\n",
    "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            maen_hidden_states, cov_hidden_states, att_scores = layer_module(mean_hidden_states, cov_hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
    "        return all_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "num_hidden_layers = 2\n",
    "\n",
    "layer = DistSAEncoder(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
    "                  attention_probs_dropout_prob, num_hidden_layers)\n",
    "\n",
    "input_tensor = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
    "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
    "\n",
    "expected_shapes = [[2, 4, 4], [2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
    "\n",
    "test_eq(output_shapes, expected_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistMeanSAEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                 attention_probs_dropout_prob, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        layer = DistMeanSALayer(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
    "                 attention_probs_dropout_prob)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
    "                                    for _ in range(num_hidden_layers)])\n",
    "\n",
    "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            maen_hidden_states, cov_hidden_states, att_scores = layer_module(mean_hidden_states, cov_hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
    "        return all_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "num_hidden_layers = 2\n",
    "\n",
    "layer = DistMeanSAEncoder(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
    "                          attention_probs_dropout_prob, num_hidden_layers)\n",
    "\n",
    "input_tensor = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
    "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
    "\n",
    "expected_shapes = [[2, 4, 4], [2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
    "\n",
    "test_eq(output_shapes, expected_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_act, num_attention_heads, \n",
    "                 hidden_dropout_prob, attention_probs_dropout_prob,\n",
    "                 num_hidden_layers):\n",
    "        super().__init__()\n",
    "        layer = Layer(hidden_size, hidden_act, num_attention_heads, \n",
    "                 hidden_dropout_prob, attention_probs_dropout_prob)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
    "                                    for _ in range(num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states, attention_scores = layer_module(hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append([hidden_states, attention_scores])\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append([hidden_states, attention_scores])\n",
    "        return all_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4\n",
    "hidden_act = 'swish'\n",
    "num_attention_heads = 2\n",
    "hidden_dropout_prob = 0.2\n",
    "attention_probs_dropout_prob = 0.2\n",
    "num_hidden_layers = 2\n",
    "\n",
    "layer = Encoder(hidden_size, hidden_act, num_attention_heads, hidden_dropout_prob,\n",
    "                          attention_probs_dropout_prob, num_hidden_layers)\n",
    "\n",
    "input_tensor = torch.rand((2,4,4))\n",
    "attention_mask = torch.rand((4,4))\n",
    "\n",
    "output = layer.forward(input_tensor, attention_mask)\n",
    "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
    "\n",
    "expected_shapes = [[2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
    "\n",
    "test_eq(output_shapes, expected_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2022-01-22 16:49:16\n",
      "\n",
      "recohut: 0.0.11\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.144+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "torch    : 1.10.0+cu111\n",
      "IPython  : 5.5.0\n",
      "watermark: 2.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
