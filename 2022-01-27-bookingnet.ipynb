{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BookingNet"]},{"cell_type":"markdown","metadata":{"id":"MRrUvPKgE0rk"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0G3R3Ab3p1Wb"},"outputs":[],"source":["import os\n","project_name = \"chef-session\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfu34YGOp1Wc"},"outputs":[],"source":["if not os.path.exists(project_path):\n","    !pip install -U -q dvc dvc[gdrive]\n","    !cp -r /content/drive/MyDrive/git_credentials/. ~\n","    path = \"/content/\" + project_name; \n","    !mkdir \"{path}\"\n","    %cd \"{path}\"\n","    !git init\n","    !git remote add origin https://github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout \"{branch}\"\n","else:\n","    %cd \"{project_path}\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":527,"status":"ok","timestamp":1631210654024,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"Bq_pdLr1p1Wf","outputId":"09c45062-aeda-47e2-88cc-b3055e578ede"},"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKT3dcx0p1Wg"},"outputs":[],"source":["!git add . && git commit -m 'commit' && git push origin \"{branch}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ez3BYNp6JExF"},"outputs":[],"source":["!dvc pull ./data/bronze/booking/*"]},{"cell_type":"markdown","metadata":{"id":"SZGyQmNZFlPH"},"source":["## Context"]},{"cell_type":"markdown","metadata":{"id":"b9CFffH-FnFA"},"source":["- Booking.com dataset\n","    - Popularity recommender, hit rate evaluation\n"]},{"cell_type":"markdown","metadata":{"id":"lCEBxCM1FcLW"},"source":["## Prototype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyJVyJgPNFZ8"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkaGHauFMz3D"},"outputs":[],"source":["train = pd.read_parquet('./data/bronze/booking/train.parquet.snappy')\n","train = train.sort_values(by=['utrip_id','checkin'])\n","train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X34UvBzRNZF3"},"outputs":[],"source":["test = pd.read_parquet('./data/bronze/booking/test.parquet.snappy')\n","test = test.sort_values(by=['utrip_id','checkin'])\n","test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wo1l1GuHNHjl"},"outputs":[],"source":["# Generate Dummy Predictions - use top 4 cities in the trainset as benchmark recommendation\n","topcities = train.city_id.value_counts().index[:4]\n","\n","test_trips = (test[['utrip_id']].drop_duplicates()).reset_index().drop('index', axis=1)\n","\n","cities_prediction = pd.DataFrame([topcities]*test_trips.shape[0], columns=['city_id_1','city_id_2','city_id_3','city_id_4'])\n","\n","cities_prediction = pd.concat([test_trips, cities_prediction], axis =1)\n","cities_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENsq0VxUOHP9"},"outputs":[],"source":["ground_truth = pd.read_parquet('./data/bronze/booking/ground_truth.parquet.snappy')\n","ground_truth.set_index('utrip_id', inplace=True)\n","ground_truth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2maoXWbN-S_"},"outputs":[],"source":["def evaluate_accuracy_at_4(predicted, actual):\n","    '''checks if the true city is within the four recommended cities'''\n","    data = predicted.join(actual, on='utrip_id')\n","\n","    hits = ((data['city_id']==data['city_id_1'])|(data['city_id']==data['city_id_2'])|\n","        (data['city_id']==data['city_id_3'])|(data['city_id']==data['city_id_4']))*1\n","    return hits.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbeGDIoyN_mp"},"outputs":[],"source":["evaluate_accuracy_at_4(cities_prediction, ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"gvEoJau1KaiU"},"source":["## Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11670,"status":"ok","timestamp":1631266839746,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"9TnNISyzKcY_","outputId":"12c977c6-e8cc-4d5d-b62d-01ade714ed35"},"outputs":[],"source":["!pip install -q ipytest\n","import ipytest\n","ipytest.autoconfig()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pd8Iwxbh08i"},"outputs":[],"source":["train = Dataset(path: str)\n","test = Dataset(path: str)\n","model = Model()\n","model.fit(train: pd.DataFrame)\n","model.recommend(test: pd.DataFrame, topk=4)\n","\n","metrics = Metrics()\n","hr = metrics.HitRate(k=4)\n","\n","eval = Evaluator(model,\n","                 data = test,\n","                 metrics=[hr])\n","eval.evaluate()\n","eval.save_results(path: str)"]},{"cell_type":"markdown","metadata":{"id":"5Ewbbn7gYlo7"},"source":["## Dev"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":407,"status":"ok","timestamp":1631270453089,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"5PeruxlZg6rW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from typing import List"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":600,"status":"ok","timestamp":1631273370583,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"cE7tL_8mdIvy"},"outputs":[],"source":["FEATURES_TO_ENCODE = ['city_id', 'device_class', 'affiliate_id',\n","                      'booker_country', 'hotel_country', 'checkin_year',\n","                      'days_stay', 'checkin_day', 'checkin_month',\n","                      'transition_days']\n","\n","NEXT_CITY_COLUMNS = ['city_id', 'affiliate_id',\n","                      'booker_country', 'days_stay',\n","                      'checkin_day']"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":618,"status":"ok","timestamp":1631273150164,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"07r6TLDJdNFn"},"outputs":[],"source":["import logging\n","from typing import List, Dict\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","class LabelEncoder:\n","    \"\"\"\n","    LabelEncoder similar to `sklearn.preprocessing.LabelEncoder`\n","    with the exception it ignores `NaN` values.\n","    .. todo:: Enhance this encoder with the option to set a `min_frequency`.\n","    \"\"\"\n","\n","    def fit_transform(self, col: pd.Series) -> pd.Series:\n","        self.rev_classes_ = dict(enumerate(sorted(col.dropna().unique())))\n","        self.classes_ = {v: k for k, v in self.rev_classes_.items()}\n","        return col.apply(lambda k: self.classes_.get(k, np.nan))\n","\n","    def inverse_transform(self, col: pd.Series) -> pd.Series:\n","        return col.apply(lambda k: self.rev_classes_.get(k, np.nan))\n","\n","\n","class DatasetEncoder:\n","    \"\"\"\n","    DatasetEncoder looks to encapsulate multiple LabelEncoder objects\n","    to fully transform a dataset.\n","    \"\"\"\n","\n","    def __init__(self, features_embedding: List[str]):\n","        self.label_encoders = {c: LabelEncoder() for c in features_embedding}\n","\n","    def fit_transform(self, df: pd.DataFrame) -> None:\n","        \"\"\"\n","        Transform columns in all columns given by feature_embedding.\n","         df:\n","        :return:\n","        \"\"\"\n","        logging.info(\"Running LabelEncoder on columns\")\n","        for column, encoder in self.label_encoders.items():\n","            # reserve zero index for OOV elements\n","            df[column] = encoder.fit_transform(df[column]) + 1\n","            logging.info(f\"{column}: {len(encoder.classes_)}\")\n","\n","\n","def get_embedding_complexity_proxy(dataset_encoder: DatasetEncoder) -> Dict:\n","    \"\"\"\n","    Get embedding complexity proxy\n","    The idea is to find out how many bits (dimension) we need to naively encode each element in the encoder.\n","    It's a proxy since we have no idea which is the dimension of the underlying manifold for every feature.\n","    \"\"\"\n","    return {k: (len(v.classes_), np.ceil(np.log2(len(v.classes_))))\n","            for k, v in dataset_encoder.label_encoders.items()}"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1631271326132,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"Sw8Ij75jJJro"},"outputs":[],"source":["class Dataset:\n","    def __init__(self, data=None, is_train=True):\n","        self.data = data\n","        self.is_train = is_train\n","\n","    def load(self, path, type='parquet'):\n","        if type=='parquet':\n","            self.data = pd.read_parquet(path)\n","        return self\n","\n","    def sort(self, by: List):\n","        self.data.sort_values(by=by)\n","        return self\n","\n","    def filter(self, by='cols', keep=[]):\n","        if by=='cols':\n","            self.data = self.data[keep]\n","        return self\n","    \n","    def rename(self, rename_map):\n","        self.data = self.data.rename(columns=rename_map)\n","        return self\n","    \n","    def cast(self, schema_map):\n","        self.data = self.data.astype(schema_map)\n","        return self\n","\n","    def preprocess(self):\n","        pass\n","\n","    def __repr__(self):\n","        return '{}\\n{}\\n{}\\n{}'\\\n","        .format(\n","            self.data.info(),\n","            '='*100,\n","            self.data.head(),\n","            '='*100\n","            )"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1631270555370,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"pMeB4-BCS40f"},"outputs":[],"source":["class BookingDataset(self.data):\n","\n","    def encode(self):\n","        de = DatasetEncoder(config.FEATURES_TO_ENCODE)\n","        de.fit_transform(self.data)\n","\n","    def set_future_features(self):\n","        # Add features about the next city to the dataframe.\n","        for column in NEXT_CITY_COLUMNS:\n","            self.data['next_' + column] = self.data.groupby('utrip_id')[column].shift(periods=-1)\n","\n","    def min_sequence_length(self):\n","        # Constrains the minimum trip length to `sequence_length`.\n","        sequence_length = 3\n","        self.data.groupby('utrip_id').filter(lambda x: len(x) >= sequence_length)\n","\n","    def preprocess(self):\n","        self.data['city_id'] = self.data['city_id'].replace({0: np.nan})\n","    \n","    def featurize(self):\n","        # create some time features\n","        self.data['days_stay'] = (self.data['checkout'] - self.data['checkin']).dt.days - 1\n","        self.data['checkin_day'] = self.data['checkin'].dt.dayofweek\n","        self.data['checkin_month'] = self.data['checkin'].dt.month\n","        self.data['checkin_year'] = self.data['checkin'].dt.year\n","\n","        # create transition time feature\n","        self.data['prev_checkout'] = self.data.groupby('utrip_id')['checkout'].shift(periods=1)\n","        self.data['transition_days'] = (self.data['checkout'] - self.data['prev_checkout']).dt.days - 1\n","        self.data['transition_days'].fillna(0, inplace=True)\n","        self.data.drop(columns=\"prev_checkout\", inplace=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2157,"status":"ok","timestamp":1631270624996,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"91AGmHAFTWV4","outputId":"edb093a4-c774-4ccd-f9c5-c12d379ea098"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1166835 entries, 0 to 1166834\n","Data columns (total 9 columns):\n"," #   Column          Non-Null Count    Dtype \n","---  ------          --------------    ----- \n"," 0   user_id         1166835 non-null  int64 \n"," 1   checkin         1166835 non-null  object\n"," 2   checkout        1166835 non-null  object\n"," 3   city_id         1166835 non-null  int64 \n"," 4   device_class    1166835 non-null  object\n"," 5   affiliate_id    1166835 non-null  int64 \n"," 6   booker_country  1166835 non-null  object\n"," 7   hotel_country   1166835 non-null  object\n"," 8   utrip_id        1166835 non-null  object\n","dtypes: int64(3), object(6)\n","memory usage: 80.1+ MB\n"]},{"data":{"text/plain":["None\n","====================================================================================================\n","   user_id     checkin    checkout  ...  booker_country hotel_country   utrip_id\n","0  1000027  2016-08-13  2016-08-14  ...         Elbonia        Gondal  1000027_1\n","1  1000027  2016-08-14  2016-08-16  ...         Elbonia        Gondal  1000027_1\n","2  1000027  2016-08-16  2016-08-18  ...         Elbonia        Gondal  1000027_1\n","3  1000027  2016-08-18  2016-08-21  ...         Elbonia        Gondal  1000027_1\n","4  1000033  2016-04-09  2016-04-11  ...          Gondal  Cobra Island  1000033_1\n","\n","[5 rows x 9 columns]\n","===================================================================================================="]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["ds = BookingDataset()\n","ds.load('./data/bronze/booking/train.parquet.snappy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIBJmW8tJdeN"},"outputs":[],"source":["class Model:\n","    def __init__(self):\n","        self.items_by_popularity = []\n","\n","    def fit(self, train):\n","        self.items_by_popularity = train.data['ITEM_ID'].value_counts().index.tolist()\n","\n","    def recommend(self, uid=None, topk=4):\n","        return self.items_by_popularity[:topk]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKHsp25GdIFn"},"outputs":[],"source":["class HitRate:\n","    def __init__(self, k=4):\n","        self.k = k\n","\n","    def calculate(self, recommended_list, actual_list):\n","        actual_list = np.array(actual_list) \n","        recommended_list = np.array(recommended_list)[:self.k]\n","        flags = np.isin(actual_list, recommended_list) \n","        return (flags.sum() > 0) * 1\n","\n","    def __repr__(self):\n","        return 'HR@{}'.format(self.k)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zg6ZlHGMKVjc"},"outputs":[],"source":["class Evaluate:\n","    def __init__(self, model, test_ids, ground_truth, metrics):\n","        self.model = model\n","        self.test_ids = test_ids\n","        self.ground_truth = ground_truth\n","        self.metrics = metrics\n","        self.results = {}\n","        self.recommendations = {}\n","        self._calculate_recommendations()\n","    \n","    def _calculate_recommendations(self):\n","        for test_id in self.test_ids:\n","            self.recommendations[test_id] = self.model.recommend(test_id)\n","\n","    def evaluate(self):\n","        for metric in self.metrics:\n","            self.results[metric] = 0\n","            scores = []\n","            for test_id in self.test_ids:\n","                actual_list = self.ground_truth[test_id]\n","                recommended_list = self.recommendations[test_id]\n","                score = metric.calculate(recommended_list=recommended_list,\n","                                         actual_list=actual_list)\n","                scores.append(score)\n","            self.results[metric] = np.mean(scores)\n","        return self\n","\n","    def save_results(self, path):\n","        with open(path, 'wt') as handle:\n","            self.results.write(str(handle))\n","    \n","    def __repr__(self):\n","        return str(self.results)"]},{"cell_type":"markdown","metadata":{"id":"s43SXdMzgmVw"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k22cNx-fieRJ"},"outputs":[],"source":["train = Dataset()\n","\n","train_info = train.load('./data/bronze/booking/train.parquet.snappy')\\\n","                        .sort(by=['utrip_id','checkin'])\\\n","                        .filter(by='cols', keep=['utrip_id','city_id'])\\\n","                        .rename({'utrip_id':'USER_ID','city_id':'ITEM_ID'})\\\n","                        .cast({'USER_ID':'str', 'ITEM_ID':'str'})\n","train_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdZT8bW6jVGg"},"outputs":[],"source":["test = Dataset()\n","\n","test_info = test.load('./data/bronze/booking/test.parquet.snappy')\\\n","                        .sort(by=['utrip_id','checkin'])\\\n","                        .filter(by='cols', keep=['utrip_id','city_id'])\\\n","                        .rename({'utrip_id':'USER_ID','city_id':'ITEM_ID'})\\\n","                        .cast({'USER_ID':'str', 'ITEM_ID':'str'})\n","test_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPtEFAe_cUps"},"outputs":[],"source":["model = Model()\n","model.fit(train)\n","model.recommend('1000066_2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7W5XpXGcXYu"},"outputs":[],"source":["hitrate = HitRate(k=4)\n","hitrate\n","print(hitrate.calculate(recommended_list=['1','2','3','4','5'], actual_list = ['4']))\n","print(hitrate.calculate(recommended_list=['1','2','3','4','5'], actual_list = ['5']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqaekUZ-o7k-"},"outputs":[],"source":["ground_truth = Dataset()\n","\n","gt_info = ground_truth.load('./data/bronze/booking/ground_truth.parquet.snappy')\\\n","                            .filter(by='cols', keep=['utrip_id','city_id'])\\\n","                            .rename({'utrip_id':'USER_ID','city_id':'ITEM_ID'})\\\n","                            .cast({'USER_ID':'str', 'ITEM_ID':'str'})\n","\n","ground_truth = ground_truth.data\\\n","                    .drop_duplicates(subset='USER_ID', keep='last')\\\n","                    .set_index('USER_ID')\\\n","                    .to_dict()['ITEM_ID']\n","\n","print(type(ground_truth), len(ground_truth.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glYtKR5SmDWM"},"outputs":[],"source":["eval = Evaluate(model=model,\n","                test_ids=test.data.USER_ID.unique(),\n","                ground_truth=ground_truth,\n","                metrics=[hitrate])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mF3AndoQm2iS"},"outputs":[],"source":["eval.evaluate()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPdQJ6WHyqgqt7PuLXSbxia","collapsed_sections":[],"mount_file_id":"15wzHAZcwJ8iWL4iclNNwcdlFBoF3jMg7","name":"chef-session-booking-v2-bookingnet.ipynb","provenance":[{"file_id":"192CbCpX6ZjFvqpDFyuYHVssGwBvFr94w","timestamp":1631266665339},{"file_id":"1E_VUk0osWTrtGH6FiGEOWTfNDMq83KGs","timestamp":1631187854996},{"file_id":"1AqVI1vgtpjVbcx5XdPgFnkJCmWXMAg7G","timestamp":1629624916062}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
