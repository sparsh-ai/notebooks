{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T471382 | FrozenLake using Value Iteration","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJEXLRdgTSNV2TTGle9JZc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BR_bT45hl6nT"},"source":["# FrozenLake using Value Iteration"]},{"cell_type":"code","metadata":{"id":"a81nLW87lHVr"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YMfFbzMkzEu"},"source":["import gym\n","import collections\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8YicPPsk2Vn"},"source":["ENV_NAME = \"FrozenLake-v0\"\n","#ENV_NAME = \"FrozenLake8x8-v0\"      # uncomment for larger version\n","GAMMA = 0.9\n","TEST_EPISODES = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_29THYQ1k1b8"},"source":["class Agent:\n","    def __init__(self):\n","        self.env = gym.make(ENV_NAME)\n","        self.state = self.env.reset()\n","        self.rewards = collections.defaultdict(float)\n","        self.transits = collections.defaultdict(\n","            collections.Counter)\n","        self.values = collections.defaultdict(float)\n","\n","    def play_n_random_steps(self, count):\n","        for _ in range(count):\n","            action = self.env.action_space.sample()\n","            new_state, reward, is_done, _ = self.env.step(action)\n","            self.rewards[(self.state, action, new_state)] = reward\n","            self.transits[(self.state, action)][new_state] += 1\n","            self.state = self.env.reset() \\\n","                if is_done else new_state\n","\n","    def calc_action_value(self, state, action):\n","        target_counts = self.transits[(state, action)]\n","        total = sum(target_counts.values())\n","        action_value = 0.0\n","        for tgt_state, count in target_counts.items():\n","            reward = self.rewards[(state, action, tgt_state)]\n","            val = reward + GAMMA * self.values[tgt_state]\n","            action_value += (count / total) * val\n","        return action_value\n","\n","    def select_action(self, state):\n","        best_action, best_value = None, None\n","        for action in range(self.env.action_space.n):\n","            action_value = self.calc_action_value(state, action)\n","            if best_value is None or best_value < action_value:\n","                best_value = action_value\n","                best_action = action\n","        return best_action\n","\n","    def play_episode(self, env):\n","        total_reward = 0.0\n","        state = env.reset()\n","        while True:\n","            action = self.select_action(state)\n","            new_state, reward, is_done, _ = env.step(action)\n","            self.rewards[(state, action, new_state)] = reward\n","            self.transits[(state, action)][new_state] += 1\n","            total_reward += reward\n","            if is_done:\n","                break\n","            state = new_state\n","        return total_reward\n","\n","    def value_iteration(self):\n","        for state in range(self.env.observation_space.n):\n","            state_values = [\n","                self.calc_action_value(state, action)\n","                for action in range(self.env.action_space.n)\n","            ]\n","            self.values[state] = max(state_values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39UDvaDPk7db","executionInfo":{"status":"ok","timestamp":1634479644135,"user_tz":-330,"elapsed":1669,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"55493d52-7526-4cd5-fe97-4efa07375e3a"},"source":["if __name__ == \"__main__\":\n","    test_env = gym.make(ENV_NAME)\n","    agent = Agent()\n","    writer = SummaryWriter(comment=\"-v-iteration\")\n","\n","    iter_no = 0\n","    best_reward = 0.0\n","    while True:\n","        iter_no += 1\n","        agent.play_n_random_steps(100)\n","        agent.value_iteration()\n","\n","        reward = 0.0\n","        for _ in range(TEST_EPISODES):\n","            reward += agent.play_episode(test_env)\n","        reward /= TEST_EPISODES\n","        writer.add_scalar(\"reward\", reward, iter_no)\n","        if reward > best_reward:\n","            print(\"Best reward updated %.3f -> %.3f\" % (\n","                best_reward, reward))\n","            best_reward = reward\n","        if reward > 0.80:\n","            print(\"Solved in %d iterations!\" % iter_no)\n","            break\n","    writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best reward updated 0.000 -> 0.300\n","Best reward updated 0.300 -> 0.400\n","Best reward updated 0.400 -> 0.500\n","Best reward updated 0.500 -> 0.550\n","Best reward updated 0.550 -> 0.650\n","Best reward updated 0.650 -> 0.700\n","Best reward updated 0.700 -> 0.850\n","Solved in 26 iterations!\n"]}]},{"cell_type":"code","metadata":{"id":"TDBzgGAmlloU"},"source":["class Agent:\n","    def __init__(self):\n","        self.env = gym.make(ENV_NAME)\n","        self.state = self.env.reset()\n","        self.rewards = collections.defaultdict(float)\n","        self.transits = collections.defaultdict(collections.Counter)\n","        self.values = collections.defaultdict(float)\n","\n","    def play_n_random_steps(self, count):\n","        for _ in range(count):\n","            action = self.env.action_space.sample()\n","            new_state, reward, is_done, _ = self.env.step(action)\n","            self.rewards[(self.state, action, new_state)] = reward\n","            self.transits[(self.state, action)][new_state] += 1\n","            self.state = self.env.reset() if is_done else new_state\n","\n","    def select_action(self, state):\n","        best_action, best_value = None, None\n","        for action in range(self.env.action_space.n):\n","            action_value = self.values[(state, action)]\n","            if best_value is None or best_value < action_value:\n","                best_value = action_value\n","                best_action = action\n","        return best_action\n","\n","    def play_episode(self, env):\n","        total_reward = 0.0\n","        state = env.reset()\n","        while True:\n","            action = self.select_action(state)\n","            new_state, reward, is_done, _ = env.step(action)\n","            self.rewards[(state, action, new_state)] = reward\n","            self.transits[(state, action)][new_state] += 1\n","            total_reward += reward\n","            if is_done:\n","                break\n","            state = new_state\n","        return total_reward\n","\n","    def value_iteration(self):\n","        for state in range(self.env.observation_space.n):\n","            for action in range(self.env.action_space.n):\n","                action_value = 0.0\n","                target_counts = self.transits[(state, action)]\n","                total = sum(target_counts.values())\n","                for tgt_state, count in target_counts.items():\n","                    key = (state, action, tgt_state)\n","                    reward = self.rewards[key]\n","                    best_action = self.select_action(tgt_state)\n","                    val = reward + GAMMA * \\\n","                          self.values[(tgt_state, best_action)]\n","                    action_value += (count / total) * val\n","                self.values[(state, action)] = action_value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlYbjLkalmmd","executionInfo":{"status":"ok","timestamp":1634479812088,"user_tz":-330,"elapsed":1900,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5765a9af-5fa2-46e3-80a4-da4f520ff547"},"source":["if __name__ == \"__main__\":\n","    test_env = gym.make(ENV_NAME)\n","    agent = Agent()\n","    writer = SummaryWriter(comment=\"-q-iteration\")\n","\n","    iter_no = 0\n","    best_reward = 0.0\n","    while True:\n","        iter_no += 1\n","        agent.play_n_random_steps(100)\n","        agent.value_iteration()\n","\n","        reward = 0.0\n","        for _ in range(TEST_EPISODES):\n","            reward += agent.play_episode(test_env)\n","        reward /= TEST_EPISODES\n","        writer.add_scalar(\"reward\", reward, iter_no)\n","        if reward > best_reward:\n","            print(\"Best reward updated %.3f -> %.3f\" % (best_reward, reward))\n","            best_reward = reward\n","        if reward > 0.80:\n","            print(\"Solved in %d iterations!\" % iter_no)\n","            break\n","    writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best reward updated 0.000 -> 0.150\n","Best reward updated 0.150 -> 0.200\n","Best reward updated 0.200 -> 0.300\n","Best reward updated 0.300 -> 0.450\n","Best reward updated 0.450 -> 0.550\n","Best reward updated 0.550 -> 0.600\n","Best reward updated 0.600 -> 0.700\n","Best reward updated 0.700 -> 0.750\n","Best reward updated 0.750 -> 0.800\n","Best reward updated 0.800 -> 0.850\n","Solved in 85 iterations!\n"]}]},{"cell_type":"code","metadata":{"id":"H5UaDa03lAEH"},"source":["%tensorboard --logdir runs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jq4typO2It4l"},"source":["<p><center><img src='_images/T471382_1.png'></center></p>"]}]}