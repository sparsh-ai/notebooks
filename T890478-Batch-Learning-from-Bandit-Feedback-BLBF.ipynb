{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T890478 | Batch Learning from Bandit Feedback (BLBF)","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNOw8iURy2upeF0TuQZfbJ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VTwABdXNnZgf"},"source":["# Batch Learning from Bandit Feedback"]},{"cell_type":"markdown","metadata":{"id":"DREUiNmICYFh"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"cPswAO-jCQ_I"},"source":["import math\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import sklearn.model_selection\n","import sklearn.preprocessing\n","import sklearn.linear_model \n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LogisticRegressionCV\n","from sklearn.ensemble.forest import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn import preprocessing\n","from sklearn.datasets import load_digits, load_breast_cancer, load_wine, fetch_openml\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ocsFkIRVCpea"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"CSemJj4ACvmG"},"source":["def create_interactions(X: np.ndarray, T: np.ndarray, one_hot_labeler=None) -> tuple:\n","    if one_hot_labeler is None:\n","        lb_fit = sklearn.preprocessing.LabelBinarizer().fit(T)\n","    else:\n","        lb_fit = one_hot_labeler\n","    T = lb_fit.transform(T)\n","    XT = np.zeros(shape=[X.shape[0], X.shape[1] * T.shape[1]]) * np.nan\n","    cnt = 0\n","    for i in range(X.shape[1]):\n","        for j in range(T.shape[1]):\n","            XT[:,cnt]= X[:, i] * T[:, j]\n","            cnt += 1\n","    X_full = np.column_stack((X, T, XT))\n","    return X_full, lb_fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BoUCLplwCSaf"},"source":["## Supervised to Bandit Transform (STBT)"]},{"cell_type":"code","metadata":{"id":"daul89OeCak1"},"source":["class STBT:\n","   \n","    \"\"\"\n","    Performs Supervised to Bandit Conversion for classification \n","    datasets. This conversion is generally used to test the limits of \n","    counterfactual learning in a well-controlled environment [1,2,3]. \n","    \n","    Parameters\n","    ----------\n","    \n","    train_frac : float, default: 0.50\n","        It should be between 0.0 and 1.0 and represents the\n","        proportion of the dataset to include in the train split.\n","        \n","    permute : bool, default: False\n","        Randomly permute the data before the random split between train and test.\n","    logging_type : str, default: \"uniform\"\n","        The type of logging policy. If \"uniform\", uniform random samples from the \n","        labels $y$ to simulate a logging policy. If \"biased\", the logging policy\n","        is a stochastic function of the covariates.\n","        \n","    sample_frac : float, default: None\n","        A sample fraction between (0.0,1.0]. This is the sample fraction of the\n","        training data used to fit the target policy. By default, the full\n","        training set is used. \n","     \n","    References\n","    ----------\n","    \n","    .. [1] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, \n","           Proceedings of Machine Learning Research, 48, 652--661, 2016.\n","    .. [2] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through \n","           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),\n","           1731--1755, 2015.\n","    .. [3] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, \n","           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.\n","           \n","    Examples\n","    --------\n","    >>> np.random.seed(42)\n","    >>> X, y = get_data(dataset='ecoli')  \n","    >>> obj = STBT()\n","    >>> sample_batch = obj.generate_batch(X, y)\n","    >>> sample_batch.y_train_logging[0:5]\n","    array([1, 1, 0, 0, 0]))\n","    \n","    \"\"\"\n","    \n","    def __init__(self, train_frac: float = 0.50, permute: bool = False, logging_type: str = 'uniform',\n","                 sample_frac: float = None):\n","        self.train_frac = train_frac\n","        self.permute = permute\n","        self.logging_type = logging_type\n","        self.sample_frac = sample_frac\n","        \n","    def __repr__(self):\n","        \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def _validate_input(self):\n","        if not isinstance(self.train_frac, float) or not (0.0 < self.train_frac < 1.0):\n","            raise ValueError(\"`train_frac` should be a float in (0.0,1.0), got %s\" % self.train_frac)\n","            \n","        if self.sample_frac is not None and self.sample_frac is not (0.0 < self.sample_frac <= 1.0):\n","            raise ValueError(\"`sample_frac` should be a float in (0.0,1.0], got %s\" % self.sample_frac)\n","\n","        if self.logging_type not in ['uniform', 'biased']:\n","            raise ValueError(\"`logging_type` should be either 'uniform' or 'biased', got %s\" % self.logging_type)\n","    \n","    def _softmax(self, x, axis=-1):\n","        \n","        kw = dict(axis=axis, keepdims=True)\n","        xrel = x - x.max(**kw)\n","        exp_xrel = np.exp(xrel)\n","        p = exp_xrel / exp_xrel.sum(**kw)  \n","         \n","        return p\n","        \n","         \n","    def generate_batch(self, X: np.ndarray, y: np.ndarray, **kwargs):\n","        \"\"\"Generate Supervised to Bandit batch\n","        \n","        Parameters\n","        ----------\n","        X : array of shape (n_samples, n_features)\n","            Training vector, where n_samples is the number of samples and\n","            n_features is the number of features.\n","        y : array of shape (n_samples,)\n","            Target vector relative to X.\n","        **kwargs : Arguments passed to fit method in \n","                   `sklearn.linear_model.LogisticRegression` class.\n","        \n","        Returns\n","        -------\n","        X_train : array of shape (n_train_samples, n_features)\n","        y_train : array of shape (n_train_samples,)\n","        X_test : array of shape (n_test_samples, n_features)\n","        y_test : array of shape (n_test_samples,)\n","        y_train_logging : array of shape (n_train_samples,)\n","            Logging policy labels on train data\n","        train_logging_probs : array of shape (n_train_samples, n_classes)     \n","            Logging policy probabilities on train data\n","        train_logging_prob : array of shape (n_train_samples,)\n","            Logging policy probability corresponding to the chosen logging label on train data\n","        y_train_logging_idx : array of shape (n_train_samples, n_classes)\n","            Binary matrix with 1s indicating which action was taken by the logging policy in train data\n","           \n","        y_test_logging : array of shape (n_test_samples,)\n","             Logging policy labels on test data\n","        test_logging_probs : array of shape (n_test_samples, n_classes)   \n","            Logging policy probabilities on test data\n","        test_logging_prob : array of shape (n_test_samples,)\n","            Logging policy probability corresponding to the chosen logging label on test data\n","       \n","        y_train_target : array of shape (n_train_samples,)\n","             Target policy labels on train data\n","        train_target_prob : array of shape (n_train_samples, n_classes)     \n","             Target policy probabilities on train data\n","        train_target_probs : array of shape (n_train_samples,)\n","            Target policy probability corresponding to the chosen logging label on train data\n","       \n","        y_test_target : array of shape (n_test_samples,)\n","             Target policy labels on test data\n","        test_target_prob : array of shape (n_test_samples, n_classes)     \n","             Target policy probabilities on test data\n","        test_target_probs : array of shape (n_test_samples,)\n","            Target policy probability corresponding to the chosen logging label on test data\n","       \n","        true_target_value_test : float\n","            True value of Target policy on test data\n","       \n","        train_logging_reward : array of shape (n_train_samples,)\n","            Observed reward of logging policy on train data \n","        test_logging_reward : array of shape (n_test_samples,)\n","            Observed reward of logging policy on test data \n","            \n","        \"\"\"\n","        self._validate_input()\n","        \n","        self.generate_batch_call = True\n","        \n","        self.dual = False\n","        \n","        if self.permute:\n","            permute = np.random.permutation(X.shape[0])\n","            X = X[permute, :]\n","            y = y[permute]\n","\n","        self.X_train, self.X_test, self.y_train, self.y_test = \\\n","            sklearn.model_selection.train_test_split(X, y,\n","                train_size = self.train_frac) \n","            \n","        n_train_samples, n_features = self.X_train.shape\n","        n_test_samples = self.X_test.shape[0]\n","\n","    \n","        y_train_u = np.unique(self.y_train)\n","        \n","        if self.logging_type == 'uniform':\n","\n","            self.y_train_logging = np.random.choice(y_train_u, size=n_train_samples)  \n","            self.train_logging_prob = np.repeat(1.0/len(y_train_u), n_train_samples)\n","            self.train_logging_probs = np.repeat(self.train_logging_prob.reshape(-1,1), len(y_train_u), axis=1)\n","            self.y_test_logging = np.random.choice(y_train_u, size=n_test_samples)  \n","            self.test_logging_prob = np.repeat(1.0/len(y_train_u), n_test_samples)\n","            self.test_logging_probs = np.repeat(self.test_logging_prob.reshape(-1,1), len(y_train_u), axis=1)\n","            \n","            self.y_train_logging_idx = np.full((n_train_samples, len(y_train_u)), False, dtype=bool)\n","            for i in range(n_train_samples):\n","                self.y_train_logging_idx[i, np.where(y_train_u==self.y_train_logging[i])[0][0]] = True \n","        \n","        else:\n","            \n","            W = np.random.normal(0, 1, (n_features, len(y_train_u)))\n","            lp_train = self.X_train @ W\n","            lp_test = self.X_test @ W\n","            self.train_logging_probs = self._softmax(lp_train)\n","            self.test_logging_probs = self._softmax(lp_test)\n","            \n","            self.y_train_logging_idx = np.full((n_train_samples, len(y_train_u)), False, dtype=bool)\n","            y_test_logging_idx = np.full((n_test_samples, len(y_train_u)), False, dtype=bool)\n","            \n","            for sample in range(n_train_samples):\n","                choice = np.random.multinomial(1, self.train_logging_probs[sample,:], size = 1)[-1]\n","                self.y_train_logging_idx[sample, :] = choice\n","            \n","            for sample in range(n_test_samples):\n","                choice = np.random.multinomial(1, self.test_logging_probs[sample,:], size = 1)[-1]\n","                y_test_logging_idx[sample, :] = choice\n","            \n","            self.y_train_logging = np.array([y_train_u,]*n_train_samples)[self.y_train_logging_idx]\n","            self.y_test_logging = np.array([y_train_u,]*n_test_samples)[y_test_logging_idx]\n","            \n","            self.train_logging_prob = self.train_logging_probs[self.y_train_logging_idx]\n","            self.test_logging_prob = self.test_logging_probs[y_test_logging_idx]\n","            \n","        if self.sample_frac is not None:\n","            n_subsamples = math.ceil(self.sample_frac * n_train_samples)\n","            idx_subsamples = np.random.randint(n_train_samples, size=n_subsamples)\n","            X_train_subsamples = self.X_train[idx_subsamples, :]\n","            y_train_subsamples = self.y_train[idx_subsamples]\n","            if n_subsamples < n_features:\n","                self.dual=True\n","            target_policy = sklearn.linear_model.LogisticRegression(**kwargs, dual=self.dual).fit(X_train_subsamples, y_train_subsamples)\n","       \n","        else:\n","            if n_train_samples < n_features:\n","                self.dual=True\n","            target_policy = sklearn.linear_model.LogisticRegression(**kwargs, dual=self.dual).fit(self.X_train, self.y_train)\n","        \n","        self.train_target_probs = target_policy.predict_proba(self.X_train)\n","        self.test_target_probs = target_policy.predict_proba(self.X_test)\n","         \n","        y_train_target = list()\n","        train_target_prob = list()\n","        y_test_target = list()\n","        test_target_prob = list()\n","         \n","        for i in range(n_train_samples):\n","            y_train_target_i = np.random.choice(y_train_u, size=1, \n","                                                 replace=False, p=self.train_target_probs[i,:])[0]\n","            y_train_target.append(y_train_target_i)\n","            train_target_prob.append(self.train_target_probs[i, np.where(y_train_u==y_train_target_i)[0][0]])\n","        self.y_train_target = np.array(y_train_target)\n","        self.train_target_prob = np.array(train_target_prob)\n","        \n","        for i in range(n_test_samples):\n","            y_test_target_i = np.random.choice(y_train_u, size=1, \n","                                                 replace=False, p=self.test_target_probs[i,:])[0]\n","            y_test_target.append(y_test_target_i)\n","            test_target_prob.append(self.test_target_probs[i, np.where(y_train_u==y_test_target_i)[0][0]])\n","        self.y_test_target = np.array(y_test_target)\n","        self.test_target_prob = np.array(test_target_prob)\n","        \n","        self.true_target_value_test = np.mean(1 * (self.y_test == self.y_test_target))\n","        \n","        self.train_logging_reward = 1 * (self.y_train == self.y_train_logging)\n","        self.test_logging_reward = 1 * (self.y_test == self.y_test_logging)\n","           \n","        return self"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_24csBqjC2jY"},"source":["## Off-Policy Evaluation Estimators"]},{"cell_type":"code","metadata":{"id":"a9IjJgXDC29C"},"source":["class PolicyEvaluation:\n","        \"\"\"\n","        Performs off-policy evaluation with bandit feedback. \n","        \n","        Parameters\n","        ----------\n","        method : str, default: 'ips'.\n","            The policy evaluation method. The default is 'ips'.\n","            It should be one of: 'ips' (Inverse Propensity Score), \n","            'dm' (Direct Method), 'dr' (Doubly Robust), 'switch'\n","            (SWITCH estimator).\n","            \n","        tau : float, default: 0.001.\n","            Hyperparameter added to IPS or SWICTH estimator for numerical stability. \n","            \n","            For method='ips', the logging probabilities in the test set get adjusted by\n","            the max(logging probabilities, tau).\n","            \n","            For method = 'switch', when logging probabilities are larger than this parameter,\n","            the 'dm' estimator is applied, otherwise the 'dr' estimator is applied. \n","            \n","            \n","        References\n","        ----------\n","    \n","        .. [1] Y. Wang, A. Agarwal and M. Dud\\'{\\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, \n","               Proceedings of Machine Learning Research, 70, 3589--3597, 2017.\n","        .. [2] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, \n","               Proceedings of Machine Learning Research, 48, 652--661, 2016.\n","        .. [3] K{\\\"u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous \n","               treatment effects using machine learning, Proceedings of the National Academy of Sciences, \n","               116(10), 4156--4165, 2019. \n","               \n","        Examples\n","        --------\n","        >>> np.random.seed(42)\n","        >>> from blbf.STBT import STBT\n","        >>> from blbf.PolicyEvaluation import PolicyEvaluation \n","        >>> X, y = get_data(dataset='ecoli')\n","        >>> obj = STBT(train_frac= 0.5)\n","        >>> data = obj.generate_batch(X, y, max_iter=1000)\n","        >>> PolicyEvaluation(method='dr').evaluate_policy(data = data)\n","        0.7241601514218099\n","        \"\"\"\n","    \n","        def __init__(self, method: str = 'ips', tau: float = 0.001):\n","            \n","            self.method = method\n","            self.tau = tau \n","            \n","            valid_methods = ['ips', 'dm', 'dr', 'switch']\n","            if self.method not in valid_methods:\n","                raise ValueError(\"%s is not a valid method.\" % self.method)\n","        \n","            if self.tau <= 0 or self.tau >1:\n","                raise ValueError(\"`tau` must be in the (0, 1) interval, got %s.\" % self.tau)\n","                       \n","        def __repr__(self):\n","            \n","            items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","            return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","        \n","        def evaluate_policy(self, data, clf: str = 'LogisticRegression', **kwargs) -> float:\n","            \"\"\"\n","            Parameters\n","            ----------\n","            data : STBT object\n","                This must be a Supervised to Bandit Transform (STBT) class with fitted \n","                `generate_batch` method.\n","                \n","            clf : str, default: 'LogisticRegression'\n","            A sklearn classification estimator. Must be one of 'LogisticRegression', \n","            'LogisticRegressionCV', 'RandomForestClassifier', or 'SVC'.\n","           \n","            **kwargs : Arguments passed to clf.\n","    \n","            Returns\n","            -------\n","            float.\n","              The estimated value of the policy.\n","        \n","            \"\"\"\n","              \n","            if not hasattr(data, 'generate_batch_call'):\n","                raise TypeError(\"The method `generate_batch` must be called first on the instance: %s.\" % (data))\n","                                    \n","            if self.method == 'ips':\n","                \n","                if self.tau is not None:\n","                    adj_test_logging_prob = np.maximum(self.tau, data.test_logging_prob)  \n","                \n","                else:\n","                    adj_test_logging_prob = data.test_logging_prob\n","                \n","                v = np.mean(data.test_logging_reward * (data.y_test_logging == data.y_test_target) / adj_test_logging_prob)\n","                \n","            else:\n","                XY_train, lb_fit = create_interactions(data.X_train, data.y_train_logging)\n","                m = eval(clf)(**kwargs).fit(XY_train, data.train_logging_reward)\n","                XY_test_target, _ = create_interactions(data.X_test, data.y_test_target, one_hot_labeler = lb_fit)\n","                test_target_pred_reward = m.predict_proba(XY_test_target)[:,1]\n","                \n","                if self.method in ['dr', 'switch']:\n","                    XY_test_logging, _ = create_interactions(data.X_test, data.y_test_logging, one_hot_labeler = lb_fit)\n","                    test_logging_pred_reward = m.predict_proba(XY_test_logging)[:,1]\n","                    dr_adj = (data.test_logging_reward - test_logging_pred_reward) * \\\n","                                 (data.y_test_logging == data.y_test_target) / data.test_logging_prob\n","                \n","                if self.method == 'dm':\n","                    v = np.mean(test_target_pred_reward) \n","                    \n","                elif self.method == 'dr':\n","                    v = np.mean(test_target_pred_reward + dr_adj)\n","                        \n","                elif self.method == 'switch':\n","                    switch_indicator = np.array(data.test_logging_prob <= self.tau, dtype=int)\n","                    switch_estimator_rewards = (1-switch_indicator) * (dr_adj + test_target_pred_reward)\n","                    switch_estimator_rewards += switch_indicator * test_target_pred_reward\n","                    v = np.mean(switch_estimator_rewards)\n","          \n","            return v"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nYhXF1yfDFRG"},"source":["## Sample datasets used in experiments"]},{"cell_type":"code","metadata":{"id":"vfX8I9biDHBe"},"source":["def get_data(dataset: str = None, scale: bool = True) -> tuple:\n","    \"\"\"Get data (features and labels) used in experiments.\n","    \n","    Parameters\n","    ----------\n","    \n","    dataset : str, default: None \n","        It should be one of: 'ecoli', 'glass', 'letter-recognition', \n","        'lymphography', 'yeast', 'digits', 'breast-cancer', 'wine', or \n","        'mnist'.\n","        \n","    scale : bool, default: True\n","        Standardize features by zero mean and unit variance.\n","        \n","    Returns\n","    -------\n","    \n","    tuple, length=2 \n","        tuple containing features-target split of inputs.\n","        \n","    References\n","    ----------\n","    Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. \n","    Irvine, CA: University of California, School of Information and Computer Science.\n","    \n","    Examples\n","    --------\n","    >>> X, y = get_data(dataset='ecoli')\n","    >>> X[0,:]\n","    array([0.49, 0.29, 0.48, 0.5 , 0.56, 0.24, 0.35])\n","    \n","    \"\"\"\n","    \n","    if dataset not in ['ecoli', 'glass', 'letter-recognition', 'lymphography', 'yeast', \n","                       'digits', 'breast-cancer', 'wine', 'mnist']:\n","        raise ValueError(\"Invalid dataset provided.\")\n","    \n","    if dataset in dataset in ['ecoli', 'glass', 'letter-recognition', 'lymphography', 'yeast']:\n","        path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/' \n","        f = path + dataset + \"/\" + dataset + \".data\"\n","     \n","    if dataset in  ['ecoli', 'yeast']:\n","        df = pd.read_table(f, delim_whitespace=True, header=None)\n","    elif dataset in [ 'glass', 'letter-recognition', 'lymphography']:\n","        df = pd.read_csv(f, header=None)\n","    elif dataset == 'digits':\n","        df = load_digits()\n","        X = df.data\n","        y = df.target\n","    elif dataset == 'breast-cancer':\n","        df = load_breast_cancer()\n","        X = df.data\n","        y = df.target\n","    elif dataset == 'wine':\n","        df = load_wine()\n","        X = df.data\n","        y = df.target\n","        \n","    if dataset == 'ecoli':\n","        y = preprocessing.LabelEncoder().fit_transform(df.iloc[:,-1])\n","        X = df.iloc[:,1:8].values\n","        \n","    elif dataset == 'glass':\n","        y = df.iloc[:,-1].values\n","        X = df.iloc[:, 1:(df.shape[1]-1)].values\n","        \n","    elif dataset in ['letter-recognition', 'lymphography']:\n","        y = preprocessing.LabelEncoder().fit_transform(df.iloc[:,0])\n","        X = df.iloc[:, 1:(df.shape[1])].values\n","     \n","    elif dataset == 'yeast':\n","        y = preprocessing.LabelEncoder().fit_transform(df.iloc[:,-1])\n","        X = df.iloc[:,1:9].values\n","        \n","    elif dataset == 'mnist':\n","        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n","        y = y.astype('int64') \n","\n","    if scale==True:\n","        scaler = preprocessing.StandardScaler()\n","        X = scaler.fit_transform(X)\n","    \n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Qo21t_dDLd2"},"source":["## Compare the following methods\n","- IPS: Inverse Propensity Score\n","- DM: Direct Method (Reward Prediction)\n","- DR: Doubly Robust\n","- SWITCH: Switch Estimator"]},{"cell_type":"code","metadata":{"id":"fCxR2jahDO47"},"source":["class ComparePolicyEvaluation:\n","    \n","    def __init__(self, B: int = 100, datasets: list = None):\n","        self.B = B\n","        self.datasets = datasets\n","        \n","    def __repr__(self):\n","            \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","\n","    def fit_policies(self, **kwargs) -> pd.DataFrame:\n","        \n","        if self.datasets is None:\n","            self.datasets = ['ecoli', 'glass', 'lymphography', 'yeast', \n","                        'digits', 'breast-cancer', 'wine'] # 'letter-recognition'\n","        dat = list()\n","        true_value = list()\n","        ips = list()\n","        dm = list()\n","        dr = list()\n","        switch = list()\n","        \n","        for s in self.datasets:\n","            for b in range(self.B):\n","                if (b % 10) == 0:\n","                    print(\"Sample: %d - Dataset: %s\" % (b, s))\n","                X, y = get_data(dataset=s)\n","                d = STBT().generate_batch(X, y, max_iter=1000)\n","                dat.append(s)\n","                true_value.append(d.true_target_value_test)\n","                ips.append(PolicyEvaluation(method='ips').evaluate_policy(data = d))\n","                dm.append(PolicyEvaluation(method='dm').evaluate_policy(data = d, **kwargs))\n","                dr.append(PolicyEvaluation(method='dr').evaluate_policy(data = d, **kwargs))\n","                switch.append(PolicyEvaluation(method='switch').evaluate_policy(data = d, **kwargs))\n","           \n","        res = pd.DataFrame.from_dict({'dataset':dat, 'true_value':true_value, 'ips':ips,\n","                                     'dm': dm, 'dr':dr, 'switch': switch})\n","    \n","        # Bias\n","        res['ips_bias'] = res['true_value'].values - res['ips'].values\n","        res['dm_bias'] = res['true_value'].values - res['dm'].values\n","        res['dr_bias'] = res['true_value'].values - res['dr'].values\n","        res['switch_bias'] = res['true_value'].values - res['switch'].values\n","        \n","        # Relative risk\n","        res['ips_rr'] = np.abs((res['true_value'].values - res['ips'].values)/res['true_value'].values)\n","        res['dm_rr'] = np.abs((res['true_value'].values - res['dm'].values)/res['true_value'].values)\n","        res['dr_rr'] = np.abs((res['true_value'].values - res['dr'].values)/res['true_value'].values)\n","        res['switch_rr'] = np.abs((res['true_value'].values - res['switch'].values)/res['true_value'].values)\n","        \n","        self.res = res\n","       \n","        return self\n","    \n","    def get_summary_stats(self):\n","        \n","        res_summary = self.res.groupby(['dataset'], as_index=False).agg({\n","                            'ips_bias': ['mean','std'], \n","                            'dm_bias': ['mean','std'],\n","                            'dr_bias': ['mean','std'],\n","                            'switch_bias': ['mean','std'],\n","                            'ips_rr': ['mean','std'], \n","                            'dm_rr': ['mean','std'],\n","                            'dr_rr': ['mean','std'],\n","                            'switch_rr': ['mean','std']\n","                            })\n","        \n","        self.res_summary = res_summary\n","        return self\n","    \n","    def plot_bias(self):\n","        \n","        res_long = pd.melt(self.res, id_vars=['dataset'], var_name = 'method', value_name = \"bias\",\n","                  value_vars=['ips_bias',  'dm_bias', 'dr_bias', 'switch_bias'])\n","\n","        ax = sns.catplot(x=\"method\", y=\"bias\", col = \"dataset\", kind = \"box\", \n","                          col_wrap=3, data=res_long)\n","        for i in range(len(ax.axes)):\n","            ax_i = ax.axes[i]\n","            ax_i.axhline(0, ls=\"--\")\n","        \n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXkv0xe4DRPP","executionInfo":{"status":"ok","timestamp":1633447795189,"user_tz":-330,"elapsed":289084,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a068cbf1-b9eb-42ca-cc5e-2ebb855992ae"},"source":["cpe = ComparePolicyEvaluation(B=100).fit_policies(max_iter=1000)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample: 0 - Dataset: ecoli\n","Sample: 10 - Dataset: ecoli\n","Sample: 20 - Dataset: ecoli\n","Sample: 30 - Dataset: ecoli\n","Sample: 40 - Dataset: ecoli\n","Sample: 50 - Dataset: ecoli\n","Sample: 60 - Dataset: ecoli\n","Sample: 70 - Dataset: ecoli\n","Sample: 80 - Dataset: ecoli\n","Sample: 90 - Dataset: ecoli\n","Sample: 0 - Dataset: glass\n","Sample: 10 - Dataset: glass\n","Sample: 20 - Dataset: glass\n","Sample: 30 - Dataset: glass\n","Sample: 40 - Dataset: glass\n","Sample: 50 - Dataset: glass\n","Sample: 60 - Dataset: glass\n","Sample: 70 - Dataset: glass\n","Sample: 80 - Dataset: glass\n","Sample: 90 - Dataset: glass\n","Sample: 0 - Dataset: lymphography\n","Sample: 10 - Dataset: lymphography\n","Sample: 20 - Dataset: lymphography\n","Sample: 30 - Dataset: lymphography\n","Sample: 40 - Dataset: lymphography\n","Sample: 50 - Dataset: lymphography\n","Sample: 60 - Dataset: lymphography\n","Sample: 70 - Dataset: lymphography\n","Sample: 80 - Dataset: lymphography\n","Sample: 90 - Dataset: lymphography\n","Sample: 0 - Dataset: yeast\n","Sample: 10 - Dataset: yeast\n","Sample: 20 - Dataset: yeast\n","Sample: 30 - Dataset: yeast\n","Sample: 40 - Dataset: yeast\n","Sample: 50 - Dataset: yeast\n","Sample: 60 - Dataset: yeast\n","Sample: 70 - Dataset: yeast\n","Sample: 80 - Dataset: yeast\n","Sample: 90 - Dataset: yeast\n","Sample: 0 - Dataset: digits\n","Sample: 10 - Dataset: digits\n","Sample: 20 - Dataset: digits\n","Sample: 30 - Dataset: digits\n","Sample: 40 - Dataset: digits\n","Sample: 50 - Dataset: digits\n","Sample: 60 - Dataset: digits\n","Sample: 70 - Dataset: digits\n","Sample: 80 - Dataset: digits\n","Sample: 90 - Dataset: digits\n","Sample: 0 - Dataset: breast-cancer\n","Sample: 10 - Dataset: breast-cancer\n","Sample: 20 - Dataset: breast-cancer\n","Sample: 30 - Dataset: breast-cancer\n","Sample: 40 - Dataset: breast-cancer\n","Sample: 50 - Dataset: breast-cancer\n","Sample: 60 - Dataset: breast-cancer\n","Sample: 70 - Dataset: breast-cancer\n","Sample: 80 - Dataset: breast-cancer\n","Sample: 90 - Dataset: breast-cancer\n","Sample: 0 - Dataset: wine\n","Sample: 10 - Dataset: wine\n","Sample: 20 - Dataset: wine\n","Sample: 30 - Dataset: wine\n","Sample: 40 - Dataset: wine\n","Sample: 50 - Dataset: wine\n","Sample: 60 - Dataset: wine\n","Sample: 70 - Dataset: wine\n","Sample: 80 - Dataset: wine\n","Sample: 90 - Dataset: wine\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"GWxONSzJDaFA","executionInfo":{"status":"ok","timestamp":1633447867092,"user_tz":-330,"elapsed":856,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"395d2f15-cbeb-4a13-b1c4-f6190716771d"},"source":["cpe.get_summary_stats()\n","cpe.res_summary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>dataset</th>\n","      <th colspan=\"2\" halign=\"left\">ips_bias</th>\n","      <th colspan=\"2\" halign=\"left\">dm_bias</th>\n","      <th colspan=\"2\" halign=\"left\">dr_bias</th>\n","      <th colspan=\"2\" halign=\"left\">switch_bias</th>\n","      <th colspan=\"2\" halign=\"left\">ips_rr</th>\n","      <th colspan=\"2\" halign=\"left\">dm_rr</th>\n","      <th colspan=\"2\" halign=\"left\">dr_rr</th>\n","      <th colspan=\"2\" halign=\"left\">switch_rr</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>breast-cancer</td>\n","      <td>0.015439</td>\n","      <td>0.056258</td>\n","      <td>0.031097</td>\n","      <td>0.014548</td>\n","      <td>0.002050</td>\n","      <td>0.009696</td>\n","      <td>0.002050</td>\n","      <td>0.009696</td>\n","      <td>0.051048</td>\n","      <td>0.033579</td>\n","      <td>0.032639</td>\n","      <td>0.015079</td>\n","      <td>0.008363</td>\n","      <td>0.006185</td>\n","      <td>0.008363</td>\n","      <td>0.006185</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>digits</td>\n","      <td>-0.000356</td>\n","      <td>0.099657</td>\n","      <td>0.271003</td>\n","      <td>0.036489</td>\n","      <td>-0.003003</td>\n","      <td>0.045847</td>\n","      <td>-0.003003</td>\n","      <td>0.045847</td>\n","      <td>0.086759</td>\n","      <td>0.063050</td>\n","      <td>0.291985</td>\n","      <td>0.039215</td>\n","      <td>0.039939</td>\n","      <td>0.029041</td>\n","      <td>0.039939</td>\n","      <td>0.029041</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ecoli</td>\n","      <td>0.036131</td>\n","      <td>0.159114</td>\n","      <td>0.221680</td>\n","      <td>0.069068</td>\n","      <td>0.021395</td>\n","      <td>0.082412</td>\n","      <td>0.021395</td>\n","      <td>0.082412</td>\n","      <td>0.168851</td>\n","      <td>0.126703</td>\n","      <td>0.288876</td>\n","      <td>0.088675</td>\n","      <td>0.086244</td>\n","      <td>0.068031</td>\n","      <td>0.086244</td>\n","      <td>0.068031</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>glass</td>\n","      <td>-0.005234</td>\n","      <td>0.135409</td>\n","      <td>0.108039</td>\n","      <td>0.077705</td>\n","      <td>-0.015941</td>\n","      <td>0.102587</td>\n","      <td>-0.015941</td>\n","      <td>0.102587</td>\n","      <td>0.231339</td>\n","      <td>0.168950</td>\n","      <td>0.231582</td>\n","      <td>0.136500</td>\n","      <td>0.177798</td>\n","      <td>0.135564</td>\n","      <td>0.177798</td>\n","      <td>0.135564</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>lymphography</td>\n","      <td>-0.030135</td>\n","      <td>0.166516</td>\n","      <td>0.210184</td>\n","      <td>0.112056</td>\n","      <td>-0.006171</td>\n","      <td>0.097335</td>\n","      <td>-0.006171</td>\n","      <td>0.097335</td>\n","      <td>0.166880</td>\n","      <td>0.141465</td>\n","      <td>0.278812</td>\n","      <td>0.132798</td>\n","      <td>0.100086</td>\n","      <td>0.078494</td>\n","      <td>0.100086</td>\n","      <td>0.078494</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>wine</td>\n","      <td>0.004831</td>\n","      <td>0.121543</td>\n","      <td>0.123857</td>\n","      <td>0.042780</td>\n","      <td>-0.000622</td>\n","      <td>0.038650</td>\n","      <td>-0.000622</td>\n","      <td>0.038650</td>\n","      <td>0.099961</td>\n","      <td>0.082773</td>\n","      <td>0.132158</td>\n","      <td>0.045198</td>\n","      <td>0.031962</td>\n","      <td>0.026401</td>\n","      <td>0.031962</td>\n","      <td>0.026401</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yeast</td>\n","      <td>-0.010755</td>\n","      <td>0.071710</td>\n","      <td>0.080556</td>\n","      <td>0.037969</td>\n","      <td>-0.006330</td>\n","      <td>0.058608</td>\n","      <td>-0.006330</td>\n","      <td>0.058608</td>\n","      <td>0.127633</td>\n","      <td>0.097028</td>\n","      <td>0.178583</td>\n","      <td>0.078501</td>\n","      <td>0.105852</td>\n","      <td>0.077361</td>\n","      <td>0.105852</td>\n","      <td>0.077361</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         dataset  ips_bias            ...     dr_rr switch_rr          \n","                      mean       std  ...       std      mean       std\n","0  breast-cancer  0.015439  0.056258  ...  0.006185  0.008363  0.006185\n","1         digits -0.000356  0.099657  ...  0.029041  0.039939  0.029041\n","2          ecoli  0.036131  0.159114  ...  0.068031  0.086244  0.068031\n","3          glass -0.005234  0.135409  ...  0.135564  0.177798  0.135564\n","4   lymphography -0.030135  0.166516  ...  0.078494  0.100086  0.078494\n","5           wine  0.004831  0.121543  ...  0.026401  0.031962  0.026401\n","6          yeast -0.010755  0.071710  ...  0.077361  0.105852  0.077361\n","\n","[7 rows x 17 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":960},"id":"vwOZOrF7D0cP","executionInfo":{"status":"ok","timestamp":1633447869281,"user_tz":-330,"elapsed":1703,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ffa690f1-8458-4652-dfc1-761c40209a80"},"source":["cpe.plot_bias()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABDAAAAQwCAYAAAATlK4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZhed10n/vdnkmmb0ieaqTw0YJUUtfKrCFkUnxaUZIkiIIviijq47uLDmuh23euHl6yisusD665XqusTKiPqzydg6dZOSRZhUUQkpSWUgmZgA4THTqClpWk7yXx/f8xJmDSTNs3M5JyZeb2u677m3Oec+5zP/W36nXve9/d8T7XWAgAAADBkI30XAAAAAPBQBBgAAADA4AkwAAAAgMETYAAAAACDJ8AAAAAABk+AAQAAAAyeAINVq6peUVU/+RD7PL+qrlri815RVd+zlMdcrKq6u/v52Kr6y77rAVae1dynVtUzqur65TwHsDKthr6vql5TVS9cimOd4vhXVNWty3X8h6uqDlTVWN91sDwEGKx1z0+ypL9wklyRZFABxjGttY+31pbtFxiw5q2pPhWgo+9bBlW1vu8aGB4BBqtKVf10Vf1TVf1tki+bt/7fVtW7quo9VfW6qjq/qr4uyXOTvKqqbqmqJyy0X/f676yqW7v1b+vWrauqV3X776uqH+pO90tJvrE75r9f5Pt5QlXdWFU3VdXfVNWXd+sfVVVv6Op5T/deUlXXdHXeWlU/scDxBpWQA8O2CvvUf9Yd+5buXCf1h1X1tKp6R1XdXFV/V1Vf1q3/yqr6h+61+6rqyqp6RFX9Vfc+bq2qFy2mPmAYVlvfN6/+b66q/znv+daqekO3fHdXx/uq6n93feFbq+pDVfXcbp+XVNUbu/X7q+pn5x1+XVX9bvf63VW1oXvNk6vq77v39oaqemS3fsH+uDvHdVX110neXFUXVNWbq+rdVfXeqnpet98VVfWBqvrjqnp/Vf3lsXbu7Jj3mi+vqpGu5su6149U1dSx56wgrTUPj1XxSPLUJO9Ncn6Si5JMJfnJbtvGefu9MsmObvk1SV44b9up9ntvksu75Uu6ny9N8vJu+dwke5N8SZJnJLn+FDVemOSWUzyuWmD/Nye5slv+miR/3S3/WZKf6JbXJbl43vt/RJILkrwvyVd3+9zd/bwiya19/7fy8PAY/mOV9qm3Jnl6t/xLx/rD+efo3uv6bvlZSV7XLV+b5MXd8jlJNiT5l0l+d97xL+77v5uHh8fiHqu073tNkhcmqSQfSHJZt/5Pknx7t9ySbO+W35Bkd5LRJF+V5JZu/UuSfCLJxq4PvDXJlsx9vjyS5Mndfn+e5Hu75X1J/nm3/PNJfq1bPlV//JIkB5Nc2j1fn+Sibnms++9R3Tlbkq/vtv3+vP9OB+a1+Y8meXW3/LP5wufnben6d4+V9TAsh9XkG5O8obV2T5JU1XXztj2pql6Z5JLM/XH/plMc41T7vT3Ja6rqz5O8vlu3LcnV9YVrCi9OcmWS+09VYGvtriRPPp03U1UXJPm6JH9RVcdWn9v9/OYk398d82iSO6vqGzL3/j/fvf71mWuTm0/nfAAPsNr61EuSXNhae0e36k+SPGeBXS9OMlFVV2buw/Fot/4dSX66qjYleX1rbX9VvTfJr1bVL2fuD42/OZ1agEFbVX3fA17Xquq1Sb63qv4gydPTfZ7szndjt/zeJPe11ma6fu6KeYfZ01o7lBz/rPkNSf5nkv/bWrul2+emJFdU1cWZC2r+T7d+InOfax+qP97TWvtMt1xJ/ktVfVOS2SSXJ3lUt+2jrbW3d8t/lGRnkv/aPT/WvjcleUG3/PtJ3pjk15L86yR/8KANxiAJMFgrXpPk+a2191TVSzKXap/2fq21H66qr0nybUluqqqnZq5D3dFaO+GXV1Wd6tipqguTnOoD7ve01m6b93wkyR2ttYf9Cwpgmb0mK69PPV2/kOQtrbXvqKorkry1q/lPquqdXc03VNUPtdb+uqqekuRbk7yyqt7cWvv5MzgnsDK8Jiu/7/uDJP8ryb1J/qK1dqRbP9Pa3NCEzAUF93U1z9aJc1G0nOjY8/vmrTuauREaZ+rz85ZfnOSyJE/tApUDSc57iFrm13M03d+8rbWPVtWnquqbkzytOzYrjDkwWE3eluT5VbWh69i/fd62C5N8oqpGc2JndVe37UH3q6ontNbe2Vr7mSS3J3lc5tL0H+n2TVU9saoescAxj2ut3dVae/IpHrc9YN/PJfm/VfWd3fGrqr6q2/zmJD/SrV/XJdx/073/87s6viOn/uUG8FBWW596R5K7uj8ekuS7T/G+L07ysW75JfNq/tIkH2qt7crcN3hXV9Vjk9zTWvujJK9K8pRTHBNYOVZV37fAaz+e5ONJXp4zG4Gwtaourbk5Lp6fuVElpzrXnUk+W1Xf2K36viT/52H0x8lcn/zpLrx4ZpIvnrft8VX19G75e5L87WnU/+rMjdb4i24UMyuMAINVo7X27szNDfGeJJNJ3jVv839K8s7MdbIfmLf+T5P8x5qbrO0JD7Lfq7pJgG5N8nfdOV6d5LYk7+7W/3bmEt59SY7W3ARNi5106cVJfrCq3pO5OS2e163/8STP7Ib13ZS56x3fnbnE/x+69/Dq1prLR4Azskr71B9M8rtVdUvm5gu6c4F9fiXJL1bVzTlxpOp3Jbm1e+2Tkvxhkv8nyT906342c9e6AyvYKu37HuiPM3f5xfvP4LX/kOR1mavvda21vQ+x/3jm3ve+zF32cmyU2un0x8dq3dJ95v3+nNie/5jk31XV+5M8Mslvnkb912Xush6Xj6xQ9YWRQgAAq1dVXdBau7tbflmSx7TWfrznsgDOqqr69SQ3t9Z+72G+7iVJtrTWfmwJalhUf9xd4nd9a+1JD/O8W5L899baNz7kzgySOTAAgLXi26rqpzL3+efDmXeJCMBaUFU3ZW6Oif/QcylnvT/ugpIfibkvVjQjMAAAAIDBMwcGAAAAMHgCDAAAAGDwVt0cGM9+9rPbjTfe2HcZAENVZ/IifSvAKelXAZbegn3rqhuBMT093XcJAKuOvhVgaelXAR6+VRdgAAAAAKuPAAMAAAAYPAEGAAAAMHgCDAAAAGDwBBgAAADA4AkwAAAAgMETYAAAAACDJ8AAAAAABk+AAQAAnGB6ejo7duzIoUOH+i4F4DgBBgAAcIKJiYns27cvExMTfZcCcJwAAwAAOG56ejqTk5NprWVyctIoDGAwBBgAAMBxExMTaa0lSWZnZ43CAAZDgAEAABy3Z8+ezMzMJElmZmaye/funisCmCPAAAAAjtu6dWtGR0eTJKOjo9m2bVvPFQHMEWAAAADHjY+Pp6qSJCMjIxkfH++5IoA5AgwAAOC4sbGxbN++PVWV7du3Z+PGjX2XBJAkWd93AQAAwLCMj4/nwIEDRl8AgyLAAAAATjA2NpZrr7227zIATuASEgAAAGDwBBgAAADA4AkwAAAAgMETYAAAAACDJ8AAAAAABk+AAQAAAAyeAAMAAAAYPAEGAAAAMHgCDAAAAGDwBBgAAADA4AkwzrLp6ens2LEjhw4d6rsUAAAAWDEEGGfZxMRE9u3bl4mJib5LAQAAgBVDgHEWTU9PZ3JyMq21TE5OGoUBAAAAp2l93wWsJRMTE2mtJUlmZ2czMTGRa665pueqAACAhezatStTU1Nn/PqDBw8mSTZt2rSoOjZv3pydO3cu6hiwGhiBcRbt2bMnMzMzSZKZmZns3r2754oAAIDlcvjw4Rw+fLjvMmDVMALjLNq6dWtuuOGGzMzMZHR0NNu2beu7JAAA4BQWO+rh2Ot37dq1FOXAmmcExlk0Pj6eqkqSjIyMZHx8vOeKAAAAYGUQYJxFY2Nj2b59e6oq27dvz8aNG/suCQAAAFaEXgOMqnp2Vf1jVU1V1cseZL9/WVWtqraczfqWw/j4eK6++mqjLwAAAOBh6G0OjKpal+Q3kmxNcjDJu6rqutbabQ/Y78IkP57knWe/yqU3NjaWa6+9tu8yAAAAYEXpcwTG05JMtdY+1Fq7P8mfJnneAvv9QpJfTnLv2SwOAAAAGI4+A4zLk3x03vOD3brjquopSR7XWvurBztQVb20qvZW1d7bb7996SsFWIP0rQBLS78KsDiDncSzqkaS/Lck/+Gh9m2t/U5rbUtrbctll122/MUBrAH6VoClpV8FWJw+A4yPJXncvOebunXHXJjkSUneWlUHknxtkutWw0SeAAAAwMPTZ4DxriRXVtWXVNU5Sb47yXXHNrbW7mytjbXWrmitXZHk75M8t7W2t59yAQAAgL70FmC01o4k+bEkb0ry/iR/3lp7X1X9fFU9t6+6AAAAgOHp7TaqSdJauyHJDQ9Y9zOn2PcZZ6Mmzo5du3ZlampqUcc4ePBgkmTTpk1nfIzNmzdn586di6oDAACA5TfYSTzhoRw+fDiHDx/uuwwAgFVneno6O3bsyKFDh/ouBeC4XkdgsHYtxaiHY8fYtWvXoo8FAMAXTExMZN++fZmYmMg111zTdzkASYzAAAAA5pmens7k5GRaa5mcnDQKAxgMIzAepsXO3bAU8zYk5m4AAGB5TExMpLWWJJmdnTUKAxgMIzDOMvM2AAAwZHv27MnMzEySZGZmJrt37+65IoA5RmA8TIsd9WDeBgAAhmzr1q254YYbMjMzk9HR0Wzbtq3vkgCSGIEBAADMMz4+nqpKkoyMjGR8fLznigDmCDAAAIDjxsbG8sxnPjNJ8sxnPjMbN27suSKAOQIMACDJ3J0HduzY4Y4DAMAgCTAAgCRzdx7Yt29fJiYm+i4F6NH09HTe8pa3JEne8pa3CDWBwRBgAACZnp7O5ORkWmuZnJz0BwusYQvdRhVgCAQYAIA/WIDj3EYVGCoBBgDgDxbguK1bt2Z0dDRJ3EYVGBQBBgDgDxbgOLdRBYZKgAEA+IMFOG5sbCzbt29PVWX79u1uowoMhgADAPAHC3CC8fHxXH311cJMYFDW910AADAM4+PjOXDggD9YgIyNjeXaa6/tuwyAEwgwAIAk/mABAIbNJSQAAADA4AkwAAAAgMETYAAAAACDZw4MAABgVdq1a1empqZ6O//+/fuTJDt37uythiTZvHlz7zXAUhBgAAAAq9LU1FT+6dZ35/EXHO3l/OfMzA14v/fAu3o5f5J85O51vZ0blpoAAwAAWLUef8HRvHzL3X2X0ZtX7r2g7xJgyZgDAwAAABg8IzAAYJVY7LXeBw8eTJJs2rTpjI/hOmsYhiH0B4k+AVhaAgwAIEly+PDhvksABkJ/AAyRAAMAVonFfst57PW7du1ainKAHukPgNVIgMEZ6fuWVMkwbktlWCQAAMDZIcDgjPR9S6qk/9tSuSUVAADA2SPA4Iy5JZVbUgEAAJwtAgwAejeE2fJdEgYAMGwCDABWPLPlAwCsfgIMAHpntnwAAB7KSN8FAP2anp7Ojh07cujQob5LWdG0IwAALC8BBqxxExMT2bdvXyYmJvouZUXTjgAAsLwEGLCGTU9PZ3JyMq21TE5OGj1whrQjAAAsP3NgwBo2MTGR1lqSZHZ2NhMTE7nmmmt6rmrl0Y4AAKe22LuNJe44lmjHxAgMWNP27NmTmZmZJMnMzEx2797dc0Urk3YEAFhehw8fdtexJbDS29EIDFjDtm7dmhtuuCEzMzMZHR3Ntm3b+i5pRdKOAACnthTf1rvjmHZMjMCANW18fDxVlSQZGRnJ+Ph4zxWtTNoRAACWnwAD1rCxsbFs3749VZXt27dn48aNfZe0ImlHAABYfi4hgTVufHw8Bw4cMGpgkbQjAAAsLwEGrHFjY2O59tpr+y5jxdOOAACwvAQYnJGDBw/m83etyyv3XtB3Kb358F3r8ojuNkQAAAyPz6w+s7K69DoHRlU9u6r+saqmquplC2y/pqpuq6p9VfXmqvriPuoEAAAA+tXbCIyqWpfkN5JsTXIwybuq6rrW2m3zdrs5yZbW2j1V9SNJfiXJi85+tTzQpk2bcu+RT+TlW+7uu5TevHLvBTlv06Zea9i1a1empqYWdYyDXSK/aRHvZfPmzUtyW6e+aEcAWJ18Zh3GZ1ZYKn2OwHhakqnW2odaa/cn+dMkz5u/Q2vtLa21e7qnf5/E/3mwxA4fPpzDhw/3XcaKpx0BAGB59TkHxuVJPjrv+cEkX/Mg+/9gksmFNlTVS5O8NEke//jHL1V9MHhL8W39sWPs2rVr0cdaqbTjwvStAEtLvwqwOL3OgXG6qup7k2xJ8qqFtrfWfqe1tqW1tuWyyy47u8UBrFL6VoClpV8FWJw+R2B8LMnj5j3f1K07QVU9K8lPJ/nnrbX7zlJtAAAAwID0OQLjXUmurKovqapzknx3kuvm71BVX53kt5M8t7X26R5qBAAAAAagtxEYrbUjVfVjSd6UZF2S32+tva+qfj7J3tbadZm7ZOSCJH9RVUnykdbac/uqGQBY/RZ7ZyJ3JZozhHZMVkdbAjCnz0tI0lq7IckND1j3M/OWn3XWiwIAWAR3JFoa2hGAB+o1wAAAGJrFflu/Gu9KdCa0IwBLTYDBGfvI3evyyr0X9Hb+T90zN4XLo86f7eX8H7l7XZ7Yy5kBAADWHgEGZ2Tz5s19l5D79+9Pkpx3xZW9nP+JGUY7AAAArAUCDM7IECbDMrQUAABg7ejzNqoAAAAAp8UIDAAYgMXecnIp7O8uzet7lJ3bXgIACxFgAMAATE1N5Z9ufXcef8HR3mo4Z2ZuYOa9B97VWw0fuXtdb+cGAIZNgAEAA/H4C47m5Vvu7ruMXvV5dysAYNjMgQEAAAAMngADAAAAGLw1dwlJ35OkmSANAAAAHr41F2BMTU3l5vfeltnzL+3l/HV/S5Lc9MFP9nL+JBm55zO9nRsAAADOxJoLMJJk9vxLc+9Vz+m7jN6cd9v1fZcAAABnxUfuXtfbBMGfumfuiv1HnT/by/mTuff/xN7ODktrTQYYAADA6rd58+Zez39/d/n4eVdc2VsNT0z/7QBLRYABAACsSn3P+Xbs/Lt27eq1Dlgt3IUEAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBcxcSABiAgwcP5vN3rcsr917Qdym9+vBd6/KIgwf7LgMAGCAjMAAAAIDBMwIDAAZg06ZNuffIJ/LyLXf3XUqvXrn3gpy3aVPfZQAAA2QEBgAAADB4AgwAAABg8FxCAsCi7Nq1K1NTU73WsH///iTJzp07e61j8+bNvdcAALBaCTAAWJSpqanc/N7bMnv+pb3VUPe3JMlNH/xkbzWM3POZ3s4NALAWCDCgR765nrPYb62145w+v/2fPf/S3HvVc3o591Ccd9v1fZcAALCqCTCgR1NTU7n5fTcnl/RYxOzcj5s/dnM/579j8YeYmprKB265JY9e/KHO2LEJhe645ZZezt/fuAMAADg7BBjQt0uS2WfM9l1Fb0beujRzCT86yQ+mluRYK9HvpfVdAgAALCt3IQEAAAAGzwgMAGDVMCfOFyxmXhzt+AXuLgT6hGPM27Y0FtOOAgwAYNUwt1BnkfMLmVtojvmFYI6+NeZtWyKL7VcFGPRiKdLHpUgPfasCsAqt8bmFkqWZX2itzy2U9Du/UN/f1A7hW9rEZ7VBWeN9q3nblsZi+1UBBivWhg0b+i4BYEl95O51eeXeC3o7/6fumftw9qjz+/uA+pG71+WJvZ0dhmNqaio3v/e2zJ5/aS/nr/vn/si46YP9jUMZueczvZ0bGKY1F2AcPHgwI/fcmfNuu77vUnozcs+hHDx4pNcaJOkAJ9q8eXPfJeT+7hvX8664srcanphhtAUMwez5l+beq57Tdxm9Wcuf14GFrbkAAwCGaAjB7rEadu3a1XMlAAAnW3MBxqZNm/Kp+9av+TR706Y+p44BAACAh2dpZiIBAAAAWEYCDAAAAGDwBBgAAADA4K25OTBgSA4ePJjcuXT3lV6R7kgOtoOLOsTBgwdzVxZ/X+mV7BNJ7j64uHYEAIAhW8N/NQEAAAArhREY0KNNmzbl9ro9s8+Y7buU3oy8dSSbLt+0qGNs2rQpd0xP5wdTS1TVyvN7ablk0+LaEQAAhswIDAAAAGDweg0wqurZVfWPVTVVVS9bYPu5VfVn3fZ3VtUVZ79KAAAAoG+9BRhVtS7JbyTZnuSqJP+qqq56wG4/mOSzrbXNSf57kl8+u1UCAAAAQ3Bac2BU1a8keWWSw0luTHJ1kn/fWvujRZz7aUmmWmsf6s7xp0mel+S2efs8L8kruuW/TPLrVVWttVPeauBDt38+L/rtd5yw7jlXPybf9/Qrcvj+o3n7uf8sd33J/Zkduej49nPbfTmv3ZfZVO4aufCkY57X7s257f4czUjuHrngpO0bZg/nnMw85PYjWZfPjzzipO3nz96T0RzJTNbnnpHzT9r+iNnPZ32O5v6M5vDIhpO2XzB7d9Zl9iG331fn5N46L3d9yb/I288953g7/eb3PjWXPuKc/MXej+Yvbzr5Lgav+YGnZcM56/LadxzI9fs+cdL2P/uhpydJfudtH8yb3//pE7adN7ouE//6aUmSXW/en7dPTZ+w/ZHnn5Pf+r6nJkl++cYP5N0f/uwJ2x9z8Xn5te/+6iTJz/2v9+W2j3/uhO1fetkj8osvuDpJ8lOv35cP3f75E7Zf9diL8rPf/pVJkp/405vziTvvPWH7U774kfl/n/3lSZIffu1N+ew995+w/es3j2Xnt1yZJBn//X/IvTNHT9j+LV/xRXnpNz0hSU76d5ec+G/vJX/wDydtv2/dY5PcnKNHN+Qzn3nBSdsf8Yh35/zz358jRy7MZz/73JO2X3DBO7Nhw1RmZi7NHXdsP2n7hRe+PeeddyD33/9FufPOrSdtv+iit+bccz+W++67PJ/73DNO2n7xxXtyzjmfzr33XpG77vr6k7ZfcslkRkc/k8OHN+fuu7/mpO2PfOR1Wb/+rtxzz1fk859/yknbL7309RnJffnIuscu2H6n+29vav0V+dhXfkV+cd620dkj+cn3/2WS5I2bnp7bLv7iE157wZHD2fGPb0yS/PnjvykfvPCxJ9Z+/1354f1/lST54yu+OR95xBedsP1Rhz+bf/2hNyVJfv9L/0U+teGRJ2x//Oc/nRcf+OskyW9d+W357Dkn9i1PuOvj+a6PvC1Jcu2XPS93rz/x/92r7vxwnndwrk3+61e8MDMjJ3bXX/XZD+ZbP/6uJMkvfuV35xNJ1p97wfF2PNW/vWNt9nA9WN/60YMfy9HZkax//40nbB9psxnJbFoqR2vdScdc7u3r2tFU2kNun81IZuvkPP/hbj862/KuTx5Z0X3r1Ln/LMlcf7pS+9aPfPJIRu56REbe+vm0NpIjM2MnvX5k3d1Zt+6etLYuR2Y2nrR93bq7MrLucNrs+hw5cunJ29d/LiMj92Z2djRHjzxyge13ZGTk/szOnpOjRy5ZYPtnMzIyk9nZ83L0yEUnbV+//jOpkSOZPbohR4+e/Llk/eihVB3N0aPnZ/boyZ871o9OJ3fO5v11xxn3rQcPHsz0ORfmZx/QN1VaHnfP7UmS6XMuyj3rzzvxvbWjufzwoSTJ7edenMPrzj2xtnYkjz38mSTJp869JPetO+eE7efMzuTR9879e/3keY/M/SOjJ2w/9+j9edR9dyRJPr7h0hypE/vGDUfvy2X33Zkk+diGjSf9v3/+kXszdv/cv/ePnn9Z2gPmTrrgyOFcev9dSZKPnP9FuT9Jm/f/9UL/9pajX/WZdfV8Zl0N/WriM6vPrMP5zHq6IzC2tdY+l+Q5SQ4k2ZzkP57ma0/l8iQfnff8YLduwX1aa0eS3JnkpE8aVfXSqtpbVXtnZmYWWRYAib4VYKnpVwEWpx5kMMMXdqq6tbX2pKp6dZK/bK3dWFXvaa191RmfuOqFSZ7dWvs33fPvS/I1rbUfm3/ebp+D3fMPdvtML3TMJNmyZUvbu3fvKc+7c+fO3PTBT+beq55zpqWveOfddn2e+oRHZ9euXX2Xsubt3LkzN3/s5jV/F5KvvvyrF/XvcefOnbnjllvcheTJTz6ddjyjRnqwvlW/Omc19K07d+5MkhX/HtZ6v5osvm/Vr845zb51yfvVRN+a6FeH5AUveEFuv/P25ORBZWvHHcllF1+W17/+9Wd8iBe84AW5a3o6j1nCslaaTyS5cGzsdNpxwb71dEdgXF9VH0jy1CRvrqrLktz7EK95KB9L8rh5zzd16xbcp6rWJ7k4yaFFnhcAAABYYU5rDozW2su6eTDubK0drarPZ25+isV4V5Irq+pLMhdUfHeS73nAPtclGU/yjiQvTPLXDzb/BQAAAEtr06ZNub1uX9Oj20beOpJNl29a1DE2bdqUO6an1/Tott9LyyWbzrwdTyvA6Dw2ybOqav5sTX94pidurR2pqh9L8qYk65L8fmvtfVX180n2ttauS/J7SV5bVVNJPpO5kAMAAABYY073LiQ/m+QZmbvd6Q2Zu/Xp32YRAUaStNZu6I43f93PzFu+N8l3LuYcAAAAwMp3unNgvDDJtyT5ZGvtB5J8VebmowAAAABYdqd7Ccnh1tpsVR2pqouSfDonTsAJnKk75q6p683d3c+Tbwd/dtyRk2+gfAY+mblr6vpybHbhk+7zfJZ8Mmt7YnAAAFa/0w0w9lbVJUl+N8lNmfuT5x3LVhWsEZs3b+67hOzfvz9JcuXlV/ZTwOWLb4chtOPtXTtecmU/7XhJhtEOAACwXE73LiQ/2i3+VlXdmOSi1tq+5SsL1oZj9wYfQg0r+f7k2hEAAFa/Bw0wqurLW2sfqKqnLLDtKa21dy9faQAAsDYdPHgwI/fcmfNuu77vUnozcs+hHDx4pNcadu3alampqTN+/bGRrov9smXz5s2D+MIG+vZQIzCuSfLSJL+anHBxeXXPv3mZ6lpWI/d8prdfBnXv55Ik7byLejl/Mvf+k0f3dn4AAFgLNmzY0HcJsKo8aIDRWntpt/itSX40yTdkLrj4myS/ubylLY++rxHfv/+uJMmVT+gzQHh07+0AAMCpbdq0KZ+6b33uveo5fZfSm/Nuuz6bNvX7pZtRDzAspwEIRx8AACAASURBVDuJ50SSzyU5dnH39yT5wyTftRxFLae+OyHXyQMAAMDDd7oBxpNaa1fNe/6WqrptOQoCAAAAeKCR09zv3VX1tceeVNXXJNm7PCUBAAAAnOih7kLy3szNeTGa5O+q6iPd8y9O8oHlLw8AAADgoS8hWbuzBgEAADDnjmTkrac7gH8Z3N39vKCn89+R5PLFH+aTSX7vhBt8nl2Hup8bezr/J5NcsojXP9RdSD68iGMDAACwwg3hDob79+9Pklx5+ZX9FHD54tthCO14e9eOl1zZTzteksW1w+lO4gkAAMAa1PedHOfXsJLv5qgdF6/HMUAAAAAAp0eAAQAAAAyeAAMAAAAYPAEGAAAAMHgm8QSAVWLXrl2Zmpo649cfm+F9MZOMbd68uf9Jytb6rf6SJbnd31q/1V+y+Nv9AbC0BBgAQJJkw4YNfZewaEO4RV3vt/pLFn27vyG0Y9+3+ksWf7s/AJaWAAOARRu55zM577brezt/3fu5JEk776Leahi55zNJHt3b+ZNh3J6tb0Nog5V+i7pEOwIwTAIMABZlCN9O7t9/V5Lkyif0GSA8ehBtAQCwWgkwAFgU39QCAHA2uAsJAAAAMHhGYAAAwAD1Ob+QuYWAIRJgAADAwPQ9p465hZbG9PR0fu7nfi6veMUrsnFjnzcFhtVBgAEAAAPT9/xC5hZaGhMTE9m3b18mJiZyzTXX9F0OrHjmwAAAAFhi09PTmZycTGstk5OTOXToUN8lwYonwAAAAFhiExMTaa0lSWZnZzMxMdFzRbDyCTAAAACW2J49ezIzM5MkmZmZye7du3uuCFY+AQYAAMAS27p1a0ZHR5Mko6Oj2bZtW88VwconwAAAAFhi4+PjqaokycjISMbHx3uuCFY+AQYAAMASGxsby/bt21NV2b59u9uowhJwG1UAAIBlMD4+ngMHDhh9AUtEgAEAALAMxsbGcu211/ZdBqwaLiEBAAAABs8IDFjBdu3alampqUUdY//+/UmSnTt3nvExNm/evKjX9007AgDA8AkwYI3bsGFD3yWsCtoRAACWlwADVjDf1i8N7QgAAMNnDgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMXi8BRlVdWlV7qmp/9/ORC+zz5Kp6R1W9r6r2VdWL+qgVAAAA6F9fIzBeluTNrbUrk7y5e/5A9yT5/tbaVyZ5dpJfq6pLzmKNAAAAwED0FWA8L8lEtzyR5PkP3KG19k+ttf3d8seTfDrJZWetQgAAAGAw+gowHtVa+0S3/Mkkj3qwnavqaUnOSfLBU2x/aVXtraq9t99++9JWCqvc9PR0duzYkUOHDvVdyoq2GttR3wqwtPSrAIuzbAFGVf3vqrp1gcfz5u/XWmtJ2oMc5zFJXpvkB1prswvt01r7ndbaltbalssuM0gDHo6JiYns27cvExMTD70zp7Qa21HfCrC09KsAi7NsAUZr7VmttSct8Hhjkk91wcSxgOLTCx2jqi5K8ldJfrq19vfLVSusVdPT05mcnExrLZOTk6tq9MDZpB0BAGD59XUJyXVJxrvl8SRvfOAOVXVOkjck+cPW2l+exdpgzZiYmMjcIKhkdnZ2VY0eOJu0IwAALL++AoxfSrK1qvYneVb3PFW1pape3e3zXUm+KclLquqW7vHkfsqF1WnPnj2ZmZlJkszMzGT37t09V7QyaUcAAFh+vQQYrbVDrbVvaa1d2V1q8plu/d7W2r/plv+otTbaWnvyvMctfdQLq9XWrVszOjqaJBkdHc22bdt6rmhl0o4AALD8+hqBAQzA+Ph4qipJMjIykvHx8Yd4BQvRjgAAsPwEGLCGjY2NZfv27amqbN++PRs3buy7pBVJOwIAwPJb33cBQL/Gx8dz4MABowYWSTsCAMDyEmDAGjc2NpZrr7227zJWPO0IAADLyyUkAAAAwOAZgQEAAMCy2bVrV6amphZ1jP379ydJdu7cecbH2Lx586Je3zftKMAAAABg4DZs2NB3CavCSm9HAQYAAADLZiWPehgS7SjAAAA4wWKH6K704blLZQjtmKyOtgRgjgADAGAJrfThuUOhHQF4IAEGAMA8vq1fGtoRgKXmNqoAAADA4AkwAAAAgMETYAAAAACDJ8AAAAAABk+AAQAAAAyeAAMAAAAYPAEGAAAAMHjr+y5gpdm1a1empqbO+PX79+9Psvh7o2/evNn91QEAAFgzBBhn2YYNG/ouAQAAAFYcAcbDZNQDwNIbwug2I9uA1WQI/WqibwWWlgADgBXP6DaApaVfBYZIgAFA73w7B7C09KvAauQuJAAAAMDgCTAAAACAwRNgAAAAAIMnwAAAAAAGT4ABAADAoE1PT2fHjh05dOhQ36WsaCu9HQUYAAAADNrExET27duXiYmJvktZ0VZ6OwowAAAAGKzp6elMTk6mtZbJyckVO3qgb6uhHQUYAAAADNbExERaa0mS2dnZFTt6oG+roR0FGAAAAAzWnj17MjMzkySZmZnJ7t27e65oZVoN7SjAAAAAYLC2bt2a0dHRJMno6Gi2bdvWc0Ur02poRwEGAAAAgzU+Pp6qSpKMjIxkfHy854pWptXQjgIMAAAABmtsbCzbt29PVWX79u3ZuHFj3yWtSKuhHdf3XQAAAAA8mPHx8Rw4cGBFjhoYkpXejgIMAAAABm1sbCzXXntt32WseCu9HV1CAgAAAAyeAAMAAAAYPAEGAABwgunp6ezYsSOHDh3quxSA4wQYAADACSYmJrJv375MTEz0XQrAcQIMAADguOnp6UxOTqa1lsnJSaMwgMEQYAAAAMdNTEyktZYkmZ2dNQoDGAwBBgAAcNyePXsyMzOTJJmZmcnu3bt7rghgjgADAAA4buvWrRkdHU2SjI6OZtu2bT1XBDCnlwCjqi6tqj1Vtb/7+cgH2feiqjpYVb9+NmsEAIC1aHx8PFWVJBkZGcn4+HjPFQHM6WsExsuSvLm1dmWSN3fPT+UXkrztrFR1FrglFQAAQzY2Npbt27enqrJ9+/Zs3Lix75IAkvQXYDwvybHZgCaSPH+hnarqqUkelWTVXHjnllQAAAzd+Ph4rr76aqMvgEHpK8B4VGvtE93yJzMXUpygqkaS/GqSn3yog1XVS6tqb1Xtvf3225e20iXkllTASrJS+laAlWIl9atjY2O59tprjb4ABmXZAoyq+t9VdesCj+fN36/N3aOpLXCIH01yQ2vt4EOdq7X2O621La21LZdddtkSvYOl55ZUwEqyUvpWgJVCvwqwOMsWYLTWntVae9ICjzcm+VRVPSZJup+fXuAQT0/yY1V1IMl/TfL9VfVLy1Xv2eCWVAAArATmbQOGqK9LSK5LcuyCuvEkb3zgDq21F7fWHt9auyJzl5H8YWvtwSb7HDy3pAIAYCUwbxswRH0FGL+UZGtV7U/yrO55qmpLVb26p5qWnVtSAQAwdOZtA4aqlwCjtXaotfYtrbUru0tNPtOt39ta+zcL7P+a1tqPnf1Kl5ZbUgEAMHTmbQOGqq8RGGuWW1IBADBk5m0DhkqAcZa5JRUAAENm3jZgqAQYAADAceZtA4ZKgAEAABxn3jZgqNb3XQAAADAs4+PjOXDggNEXwKAIMAAAgBMcm7cNYEhcQgIAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAnmJ6ezo4dO3Lo0KG+SwE4ToABAACcYGJiIvv27cvExETfpQAcJ8AAAACOm56ezuTkZFprmZycNAoDGAwBBgAAcNzExERaa0mS2dlZozCAwRBgAAAAx+3ZsyczMzNJkpmZmezevbvnigDmCDAAAIDjtm7dmtHR0STJ6Ohotm3b1nNFAHMEGAAAwHHj4+OpqiTJyMhIxsfHe64IYI4AAwAAOG5sbCzbt29PVWX79u3ZuHFj3yUBJEnW910AAAAwLOPj4zlw4IDRF8CgCDAAAIATjI2N5dprr+27DIATuIQEAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMXrXW+q5hSVXV7Uk+3HcdD2EsyXTfRawS2nJpaMelsRLacbq19uyH+yJ965qiHZeGdlwaK6Ed9as8FO24dLTl0lgJ7bhg37rqAoyVoKr2tta29F3HaqAtl4Z2XBrasV/af2lox6WhHZeGduyX9l8a2nHpaMulsZLb0SUkAAAAwOAJMAAAAIDBE2D043f6LmAV0ZZLQzsuDe3YL+2/NLTj0tCOS0M79kv7Lw3tuHS05dJYse1oDgwAAABg8IzAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAYNWpqldU1U8+xD7Pr6qrlvi8V1TV9yzlMZdDVT25qr617zqAlWO19avdcW/tlrdU1a7TeM3fLWdNwLCthn6wqt5aVVuW4linca5LqupHz8a5WFsEGKxVz0+ypL9gklyRZCV8qH1yEgEGsNRWZL/aWtvbWtt5Gvt93dmqCVixVmQ/OF9VrV+iQ12SZNABRlWt67sGHj4BBqtCVf10Vf1TVf1tki+bt/7fVtW7quo9VfW6qjq/qr4uyXOTvKqqbqmqJyy0X/f676yqW7v1b+vWrauqV3X776uqH+pO90tJvrE75r9fxHt5QlW9e97zK489r6qnVtX/qaqbqupNVfWYU73PheqvqnOS/HySF3V1vuhM6wRWt9XUr3bneGp3zvck+Xfz1j+jqq7vli+rqj1V9b6qenVVfbiqxrptdy9UU1V9ZVX9Q/d8X1VduZg6geFYbf1g5/u6Y91aVU/rzv2KqnptVb09yWu7vvB1XS3vqqqv7/Z7WlW9o6purqq/q6ov69Yv1A/+UpIndOtetUDbPqqq3nCsX+7aL1X1P7vPue+rqpfO2//uqvrP3b5/X1WPeojjfO+8mn67urCiO86vdr8Lnr4E7cnZ1lrz8FjRjyRPTfLeJOcnuSjJVJKf7LZtnLffK5Ps6JZfk+SF87adar/3Jrm8W76k+/nSJC/vls9NsjfJlyR5RpLrT1HjhUluOcXjqgX2f0uSJ3fL/yXJjiSjSf4uyWXd+hcl+f0zqP8lSX697/9uHh4ew32s0n51X5Jv6pZfleTWbvn4OZL8epKf6pafnaQlGeue3/3A/bvn1yZ5cbd8TpINff/38/DwWPxjlfaDb03yu93yN83rB1+R5KZj/VeSP0nyDd3y45O8v1u+KMn6bvlZSV7XLZ/UD2Zu5MitD9K+f5bkJ7rldUku7pYv7X5uSHLrsTbs+uNv75Z/ZV5bnXScJF+R5H8lGe3W/48k3z/vON/V978vjzN/LNUQIejTNyZ5Q2vtniSpquvmbXtSVb0yc8PYLkjyplMc41T7vT3Ja6rqz5O8vlu3LcnVVfXC7vnFSa5Mcv+pCmyt3ZW5SzdO16uT/EBVXZO5oOJpmUv+n5RkT1Ulc530J86gfoCHsqr61aq6JHN/JLytW/XaJNsX2PUbknxHd/wbq+qzp3H4dyT56aralOT1rbX9p1MTMHirqh+c5//rXvu2qrqo6x+T5LrW2uFu+VlJruo+bybJRVV1QVfTRDfComXuy7VkgX5w3mtP5ZuTfH9Xy9Ekd3brd1bVd3TLj8tcGxzKXDtc362/KcnWUx2nqr4vcwHUu7o6NiT5dLf/0SSve6jiGC4BBqvda5I8v7X2nqp6SeZS7NPer7X2w1X1NUm+LclNVfXUJJW5BP2EX1ZVdapjp6ouTPI3p9j8Pa212x6w7nVJfjbJXye5qbV2qKoem+R9rbWFhrs9nPoBFuM1WZn96rJorf1JVb0zc+/nhqr6odbaX5+NcwO9eU1Wbj/YTvH88/PWjST52tbavQ84368neUtr7Tuq6orMjehYsB9M8qEHvPY/d9vTWlswdOne67OSPL21dk9VvTXJed3mmdbasVqP5sH/jq0kE621n1pg271d0MEKZQ4MVoO3JXl+VW3oOvJvn7ftwiSfqKrRJC+et/6ubtuD7ldVT2itvbO19jNJbs9cEvymJD/S7ZuqemJVPWKBYx7XWrurtfbkUzxO+uXS/cJ4U5LfTPIH3ep/THJZVT29O+9oVX3lGdR/yjoBOquqX22t3ZHkjqr6hm7Vi08+YpK5b0W/q6thW5JHLrDPCTVV1Zcm+VBrbVeSNya5+hTHBlaWVdUPzvOi7vjfkOTO1tqdC+yzO3OXLx+r91jgcHGSj3XLL5m3faF+8IS6W2s/fay2btWbk/xI9/p1VXVxd/zPduHFlyf52lO8h/kWOs6bk7ywqr6oW39pVX3xaRyLFUCAwYrXWnt35q5/e0+SySTvmrf5PyV5Z+Y+lH5g3vo/TfIfa24Soic8yH6vqqr31tzt9v6uO8erk9yW5N3d+t/OXAq8L8nRbgKhpZhk6Y+TzGbul0haa/cneWGSX+4mHrolybFZ8R9O/W/J3LBAk3gCC1ql/eoPJPmNqrolc9/OLeTnkmzravjOJJ/M3Ifw+R5Y03clubU77pOS/OEi6wQGYJX2g0lyb1XdnOS3kvzgKfbZmWRLzU3IeVuSH+7W/0qSX+xeP38ExEn9YGvtUJK319xkoSdN4pnkx5M8s6rem7lLQq5KcmOS9VX1/sxNAvr3p/F+TjpOF968PMnuqtqXZE+Sx5zGsVgB6gsjcYAhqbl7jV/cWvtPfdcCsBZU1blJjrbWjnSj3X7zVEOdAYCzzxwYMEBV9YYkT8jcxEQAnB2PT/LnVTWSuQnj/m3P9QAA8xiBAQAAAAyeOTAAAACAwRNgAAAAAIO36ubAePazn91uvPHGvssAGKpT3X3hQelbAU5Jvwqw9BbsW1fdCIzp6em+SwBYdfStAEtLvwrw8K26AAMAAABYfQQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAgyfAAAAAAAZPgAEAAAAMngADAAAAGDwBBgAAADB4AgwAAABg8AQYAAAAwOAJMAAAAIDBE2AAAAAAg9drgFFVz66qf6yqqap62YPs9y+rqlXVlrNZHwAAADAMvQUYVbUuyW8k2Z7kqiT/qqquWmC/C5P8eJJ3nt0KAQAAgKHocwTG05JMtdY+1Fq7P8mfJnneAvv9QpJfTnLv2SwOAAAAGI4+A4zLk3x03vOD3brjquopSR7XWvurBztQVb20qvZW1d7bb7996SsFWIP0rQBLS78KsDiDncSzqkaS/Lck/+Gh9m2t/U5rbUtrbctll122/MUBrAH6VoClpV8F/n/27j3KsrOuE/73V93VSScNBLpjkDQxSAc1IoK0qKMgDuk27Sg4Dgrj6JS3AXVMj2Z8R+aVFwQzMyoz40xFl4KolJd3vDC4zCtpSGRgIYiSJoEGwqULbEIngaQ6IeTSSaq7nvePcxr7fqtTtXdVfT5rZfU5Z++z96+enHrqnO959vMwP10GGLcnefJh9zcOHzvkMUmenuRdVbUnyTcnuc5EngCwMGZmZnLVVVdl3759XZcCAHCMLgOMm5JcVlVPqao1SV6a5LpDG1tr97XWNrTWLm2tXZrk75K8sLW2s5tyAWB5e/3rX58PfehDef3rX991KQAAx+gswGitHUjyM0nenuRjSf6stfbRqnptVb2wq7oAYCWamZnJjTfemCS54YYbjMIAAHqn0zkwWmvXt9ae1lp7amvtPw0fe1Vr7brj7Pt8oy8AYGG8/vWvz9zcXJJkbm7OKAwAoHd6O4knALB4/vqv//qI+4dGYwAA9IUAAwBIVZ30PgBA1wQYAEBe8IIXHHH/iiuu6KgSAIDjE2AAAHn5y1+esbHB24KxsbG8/OUv77giAIAjCTAAgGzYsCFbtmxJkmzdujXr16/vuCIAgCOt7roAAKAfXv7yl+dzn/uc0RcAQC8JMACAJINRGNdee23XZQAAHJcAAwCWicnJyUxPT5/18/fu3Zsk2bhx41kfY9OmTdm+fftZPx8A4EQEGABAkmT//v1dlwAAcEICDABYJuY78uHQ8ycnJ0dRDgDASFmFBAAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL0nwAAAAAB6T4ABAAAA9J4AAwAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvre66AAAgmZyczPT0dKc17N69O0myffv2TuvYtGlT5zUAAP0jwACAHpiens4nP3JzLll3sLMa1swOBmY+vOemzmq47YFVnZ0bAOg3AQYA9MQl6w7mlZsf6LqMTl2zc13XJQAAPWUODAAAAKD3BBgAAABA77mEBAB6YO/evXnw/lUr/hKKz9y/Kufv3dt1GQBADxmBAQAAAPSeERgA0AMbN27MwwfuNInnznU5d+PGrssAAHrICAwAAACg9wQYAAAAQO8JMAAAAIDeE2AAAAAAvWcSTwA6Nzk5menp6bN+/t7hspsb5zH546ZNm7J9+/azfj4AAAtLgAHAkrd///6uSxiJ2x5YlWt2ruvs/J9/aDAw86Lz5jqr4bYHVuVpnZ0dAOgzAQYAnZvvyIdDz5+cnBxFOZ3YtGlT1yXk0d27kyTnXnpZZzU8Lf1oCwCgfwQYANADfbh8ZTkEQQDA8mUSTwAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AwZI1MzOTq666Kvv27eu6FAAAABaYAIMla2pqKrt27crU1FTXpQAAALDAOg0wqurKqvpEVU1X1SuOs/3qqrq1qnZV1Tuq6iu6qJP+mZmZyY4dO9Jay44dO4zCAAAAWOY6CzCqalWS30yyLcnlSf5lVV1+1G63JNncWntGkjcn+bXFrZK+mpqaSmstSTI3N2cUBgAAwDLX5QiM5ySZbq19urX2aJI/SfKiw3dorb2ztfbQ8O7fJdm4yDXSUzfeeGNmZ2eTJLOzs7nhhhs6rggAAICFtLrDc1+c5LOH3d+b5JtOsv+PJ9lxvA1V9bIkL0uSSy65ZFT10WNbtmzJ9ddfn9nZ2YyPj2fr1q1dlwTLjr516ZmcnMz09PRZP3/37t1Jku3bt5/1MTZt2jSv58Nypl8FmJ8lMYlnVf1Qks1JXne87a21N7TWNrfWNl944YWLWxydmJiYSFUlScbGxjIxMdFxRbD86FtXnrVr12bt2rVdlwHLln4VYH66HIFxe5InH3Z/4/CxI1TVFUl+Mcm3t9YeWaTa6LkNGzZk27Ztue6667Jt27asX7++65IAOmfkAwCwnHUZYNyU5LKqekoGwcVLk/zg4TtU1bOSvD7Jla21uxa/RPpsYmIie/bsMfoCAABgBegswGitHaiqn0ny9iSrkvxea+2jVfXaJDtba9dlcMnIuiR/Prxc4LbW2gu7qpl+2bBhQ6699tquywAAAGARdDkCI62165Ncf9Rjrzrs9hWLXhQAAADQO0tiEk8AAABgZRNgAAAAAL0nwAAAAAB6T4ABAAAA9F6nk3guRZOTk5menj7r5+/duzdJsnHjxnnVsWnTpmzfvn1ex+jSfNsxGU1bLvV2BAAAWCkEGIts//79XZewbGhLAACAlUOAcYbm+239oedPTk6OopwlaxSjHrQlAADAymEODAAAAKD3jMAAAIBlxrxtwHIkwAAAAI5grjGgjwQYsIRZzWU0tCMAy41524DlSIABK5xvWEZDOwIAwMISYMASZjWX0dCOAADQf1YhAQAAAHpPgAEAAAD0ngADAAAA6D0BBgAAANB7AgwAAACg9wQYAAAAQO9ZRpWzMjk5menp6U5r2L17d5LRLIF5tjZt2tTp+QEAAFYKAQZnZXp6Op/8yM25ZN3BzmpYMzsYQPTwnps6Of9tD6zq5LwAAAArkQCDs3bJuoN55eYHui6jM9fsXNd1CQAAACuGOTAAAAAWwMzMTK666qrs27ev61JgWRBgAAAALICpqans2rUrU1NTXZcCy4JLSDgre/fuzYP3r1rRl1F85v5VOX/v3q7LAACgh2ZmZrJjx4601nL99ddnYmIi69ev77osWNIEGAAAh5nvSlt7h+H2xo0bz/oYy2GVqz60Y7I82pKlaWpqKrOzs0mS2dnZTE1N5eqrr+64KljaBBiclY0bN+bhA3eu+Ek8z53nmyoAlp/9+/d3XcKyoB1Z6m644Ya01pIkrbW8/e1vF2DAPAkwAAAOM99v6w89f3JychTlLFnakZXuoosuyp49e464D8yPSTwBAABG7POf//xJ7wNnToABAAAwYlu3bk1VJUmqKt/5nd/ZcUWw9LmEBIB5me9EfaOwe/fuJPMfsj5fJgsEWF7m8zdudnb2iDkwdu/efdZ/I/x9gQEBBgDzMj09nVs+fGvmzntCZzXUo4M3iB/41Oc6q2HsoXs6OzcA/TM+Pp7Vq1fnwIEDWb9+fcbHx7su4qESQQAAIABJREFUCZY8AQZn7bYHVuWanes6O//nHxpcAXXReXOdnP+2B1blaZ2cGfpn7rwn5OHLv7vrMjp17q1/1XUJAIzYfEc9/NRP/VT27NmTN77xjVm/fv2IqoKVS4DBWdm0aVPXJeTR4ZDxcy+9rJPzPy39aAcAYPnp+vI8l+aNxvj4eC677DLhBYyIAIOz0oc/JJZXAwCWq64vz3NpHtBHAgwAAOihlX55nkvzgKMJMAAAgGXJpTgDS/1SHDhEgAEAACxL09PT+eRHbs4l6w52cv41s4NJ5x/ec1Mn508GE8/DciHAgA51/a1A0o9vBub7rYB2HPDtCgAc65J1B/PKzQ90XUZnulw1EEZtxQUYXX/Q6cOHnMQHnb6Ynp7OLR+9JbmgwyKGq9Decvst3Zz/C/M/xPT0dD7+wQ/mifM/1FkbG/77hQ9+sJPzdzfFGgD01969e/Pg/atW9If4z9y/Kufv3dt1GTASKy7AMKOzGZ1754Jk7vlzXVfRmbF3jZ16p9PwxCQ/nhrJsZai303rugToha6/qEiWx5cV2vEf+dIHoD9WXICRmNHZjM4ALFdGtg3Nc3SbkW0DXY5u27t3b8Yeum9Fv28be2hf9u49MK9jbNy4MQ8fuHPFX0Jy7saNndYwilB073AUycZ5/CxLPZDUjis0wAAAlrEVPrItGc3otpU+si0xum25uO2B7i4h+fxDg9/Fi87rrk+67YFVeVpnZx+d/fv3d13CsrDU21GAAQAAPbNx48Z8/pHVK37U8MaN8xsHtGnTphFVc3YeHV4Kde6ll3VWw9PSfTuM4tv6Q8eYnJyc97GWKu0owAAAAJapri8XWOofFqFvOg0wqurKJP8zyaokb2yt/cpR289J8gdJnp1kX5KXtNb2LHadAJyY67QHRnGtNgD0kYl9B+Y794N2HJhPO3YWYFTVqiS/mWRLkr1Jbqqq61prtx62248nube1tqmqXprkV5O8ZPGrBQAAVpr5fuAc1YfFriefNEFy5j05cmKC5GT+kyOfVoBRVb+W5Jok+5O8Lckzkvxca+2P5nHu5ySZbq19eniOP0nyoiSHBxgvSvJLw9tvTvIbVVWttRPOqPTpux/MS17/viMe++5nfHl++Fsuzf5HD+a953xj7n/Ko5kbe+yXtp/THsm57ZHMpXL/2GOOOea57eGc0x7NwYzlgbFjJwBaO7c/azJ7yu0HsioPjp1/zPbz5h7KeA5kNqvz0Nh5x2w/f+7BrM7BPJrx7B9be8z2dXMPZFXmTrn9kVqTh+vc3P+U78x7z1nzpXb6rR96dp5w/pr8+c7P5s0fOHaN6Df96HOyds2q/OH79uSvdt15zPY/ffm3JEne8O5P5R0fu+uIbeeOr8rUjz0nSTL5jt157/TMEdsff96a/PYPPztJ8qtv+3hu/sy9R2z/8sedm//x0mclSV7z/300t97xxS9tmz7nG7OuPfil+//xLbvy6bsfPOL5lz/psXn193xtkuRn/+SW3Hnfw0ds/4aveHx+4cqvTpL85B9+IPc+9OgR279104Zsf8HgmsWJ33t/Hp49eMT2F3zNl+Vlz3tqkhzzukuOfO39yO+//5jtj6x6UpJbcvDg2txzz/cds/3882/Oeed9LAcOPCb33vvCY7avW/f3Wbt2OrOzT8gXvrDtmO2Pecx7c+65e/Loo1+W++7bcsz2xz72XTnnnNvzyCMX54tffP4x2x/3uBuzZs1defjhS3P//d96zPYLLtiR8fF7sn//pjzwwDcds/3xj78uq1ffn4ce+po8+OA3HLP9CU94S8bySG5b9aTjtt/pvvamV1+a27/2a/JfDts2PncgP/+xNydJ/nLjt+TWx33FEc9dd2B/rvrEXyZJ/uyS5+VTj3nSkbU/en9+cvdbkyR/fOk/zW3nf9kR2y/af29+7NNvT5L83ld+Zz6/9vFHbL/kwbvyr/b8nyTJb1/2z3LvmiP7lqfef0d+4LZ3J0mu/aoX5YHVR/7uXn7fZ/KivYM2+a9f8+LMjh3ZXX/9vZ/Kd91xU5Lkv3ztS3NnktXnrPtSO57otXeozc7UyfrWJ268JB950tdl7vz1R2xfaX3r2IP78tDapd+3JslXXnh+/sv3PSPJ0utbb/vcgYzdf37G3vVgWhvLgdkNxzx/bNUDWbXqobS2Kgdm1x+zfdWq+zO2an/a3OocOHDssuurVn8xY2MPZ25uPAcPPP4427+QsbFHMze3JgcPHPtuf9XqezM2Npu5uXNz8MBjj9m+evU9qbEDmTu4NgcPHvu7s3p8X6oO5uDB8zJ38NjfjdXjM8l9c/lYfeGs+9a9e/dmZs1j8uqj+qZKy5MfujtJMrPmsXlo9blH/mztYC7evy9Jcvc5j8v+VeccWVs7kCftHyzn/vlzLsgjq9YcsX3N3Gye+PDg9fq5cx+fR8fGj9h+zsFHc9Ejg08Rd6x9Qg7UkX3j2oOP5MJH7kuS3L52fQ7WqiO2n3fg4Wx4dPB6/+x5F6YdNUnpugP784RH70+S3Hbel+XRJO1zB07aty5Ev+o9a3/es94+86TsP+fxWdNm842PDj7w3Tp+We4dO/J3+9z2cJ796IeTJB8Z/+rcN/z/88hlg770oTUH8vWPDj7mfGjN5Xmgjmzfx83dn6fPfjxJ8oE1X5eH68jfrTu/WDkUX3TxnvWeOwa/d532q+uG/eqj3fSrlbl87I6z71eT5KN3fDH7z/uy3HbYtq761UN/2bvoV286Rb96eJsd7XRHYGxtrf2HqvrnSfYk+b4k704ynwDj4iSfPez+3iRHfwL60j6ttQNVdV+S9UmOeKdWVS9L8rIkWfflT51HSSyW22+/Pfv378+aNpvtN00lOf4fg73t4Wz/299PcuQfg2Qwg+7BR774pTT6eH8M7v7k/dl+4+uTHP+PwdzdlQzfZANH0rcCjJZ+dem5+OKLkwyC4ckf/rEkJwuG/02SkwXDP5nkZMHwTyc5cTAMJHWSwQz/uFPVR1prT6+qNyZ5c2vtbVX1odba15/1iatenOTK1tpPDO//cJJvaq39zOHnHe6zd3j/U8N9Zo53zCTZvHlz27lz5wnPu3379nzgU59b8TM6P/upT+x0MiFrGA9s3749t9x+y4pe7m/sXWN51sXPmtfrcfv27fnCBz+4opf7+920XPDMZ55OO55VI52sb9WvDvShb0W/esh8+1b96sBp9q0j71cTfWuiX+2T7du3d38JyQPDf7tZETf5QvKsr53/e9auLyHZN/z32HEyi+NzSb56Hu9ZT3cExl9V1cczuITkp6rqwiQPn+I5p3J7kicfdn/j8LHj7bO3qlYneVz+sc3Pisnm+jHR3ChCg5mZmbzmNa/Jq1/96qxf39Wv4Pzs3bs3uW/wRnPF+kKytx07DPRM7N27N/dn8EZzpbozyQN759eOAADH0/UyrMk/zidy2cUdLUl78fzboQ/tePewHS+4rJt2vCDza4fTCjBaa68YzoNxX2vtYFU9mMH8FPNxU5LLquopGQQVL03yg0ftc12SiSTvS/LiJP/nZPNfsLJMTU1l165dmZqaytVXX911OQAAsCx1vRzt4TUs5RE52nH+zmQVkicluaLqiEkE/uBsTzyc0+Jnkrw9g2VUf6+19tGqem2Sna2165L8bpI/rKrpJPdkEHLMy8aNG/P5R1av+OF4Gzd2OXBp/mZmZrJjx4601rJjx45MTEwsyVEYGzduzN1194oe6jz2rrFsvPjsLwNKBu34hZmZFT3U+XfTcsE8LqcCAIC+O91VSF6d5PlJLk9yfZJtSd6TeQQYSdJau354vMMfe9Vhtx9O8v3zOQfL09TUVA4NxpmbmzMKAwAAemoU89+NYknarue/my/tePojMF6c5OuT3NJa+9GquijzW4EE5uXGG2/M7OxskmR2djY33HCDAAMAWFbGHrqns3nb6uHBKhrt3GOXpFwsYw/dk3Q63SF9snbtsUvvcuaWejueboCxv7U2V1UHquqxSe7KkRNwwqLasmVLrr/++szOzmZ8fDxbt27tuiQAgJHperK/3bvvT5Jc9tQuA4Qndt4OjMZSHvXQJ9rx9AOMnVV1QZLfSfKBDBaxed+CVQWnMDExkR07diRJxsbGMjEx0XFFAPTGFzpe3anrpf6S5AtJLp7fIT6Xbld36nqpv2TQBl2tGtn1B5WlPtEfsDyd7iokPz28+dtV9bYkj22t7Vq4suDkNmzYkG3btuW6667Ltm3bluQEngCMXh++re18qb9k3sv99aEdu17qL5n/cn8AjNZJA4yq+urW2ser6huOs+0bWms3L1xpcHITExPZs2eP0RcAfEnX31ofXsNS/uZaOwLQR6cagXF1kpcl+W/JEWMIa3j/ny5QXXBKGzZsyLXXXtt1GQAAACyCkwYYrbWXDW9+V5KfTvJtGQQXf5Pktxa2NFghVvq12iO4TjtxrXaX12kDAMBiON1JPKeSfDHJoTF8P5jkD5L8wEIUBStFH66r7fxa7Xlep530ox27vlbbddoAACx3pxtgPL21dvlh999ZVbcuREGwkrjGeDS0IwAALH+nG2DcXFXf3Fr7uySpqm9KsnPhylpYYw/dk3Nv/atOzl0PfzFJ0s59bCfnTwY/f9Llmt4AAABwZk61CsmHM5jzYjzJ31bVbcP7X5Hk4wtf3uh1PcR69+77kySXPbXLAOGJnbcDsLx0GQwnwmEAgJXgVCMwvntRqlhEXQ81N8wcWG76EIgKhwEAlr9TrULymcUqBIClqetg+PAahMMAAMtXh2s3AgAAAJweAQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL130mVUAQBWmsnJyUxPT5/183fv3p1kfksMb9q0qRdLFM9HH9oxWR5tCcCAAAMAYITWrl3bdQnLgnYE4GgCDACAw/i2fjS0IwCjJsAAAIBlxiU8wHIkwAAAAI7gEh6gjwQYAACwzBj1ACxHllEFAAAAek+AAQAAAPSeAAMAAADoPQEGAMAIzczM5Kqrrsq+ffu6LmVJ044AHE2AAQAwQlNTU9m1a1empqa6LmVJ044AHE2AAQAwIjMzM9mxY0daa9mxY4fRA2dJOwJwPAIMAIARmZqaSmstSTI3N2f0wFnSjgAcjwADAGBEbrzxxszOziZJZmdnc8MNN3Rc0dKkHQE4HgEGAMCIbNmyJePj40mS8fHxbN26teOKlibtCMDxCDAAAEZkYmIiVZUkGRsby8TERMcVLU3aEYDjEWAAAIzIhg0bsm3btlRVtm3blvXr13dd0pKkHQE4ntVdFwAAsJxMTExkz549Rg3Mk3YE4GgCDACAEdqwYUOuvfbarstY8rQjAEcTYMASNjk5menp6XkdY/fu3UmS7du3n/UxNm3aNK/nd007AgBA/wkwYIVbu3Zt1yUsC9oRAAAWlgADljDf1o+GdgQAgP6zCgkAAADQe0ZgnKH5Xis/iuvkE9fKAwAAsLIIMBaZ6+QBAADgzAkwzpBRDwAAALD4OpkDo6qeUFU3VtXu4b+PP84+z6yq91XVR6tqV1W9pItaAQAAgO51NYnnK5K8o7V2WZJ3DO8f7aEk/7q19rVJrkzyP6rqgkWsEQAAAOiJrgKMFyWZGt6eSvK9R+/QWvtka2338PYdSe5KcuGiVQgAAAD0RlcBxkWttTuHtz+X5KKT7VxVz0myJsmnTrD9ZVW1s6p23n333aOtFGCF0rcCjJZ+FWB+FizAqKq/rqqPHOe/Fx2+X2utJWknOc6XJ/nDJD/aWps73j6ttTe01ja31jZfeKFBGgCjoG8FGC39KsD8LNgqJK21K060rao+X1Vf3lq7cxhQ3HWC/R6b5K1JfrG19ncLVCoAAADQc11dQnJdkonh7Ykkf3n0DlW1JslfJPmD1tqbF7E2AAAAoGe6CjB+JcmWqtqd5Irh/VTV5qp643CfH0jyvCQ/UlUfHP73zG7KBQAAALq0YJeQnExrbV+SFxzn8Z1JfmJ4+4+S/NEilwYAAAD0UFcjMAAAAABOmwADAAAA6L1OLiEBgMNNTk5menr6rJ+/e/fuJMn27dvP+hibNm2a1/MBAFhYAgwAlry1a9d2XQIAAAtMgAFA54x8AADgVMyBAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAcCSNzMzk6uuuir79u3ruhQAABaIAAOAJW9qaiq7du3K1NRU16UAALBABBgALGkzMzPZsWNHWmvZsWOHURgAAMuUAAOAJW1qaiqttSTJ3NycURgAAMuUAAOAJe3GG2/M7OxskmR2djY33HBDxxUBALAQBBgALGlbtmzJ+Ph4kmR8fDxbt27tuCIAABaCAAOAJW1iYiJVlSQZGxvLxMRExxUBALAQBBgALGkbNmzItm3bUlXZtm1b1q9f33VJAAAsgNVdFwAA8zUxMZE9e/YYfQEAsIwJMABY8jZs2JBrr7226zIAAFhALiEBAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA73USYFTVE6rqxqraPfz38SfZ97FVtbeqfmMxawQAAAD6o6sRGK9I8o7W2mVJ3jG8fyK/nOTdi1IVAAAA0EtdBRgvSjI1vD2V5HuPt1NVPTvJRUluWKS6AAAAgB7qKsC4qLV25/D25zIIKY5QVWNJ/luSnz/VwarqZVW1s6p23n333aOtFGCF0rcCjJZ+FWB+FizAqKq/rqqPHOe/Fx2+X2utJWnHOcRPJ7m+tbb3VOdqrb2htba5tbb5wgsvHNFPALCy6VsBRku/CjA/qxfqwK21K060rao+X1Vf3lq7s6q+PMldx9ntW5I8t6p+Osm6JGuq6oHW2snmywAAAACWoQULME7huiQTSX5l+O9fHr1Da+1fHbpdVT+SZLPwAgAAAFamrubA+JUkW6pqd5IrhvdTVZur6o0d1QQAAAD0VCcjMFpr+5K84DiP70zyE8d5/E1J3rTghQEAAAC91NUIDAAAAIDTJsAAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3BBgAAABA7wkwAAAAgN4TYAAAAAC9J8AAAAAAek+AAQAAAPSeAAMAAADoPQEGAAAA0HsCDAAAAKD3qrXWdQ0jVVV3J/lM13WcwoYkM10XsUxoy9HQjqOxFNpxprV25Zk+Sd+6omjH0dCOo7EU2lG/yqlox9HRlqOxFNrxuH3rsgswloKq2tla29x1HcuBthwN7Tga2rFb2n80tONoaMfR0I7d0v6joR1HR1uOxlJuR5eQAAAAAL0nwAAAAAB6T4DRjTd0XcAyoi1HQzuOhnbslvYfDe04GtpxNLRjt7T/aGjH0dGWo7Fk29EcGAAAAEDvGYEBAAAA9J4AAwAAAOg9AQYAAADQewIMADpTVX87wmO9q6qOWdO8ql5YVa8Y1Xn6rqp+qap+fh7Pv7SqPnKCbW+sqsvPvrql6UzatKreVFUvPs7jm6tqcvTV9V9Vvbaqrhje/tmqOu8U+59Je3u9Hoe+dbT0q6OnX52fldyvru7y5ACsbK21f7II57guyXULfZ6VoLX2E13X0BdVtbq1duB092+t7UyycwFL6q3W2qsOu/uzSf4oyUOLcN4V+3rVty4dK/l1ejT96ulbyf2qERgAdKaqHhj++/yqendVvbWqPlFVv11VY1W1avjNy0eq6sNV9XOnOOQPV9UHh/s/Z3jsH6mq3xje/p6q+vuquqWq/rqqLho+/u3D531wuO0xC/qDj1hV/WJVfbKq3pPkq4aPvauqfr2qdlbVx6rqG6vqLVW1u6quOcUhV1fVHw+f9+ZD3+wc/k1sVf3W8NgfrarXHFbLr1TVrVW1q6r+60L9zAvtJG36P6pqZ5J/d5KnXzFsm09W1XcPn/v8qvqr4e3nVNX7hq+1v62qQ8f/2qp6//B1uKuqLlvgH/OMVdX5w9/TDw1/z36hqt4y3PaiqtpfVWuq6tyq+vTw8TdV1YuranuSJyV5Z1W9c7jtyqq6eXi8dxx2qsuH7f3p4fNOZsW/Xo+mb50//ero6VePT796ZozAAKAvnpPk8iSfSfK2JN+X5B+SXNxae3qSVNUFpzjGea21Z1bV85L8XpKnH7X9PUm+ubXWquonkvyHJP8+yc8n+bettfdW1bokD4/qh1poVfXsJC9N8swM/q7fnOQDw82PttY2V9W/S/KXSZ6d5J4kn6qqX2+t7TvBYb8qyY8P2+P3kvx0kqPfhPxia+2eqlqV5B1V9Ywktyf550m+etjGp/r/1UunaNM1rbVjhtMf5dIMXs9PzeBN5aajtn88yXNbawdqMAT4Pyf5F0l+Msn/bK39cVWtSbJqFD/PiF2Z5I7W2j9Lkqp6XJKXD7c9N8lHknxjBu3294c/sbU2WVVXJ/mO1tpMVV2Y5HeSPK+19g9V9YTDdv/qJN+R5DFJPlFVv9Vamz1BTSv69Xoa9K1nSL86evrVk9KvngEjMADoi/e31j7dWjuY5H8l+bYkn07ylVV1bVVdmeSLpzjG/0qS1tq7kzz2OH84NyZ5e1V9OMn/leRrh4+/N8l/H34jccGZDGHtgecm+YvW2kOttS/myCHdh25/OMlHW2t3ttYeyaBdn3ySY362tfbe4e0/yuD/xdF+oKpuTnJLBu14eZL7MviA8rtV9X1ZhOGsC+Rkbfqnp/H8P2utzbXWdmfQ1l991PbHJfnzGlxj/Ov5x9fh+5L831X1C0m+orW2f14/xcL4cJItVfWrVfXc1tp9GXxw+5oMPlz89yTPy6AN/+YUx/rmJO9urf1DkrTW7jls21tba4+01maS3JXkopMcZ6W/Xk9F33rm9Kujp189Mf3qGRBgANAX7ej7rbV7k3x9kndl8C3KG8/0GEfdvzbJb7TWvi6DbzfOHZ7oV5L8RJK1Sd5bVUe/MVqqHhn+O3fY7UP3TzYK86TtWFVPyeCb1Re01p6R5K1Jzh1+OHlOkjcn+e4Mvu1dbh48jX1O9Tr85STvHH77/T35x9fh/5vkhUn2J7m+qv7pPGsdudbaJ5N8QwZvuK+pqlcleXeSbUlmk/x1Bm90vy2nfqN9Moe/Xg/G63U+9K2jpV8dPf2qfvW0CTAA6IvnVNVTqmosyUuSvKeqNiQZa6397ySvzOAP/Mm8JEmq6tuS3Df8FuNwj8tgeGOSTBx6sKqe2lr7cGvtV5PclGO/2emzdyf53qpaW4Pry79nBMe8pKq+ZXj7BzMYHn64x2bwhvO+Glzrvi1JhkPEH9dauz7Jz2XwAWkpmm+bfn8N5hl4apKvTPKJo7Yf/jr8kUMPVtVXJvl0a20yg6Hpzzib4hdSVT0pyUOttT9K8roMfif/JoNJ5N7XWrs7yfoMhh8fbxb7+zMYvpwkf5fkecM3wjlqqPOZWOmv11PRt545/ero6VdPQL96ZsyBAUBf3JTkN5JsSvLOJH+R5OuS/P7wjXeS/MdTHOPhqrolyXiSHzvO9l/KYIjpvUn+T5KnDB//2ar6jgy+Qftokh3z+DkWVWvt5qr60yQfymBI6E0jOOwnkvzb4XWvtyb5raPO+aFhO388yWczGCaeDN5A/WVVnZukklw9gloW3Qja9LYk78/gDd5PttYerqrDt/9akqmqemUG31od8gMZTJY4m+RzGVzD3Tdfl+R1VTWXwTeDP5XB78xFGXxASZJdSZ7YWjv6G7wkeUOSt1XVHa2176iqlyV5y/B3/K4kW86iphX9ej0N+tYzpF8dPf3qSelXz0Advw0AYPFU1fOT/Hxr7bu7rgVgudC3AsuNS0gAAACA3jMCA4Alpap+M8m3HvXw/2yt/X4X9SxVVbU+yTuOs+kFJ1kGkKGq+sUk33/Uw3/eWvtPXdSz3Hm9Ljx96/x5nc6PfnVxLdXXqwADAAAA6D2XkAAAAAC9J8AAAAAAek+AAQD0XlU9s6q+67D7v1RVPz+P483r+QBLnX6VpUiAAQAsBc9M8l2n3AuA06VfZckRYAAAi6KqLq2qj1fVm6rqk1X1x1V1RVW9t6p2V9Vzqur8qvq9qnp/Vd1SVS+qqjVJXpvkJVX1wap6yfCQl1fVu6rq01W1/bDzXF1VHxn+97OHPf6Lw/O+J8lXLe5PDzB6+lVWGquQAACLoqouTTKd5FlJPprkpiQfSvLjSV6Y5EeT3Jrk1tbaH1XVBUneP9z/+5Nsbq39zPBYv5Rka5LvSPKYJJ9I8sQkz0jypiTfnKSS/H2SH8rgS5s3JfmmJKuT3Jzkt1tr/3Uhf2aAhaRfZaVZ3XUBAMCK8g+ttQ8nSVV9NMk7Wmutqj6c5NIkG5O88LDrqM9NcskJjvXW1tojSR6pqruSXJTk25L8RWvtweE53pLkuRm80f6L1tpDw8evW5CfDmDx6VdZMQQYAMBieuSw23OH3Z/L4H3JwST/orX2icOfVFXfdIpjHYz3NcDKpF9lxTAHBgDQJ29PclVVVZLG9cNgAAAgAElEQVRU1bOGj9+fwZDmU/mbJN9bVedV1flJ/vnwsXcPH19bVY9J8j2jLx2gl/SrLBsCDJat01nKqaq+t6ouH/F5L62qHxzlMU9yrp+sqn+9GOcCWCS/nGQ8ya7hUOhfHj7+zgwmlzt8srljtNZuzuCa7PdncJ32G1trtwwf/9MMrg3fkcF14gArgX6VZcMknixbw4mIHjjZREJV9aYkf9Vae/MIz/v8JD/fWvvuUR0TAABgpTMCg2XlREs5VdW/qaqbqupDVfW/h0Pg/kkGszO/bpg8P/V4+w2f//3DZaM+VFXvHj62qqpeN9x/V1W9fHi6X0ny3OExf24eP8uXVdUHhre/vqpaVV0yvP+p4c/wpVEmwyWvfnW4RNYnq+q5p6gTAABgyTApC8tGVT07yUuTPDP/uJTTB4ab39Ja+53hftck+fHW2rXD2ZK/NAKjqr5w9H5Jrk3yqiTf2Vq7fbj8VIbb7mutfWNVnZPkvVV1Q5JX5AQjMIbXB/7NCX6EH2yt3XroTmvtrqo6t6oem8FMzzszCEbek+Su1tpDw0sZD7e6tfacqvquJK9OcsWJ6myt/cOpWxUAAKAfBBgsJ8/NiZdyevowkLggyboMJjM6nhPt994kb6qqP0vyluFjW5M8o6pePLz/uCSXJXn0RAW21u7PIGA5XX+b5FuTPC/Jf05yZQbrb58oBDlU2wcyWDbrZHUKMAAAgCVDgMFK8aYk39ta+1BV/UiS55/Jfq21nxwuNfXPknxgONqjklzVWjsiDBnOgXFcZzICY+jdGQQzX5HkL5P8QpKW5K0nOMahpa8OX/bquHUCAAAsJebAYDk52VJOj0lyZ1WNJ/lXhz1+9PJRx92vqp7aWvv71tqrktyd5MkZjM74qeG+qaqnDZeWOuGSVK21+1trzzzBf0eHF8kg7PihJLtba3NJ7knyXUnec/rNcsI6AQAAlgwjMFg2Wms3V9WhpZzuypFLOf0/GSz7dPfw30MBw58k+Z2q2p7kxSfZ73VVdVkGoxneMTzHrgwu07h5uK723Um+d/j4war6UJI3tdZ+fR4/057hsd89fOg9STa21u49g8O88QR1AgAALBmWUQUAAAB6zyUkAAAAQO8JMAAAAIDeE2AAAAAAvSfAAAAAAHpv2a1CcuWVV7a3ve1tXZcB0FfVdQEAAHA2lt0IjJmZma5LAAAAAEZs2QUYAAAAwPIjwAAAAAB6T4ABAAAA9J4AAwAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL0nwAAAAAB6T4ABAAAA9J4AAwAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL0nwAAAAAB6T4ABAAAA9J4AAwAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL0nwAAAAAB6T4ABAAAA9J4AAwAAAOg9AQYAAADQewIMAAAAoPcEGAAAAEDvCTAAAACA3hNgAAAAAL0nwAAAAAB6T4ABAAAA9J4AAwAAAOi9TgOMqrqyqj5RVdNV9YqT7PcvqqpV1ebFrA8AAADoh84CjKpaleQ3k2xLcnmSf1lVlx9nv8ck+XdJ/n5xKwQAAAD6ossRGM9JMt1a+3Rr7dEkf5LkRcfZ75eT/GqShxezOAAAAKA/ugwwLk7y2cPu7x0+9iVV9Q1Jntxae+vJDlRVL6uqnVW18+677x59pQAAAECnejuJZ1WNJfnvSf79qfZtrb2htba5tbb5wgsvXPjiAAAAgEXVZYBxe5InH3Z/4/CxQx6T5OlJ3lVVe5J8c5LrTOQJAAAAK0+XAcZNSS6rqqdU1ZokL01y3aGNrbX7WmsbWmuXttYuTfJ3SV7YWtvZTbkAAABAVzoLMFprB5L8TJK3J/lYkj9rrX20ql5bVS/sqi4AAACgf6q11nUNI7V58+a2c6dBGgAnUF0XAAAAZ6O3k3gCAAAAHCLAAAAAAHpPgAEAAAD0ngADAAAA6D0BBgAAANB7AgwAAACg9wQYAAAAQO8JMBbZzMxMrrrqquzbt6/rUgAAAGDJEGAssqmpqezatStTU1NdlwIAAABLhgBjEc3MzGTHjh1prWXHjh1GYQAAAMBpEmAsoqmpqbTWkiRzc3NGYQAAAMBpEmAsohtvvDGzs7NJktnZ2dxwww0dVwQAAABLgwBjEW3ZsiXj4+NJkvHx8WzdurXjigAAAGBpEGAsoomJiVRVkmRsbCwTExMdVwQAAABLgwBjEW3YsCHbtm1LVWXbtm1Zv3591yUBAADAkrC66wJWmomJiezZs8foCwAAADgDRmAssnvuuSfT09O59957uy4FAAAAlgwBxiK75ppr8uCDD+a1r31t16UAAADAkiHAWESf/OQns2fPniTJnj17Mj093W1BAAAAsEQIMBbRNddcc8R9ozAAAADg9AgwFtGh0Rcnug8AAAAcnwBjEV166aUnvQ8AAAAcnwBjEb3yla884v6rXvWqjioBAACApUWAsYie9rSnfWnUxaWXXppNmzZ1WxAAAAAsEQKMRfbKV74y559/vtEXAAAAcAaqtdZ1DSO1efPmtnPnzq7LAOir6roAAAA4G0ZgAAAAAL0nwGDJmpmZyVVXXZV9+/Z1XQoAAAALTIDBkjU1NZVdu3Zlamqq61IAAABYYAIMlqSZmZns2LEjrbXs2LHDKAwAAIBlToDBkjQ1NZVDE9DOzc0ZhQEAALDMre66gKVmcnIy09PTZ/38vXv3Jkk2btw4rzo2bdqU7du3z+sYS9mNN96Y2dnZJMns7GxuuOGGXH311R1XBQAAwEIxAmOR7d+/P/v37++6jCVvy5YtGR8fT5KMj49n69atHVcEAADAQqpDw/CXi82bN7edO3d2XcYJHRo1MTk52XElS9vMzExe8pKXZHZ2NmvWrMmf/umfZv369V2XBUtBdV0AAACcDSMwWJI2bNiQiy++OEnypCc9SXgBAACwzAkwWJJmZmZyxx13JEnuuOMOq5AAAAAscwIMlqTDVyFprVmFBAAAYJkTYLAkHW8VEgAAAJYvAQZLklVIAAAAVhYBBkvSxMREqgaLKYyNjWViYqLjigAAAFhIq7sugJVpcnIy09PT8zrGoQBj3bp1ec1rXnNWx9i0adOXlrYFAACgv4zAYMkaGxvL2NhYnvjEJ3ZdCgAAAAvMCAw6MYpRD4eOMTk5Oe9jAQAA0G9GYAAAAAC9J8AAAAAAeq/TAKOqrqyqT1TVdFW94jjbr66qW6tqV1W9o6q+oos6AQAAgG51FmBU1aokv5lkW5LLk/zLqrr8qN1uSbK5tfaMJG9O8muLWyUAAADQB12OwHhOkunW2qdba48m+ZMkLzp8h9baO1trDw3v/l2SjYtcIwAAANADXQYYFyf57GH39w4fO5EfT7LjeBuq6mVVtbOqdt59990jLBEAAADogyUxiWdV/VCSzUled7ztrbU3tNY2t9Y2X3jhhYtbHAAAALDgVnd47tuTPPmw+xuHjx2hqq5I8otJvr219sgi1QYAAAD0SJcjMG5KcllVPaWq1iR5aZLrDt+hqp6V5PVJXthau6uDGgEAAIAe6CzAaK0dSPIzSd6e5GNJ/qy19tGqem1VvXC42+uSrEvy51X1waq67gSHAwAAAJaxLi8hSWvt+iTXH/XYqw67fcWiFwUAAAD0zpKYxBMAAABY2QQYAAAAQO8JMAAAAIDeE2AAAAAAvSfAAAAAAHpPgAEAAAD0ngADAAAA6L3VXRfA0jQ5OZnp6elOa9i9e3eSZPv27Z3VsGnTpk7PDwAAsFIIMDgr09PT+eRHbs4l6w52VsOa2cEAoof33NTJ+W97YFUn5wUAAFiJBBictUvWHcwrNz/QdRmduWbnuq5LAAAAWDHMgQEAAAD0ngADAAAA6D0BBgAAANB7AgxY4WZmZnLVVVdl3759XZeypGlHAABYWCbx5Kzs3bs3D96/akVPZPmZ+1fl/L17uy5j3qamprJr165MTU3l6quv7rqcJUs7AgDAwjICA1awmZmZ7NixI6217Nixw+iBs6QdAQBg4RmBwVnZuHFjHj5w54pfRvXcjRu7LmNepqam0lpLkszNzRk9cJa0IwAALDwjMGAFu/HGGzM7O5skmZ2dzQ033NBxRUuTdgQAgIUnwIAVbMuWLRkfH0+SjI+PZ+vWrR1XtDRpRwAAWHgCDFjBJiYmUlVJkrGxsUxMTHRc0dKkHQEAYOEJMGAF27BhQ7Zt25aqyrZt27J+/fquS1qStCMAACw8k3hy1m57oNtlVD//0CB/u+i8uU7Of9sDq/K0Ts48WhMTE9mzZ49RA/OkHQEAYGEJMDgrmzZt6rqEPLp7d5Lk3Esv6+T8T0s/2mG+NmzYkGuvvbbrMpY87cj/3979R+lV13cCf38mP0xQASEW/NGKGk4tVouaorbqagUOafFHrb+2W3ds9dBq69S6bmuXnmprd1f7yzbYo0v9lUq3dXX1yKooSPHgDyqMBEEQzIhYEVISEBAJIcl894/niU6SySSZmSfPnczrdQ5n7r3f+3zv5/lyh8Pznu/9PgAADJYAg1kZGxsbdgk/rGHdunVDrgQAAIBBswYGAAAA0HlmYMACtm7dukxMTMypj5tvvjlJ8shHPnLWfaxevboTs3JmyzgCAED3LboAYz4+qMzFxv66DcP+kOKDErts3bp12CUcFowjAAAM1qILMCYmJrLhmusyecQxQ7l+3d+SJF/55qahXD9JRu69Y2jXZn7NRwhlLRHjCAAAC8GiCzCSZPKIY3LfSWcOu4yhWXHdJ4ZdAgAAABwUi3gCAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8xbl16gyfOvWrcvExMSc+ti4cWOSZGxsbNZ9rF69ek6vBwAA4NAQYLBgrVy5ctglAAAAcIgIMBgKsx4AAAA4GNbAAAAAADpPgAEAAAB0nkdIYIjmYzHTuZqPxVDnaq6LqRrHHovSAgBwOBNgwBBNTExkw7UbkqOHWMRk78eG724YzvXvnHsXExMTuf6qq3L83LuatV3T2e686qqhXH/TUK4KAACHjgADhu3oZPLZk8OuYmhGPjc/T7Idn+RVqXnpayF6b9qwSwAAgIGyBgYAAADQeQIMAAAAoPOGGmBU1RlVdUNVTVTVm6Zpf0BVfajf/uWqOuHQVwkAAAAM2wEFGFX151V1ZFUtq6qLq2pzVf3aXC5cVUuS/F2StUlOSvIfq+qkPU57VZLvtdZWJ3lHkrfP5ZoAAADAwnSgi3ie3lr7/ar65SQ3JXlRkkuTnDeHa5+SZKK1dmOSVNU/J3lBkuumnPOCJG/pb38kyTurqlpr+1yt7sbNP8jL/tdlux0784kPyyuefkK23r8zV2zakTbZsvTrn/5h+0ibzEgm01LZWUv26nPQ7UvazlTaftsnM5LJ2jtzOtj2nZMtV2za8cNxetevPSXHPHB5Pjz+nXzkKzfv9foP/PopWbl8ST542U35xNW37tX+od98epLk3Eu/mYu/fttubSuWLcn63zglSbLu4o354sSW3dofcsTyvPsVT0mSvP3T1+fKb39vt/aHHbUif/PyJyVJ/uT/XZvrbrl7t/bHPPSB+Z8vemKS5A8/enVu3PyD3dpPeviRefPzHp8kef0/b8itd923W/uTH/WQ/MEZj0uS/NYHv5Lv3Xv/bu0/v3pVxp57YpJk9H2X577tO3drf+5P/VjOetZjk2Sv+y7Z/d575fsv36v9jlvuTO5M6pKl2bF91V7tI0vuyZIl96a1Jdmx/di92pcs+X5GlmxNm1yaHTuO2bt96d0ZGbkvk5PLsnPHQ6ZpvzMjI/dncnJ5du7Y+6tQliz9XkZGtmdyckV27jhyr/alS+9IjezI5M6V2bnzwXu3L7s9VTuzc+cRmdz5oGnatyR3Tebrdee043eg9961t9ydrUf8WN48pa3S8uP3bk6SbFl+ZO5dumL399Z25hFbb0+SbH7AUdm65AG719Z25OFb70iS/PsDjs62Jct3a18+uT3H39e7XzeteEjuH1m2W/sDdt6f47b1vmLllpXHZEft/p/blTu35aHb7kqSfHflsXv97h+x476sur93v3/niIem7bFA6YN2bM0x938/SfJvR/xY7k/Spvxe7+ve2zVmAACw0BzoIyS7/s/7l5J8uLV21zxc+xFJvjNl/+b+sWnPaa3tSHJXkr0+xVXVWVU1XlXj27dvn4fSAAAAgC6pGSYz/OikqrcleWGSrenNnDg6ySdaa0+d9YWrXpzkjNbaq/v7r0jy1Nba70w552v9c27u73+zf86W6fpMkjVr1rTx8fF9XndsbCxf+eam3HfSmbMtfcFbcd0n8pTHHp9169YNu5RFb2xsLBu+u2HRf43qkx7xpDndj2NjY7nzqqsW/deoHn3yyQcyjot3kAAAWNAOaAZGa+1NSX4uyZrW2vYkP0jv8Y65+G6SH5+y/8j+sWnPqaqlSY5KcvscrwsAAAAsMAe6BkaSPDzJqVU19UHyf5jDta9IcmJVPTq9oOLlSX51j3POTzKa5LIkL07yLzOtfwEAAAAcng4owKiqNyd5dnrfFvKp9L455AuZQ4DRWttRVb+T5DNJliR5X2vt2qr60yTjrbXzk7w3yQeraiLJHemFHAAAAMAic6AzMF6c5GeSbGit/XpVHZe5fQNJkqS19qn0ApGpx/54yvZ9SV4y1+tAp93ZWwdiaO7p/9z7S0IOjTuz9/K9s7ApvXUghmXXs217f1fMobEpvcWJAADgcHWgAcbW1tpkVe2oqiOT3Jbd168AZmH16tXDLiEbN25Mkpz4iBOHU8Aj5j4OXRjHzf1xPPrE4Yzj0enGOAAAwKAcaIAxXlVHJ/n7JF9J72+2lw2sKlgkxsbGhl3CD2tYyN9KYxwBAODwd0ABRmvttf3Nd1fVp5Mc2Vq7enBlAQAAAPzIjAFGVT2utXZ9VT15mrYnt9auHFxpAAAAAD37m4HxhiRnJfmrZLfV8aq//wsDqgsAAADgh2b86oPW2ln9zV9M8skkd6X3nQHn948BAAAADNyBLuK5PsndSXatTverSf4hyUsHURQAAADAVAcaYPx0a+2kKfuXVNV1gygIAAAAYE8zPkIyxZVV9bRdO1X11CTjgykJAAAAYHf7+xaSa9JbrHNZki9V1b/19x+V5PrBlwcAAACw/0dIzjwkVQAAAADMYMYAo7X27UNVyKE0cu8dWXHdJ4Zy7brv7iRJW3HkUK6f9N5/cvzQrg8AAAAH60AX8TxsrF69eqjX37jx+0mSEx87zADh+KGPAwAAAByMRRdgjI2NdeL669at28+ZAAAAwC4H+i0kAAAAAEMjwAAAAAA6b9E9QgKHk3Xr1mViYmJOfdxwww3Ztm1bXvOa12TZsmWz6mP16tVDfzxrLowjAAB0nxkYsMhNTk5mcnIymzZtGnYpC5pxBACAwTIDAxawuf61fsuWLXn5y1+eJLnnnnvy5je/Occee+x8lLagGEcAAOg+MzBgEVu/fn1aa0l6MwjWr18/5IoWJuMIAACDJ8CAReyiiy7K9u3bkyTbt2/PhRdeOOSKFibjCAAAgyfAgEXstNNO++GCk8uWLcvpp58+5IoWJuMIAACDJ8CARWx0dDRVlSQZGRnJ6OjokCtamIwjAAAMngADFrFVq1Zl7dq1qaqsXbvWwpOzZBwBAGDwfAsJLHKjo6O56aabzBqYI+MIAACDJcCARW7VqlU555xzhl3GgmccAQBgsDxCAovcli1b8rrXvS633377sEtZ0IwjAAAMlgADFrn169fn6quvzvr164ddyoJmHAEAYLAEGLCIbdmyJRdccEFaa7ngggvMHpgl4wgAAIMnwIBFbP369WmtJUkmJyfNHpgl4wgAAIMnwIBF7KKLLsr27duTJNu3b8+FF1445IoWJuMIAACDJ8CARey0007LsmXLkiTLli3L6aefPuSKFibjCAAAgyfAgEVsdHQ0VZUkGRkZyejo6JArWpiMIwAADJ4AAxaxVatWZe3atamqrF27Nscee+ywS1qQjCMAAAze0mEXAAzX6OhobrrpJrMG5sg4AgDAYAkwYJFbtWpVzjnnnGGXseAZRwAAGCyPkAAAAACdJ8AAAAAAOk+AAQAAAHSeAAMAAADoPAEGAAAA0HkCDAAAAKDzBBgAAABA5wkwAAAAgM4TYAAAAACdN5QAo6qOqaqLqmpj/+dDpjnn5Kq6rKquraqrq+plw6gVAAAAGL5hzcB4U5KLW2snJrm4v7+ne5P859ba45OckeRvquroQ1gjAAAA0BHDCjBekGR9f3t9khfueUJr7RuttY397VuS3JbkoYesQgAAAKAzhhVgHNdau7W/vSnJcTOdXFWnJFme5Jv7aD+rqsaranzz5s3zWykAAAAwdEsH1XFVfTbJ8dM0nT11p7XWqqrN0M/DknwwyWhrbXK6c1pr5yY5N0nWrFmzz74AAACAhWlgAUZr7dR9tVXVv1fVw1prt/YDitv2cd6RST6Z5OzW2r8OqFQAAACg44b1CMn5SUb726NJPr7nCVW1PMnHkvxDa+0jh7A2AAAAoGOGFWC8LclpVbUxyan9/VTVmqp6T/+clyZ5VpJXVtVV/X9OHk65AAAAwDAN7BGSmbTWbk/y3GmOjyd5dX/7vCTnHeLSAAAAgA4a1gwMAAAAgAMmwAAAAAA6T4ABAAAAdJ4AAwAAAOg8AQYAAADQeQIMAAAAoPMEGAAAAEDnCTAAAACAzhNgAAAAAJ0nwAAAAAA6T4ABAAAAdJ4AAwAAAOi8pcMuYKFZt25dJiYmZv36jRs3JknGxsbmVMfq1avn3AcAAAAsFAKMQ2zlypXDLgEAAAAWnGqtDbuGebVmzZo2Pj4+7DIAuqqGXQAAAMyGNTAAAACAzhNgAAAAAJ0nwAAAAAA6T4ABAAAAdJ4AAwAAAOg8AQYAAADQeQIMAAAAoPMEGAAAAEDnCTAAAACAzhNgAAAAAJ0nwAAAAAA6T4ABAAAAdJ4AAwAAAOg8AQYAAADQeQIMAAAAoPMEGAAAAEDnCTAAAACAzhNgAAAAAJ0nwAAAAAA6T4ABAAAAdJ4AAwAAAOg8AQYAAADQeQIMAAAAoPMEGAAAAEDnCTAAAACAzhNgAAAAAJ0nwAAAAAA6T4ABAAAAdJ4AAwAAAOg8AQYAAADQeUMJMKrqmKq6qKo29n8+ZIZzj6yqm6vqnYeyRgAAAKA7hjUD401JLm6tnZjk4v7+vrw1yaWHpCoAAACgk4YVYLwgyfr+9vokL5zupKp6SpLjklx4iOoCAAAAOmhYAcZxrbVb+9ub0gspdlNVI0n+Kskb99dZVZ1VVeNVNb558+b5rRQAAAAYuqWD6riqPpvk+Gmazp6601prVdWmOe+1ST7VWru5qma8Vmvt3CTnJsmaNWum6wsAAABYwAYWYLTWTt1XW1X9e1U9rLV2a1U9LMlt05z29CTPrKrXJnlQkuVVdU9rbab1MgAAAIDD0MACjP04P8lokrf1f358zxNaa/9p13ZVvTLJGuEFAAAALE7DWgPjbUlOq6qNSU7t76eq1lTVe4ZUEwAAANBR1drhtWTEmjVr2vj4+LDLAOiqmRcVAgCAjhrWDAwAAACAAybAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8wQYAAAAQOcJMAAAAIDOE2AAAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8wQYAAAAQOcJMAAAAIDOE2AAAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8wQYAAAAQOcJMAAAAIDOE2AAAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8wQYAAAAQOcJMAAAAIDOE2AAAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg8wQYAAAAQOcJMAAAAIDOE2AAAAAAnSfAAAAAADpPgAEAAAB0ngADAAAA6DwBBgAAANB5AgwAAACg86q1Nuwa5lVVbU7y7WHXsR+rkmwZdhGHCWM5P4zj/FgI47iltXbGsIsAAICDddgFGAtBVY231tYMu47DgbGcH8ZxfhhHAAAYHI+QAAAAAJ0nwAAAAAA6T4AxHOcOu4DDiLGcH8ZxfhhHAAAYEGtgAAAAAJ1nBgYAAADQeQIMAAAAoPMEGAAAAEDnCTAOQlV9aR77+lxVrZnm+POr6k3zdZ0uq6q3VNUb5/D6E6rqa/toe09VnTT76hamgxnTqvpAVb14muNrqmrd/FfXfVX1p1V1an/79VV1xH7OP5jxdr8CAMAcLB12AQtJa+3nDsE1zk9y/qCvc7hrrb162DV0RVUtba3tONDzW2vjScYHWFJntdb+eMru65Ocl+TeQ3Bd9ysAAOyHGRgHoaru6f98dlVdWlWfrKobqurdVTVSVUv6f9X+WlVdU1W/t58uX1FVV/XPP6Xf9yur6p397edV1ZerakNVfbaqjusf/w/9113Vb3vwQN/4PKqqs6vqG1X1hSQ/2T/2uap6R1WNV9XXq+pnq+qjVbWxqv5sP10urap/7L/uI7v+Yj51hktVvavf97VV9SdTanlbVV1XVVdX1V8O6j0P2gxj+jdVNZ7kd2d4+an9sflGVZ3Zf+2zq+oT/e1Tquqy/n32para1f/jq+ry/j14dVWdOOC3edCq6oH939Gv9n/H/qCqPtpve0FVba2q5VW1oqpu7B//QFW9uKrGkjw8ySVVdUm/7YyqurLf38VTLnVSf7xv7L9uJov+fgUAgNkyA2P2TklyUpJvJ/l0khcl+VaSR7TWfjpJquro/fRxRGvt5Kp6VpL3JfnpPdq/kORprbVWVa9O8vtJ/kuSNyb57fHfc5UAAAbpSURBVNbaF6vqQUnum683NUhV9ZQkL09ycnr33pVJvtJvvr+1tqaqfjfJx5M8JckdSb5ZVe9ord2+j25/Msmr+mPxviSvTbLnh7uzW2t3VNWSJBdX1ROTfDfJLyd5XH989/fvqpP2M6bLW2t7Paa0hxPSu5cfm96H9dV7tF+f5JmttR3Ve7TifyT5lSS/leRvW2v/WFXLkyyZj/czz85Icktr7ZeSpKqOSvKb/bZnJvlakp9Nb9y+PPWFrbV1VfWGJM9prW2pqocm+fskz2qtfauqjply+uOSPCfJg5PcUFXvaq1t30dNi/p+BQCAuTADY/Yub63d2FrbmeSfkjwjyY1JHlNV51TVGUnu3k8f/5QkrbVLkxw5zYeSRyb5TFVdk+S/Jnl8//gXk/x1/6+9Rx/M4wFD9swkH2ut3dtauzu7Pyqza/uaJNe21m5trW1Lb0x/fIY+v9Na+2J/+7z0/j3s6aVVdWWSDemN4UlJ7kov+HlvVb0oh+AxgQGZaUw/dACv/z+ttcnW2sb0xvpxe7QfleTD1Vu74R350T14WZL/VlV/kORRrbWtc3oXg3FNktOq6u1V9czW2l3pBWI/lV5o89dJnpXeGH5+P309LcmlrbVvJUlr7Y4pbZ9srW1rrW1JcluS42boZ7HfrwAAMGsCjNlre+631r6X5GeSfC69v1C/52D72GP/nCTvbK09Ib2/HK/oX+htSV6dZGWSL1bVnh86F6Jt/Z+TU7Z37c80U2jGMayqR6c3Y+W5rbUnJvlkkhX90OeUJB9JcmZ6s2gONz84gHP2dw++Nckl/VlFz8uP7sH/neT5SbYm+VRV/cIca513rbVvJHlyekHGn1XVHye5NMnaJNuTfDa9AOEZ2X+AMZOp9+vOuF8BAGAgBBizd0pVPbqqRpK8LMkXqmpVkpHW2v9N8kfpfXiaycuSpKqekeSu/l+IpzoqvanjSTK662BVPba1dk1r7e1JrsjefzXvqkuTvLCqVlZv3Y7nzUOfP1FVT+9v/2p6j91MdWR6H+Tvqt4aImuTpP/ozVGttU8l+b30gqeFaK5j+pLqrd/y2CSPSXLDHu1T78FX7jpYVY9JcmNrbV16j/w8cTbFD1JVPTzJva2185L8RXq/j59Pb3HOy1prm5Mcm95jHdN9O8j303ssJEn+Ncmz+gFD9niE5GAs9vsVAABmzRoYs3dFkncmWZ3kkiQfS/KEJO/vhxpJ8of76eO+qtqQZFmS35im/S3pTd//XpJ/SfLo/vHXV9Vz0pudcG2SC+bwPg6Z1tqVVfWhJF9Nb6r9FfPQ7Q1Jfru/nsB1Sd61xzW/2h/j65N8J73Hb5LeB9OPV9WKJJXkDfNQyyE3D2P6b0kuT++D82+11u6rqqntf55kfVX9UXqzAXZ5aXqL0G5Psim9tTG65glJ/qKqJtObcfGa9H5fjksv+EmSq5Mc31rbc2ZEkpyb5NNVdUtr7TlVdVaSj/Z/v29LctosalrU9ysAAMxFTf//7cykqp6d5I2ttTOHXQsAAAAsBh4hAQAAADrPDIwBq6q/S/Lzexz+29ba+4dRz0JUVccmuXiapufO8PWq9FXV2UlessfhD7fW/vsw6jncuV8BAGAwBBgAAABA53mEBAAAAOg8AQYAAADQeQIMmGdVdXJV/eKU/bdU1Rvn0N+cXg8AAHA4EGDA/Ds5yS/u9ywAAAAOmAADplFVJ1TV9VX1gar6RlX9Y1WdWlVfrKqNVXVKVT2wqt5XVZdX1YaqekFVLU/yp0leVlVXVdXL+l2eVFWfq6obq2psynXeUFVf6//z+inHz+5f9wtJfvLQvnsAAIDu8S0kMI2qOiHJRJInJbk2yRVJvprkVUmen+TXk1yX5LrW2nlVdXSSy/vnvyTJmtba7/T7ekuS05M8J8mDk9yQ5PgkT0zygSRPS1JJvpzk19ILFj+Q5KlJlia5Msm7W2t/Ocj3DAAA0GVLh10AdNi3WmvXJElVXZvk4tZaq6prkpyQ5JFJnj9lfYoVSX5iH319srW2Lcm2qrotyXFJnpHkY621H/Sv8dEkz0wvwPhYa+3e/vHzB/LuAAAAFhABBuzbtinbk1P2J9P73dmZ5FdaazdMfVFVPXU/fe2M3z0AAICDYg0MmL3PJHldVVWSVNWT+se/n96jIvvz+SQvrKojquqBSX65f+zS/vGVVfXgJM+b/9IBAAAWFgEGzN5bkyxLcnX/EZO39o9fkt6inVMX8dxLa+3K9Na6uDy99S/e01rb0D/+ofTW3LggvfU3AAAAFjWLeAIAAACdZwYGAAAA0HkCDAAAAKDzBBgAAABA5wkwAAAAgM4TYAAAAACdJ8AAAAAAOk+AAQAAAHTe/wfZhcZCWZWdhgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 1080x1080 with 7 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"OyjW7XlfEBFw"},"source":["## Off-Policy Learning Estimators"]},{"cell_type":"code","metadata":{"id":"b0PQbmmBEBhr"},"source":["class EvaluationMetrics:\n","    \n","    def __init__(self) -> None:\n","        pass\n","    \n","    @staticmethod\n","    def error_rate(y_pred, y) -> float:\n","        er = 1 - np.mean(1 * (y_pred == y))\n","        \n","        return er\n","\n","class BanditDataset(Dataset):\n","    \n","    def __init__(self, X, y, p0, r, y_idx):\n","        self.X = X\n","        self.y = y\n","        self.p0 = p0\n","        self.r = r\n","        self.y_idx = y_idx\n","        \n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index], self.p0[index], self.r[index], self.y_idx[index]\n","        \n","    def __len__ (self):\n","        return len(self.X)\n","    \n","    \n","class LinearModel(torch.nn.Module):\n","    def __init__(self, n_features, n_actions):\n","        super(LinearModel, self).__init__()\n","        self.linear = torch.nn.Linear(n_features, n_actions)\n","\n","    def forward(self, x):\n","        xw_plus_b = self.linear(x)\n","        return xw_plus_b # batch size x n_actions\n","    \n","class NonLinearModel(torch.nn.Module):\n","    def __init__(self, n_features, n_actions, n_hidden=3):\n","        super().__init__()\n","        self.l1 = nn.Linear(n_features,n_hidden)\n","        self.l2 = nn.Linear(n_hidden,n_actions)\n","        \n","    def forward(self, x):\n","        return self.l2(F.relu(self.l1(x)))\n","   \n","\n","class RewardPredictor(EvaluationMetrics):\n","    \"\"\"\n","    Performs policy learning using by directly predicting the Reward as a function of covariates, \n","    actions and their interaction. \n","    \n","    References\n","    ----------\n","    \n","    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through \n","           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),\n","           1731--1755, 2015.\n","    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, \n","           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.\n","    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, \n","           International Conference on Learning Representations,  2018.\n","    \n","    \"\"\"\n","        \n","    \n","    def __init__(self) -> None:\n","        pass\n","     \n","    def __repr__(self) -> str:\n","    \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def learn_policy(self, data, clf: str = 'LogisticRegression', **kwargs) -> None:\n","        \"\"\"\n","        Parameters\n","        ----------\n","        data : STBT object\n","            This must be a Supervised to Bandit Transform (STBT) class with fitted \n","            `generate_batch` method.\n","            \n","        clf : str, default: 'LogisticRegression'\n","        A sklearn classification estimator. Must be one of 'LogisticRegression', \n","        'LogisticRegressionCV', 'RandomForestClassifier', or 'SVC'.\n","       \n","        **kwargs : Arguments passed to clf.\n","        Returns\n","        -------\n","        int.\n","          The predicted best policy.\n","        \n","        \"\"\"    \n","    \n","        XY_train, lb_fit = create_interactions(data.X_train, data.y_train_logging)\n","        y_train_logging_u = np.unique(data.y_train_logging)\n","        self.train_pred_reward_arr = np.zeros(shape=[data.X_train.shape[0], len(y_train_logging_u)]) \n","        self.test_pred_reward_arr = np.zeros(shape=[data.X_test.shape[0], len(y_train_logging_u)]) \n","        m = eval(clf)(**kwargs).fit(XY_train, data.train_logging_reward)\n","        \n","        for i, yval in enumerate(y_train_logging_u):\n","           XY_train_yval, _ = create_interactions(data.X_train, np.repeat(yval, data.X_train.shape[0]), one_hot_labeler = lb_fit)\n","           XY_test_yval, _ = create_interactions(data.X_test, np.repeat(yval, data.X_test.shape[0]), one_hot_labeler = lb_fit)\n","           self.train_pred_reward_arr[:,i] = m.predict_proba(XY_train_yval)[:,1]\n","           self.test_pred_reward_arr[:,i] = m.predict_proba(XY_test_yval)[:,1]\n","             \n","        self.est_best_policy = np.array(y_train_logging_u[np.argmax(self.test_pred_reward_arr, axis=1)])\n","             \n","        return self\n","    \n","class OutcomeWeightedLearning(EvaluationMetrics):\n","    \"\"\"\n","    Performs policy learning by transforming the learning problem into a \n","    weighted multi-class classification problem. \n","    \n","    \n","    References\n","    ----------\n","    \n","    .. [1] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment \n","           Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, \n","           107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.\n","    \"\"\"\n","        \n","    def __init__(self) -> None:\n","        pass\n","     \n","    def __repr__(self) -> str:\n","    \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def learn_policy(self, data, clf: str = 'SVC', **kwargs) -> None:\n","    \n","        \"\"\"\n","        Parameters\n","        ----------\n","        data : STBT object\n","            This must be a Supervised to Bandit Transform (STBT) class with fitted \n","            `generate_batch` method.\n","            \n","        clf : str, default: 'SVC'\n","        A sklearn classification estimator. Must be one of 'LogisticRegression', \n","        'LogisticRegressionCV', 'RandomForestClassifier', or 'SVC'.\n","       \n","        **kwargs : Arguments passed to clf.\n","        Returns\n","        -------\n","        int.\n","          The predicted best policy.\n","        \n","        \"\"\"    \n","        \n","        wt = data.train_logging_reward / data.train_logging_prob\n","        \n","        if clf in ['SVC', 'RandomForestClassifier']:\n","            m = eval(clf)(**kwargs).fit(data.X_train, data.y_train_logging, sample_weight = wt)\n","        elif clf in ['LogisticRegression', 'LogisticRegressionCV']:\n","            m = eval(clf)(multi_class='multinomial', **kwargs).fit(data.X_train, data.y_train_logging, sample_weight = wt)\n","        \n","        self.est_best_policy = m.predict(data.X_test)\n","        \n","        return self\n","         \n","\n","class VowpalWabbit(EvaluationMetrics):\n","    \"\"\"\n","    Performs policy learning using Vowpal Wabbit. \n","    \n","    Parameters\n","    ----------\n","    method : str, default: 'ips'\n","        The policy evaluation approach to optimize a policy. Vowpal Wabbit offers four \n","        approaches to specify a contextual bandit approach:\n","            * Inverse Propensity Score: 'ips'\n","            * Doubly Robust: 'dr'\n","            * Direct Method: 'dm'\n","            * Multi Task Regression/Importance Weighted Regression: 'mtr' \n","       \n","    References\n","    ----------\n","    \n","    .. [1] A. Bietti and A. Agarwal and J. Langford, A Contextual Bandit Bake-off, \n","        arXiv preprint arXiv:1802.04064, 2018.\n","    \n","    \"\"\"\n","\n","    def __init__(self, method = 'dr') -> None:\n","        self.method = method\n","     \n","    def __repr__(self) -> str:\n","    \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def _train_vw(self, data):\n","        n_actions = len(np.unique(data.y_train_logging))\n","        vw = pyvw.vw(str(\"--cb_type\") + \" \" +  self.method + \" \" + str(n_actions))\n","        for i in range(data.X_train.shape[0]):\n","            action = data.y_train_logging[i]\n","            cost = 1 - data.train_logging_reward[i] # input requires cost instead of reward\n","            probability = data.train_logging_prob[i]\n","            train_features_ls = list()\n","            for f in range(data.X_train.shape[1]):\n","                train_features_ls.append(str(data.X_train[i, f]))\n","                train_features = \" \".join(train_features_ls)\n","            learn_example = str(action) + \":\" + str(cost) + \":\" + str(probability) + \" | \" + train_features\n","            vw.learn(learn_example) \n","        return vw\n","    \n","    def _predict_vw(self, vw_object, data):\n","        test_features_ls = list()\n","        predictions = list()\n","        for i in range(data.X_test.shape[0]):\n","            for f in range(data.X_test.shape[1]):\n","                test_features_ls.append(str(data.X_test[i, f]))\n","                features = \" \".join(test_features_ls)\n","            test_example = \" | \" + features\n","            pred = vw_object.predict(test_example) \n","            predictions.append(pred)\n","        predictions = np.array(predictions)\n","    \n","        return predictions \n","        \n","    \n","    def learn_policy(self, data) -> None:\n","        \"\"\"\n","        Parameters\n","        ----------\n","        data : STBT object\n","            This must be a Supervised to Bandit Transform (STBT) class with fitted \n","            `generate_batch` method.\n","            \n","        Returns\n","        -------\n","        int.\n","          The predicted best policy.\n","        \n","        \"\"\" \n","        \n","        vw_fit = self._train_vw(data)\n","        self.est_best_policy = self._predict_vw(vw_fit, data)\n","        \n","        return self\n","\n","class CounterfactualRiskMinimization(EvaluationMetrics):\n","    \"\"\"\n","    Performs policy learning using the Counterfactual Risk Minimization \n","    approach proposed in [1], and later refined in [2].\n","    \n","    Parameters\n","    ----------\n","    \n","    batch_size : int, default: 96\n","        The number of samples per batch to load \n","    learning_rate : float, default: 0.01\n","        Stochastic gradient descent learning rate \n","    weight_decay : float, default: 0.001\n","        L2 regularization on parameters\n","    lambda_ : float, default: 0.1\n","        Variance regularization. Penalty on the variance of the \n","        learnt policy relative to the logging policy.\n","    self_normalize: bool, default: True\n","        Whether to normalize the IPS estimator. See [2].\n","    clipping: float, default: 100.\n","        Clipping the importance sample weights. See [1].\n","    verbose: bool, default: False\n","        Whether to print Poem Loss during training .\n","    \n","    References\n","    ----------\n","    \n","    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through \n","            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),\n","            1731--1755, 2015.\n","    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, \n","            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.\n","    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, \n","            International Conference on Learning Representations,  2018.\n","    \n","    \"\"\"\n","\n","    \n","    def __init__(self, batch_size: int = 96, learning_rate: float = 0.001, weight_decay: float = 0.001, \n","                 lambda_: float = 0.5, self_normalize: bool = True, clipping : float = 100.,\n","                 verbose: bool = False) -> None:\n","        \n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.weight_decay = weight_decay\n","        self.lambda_ = lambda_\n","        self.self_normalize = self_normalize\n","        self.clipping = clipping \n","        self.verbose = verbose\n","       \n","    def __repr__(self) -> str:\n","    \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def _poem_loss(self, pi, p0, r, y_idx, Lambda):\n","        \n","        if torch.sum(r) == 0: \n","            r = torch.repeat_interleave(torch.tensor(1e-05, dtype=torch.float), len(r))\n","        \n","        bsz = pi.shape[0]\n","        softmax_pi = F.softmax(pi, dim=1)\n","        pi_i = softmax_pi.masked_select(y_idx)\n","        log_importance = torch.log(pi_i) - torch.log(p0) \n","        importance = torch.exp(log_importance)    \n","        clip_importance_vals = torch.repeat_interleave(torch.tensor(self.clipping, dtype=torch.float), len(importance))\n","        importance = torch.min(clip_importance_vals, importance)\n","        off_policy_est = torch.mul(importance, r)\n","        # Eq.(8) in [2] \n","        var_n = torch.sum(torch.mul(torch.pow(torch.sub(r, off_policy_est), 2), torch.pow(torch.div(pi_i, p0), 2)))\n","        var_d = torch.pow(torch.sum(torch.div(pi_i, p0)), 2)\n","        empirical_var = torch.div(var_n, var_d)\n","        if self.self_normalize:\n","            effective_sample_size = torch.sum(importance).detach() # turns off requires grad\n","            mean_off_policy_est = torch.div(torch.sum(off_policy_est), effective_sample_size) \n","        else:\n","            mean_off_policy_est = torch.mean(off_policy_est)\n","        \n","        penalty = torch.mul(Lambda, torch.sqrt(torch.div(empirical_var, bsz)))\n","        loss = torch.mul(-1.0, mean_off_policy_est) + penalty\n","        \n","        return loss\n","\n","   \n","    \n","    def learn_policy(self, model, data, epochs: int = 500) -> None:\n","\n","        \"\"\"\n","        Parameters\n","        ----------\n","        data : STBT object\n","            This must be a Supervised to Bandit Transform (STBT) class with fitted \n","            `generate_batch` method.\n","        epochs : int, default \n","            Number of training epochs.\n","            \n","        Returns\n","        -------\n","        int.\n","          The predicted best policy.\n","        \n","        \"\"\" \n","        \n","        train_ds = BanditDataset(torch.from_numpy(data.X_train).float(),\n","                                 torch.from_numpy(data.y_train_logging).long(), \n","                                 torch.from_numpy(data.train_logging_prob).float(), \n","                                 torch.from_numpy(data.train_logging_reward).long(),\n","                                 torch.from_numpy(data.y_train_logging_idx).bool())\n","        \n","        \n","        n_features = train_ds.X.shape[1]\n","        actions = torch.unique(train_ds.y)\n","        n_actions = len(actions)\n","       \n","        train_dl = DataLoader(train_ds, self.batch_size)\n","        \n","        Model = model(n_features = n_features, n_actions = n_actions)\n","        \n","        optimizer = torch.optim.Adam(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  \n","       \n","        for epoch in range(epochs):\n","            Model.train()\n","            train_epoch_loss = 0.\n","            for x_batch,y_batch,p0_batch,r_batch,y_idx_batch in train_dl:\n","                pi = Model(x_batch)\n","                loss = self._poem_loss(pi, p0_batch, r_batch, y_idx_batch, self.lambda_)\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                train_epoch_loss += loss.item()\n","            if self.verbose:\n","                if epoch % 100 == 0:\n","                    print(f'Epoch {epoch}: | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}')\n","            \n","        Model.eval()\n","        with torch.no_grad():\n","            X_test = torch.from_numpy(data.X_test).float()\n","            pred = Model(X_test)\n","            est_best_policy = actions[torch.argmax(pred, dim=1)]\n","            \n","        self.est_best_policy = est_best_policy.numpy()\n","         \n","        return self\n","    \n","    \n","\n","class CounterfactualRiskMinimizationCV(CounterfactualRiskMinimization, EvaluationMetrics):\n","    \"\"\"\n","    Tune variance penalty for Counterfactual Risk Minimization.\n","    \n","    Parameters\n","    ----------\n","    \n","    batch_size : int, default: 96\n","        The number of samples per batch to load \n","    learning_rate : float, default: 0.01\n","        Stochastic gradient descent learning rate \n","    weight_decay : float, default: 0.001\n","        L2 regularization on parameters\n","    self_normalize: bool, default: True\n","        Whether to normalize the IPS estimator. See [2].\n","    clipping: float, default: 100.\n","        Clipping the importance sample weights. See [1].\n","    verbose: bool, default: True\n","        Whether to print Poem Loss during training .\n","    lambda_ : 1D array, optional, defaults to grid of values \n","        chosen in a logarithmic scale between 1e-4 and 1e+01.\n","    \n","    \"\"\"\n","    \n","    def __init__(self, batch_size: int = 96, learning_rate: float = 0.001, weight_decay: float = 0.001, \n","                 self_normalize: bool = True, clipping : float = 100., verbose: bool = False, \n","                 lambda_: np.ndarray = None) -> None:\n","        \n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.weight_decay = weight_decay\n","        self.self_normalize = self_normalize\n","        self.clipping = clipping \n","        self.verbose = verbose\n","        \n","        if lambda_ is None:\n","            self.lambda_ = 10 ** np.linspace(-4., 1., 10) # search in log scale\n","        else:\n","            self.lambda_= lambda_\n","                           \n","    def __repr__(self) -> str:\n","    \n","        items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","        return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","    def _get_params_min_loss(self, x):\n","        x = x.numpy()\n","        xmin_idx = np.unravel_index(x.argmin(), x.shape)\n","        l_best = self.lambda_[xmin_idx[0]]\n","          \n","        return l_best\n","\n","    \n","    def learn_policy(self, model, data, valid_frac: float = 0.5, epochs: int = 500) -> None:\n","        \"\"\"\n","        Parameters\n","        ----------\n","        data : STBT object\n","            This must be a Supervised to Bandit Transform (STBT) class with fitted \n","            `generate_batch` method.\n","        valid_frac : float, default: 0.5\n","            Fraction of training data set for validation. Test data are not modified. \n","        epochs : int, default: 500\n","            Number of training epochs.\n","            \n","        Returns\n","        -------\n","        int.\n","          The predicted best policy.\n","        \n","        \"\"\" \n","        \n","        self.epochs = epochs\n","        self.valid_frac = valid_frac\n","        \n","        n_train_samples, n_features = data.X_train.shape\n","        idx_valid_samples = np.random.choice(range(n_train_samples), \n","                                              size = int(np.floor(n_train_samples * valid_frac)), replace = False)\n","        \n","        train_ds = BanditDataset(torch.from_numpy(np.delete(data.X_train, idx_valid_samples, axis=0)).float(),\n","                                  torch.from_numpy(np.delete(data.y_train_logging, idx_valid_samples)).long(), \n","                                  torch.from_numpy(np.delete(data.train_logging_prob, idx_valid_samples)).float(), \n","                                  torch.from_numpy(np.delete(data.train_logging_reward, idx_valid_samples)).long(),\n","                                  torch.from_numpy(np.delete(data.y_train_logging_idx, idx_valid_samples, axis=0)).bool())\n","        \n","        \n","        valid_ds = BanditDataset(torch.from_numpy(data.X_train[idx_valid_samples, :]).float(),\n","                                  torch.from_numpy(data.y_train_logging[idx_valid_samples]).long(), \n","                                  torch.from_numpy(data.train_logging_prob[idx_valid_samples]).float(), \n","                                  torch.from_numpy(data.train_logging_reward[idx_valid_samples]).long(),\n","                                  torch.from_numpy(data.y_train_logging_idx[idx_valid_samples, :]).bool())\n","            \n","        y_train = np.delete(data.y_train, idx_valid_samples, axis=0)\n","        y_valid = data.y_train[idx_valid_samples]\n","        X_test = torch.from_numpy(data.X_test).float()\n","        \n","        actions = torch.unique(train_ds.y)\n","        n_actions = len(actions)\n","       \n","        train_dl = DataLoader(train_ds, self.batch_size)\n","        valid_dl = DataLoader(valid_ds, self.batch_size)\n","        \n","        Model = model(n_features=n_features, n_actions=n_actions)\n","        \n","        optimizer = torch.optim.Adam(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  \n","           \n","        self.train_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)   \n","        self.valid_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)\n","        self.valid_acc = torch.zeros(len(self.lambda_), epochs) \n","        self.train_acc = torch.zeros(len(self.lambda_), epochs) \n","        self.test_acc = torch.zeros(len(self.lambda_), epochs) \n","    \n","        for l_idx, l in enumerate(self.lambda_):\n","       \n","            for epoch in range(epochs):\n","                Model.train()\n","                train_epoch_loss = 0.\n","                for x_batch,y_batch,p0_batch,r_batch,y_idx_batch in train_dl:\n","                    pi = Model(x_batch)\n","                    loss = self._poem_loss(pi, p0_batch, r_batch, y_idx_batch, l)\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","                    train_epoch_loss += loss.item()\n","                self.train_tot_loss_hist[l_idx, epoch] = train_epoch_loss/len(train_dl)\n","                if self.verbose:\n","                    if epoch % 100 == 0:\n","                        print(f'Epoch: {epoch} | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}')\n","                \n","                Model.eval()\n","                with torch.no_grad():\n","                    valid_tot_loss=0.\n","                    for x_batch,y_batch,p0_batch,r_batch,y_idx_batch in valid_dl:\n","                        pi = Model(x_batch)\n","                        valid_loss = self._poem_loss(pi, p0_batch, r_batch, y_idx_batch, l)\n","                        valid_tot_loss += valid_loss.item()\n","                self.valid_tot_loss_hist[l_idx, epoch] = valid_tot_loss/len(valid_dl)\n","                if self.verbose:\n","                      if epoch % 100 == 0:\n","                          print(f'Epoch: {epoch} | Valid Poem Loss: {valid_tot_loss/len(valid_dl):.5f}')\n","                \n","                pred_train = Model(train_ds.X)\n","                est_best_policy_train = actions[torch.argmax(pred_train, dim=1)]\n","                est_best_policy_train = est_best_policy_train.numpy()\n","                self.train_acc[l_idx, epoch] = self.error_rate(est_best_policy_train, y_train)\n","                pred_valid = Model(valid_ds.X)\n","                est_best_policy_valid = actions[torch.argmax(pred_valid, dim=1)]\n","                est_best_policy_valid = est_best_policy_valid.numpy()\n","                self.valid_acc[l_idx, epoch] = self.error_rate(est_best_policy_valid, y_valid)\n","                \n","                pred_test = Model(X_test)\n","                est_best_policy_test = actions[torch.argmax(pred_test, dim=1)]\n","                est_best_policy_test = est_best_policy_test.numpy()\n","                self.test_acc[l_idx, epoch] = self.error_rate(est_best_policy_test, data.y_test)\n","            \n","                          \n","        self.l_best = self._get_params_min_loss(self.valid_tot_loss_hist)\n","            \n","    \n","        \n","        crm = CounterfactualRiskMinimization(lambda_=self.l_best, batch_size = self.batch_size,\n","                                              learning_rate = self.learning_rate, weight_decay = self.weight_decay,\n","                                              clipping = self.clipping, self_normalize = self.self_normalize, verbose = self.verbose)\n","         \n","        crm.learn_policy(model=model, data=data, epochs=epochs) \n","        self.est_best_policy = crm.est_best_policy\n","                \n","        return self\n","    \n","    def plot_cv_loss(self):\n","         \n","        train_loss_flatten = self.train_tot_loss_hist.T.flatten(1).numpy()\n","        valid_loss_flatten = self.valid_tot_loss_hist.T.flatten(1).numpy()\n","        \n","        train_acc_flatten =  self.train_acc.T.flatten(1).numpy()\n","        valid_acc_flatten = self.valid_acc.T.flatten(1).numpy()\n","        test_acc_flatten = self.test_acc.T.flatten(1).numpy()\n","        \n","        fig, axs = plt.subplots(2, 3)\n","        fs = 8\n","        \n","        for l_idx, l in enumerate(self.lambda_):\n","            axs[0, 0].plot(train_loss_flatten[:,l_idx], label = round(l, 4))\n","            axs[0, 1].plot(valid_loss_flatten[:,l_idx], label = round(l, 4))\n","            axs[1, 0].plot(train_acc_flatten[:,l_idx], label = round(l, 4))\n","            axs[1, 1].plot(valid_acc_flatten[:,l_idx], label = round(l, 4))\n","            axs[1, 2].plot(test_acc_flatten[:,l_idx], label = round(l, 4))\n","            \n","        axs[0, 0].set_title(\"Train: Poem Loss\", fontsize=fs)\n","        axs[0, 1].set_title(\"Validation: Poem Loss\", fontsize=fs)\n","        axs[1, 0].set_title(\"Train: Accuracy\", fontsize=fs)\n","        axs[1, 1].set_title(\"Validation: Accuracy\", fontsize=fs)\n","        axs[1, 2].set_title(\"Test: Accuracy\", fontsize=fs)\n","        \n","        for i, ax in enumerate(axs.flat):\n","            if i < 2:\n","                ax.set_xlabel(xlabel='Epoch', fontsize=fs)\n","                ax.set_ylabel(ylabel='Loss', fontsize=fs)\n","            else:\n","                ax.set_xlabel(xlabel='Epoch', fontsize=fs)\n","                ax.set_ylabel(ylabel='Accuracy', fontsize=fs)\n","        fig.legend(self.lambda_, loc='upper right', fontsize=fs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTHGvZCME04G"},"source":["## Alternative using Doubly Robust (as opposed to the IPS estimator)"]},{"cell_type":"code","metadata":{"id":"7CxK2hBaE2zm"},"source":["# class CounterfactualRiskMinimization(EvaluationMetrics):\n","#     \"\"\"\n","#     Performs policy learning using the Counterfactual Risk Minimization \n","#     approach proposed in [1], and later refined in [2].\n","    \n","#     Parameters\n","#     ----------\n","#     batch_size : int, default: 96\n","#         The number of samples per batch to load \n","#     learning_rate : float, default: 0.01\n","#         Stochastic gradient descent learning rate \n","#     weight_decay : float, default: 0.001\n","#         L2 regularization on parameters\n","#     lambda_ : float, default: 0.1\n","#         Variance regularization. Penalty on the variance of the \n","#         learnt policy relative to the logging policy.\n","#     self_normalize: bool, default: True\n","#         Whether to normalize the IPS estimator. See [2].\n","#     clipping: float, default: 100.\n","#         Clipping the importance sample weights. See [1].\n","#     verbose: bool, default: False\n","#         Whether to print Poem Loss during training .\n","    \n","#     References\n","#     ----------\n","    \n","#     .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through \n","#            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),\n","#            1731--1755, 2015.\n","#     .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, \n","#            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.\n","#     .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, \n","#            International Conference on Learning Representations,  2018.\n","    \n","#     \"\"\"\n","\n","    \n","#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, \n","#                  lambda_: float = 0.5, self_normalize: bool = True, clipping : float = 100.,\n","#                  verbose: bool = False) -> None:\n","#         self.batch_size = batch_size\n","#         self.learning_rate = learning_rate\n","#         self.weight_decay = weight_decay\n","#         self.lambda_ = lambda_\n","#         self.self_normalize = self_normalize\n","#         self.verbose = verbose\n","#         self.clipping = clipping \n","     \n","#     def __repr__(self) -> str:\n","    \n","#         items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","#         return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","  \n","#     def _poem_loss(self, pi, p0, r, r_pred, y_idx, Lambda, self_normalize):\n","        \n","#         #if torch.sum(r) == 0: \n","#         #    r = torch.repeat_interleave(torch.tensor(1e-05, dtype=torch.float), len(r))\n","        \n","        \n","#         bsz = pi.shape[0]\n","#         softmax_pi = F.softmax(pi, dim=1)\n","#         pi_i = softmax_pi.masked_select(y_idx)\n","#         r_pred_i = r_pred.masked_select(y_idx)\n","#         importance = torch.div(pi_i, p0) \n","#         clip_importance_vals = torch.repeat_interleave(torch.tensor(self.clipping, dtype=torch.float), len(importance))\n","#         importance_clipped = torch.min(clip_importance_vals, importance)\n","#         reward_residual = torch.sub(r, r_pred_i)\n","#         weighted_reward_pred = torch.sum(torch.mul(softmax_pi, r_pred), dim=1)\n","#         off_policy_est = torch.add(torch.mul(importance_clipped, reward_residual), weighted_reward_pred)\n","#         empirical_var = torch.var(off_policy_est)\n","        \n","#         if self_normalize:\n","#             effective_sample_size = torch.sum(importance_clipped).detach() # turns off requires grad\n","#             sum_off_policy_est = torch.div(torch.sum(off_policy_est), effective_sample_size) \n","#         else:\n","#             sum_off_policy_est = torch.sum(off_policy_est)\n","        \n","#         penalty = torch.mul(Lambda, torch.sqrt(torch.div(empirical_var, bsz)))\n","#         loss = torch.mul(-1.0, sum_off_policy_est) + penalty\n","             \n","#         return loss\n","\n","    \n","#     def learn_policy(self, model, data, epochs: int = 500) -> None:\n","\n","#         \"\"\"\n","#         Parameters\n","#         ----------\n","#         data : STBT object\n","#             This must be a Supervised to Bandit Transform (STBT) class with fitted \n","#             `generate_batch` method.\n","#         epochs : int, default \n","#             Number of training epochs.\n","            \n","#         Returns\n","#         -------\n","#         int.\n","#           The predicted best policy.\n","        \n","#         \"\"\" \n","        \n","#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)\n","        \n","#         train_ds = BanditDataset(torch.from_numpy(data.X_train).float(),\n","#                                  torch.from_numpy(data.y_train_logging).long(), \n","#                                  torch.from_numpy(data.train_logging_prob).float(), \n","#                                  torch.from_numpy(data.train_logging_reward).long(),\n","#                                  torch.from_numpy(data.y_train_logging_idx).bool(),\n","#                                  torch.from_numpy(rp.train_pred_reward_arr).float() \n","#                                  )\n","        \n","        \n","#         n_features = train_ds.X.shape[1]\n","#         actions = torch.unique(train_ds.y)\n","#         n_actions = len(actions)\n","       \n","#         train_dl = DataLoader(train_ds, self.batch_size)\n","        \n","#         Model = model(n_features = n_features, n_actions = n_actions)\n","        \n","#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  \n","        \n","#         for epoch in range(epochs):\n","#             Model.train()\n","#             train_epoch_loss = 0.\n","#             for x_batch, y_batch, p0_batch, r_batch, y_idx_batch, r_pred_batch in train_dl:\n","#                 pi = Model(x_batch)\n","#                 loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, self.lambda_, self.self_normalize)\n","#                 loss.backward()\n","#                 optimizer.step()\n","#                 optimizer.zero_grad()\n","#                 train_epoch_loss += loss.item()\n","#             if self.verbose:\n","#                 print(f'Epoch {epoch}: | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}')\n","            \n","#         Model.eval()\n","#         with torch.no_grad():\n","#            X_test = torch.from_numpy(data.X_test).float()\n","#            pred = Model(X_test)\n","#            est_best_policy = actions[torch.argmax(pred, dim=1)]\n","            \n","#         self.est_best_policy = est_best_policy.numpy()\n","         \n","#         return self\n","    \n","    \n","\n","# class CounterfactualRiskMinimizationCV(CounterfactualRiskMinimization, EvaluationMetrics):\n","#     \"\"\"\n","#     Tune variance regularizer for Counterfactual Risk Minimization.\n","    \n","#     Parameters\n","#     ----------\n","    \n","#     batch_size : int, default: 96\n","#         The number of samples per batch to load \n","#     learning_rate : float, default: 0.01\n","#         Stochastic gradient descent learning rate \n","#     weight_decay : float, default: 0.001\n","#         L2 regularization on parameters\n","#     clipping: float, default: 100.\n","#         Clipping the importance sample weights. See [1].\n","#     self_normalize: bool, default: True\n","#         Whether to normalize the IPS estimator. See [2].\n","#     verbose: bool, default: True\n","#         Whether to print Poem Loss during training .\n","#     lambda_ : 1D array, optional, defaults to grid of values \n","#         chosen in a logarithmic scale between 1e-4 and 1e+01.\n","    \n","#     \"\"\"\n","    \n","#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, \n","#                  clipping : float = 100., self_normalize: bool = True, verbose: bool = False, \n","#                  lambda_: np.ndarray = None) -> None:\n","        \n","#         self.batch_size = batch_size\n","#         self.learning_rate = learning_rate\n","#         self.weight_decay = weight_decay\n","#         self.clipping = clipping \n","#         self.self_normalize = self_normalize\n","#         self.verbose = verbose\n","        \n","#         if lambda_ is None:\n","#             self.lambda_ = 10 ** np.linspace(-4., 1., 10) # search in log scale\n","#         else:\n","#             self.lambda_= lambda_\n","                           \n","#     def __repr__(self) -> str:\n","    \n","#         items = (\"%s = %r\" % (k, v) for k, v in self.__dict__.items())\n","#         return \"<%s: {%s}>\" % (self.__class__.__name__, ', '.join(items))\n","    \n","#     def _get_params_min_loss(self, x):\n","#         x = x.numpy()\n","#         xmin_idx = np.unravel_index(x.argmin(), x.shape)\n","#         l_best = self.lambda_[xmin_idx[0]]\n","          \n","#         return l_best\n","\n","    \n","#     def learn_policy(self, model, data, valid_frac: float = 0.5, epochs: int = 500) -> None:\n","#         \"\"\"\n","#         Parameters\n","#         ----------\n","#         data : STBT object\n","#             This must be a Supervised to Bandit Transform (STBT) class with fitted \n","#             `generate_batch` method.\n","#         valid_frac : float, default: 0.5\n","#             Fraction of training data set for validation. Test data are not modified. \n","#         epochs : int, default: 500\n","#             Number of training epochs.\n","            \n","#         Returns\n","#         -------\n","#         int.\n","#           The predicted best policy.\n","        \n","#         \"\"\" \n","        \n","#         self.epochs = epochs\n","#         self.valid_frac = valid_frac\n","        \n","#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)\n","        \n","#         n_train_samples, n_features = data.X_train.shape\n","#         idx_valid_samples = np.random.choice(range(n_train_samples), \n","#                                              size = int(np.floor(n_train_samples * valid_frac)), replace = False)\n","        \n","#         train_ds = BanditDataset(torch.from_numpy(np.delete(data.X_train, idx_valid_samples, axis=0)).float(),\n","#                                  torch.from_numpy(np.delete(data.y_train_logging, idx_valid_samples)).long(), \n","#                                  torch.from_numpy(np.delete(data.train_logging_prob, idx_valid_samples)).float(), \n","#                                  torch.from_numpy(np.delete(data.train_logging_reward, idx_valid_samples)).long(),\n","#                                  torch.from_numpy(np.delete(data.y_train_logging_idx, idx_valid_samples, axis=0)).bool(), \n","#                                  torch.from_numpy(np.delete(rp.train_pred_reward_arr, idx_valid_samples, axis=0)).float()\n","#                                  )\n","        \n","        \n","#         valid_ds = BanditDataset(torch.from_numpy(data.X_train[idx_valid_samples, :]).float(),\n","#                                  torch.from_numpy(data.y_train_logging[idx_valid_samples]).long(), \n","#                                  torch.from_numpy(data.train_logging_prob[idx_valid_samples]).float(), \n","#                                  torch.from_numpy(data.train_logging_reward[idx_valid_samples]).long(),\n","#                                  torch.from_numpy(data.y_train_logging_idx[idx_valid_samples, :]).bool(),\n","#                                  torch.from_numpy(rp.train_pred_reward_arr[idx_valid_samples, :]).float()\n","#                                  )\n","            \n","#         y_train = np.delete(data.y_train, idx_valid_samples, axis=0)\n","#         y_valid = data.y_train[idx_valid_samples]\n","#         X_test = torch.from_numpy(data.X_test).float()\n","        \n","#         actions = torch.unique(train_ds.y)\n","#         n_actions = len(actions)\n","       \n","#         train_dl = DataLoader(train_ds, self.batch_size)\n","#         valid_dl = DataLoader(valid_ds, self.batch_size)\n","        \n","#         Model = model(n_features=n_features, n_actions=n_actions)\n","        \n","#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  \n","           \n","#         self.train_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)   \n","#         self.valid_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)\n","#         self.valid_acc = torch.zeros(len(self.lambda_), epochs) \n","#         self.train_acc = torch.zeros(len(self.lambda_), epochs) \n","#         self.test_acc = torch.zeros(len(self.lambda_), epochs) \n","    \n","#         for l_idx, l in enumerate(self.lambda_):\n","       \n","#             for epoch in range(epochs):\n","#                 Model.train()\n","#                 train_epoch_loss = 0.\n","#                 for x_batch, y_batch, p0_batch,r_batch,y_idx_batch,r_pred_batch in train_dl:\n","#                     pi = Model(x_batch)\n","#                     loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)\n","#                     loss.backward()\n","#                     optimizer.step()\n","#                     optimizer.zero_grad()\n","#                     train_epoch_loss += loss.item()\n","#                 self.train_tot_loss_hist[l_idx, epoch] = train_epoch_loss/len(train_dl)\n","#                 if self.verbose:\n","#                     print(f'Epoch: {epoch} | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}')\n","                \n","#                 Model.eval()\n","#                 with torch.no_grad():\n","#                     valid_tot_loss=0.\n","#                     for x_batch,y_batch,p0_batch,r_batch,y_idx_batch,r_pred_batch in valid_dl:\n","#                         pi = Model(x_batch)\n","#                         valid_loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)\n","#                         valid_tot_loss += valid_loss.item()\n","#                 self.valid_tot_loss_hist[l_idx, epoch] = valid_tot_loss/len(valid_dl)\n","#                 if self.verbose:\n","#                       print(f'Epoch: {epoch} | Valid Poem Loss: {valid_tot_loss/len(valid_dl):.5f}')\n","                \n","#                 pred_train = Model(train_ds.X)\n","#                 est_best_policy_train = actions[torch.argmax(pred_train, dim=1)]\n","#                 est_best_policy_train = est_best_policy_train.numpy()\n","#                 self.train_acc[l_idx, epoch] = self.error_rate(est_best_policy_train, y_train)\n","#                 pred_valid = Model(valid_ds.X)\n","#                 est_best_policy_valid = actions[torch.argmax(pred_valid, dim=1)]\n","#                 est_best_policy_valid = est_best_policy_valid.numpy()\n","#                 self.valid_acc[l_idx, epoch] = self.error_rate(est_best_policy_valid, y_valid)\n","                \n","#                 pred_test = Model(X_test)\n","#                 est_best_policy_test = actions[torch.argmax(pred_test, dim=1)]\n","#                 est_best_policy_test = est_best_policy_test.numpy()\n","#                 self.test_acc[l_idx, epoch] = self.error_rate(est_best_policy_test, data.y_test)\n","            \n","                          \n","#         self.l_best = self._get_params_min_loss(self.valid_tot_loss_hist)\n","            \n","    \n","        \n","#         crm = CounterfactualRiskMinimization(lambda_=self.l_best, batch_size = self.batch_size,\n","#                                              learning_rate = self.learning_rate, weight_decay = self.weight_decay,\n","#                                              clipping = self.clipping, self_normalize = self.self_normalize, verbose = self.verbose)\n","        \n","#         crm.learn_policy(model=model, data=data, epochs=epochs) \n","#         self.est_best_policy = crm.est_best_policy\n","                \n","#         return self\n","    \n","#     def plot_cv_loss(self):\n","         \n","#         train_loss_flatten = self.train_tot_loss_hist.T.flatten(1).numpy()\n","#         valid_loss_flatten = self.valid_tot_loss_hist.T.flatten(1).numpy()\n","        \n","#         train_acc_flatten =  self.train_acc.T.flatten(1).numpy()\n","#         valid_acc_flatten = self.valid_acc.T.flatten(1).numpy()\n","#         test_acc_flatten = self.test_acc.T.flatten(1).numpy()\n","        \n","#         fig, axs = plt.subplots(2, 3)\n","#         fs = 8\n","        \n","#         for l_idx, l in enumerate(self.lambda_):\n","#             axs[0, 0].plot(train_loss_flatten[:,l_idx], label = round(l, 4))\n","#             axs[0, 1].plot(valid_loss_flatten[:,l_idx], label = round(l, 4))\n","#             axs[1, 0].plot(train_acc_flatten[:,l_idx], label = round(l, 4))\n","#             axs[1, 1].plot(valid_acc_flatten[:,l_idx], label = round(l, 4))\n","#             axs[1, 2].plot(test_acc_flatten[:,l_idx], label = round(l, 4))\n","            \n","#         axs[0, 0].set_title(\"Train: Poem Loss\", fontsize=fs)\n","#         axs[0, 1].set_title(\"Validation: Poem Loss\", fontsize=fs)\n","#         axs[1, 0].set_title(\"Train: Accuracy\", fontsize=fs)\n","#         axs[1, 1].set_title(\"Validation: Accuracy\", fontsize=fs)\n","#         axs[1, 2].set_title(\"Test: Accuracy\", fontsize=fs)\n","        \n","#         for i, ax in enumerate(axs.flat):\n","#             if i < 2:\n","#                 ax.set_xlabel(xlabel='Epoch', fontsize=fs)\n","#                 ax.set_ylabel(ylabel='Loss', fontsize=fs)\n","#             else:\n","#                 ax.set_xlabel(xlabel='Epoch', fontsize=fs)\n","#                 ax.set_ylabel(ylabel='Accuracy', fontsize=fs)\n","#         fig.legend(self.lambda_, loc='upper right', fontsize=fs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANRUFyRVFJT_"},"source":["## Read data"]},{"cell_type":"code","metadata":{"id":"L2sNkHX7FeJ6"},"source":["np.random.seed(1)\n","X, y = get_data(dataset= 'glass')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Akh4wU7FhsV"},"source":["## Perform Supervised-to-Bandit Conversion\n","Performs Supervised to Bandit Conversion for classification datasets. This conversion is generally used to test the limits of counterfactual learning in a well-controlled environment.\n","\n","Here, we take a supervised dataset with features x and labeled classes y, and simulate a bandit feedback data set from a logging policy. Basically, this involves: (i) simulating a stochastic logging policy, which may be uniform (logging_type='uniform'), or given as a function of covariates (logging_type = 'biased'), (ii) when the logging policy for a given observation equals the optimal policy (true label), a positive reward is observed."]},{"cell_type":"code","metadata":{"id":"SEjRi6zDFlY4"},"source":["data = STBT(train_frac= 0.5, logging_type='biased').generate_batch(X, y, max_iter=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ID37lE_RFsh6"},"source":["## Skyline\n","Best possible error rate, assuming we have full feedback (this can only be tested from the simulation as in practice as we have bandit feedback)x."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBbfgH06Fu3C","executionInfo":{"status":"ok","timestamp":1633448089644,"user_tz":-330,"elapsed":2011,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"04cb9fde-0d4b-431a-f157-4ac214f085b1"},"source":["clf = LogisticRegressionCV(multi_class='multinomial', max_iter=2000).fit(data.X_train, data.y_train)\n","optimal_policy = clf.predict(data.X_test)\n","print(\"Skyline Error:\", EvaluationMetrics.error_rate(optimal_policy, data.y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skyline Error: 0.30841121495327106\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6WMQEBAFyc8","executionInfo":{"status":"ok","timestamp":1633448089646,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"40deeec7-7de7-4e7d-ece2-b3c8965870ab"},"source":["## Reward Predictor (RP)\n","rp = RewardPredictor()\n","rp.learn_policy(data, max_iter=1000)\n","print(\"Reward Predictor Error:\", rp.error_rate(rp.est_best_policy, data.y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reward Predictor Error: 0.7009345794392523\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UregJYjF13T","executionInfo":{"status":"ok","timestamp":1633448098439,"user_tz":-330,"elapsed":646,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c770f7c2-c8b1-47b5-e9ca-2084b6642db2"},"source":["## Outcome Weighted Learning (OWL)\n","owl = OutcomeWeightedLearning()\n","owl.learn_policy(data, clf = 'LogisticRegressionCV', max_iter=1000)\n","print(\"OWL-LR:\", owl.error_rate(owl.est_best_policy, data.y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["OWL-LR: 0.7289719626168225\n"]}]},{"cell_type":"markdown","metadata":{"id":"CLnzYa8bGG4N"},"source":["## Counterfactual Risk Minimization (CRM)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"levG8SWBF-p7","executionInfo":{"status":"ok","timestamp":1633448121354,"user_tz":-330,"elapsed":6418,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"843d16bb-3faf-4fe2-c326-dde45d1d389c"},"source":["crm = CounterfactualRiskMinimization(verbose=True, lambda_ = 1e-06)\n","crm.learn_policy(model=LinearModel, data=data, epochs = 2000)\n","print(\"CRM:\", crm.error_rate(crm.est_best_policy, data.y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: | Train Poem Loss: -0.10087\n","Epoch 100: | Train Poem Loss: -0.23397\n","Epoch 200: | Train Poem Loss: -0.37680\n","Epoch 300: | Train Poem Loss: -0.49386\n","Epoch 400: | Train Poem Loss: -0.54733\n","Epoch 500: | Train Poem Loss: -0.57395\n","Epoch 600: | Train Poem Loss: -0.58959\n","Epoch 700: | Train Poem Loss: -0.60032\n","Epoch 800: | Train Poem Loss: -0.60866\n","Epoch 900: | Train Poem Loss: -0.61578\n","Epoch 1000: | Train Poem Loss: -0.62223\n","Epoch 1100: | Train Poem Loss: -0.62831\n","Epoch 1200: | Train Poem Loss: -0.63413\n","Epoch 1300: | Train Poem Loss: -0.63967\n","Epoch 1400: | Train Poem Loss: -0.64488\n","Epoch 1500: | Train Poem Loss: -0.64968\n","Epoch 1600: | Train Poem Loss: -0.65401\n","Epoch 1700: | Train Poem Loss: -0.65786\n","Epoch 1800: | Train Poem Loss: -0.66122\n","Epoch 1900: | Train Poem Loss: -0.66412\n","CRM: 0.719626168224299\n"]}]},{"cell_type":"markdown","metadata":{"id":"dMXQbGB3GCw3"},"source":["## Experiments"]},{"cell_type":"code","metadata":{"id":"vFs_4fd1GJq0"},"source":["## Params\n","B = 10 # Number of simulations\n","EPOCHS = 500\n","LOGGING_TYPE = 'biased'\n","MODEL = LinearModel\n","LAMBDA = 1e-06\n","DATASETS = ['ecoli', 'glass', 'lymphography', 'yeast', 'digits', 'breast-cancer', 'wine', 'letter-recognition']\n","dat = list()\n","skyline_error = list()\n","randomized_error = list()\n","reward_predictor_error = list()\n","owl_lrcv_error = list()\n","crm_error = list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTaeEnReGMD4","executionInfo":{"status":"ok","timestamp":1633450881363,"user_tz":-330,"elapsed":2673628,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0e6fd501-3a30-4202-d6c7-ca516983ba6c"},"source":["for s in DATASETS:\n","    \n","    X, y = get_data(dataset=s)\n","    \n","    for b in range(B):\n","        if (b % 10) == 0:\n","            print(\"Sample: %d - Dataset: %s\" % (b, s))\n","        \n","        d = STBT(logging_type = LOGGING_TYPE).generate_batch(X, y, max_iter=1000)\n","        dat.append(s)    \n","       \n","        skyline = LogisticRegression(multi_class='multinomial', max_iter=2000).fit(d.X_train, d.y_train)\n","        optimal_policy = skyline.predict(d.X_test)\n","        \n","        rp = RewardPredictor().learn_policy(data=d, max_iter=1000)\n","        erm_lrcv = OutcomeWeightedLearning().learn_policy(data=d, clf = 'LogisticRegressionCV', max_iter=1000)\n","        crm = CounterfactualRiskMinimization(lambda_=LAMBDA).learn_policy(model=MODEL, data=d, epochs=EPOCHS)     \n","        \n","        skyline_error.append(EvaluationMetrics.error_rate(optimal_policy, d.y_test))\n","        randomized_error.append(EvaluationMetrics.error_rate(d.y_test_logging, d.y_test))\n","        reward_predictor_error.append(rp.error_rate(rp.est_best_policy, d.y_test))\n","        owl_lrcv_error.append(erm_lrcv.error_rate(erm_lrcv.est_best_policy, d.y_test))\n","        crm_error.append(crm.error_rate(crm.est_best_policy, d.y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample: 0 - Dataset: ecoli\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Sample: 0 - Dataset: glass\n","Sample: 0 - Dataset: lymphography\n","Sample: 0 - Dataset: yeast\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Sample: 0 - Dataset: digits\n","Sample: 0 - Dataset: breast-cancer\n","Sample: 0 - Dataset: wine\n","Sample: 0 - Dataset: letter-recognition\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"IpKgg5l6GSxm","executionInfo":{"status":"ok","timestamp":1633451101502,"user_tz":-330,"elapsed":628,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"2a52bbdc-47a4-44fd-aa24-397cd7d3dcdf"},"source":["res = pd.DataFrame.from_dict({'dataset':dat[1:], 'skyline_error': skyline_error, 'randomized_error':randomized_error, 'reward_predictor_error':reward_predictor_error,\n","                              'owl_lrcv_error':owl_lrcv_error, 'crm_error':crm_error})\n","\n","res_summary = res.groupby(['dataset'], as_index=False).agg({\n","                            'skyline_error': ['mean','std'], \n","                            'randomized_error': ['mean','std'], \n","                            'reward_predictor_error': ['mean','std'],\n","                            'owl_lrcv_error': ['mean','std'],\n","                            'crm_error': ['mean','std']\n","                            })\n","\n","res_summary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>dataset</th>\n","      <th colspan=\"2\" halign=\"left\">skyline_error</th>\n","      <th colspan=\"2\" halign=\"left\">randomized_error</th>\n","      <th colspan=\"2\" halign=\"left\">reward_predictor_error</th>\n","      <th colspan=\"2\" halign=\"left\">owl_lrcv_error</th>\n","      <th colspan=\"2\" halign=\"left\">crm_error</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>breast-cancer</td>\n","      <td>0.029123</td>\n","      <td>0.009792</td>\n","      <td>0.558596</td>\n","      <td>0.191854</td>\n","      <td>0.026667</td>\n","      <td>0.009813</td>\n","      <td>0.209825</td>\n","      <td>0.162483</td>\n","      <td>0.064561</td>\n","      <td>0.051467</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>digits</td>\n","      <td>0.036151</td>\n","      <td>0.004104</td>\n","      <td>0.888432</td>\n","      <td>0.054886</td>\n","      <td>0.376529</td>\n","      <td>0.096568</td>\n","      <td>0.529366</td>\n","      <td>0.120459</td>\n","      <td>0.426251</td>\n","      <td>0.111795</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ecoli</td>\n","      <td>0.132937</td>\n","      <td>0.018231</td>\n","      <td>0.835714</td>\n","      <td>0.093679</td>\n","      <td>0.278175</td>\n","      <td>0.043127</td>\n","      <td>0.397619</td>\n","      <td>0.178276</td>\n","      <td>0.310714</td>\n","      <td>0.080024</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>glass</td>\n","      <td>0.401869</td>\n","      <td>0.037642</td>\n","      <td>0.825234</td>\n","      <td>0.061372</td>\n","      <td>0.588785</td>\n","      <td>0.103134</td>\n","      <td>0.591589</td>\n","      <td>0.080883</td>\n","      <td>0.629907</td>\n","      <td>0.093996</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>letter-recognition</td>\n","      <td>0.228200</td>\n","      <td>0.004190</td>\n","      <td>0.966280</td>\n","      <td>0.011429</td>\n","      <td>0.737560</td>\n","      <td>0.031631</td>\n","      <td>0.713590</td>\n","      <td>0.030353</td>\n","      <td>0.741250</td>\n","      <td>0.028611</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>lymphography</td>\n","      <td>0.168919</td>\n","      <td>0.032638</td>\n","      <td>0.748649</td>\n","      <td>0.075965</td>\n","      <td>0.295946</td>\n","      <td>0.067553</td>\n","      <td>0.347297</td>\n","      <td>0.111444</td>\n","      <td>0.410811</td>\n","      <td>0.119722</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>wine</td>\n","      <td>0.026966</td>\n","      <td>0.022596</td>\n","      <td>0.723596</td>\n","      <td>0.098695</td>\n","      <td>0.065169</td>\n","      <td>0.047611</td>\n","      <td>0.365169</td>\n","      <td>0.104097</td>\n","      <td>0.158427</td>\n","      <td>0.094074</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yeast</td>\n","      <td>0.411456</td>\n","      <td>0.011078</td>\n","      <td>0.901482</td>\n","      <td>0.024659</td>\n","      <td>0.516981</td>\n","      <td>0.058388</td>\n","      <td>0.606334</td>\n","      <td>0.062139</td>\n","      <td>0.569946</td>\n","      <td>0.045408</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              dataset skyline_error            ... owl_lrcv_error crm_error          \n","                               mean       std  ...            std      mean       std\n","0       breast-cancer      0.029123  0.009792  ...       0.162483  0.064561  0.051467\n","1              digits      0.036151  0.004104  ...       0.120459  0.426251  0.111795\n","2               ecoli      0.132937  0.018231  ...       0.178276  0.310714  0.080024\n","3               glass      0.401869  0.037642  ...       0.080883  0.629907  0.093996\n","4  letter-recognition      0.228200  0.004190  ...       0.030353  0.741250  0.028611\n","5        lymphography      0.168919  0.032638  ...       0.111444  0.410811  0.119722\n","6                wine      0.026966  0.022596  ...       0.104097  0.158427  0.094074\n","7               yeast      0.411456  0.011078  ...       0.062139  0.569946  0.045408\n","\n","[8 rows x 11 columns]"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"U7B5OwaeGg5E"},"source":["## References\n","[1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52), 1731--1755, 2015.\n","\n","[2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.\n","\n","[3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, International Conference on Learning Representations, 2018.\n","\n","[4] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, 107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.\n","\n","[5] Y. Wang, A. Agarwal and M. Dud'{\\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, Proceedings of Machine Learning Research, 70, 3589--3597, 2017.\n","\n","[6] M. Dudik and J. Langford and L. Li, Doubly Robust Policy Evaluation and Learning, CoRR, 2011. http://arxiv.org/abs/1103.4601\n","\n","[7] K{\"u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous treatment effects using machine learning, Proceedings of the National Academy of Sciences, 116(10), 4156--4165, 2019.\n","\n","[8] Batch Learning from Bandit Feedback (BLBF). https://github.com/leoguelman/BLBF."]}]}