{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.xdeepfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xDeepFM\n",
    "> A pytorch implementation of Extreme Deep Factorization Machines (xDeepFM).\n",
    "\n",
    "xDeepFM combines the CIN and a classical DNN into one unified model. xDeepFM is able to learn certain bounded-degree feature interactions explicitly; on the other hand, it can learn arbitrary low- and high-order feature interactions implicitly.\n",
    "\n",
    "**The architecture of xDeepFM.**\n",
    "<img src='https://github.com/RecoHut-Stanzas/S021355/raw/main/images/img13.png'>\n",
    "\n",
    "Compressed Interaction Network (CIN) aims to generate feature interactions in an explicit fashion and at the vector-wise level. CIN share some functionalities with convolutional neural networks (CNNs) and recurrent neural networks (RNNs).\n",
    "\n",
    "**Components and architecture of the Compressed Interaction Network (CIN).**\n",
    "<img src='https://github.com/RecoHut-Stanzas/S021355/raw/main/images/img14.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from recohut.models.layers.embedding import EmbeddingLayer\n",
    "from recohut.models.layers.common import MLP_Layer, LR_Layer\n",
    "from recohut.models.layers.interaction import CompressedInteractionNet\n",
    "\n",
    "from recohut.models.bases.ctr import CTRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class xDeepFM(CTRModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"xDeepFM\",\n",
    "                 task=\"binary_classification\",\n",
    "                 learning_rate=1e-3, \n",
    "                 embedding_initializer=\"torch.nn.init.normal_(std=1e-4)\",\n",
    "                 embedding_dim=10, \n",
    "                 dnn_hidden_units=[64, 64, 64], \n",
    "                 dnn_activations=\"ReLU\",\n",
    "                 cin_layer_units=[16, 16, 16], \n",
    "                 net_dropout=0, \n",
    "                 batch_norm=False, \n",
    "                 **kwargs):\n",
    "        super(xDeepFM, self).__init__(feature_map, \n",
    "                                           model_id=model_id,\n",
    "                                           **kwargs)\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        input_dim = feature_map.num_fields * embedding_dim\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=1, \n",
    "                             hidden_units=dnn_hidden_units,\n",
    "                             hidden_activations=dnn_activations,\n",
    "                             output_activation=None, \n",
    "                             dropout_rates=net_dropout, \n",
    "                             batch_norm=batch_norm, \n",
    "                             use_bias=True) \\\n",
    "                   if dnn_hidden_units else None # in case of only CIN used\n",
    "        self.lr_layer = LR_Layer(feature_map, output_activation=None, use_bias=False)\n",
    "        self.cin = CompressedInteractionNet(feature_map.num_fields, cin_layer_units, output_dim=1)\n",
    "        self.output_activation = self.get_final_activation(task)\n",
    "        self.init_weights(embedding_initializer=embedding_initializer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature_emb = self.embedding_layer(inputs) # list of b x embedding_dim\n",
    "        lr_logit = self.lr_layer(inputs)\n",
    "        cin_logit = self.cin(feature_emb)\n",
    "        if self.dnn is not None:\n",
    "            dnn_logit = self.dnn(feature_emb.flatten(start_dim=1))\n",
    "            y_pred = lr_logit + cin_logit + dnn_logit # LR + CIN + DNN\n",
    "        else:\n",
    "            y_pred = lr_logit + cin_logit # only LR + CIN\n",
    "        if self.output_activation is not None:\n",
    "            y_pred = self.output_activation(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'model_id': 'xDeepFM',\n",
    "              'data_dir': '/content/data',\n",
    "              'model_root': './checkpoints/',\n",
    "              'learning_rate': 1e-3,\n",
    "              'optimizer': 'adamw',\n",
    "              'task': 'binary_classification',\n",
    "              'loss': 'binary_crossentropy',\n",
    "              'metrics': ['logloss', 'AUC'],\n",
    "              'embedding_dim': 10,\n",
    "              'dnn_hidden_units': [500, 500, 500],\n",
    "              'cin_layer_units': [32, 32, 32],\n",
    "              'hidden_activations': 'relu',\n",
    "              'net_dropout': 0,\n",
    "              'batch_size': 64,\n",
    "              'epochs': 3,\n",
    "              'shuffle': True,\n",
    "              'seed': 2019,\n",
    "              'use_hdf5': True,\n",
    "              'workers': 1,\n",
    "              'verbose': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xDeepFM(ds.dataset.feature_map, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type                     | Params\n",
      "---------------------------------------------------------------\n",
      "0 | embedding_layer   | EmbeddingLayer           | 4.8 K \n",
      "1 | dnn               | MLP_Layer                | 572 K \n",
      "2 | lr_layer          | LR_Layer                 | 476   \n",
      "3 | cin               | CompressedInteractionNet | 35.1 K\n",
      "4 | output_activation | Sigmoid                  | 0     \n",
      "---------------------------------------------------------------\n",
      "612 K     Trainable params\n",
      "0         Non-trainable params\n",
      "612 K     Total params\n",
      "2.449     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2beefdcd50140a9a47719b49c8afbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88835510e92941f693c0ec00e33f2f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915bda10ef3146ae84b4c1b73891abed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.1219)}}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.1219)}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_trainer(model, ds, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "\n",
    "from recohut.models.layers.common import FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CompressedInteractionNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, cross_layer_sizes, split_half=True):\n",
    "        super().__init__()\n",
    "        self.num_layers = len(cross_layer_sizes)\n",
    "        self.split_half = split_half\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        prev_dim, fc_input_dim = input_dim, 0\n",
    "        for i in range(self.num_layers):\n",
    "            cross_layer_size = cross_layer_sizes[i]\n",
    "            self.conv_layers.append(torch.nn.Conv1d(input_dim * prev_dim, cross_layer_size, 1,\n",
    "                                                    stride=1, dilation=1, bias=True))\n",
    "            if self.split_half and i != self.num_layers - 1:\n",
    "                cross_layer_size //= 2\n",
    "            prev_dim = cross_layer_size\n",
    "            fc_input_dim += prev_dim\n",
    "        self.fc = torch.nn.Linear(fc_input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        xs = list()\n",
    "        x0, h = x.unsqueeze(2), x\n",
    "        for i in range(self.num_layers):\n",
    "            x = x0 * h.unsqueeze(1)\n",
    "            batch_size, f0_dim, fin_dim, embed_dim = x.shape\n",
    "            x = x.view(batch_size, f0_dim * fin_dim, embed_dim)\n",
    "            x = F.relu(self.conv_layers[i](x))\n",
    "            if self.split_half and i != self.num_layers - 1:\n",
    "                x, h = torch.split(x, x.shape[1] // 2, dim=1)\n",
    "            else:\n",
    "                h = x\n",
    "            xs.append(x)\n",
    "        return self.fc(torch.sum(torch.cat(xs, dim=1), 2))\n",
    "\n",
    "\n",
    "class xDeepFM_v2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A pytorch implementation of xDeepFM.\n",
    "    Reference:\n",
    "        J Lian, et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims, dropout, cross_layer_sizes, split_half=True):\n",
    "        super().__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.cin = CompressedInteractionNetwork(len(field_dims), cross_layer_sizes, split_half)\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n",
    "        self.linear = FeaturesLinear(field_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        embed_x = self.embedding(x)\n",
    "        x = self.linear(x) + self.cin(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n",
    "        return torch.sigmoid(x.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **References:-**\n",
    "- J Lian, et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, 2018.\n",
    "- https://github.com/rixwew/pytorch-fm/blob/master/torchfm/model/xdfm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
