{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-18-sdlib.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T006054%20%7C%20SDLib.ipynb","timestamp":1644647380904}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNIMtcFr0K1BrltUr4EkRbV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X7ppGxG8tVvE"},"source":["# Shilling simulated attacks and detection methods"]},{"cell_type":"markdown","metadata":{"id":"SYGvUUUTtjph"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"N2ItYIT7-FDW"},"source":["!mkdir -p results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qTLZ7TT5vMPN"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"9QQSmT2-vNZk"},"source":["from collections import defaultdict\n","import numpy as np\n","import random\n","import os\n","import os.path\n","from os.path import abspath\n","from os import makedirs,remove\n","from re import compile,findall,split\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics.pairwise import pairwise_distances,cosine_similarity\n","from numpy.linalg import norm\n","from scipy.stats.stats import pearsonr\n","from math import sqrt,exp\n","\n","import sys\n","from re import split\n","from multiprocessing import Process,Manager\n","from time import strftime,localtime,time\n","import re\n","\n","from os.path import abspath\n","from time import strftime,localtime,time\n","from sklearn.metrics import classification_report\n","from re import split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from random import shuffle\n","from sklearn.tree import DecisionTreeClassifier\n","import time as tm\n","\n","from sklearn.metrics import classification_report\n","import numpy as np\n","from collections import defaultdict\n","from math import log,exp\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from random import choice\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","import random\n","\n","from sklearn.metrics import classification_report\n","import numpy as np\n","from collections import defaultdict\n","from math import log,exp\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.metrics import classification_report\n","from sklearn import metrics\n","\n","from sklearn.metrics import classification_report\n","from sklearn import preprocessing\n","from sklearn import metrics\n","import scipy\n","from scipy.sparse import csr_matrix\n","\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","import math\n","from sklearn.naive_bayes import GaussianNB"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOwMLh6_9ok0"},"source":["## Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a41XYOT-DZg","executionInfo":{"status":"ok","timestamp":1634217832326,"user_tz":-330,"elapsed":1409,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d09d3bf4-6143-40f1-cf37-2812480c4713"},"source":["!mkdir -p dataset/amazon\n","!cd dataset/amazon && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/amazon/profiles.txt\n","!cd dataset/amazon && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/amazon/labels.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["profiles.txt.2      100%[===================>]   1.46M  --.-KB/s    in 0.01s   \n","labels.txt.2        100%[===================>]  82.62K  --.-KB/s    in 0.002s  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JV8I8iqLy8-W","executionInfo":{"status":"ok","timestamp":1634217826906,"user_tz":-330,"elapsed":1267,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"4c40d1db-265e-46fe-f788-f84edf11ccb6"},"source":["!mkdir -p dataset/averageattack\n","!cd dataset/averageattack && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/averageattack/ratings.txt\n","!cd dataset/averageattack && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/averageattack/labels.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ratings.txt         100%[===================>] 531.60K  --.-KB/s    in 0.007s  \n","labels.txt          100%[===================>]  10.25K  --.-KB/s    in 0s      \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPu_agBp-R9D","executionInfo":{"status":"ok","timestamp":1634217866087,"user_tz":-330,"elapsed":1220,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"457130bc-9e7b-458d-af44-bcf7c5907817"},"source":["!mkdir -p dataset/filmtrust\n","!cd dataset/filmtrust && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/filmtrust/ratings.txt\n","!cd dataset/filmtrust && wget -q --show-progress https://github.com/Coder-Yu/SDLib/raw/master/dataset/filmtrust/trust.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ratings.txt         100%[===================>] 367.62K  --.-KB/s    in 0.006s  \n","trust.txt           100%[===================>]  19.15K  --.-KB/s    in 0s      \n"]}]},{"cell_type":"markdown","metadata":{"id":"OQCzsVZRt2ZB"},"source":["## Config"]},{"cell_type":"markdown","metadata":{"id":"5WkBfSket3c-"},"source":["### Configure the Detection Method\n","\n","<div>\n"," <table class=\"table table-hover table-bordered\">\n","  <tr>\n","    <th width=\"12%\" scope=\"col\"> Entry</th>\n","    <th width=\"16%\" class=\"conf\" scope=\"col\">Example</th>\n","    <th width=\"72%\" class=\"conf\" scope=\"col\">Description</th>\n","  </tr>\n","  <tr>\n","    <td>ratings</td>\n","    <td>dataset/averageattack/ratings.txt</td>\n","    <td>Set the path to the dirty recommendation dataset. Format: each row separated by empty, tab or comma symbol. </td>\n","  </tr>\n"," <tr>\n","    <td>label</td>\n","    <td>dataset/averageattack/labels.txt</td>\n","    <td>Set the path to labels (for users). Format: each row separated by empty, tab or comma symbol. </td>\n","  </tr>\n","  <tr>\n","    <td scope=\"row\">ratings.setup</td>\n","    <td>-columns 0 1 2</td>\n","    <td>-columns: (user, item, rating) columns of rating data are used;\n","      -header: to skip the first head line when reading data<br>\n","    </td>\n","  </tr>\n","\n","  <tr>\n","    <td scope=\"row\">MethodName</td>\n","    <td>DegreeSAD/PCASelect/etc.</td>\n","    <td>The name of the detection method<br>\n","    </td>\n","  </tr>\n","  <tr>\n","    <td scope=\"row\">evaluation.setup</td>\n","    <td>-testSet dataset/testset.txt</td>\n","    <td>Main option: -testSet, -ap, -cv <br>\n","      -testSet path/to/test/file   (need to specify the test set manually)<br>\n","      -ap ratio   (ap means that the user set (including items and ratings) are automatically partitioned into training set and test set, the number is the ratio of test set. e.g. -ap 0.2)<br>\n","      -cv k   (-cv means cross validation, k is the number of the fold. e.g. -cv 5)<br>\n","     </td>\n","  </tr>\n","\n","  <tr>\n","    <td scope=\"row\">output.setup</td>\n","    <td>on -dir Results/</td>\n","    <td>Main option: whether to output recommendation results<br>\n","      -dir path: the directory path of output results.\n","       </td>\n","  </tr>\n","  </table>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"pC7aeK-audZW"},"source":["### Configure the Shilling Model\n","\n","<div>\n"," <table class=\"table table-hover table-bordered\">\n","\n","  <tr>\n","    <th width=\"12%\" scope=\"col\"> Entry</th>\n","    <th width=\"16%\" class=\"conf\" scope=\"col\">Example</th>\n","    <th width=\"72%\" class=\"conf\" scope=\"col\">Description</th>\n","  </tr>\n","   <tr>\n","    <td>ratings</td>\n","    <td>dataset/averageattack/ratings.txt</td>\n","    <td>Set the path to the recommendation dataset. Format: each row separated by empty, tab or comma symbol. </td>\n","  </tr>\n","  <tr>\n","    <td scope=\"row\">ratings.setup</td>\n","    <td>-columns 0 1 2</td>\n","    <td>-columns: (user, item, rating) columns of rating data are used;\n","      -header: to skip the first head line when reading data<br>\n","    </td>\n","  </tr>\n","  <tr>\n","    <td>attackSize</td>\n","    <td>0.01</td>\n","    <td>The ratio of the injected spammers to genuine users</td>\n","  </tr>\n"," <tr>\n","    <td>fillerSize</td>\n","    <td>0.01</td>\n","    <td>The ratio of the filler items to all items </td>\n","  </tr>\n"," <tr>\n","    <td>selectedSize</td>\n","    <td>0.001</td>\n","    <td>The ratio of the selected items to all items </td>\n"," </tr>\n","  <tr>\n","    <td>linkSize</td>\n","    <td>0.01</td>\n","    <td>The ratio of the users maliciously linked by a spammer to all user </td>\n"," </tr>\n","   <tr>\n","    <td>targetCount</td>\n","    <td>20</td>\n","    <td>The count of the targeted items </td>\n","  </tr>\n","\n","   <tr>\n","    <td>targetScore</td>\n","    <td>5.0</td>\n","    <td>The score given to the target items</td>\n","  </tr>\n","  <tr>\n","    <td>threshold</td>\n","    <td>3.0</td>\n","    <td>Item has an average score lower than threshold may be chosen as one of the target items</td>\n","  </tr>\n","\n","  <tr>\n","    <td>minCount</td>\n","    <td>3</td>\n","    <td>Item has a ratings count larger than minCount may be chosen as one of the target items</td>\n","  </tr>\n","\n","  <tr>\n","    <td>maxCount</td>\n","    <td>50</td>\n","    <td>Item has a rating count smaller that maxCount may be chosen as one of the target items</td>\n","  </tr>\n","\n","  <tr>\n","    <td scope=\"row\">outputDir</td>\n","    <td>data/</td>\n","    <td> User profiles and labels will be output here     </td>\n","  </tr>\n","  </table>\n","</div>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXC3PBoey0Vy","executionInfo":{"status":"ok","timestamp":1634217508419,"user_tz":-330,"elapsed":440,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3ae7604b-ae74-431f-bd16-3f4198d59928"},"source":["%%writefile BayesDetector.conf\n","ratings=dataset/amazon/profiles.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/amazon/labels.txt\n","methodName=BayesDetector\n","evaluation.setup=-cv 5\n","item.ranking=off -topN 50\n","num.max.iter=100\n","learnRate=-init 0.03 -max 0.1\n","reg.lambda=-u 0.3 -i 0.3\n","BayesDetector=-k 10 -negCount 256 -gamma 1 -filter 4 -delta 0.01\n","output.setup=on -dir results/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing BayesDetector.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOBzPax48pyk","executionInfo":{"status":"ok","timestamp":1634217536217,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"77f23523-2602-4ec5-a7ae-5ac6c5f98b75"},"source":["%%writefile CoDetector.conf\n","ratings=dataset/amazon/profiles.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/amazon/labels.txt\n","methodName=CoDetector\n","evaluation.setup=-ap 0.3\n","item.ranking=on -topN 50\n","num.max.iter=200\n","learnRate=-init 0.01 -max 0.01\n","reg.lambda=-u 0.8 -i 0.4\n","CoDetector=-k 10 -negCount 256 -gamma 1 -filter 4\n","output.setup=on -dir results/amazon/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing CoDetector.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hASGWg768p14","executionInfo":{"status":"ok","timestamp":1634215085313,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"f5829e02-e847-456a-ee01-8131ad429d48"},"source":["%%writefile DegreeSAD.conf\n","ratings=dataset/amazon/profiles.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/amazon/labels.txt\n","methodName=DegreeSAD\n","evaluation.setup=-cv 5\n","output.setup=on -dir results/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting DegreeSAD.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlbnbUFT8p6j","executionInfo":{"status":"ok","timestamp":1634217562478,"user_tz":-330,"elapsed":456,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"c3891e2b-c649-4937-eb61-ba4edd3445d3"},"source":["%%writefile FAP.conf\n","ratings=dataset/averageattack/ratings.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/averageattack/labels.txt\n","methodName=FAP\n","evaluation.setup=-ap 0.000001\n","seedUser=350\n","topKSpam=1557\n","output.setup=on -dir results/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing FAP.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dr17WXks8p9A","executionInfo":{"status":"ok","timestamp":1634217585257,"user_tz":-330,"elapsed":465,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ed7252eb-6a8a-4d5e-85a8-14a776f38d45"},"source":["%%writefile PCASelectUsers.conf\n","ratings=dataset/averageattack/ratings.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/averageattack/labels.txt\n","methodName=PCASelectUsers\n","evaluation.setup=-ap 0.00001\n","kVals=3\n","attackSize=0.1\n","output.setup=on -dir results/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing PCASelectUsers.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCR6LD748qO_","executionInfo":{"status":"ok","timestamp":1634217607813,"user_tz":-330,"elapsed":427,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a72e2b67-2392-43c6-a9aa-d3be593e4373"},"source":["%%writefile SemiSAD.conf\n","ratings=dataset/averageattack/ratings.txt\n","ratings.setup=-columns 0 1 2\n","label=dataset/averageattack/labels.txt\n","methodName=SemiSAD\n","evaluation.setup=-ap 0.2\n","Lambda=0.5\n","topK=28\n","output.setup=on -dir results/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing SemiSAD.conf\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dcb8Xwds-hbU"},"source":["## Baseclass"]},{"cell_type":"code","metadata":{"id":"ZOJBdRaX0s54"},"source":["class SDetection(object):\n","\n","    def __init__(self,conf,trainingSet=None,testSet=None,labels=None,fold='[1]'):\n","        self.config = conf\n","        self.isSave = False\n","        self.isLoad = False\n","        self.foldInfo = fold\n","        self.labels = labels\n","        self.dao = RatingDAO(self.config, trainingSet, testSet)\n","        self.training = []\n","        self.trainingLabels = []\n","        self.test = []\n","        self.testLabels = []\n","\n","    def readConfiguration(self):\n","        self.algorName = self.config['methodName']\n","        self.output = LineConfig(self.config['output.setup'])\n","\n","\n","    def printAlgorConfig(self):\n","        \"show algorithm's configuration\"\n","        print('Algorithm:',self.config['methodName'])\n","        print('Ratings dataSet:',abspath(self.config['ratings']))\n","        if LineConfig(self.config['evaluation.setup']).contains('-testSet'):\n","            print('Test set:',abspath(LineConfig(self.config['evaluation.setup']).getOption('-testSet')))\n","        #print 'Count of the users in training set: ',len()\n","        print('Training set size: (user count: %d, item count %d, record count: %d)' %(self.dao.trainingSize()))\n","        print('Test set size: (user count: %d, item count %d, record count: %d)' %(self.dao.testSize()))\n","        print('='*80)\n","\n","    def initModel(self):\n","        pass\n","\n","    def buildModel(self):\n","        pass\n","\n","    def saveModel(self):\n","        pass\n","\n","    def loadModel(self):\n","        pass\n","\n","    def predict(self):\n","        pass\n","\n","    def execute(self):\n","        self.readConfiguration()\n","        if self.foldInfo == '[1]':\n","            self.printAlgorConfig()\n","        # load model from disk or build model\n","        if self.isLoad:\n","            print('Loading model %s...' % (self.foldInfo))\n","            self.loadModel()\n","        else:\n","            print('Initializing model %s...' % (self.foldInfo))\n","            self.initModel()\n","            print('Building Model %s...' % (self.foldInfo))\n","            self.buildModel()\n","\n","        # preict the ratings or item ranking\n","        print('Predicting %s...' % (self.foldInfo))\n","        prediction = self.predict()\n","        report = classification_report(self.testLabels, prediction, digits=4)\n","        currentTime = currentTime = strftime(\"%Y-%m-%d %H-%M-%S\", localtime(time()))\n","        FileIO.writeFile(self.output['-dir'],self.algorName+'@'+currentTime+self.foldInfo,report)\n","        # save model\n","        if self.isSave:\n","            print('Saving model %s...' % (self.foldInfo))\n","            self.saveModel()\n","        print(report)\n","        return report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lydTjwcQ-kwU"},"source":["class SSDetection(SDetection):\n","\n","    def __init__(self,conf,trainingSet=None,testSet=None,labels=None,relation=list(),fold='[1]'):\n","        super(SSDetection, self).__init__(conf,trainingSet,testSet,labels,fold)\n","        self.sao = SocialDAO(self.config, relation)  # social relations access control"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUmrP4xLvaqW"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"no_eNBw8vbsg"},"source":["class Config(object):\n","    def __init__(self,fileName):\n","        self.config = {}\n","        self.readConfiguration(fileName)\n","\n","    def __getitem__(self, item):\n","        if not self.contains(item):\n","            print('parameter '+item+' is invalid!')\n","            exit(-1)\n","        return self.config[item]\n","\n","    def getOptions(self,item):\n","        if not self.contains(item):\n","            print('parameter '+item+' is invalid!')\n","            exit(-1)\n","        return self.config[item]\n","\n","    def contains(self,key):\n","        return key in self.config\n","\n","    def readConfiguration(self,fileName):\n","        if not os.path.exists(abspath(fileName)):\n","            print('config file is not found!')\n","            raise IOError\n","        with open(fileName) as f:\n","            for ind,line in enumerate(f):\n","                if line.strip()!='':\n","                    try:\n","                        key,value=line.strip().split('=')\n","                        self.config[key]=value\n","                    except ValueError:\n","                        print('config file is not in the correct format! Error Line:%d'%(ind))\n","\n","\n","class LineConfig(object):\n","    def __init__(self,content):\n","        self.line = content.strip().split(' ')\n","        self.options = {}\n","        self.mainOption = False\n","        if self.line[0] == 'on':\n","            self.mainOption = True\n","        elif self.line[0] == 'off':\n","            self.mainOption = False\n","        for i,item in enumerate(self.line):\n","            if (item.startswith('-') or item.startswith('--')) and  not item[1:].isdigit():\n","                ind = i+1\n","                for j,sub in enumerate(self.line[ind:]):\n","                    if (sub.startswith('-') or sub.startswith('--')) and  not sub[1:].isdigit():\n","                        ind = j\n","                        break\n","                    if j == len(self.line[ind:])-1:\n","                        ind=j+1\n","                        break\n","                try:\n","                    self.options[item] = ' '.join(self.line[i+1:i+1+ind])\n","                except IndexError:\n","                    self.options[item] = 1\n","\n","\n","    def __getitem__(self, item):\n","        if not self.contains(item):\n","            print('parameter '+item+' is invalid!')\n","            exit(-1)\n","        return self.options[item]\n","\n","    def getOption(self,key):\n","        if not self.contains(key):\n","            print('parameter '+key+' is invalid!')\n","            exit(-1)\n","        return self.options[key]\n","\n","    def isMainOn(self):\n","        return self.mainOption\n","\n","    def contains(self,key):\n","        return key in self.options"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec4gpP9Kvsvv"},"source":["class FileIO(object):\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def writeFile(dir,file,content,op = 'w'):\n","        if not os.path.exists(dir):\n","            os.makedirs(dir)\n","        if type(content)=='str':\n","            with open(dir + file, op) as f:\n","                f.write(content)\n","        else:\n","            with open(dir+file,op) as f:\n","                f.writelines(content)\n","\n","    @staticmethod\n","    def deleteFile(filePath):\n","        if os.path.exists(filePath):\n","            remove(filePath)\n","\n","    @staticmethod\n","    def loadDataSet(conf, file, bTest=False):\n","        trainingData = defaultdict(dict)\n","        testData = defaultdict(dict)\n","        ratingConfig = LineConfig(conf['ratings.setup'])\n","        if not bTest:\n","            print('loading training data...')\n","        else:\n","            print('loading test data...')\n","        with open(file) as f:\n","            ratings = f.readlines()\n","        # ignore the headline\n","        if ratingConfig.contains('-header'):\n","            ratings = ratings[1:]\n","        # order of the columns\n","        order = ratingConfig['-columns'].strip().split()\n","\n","        for lineNo, line in enumerate(ratings):\n","            items = split(' |,|\\t', line.strip())\n","            if not bTest and len(order) < 3:\n","                print('The rating file is not in a correct format. Error: Line num %d' % lineNo)\n","                exit(-1)\n","            try:\n","                userId = items[int(order[0])]\n","                itemId = items[int(order[1])]\n","                if bTest and len(order)<3:\n","                    rating = 1 #default value\n","                else:\n","                    rating  = items[int(order[2])]\n","\n","            except ValueError:\n","                print('Error! Have you added the option -header to the rating.setup?')\n","                exit(-1)\n","            if not bTest:\n","                trainingData[userId][itemId]=float(rating)\n","            else:\n","                testData[userId][itemId] = float(rating)\n","        if not bTest:\n","            return trainingData\n","        else:\n","            return testData\n","\n","    @staticmethod\n","    def loadRelationship(conf, filePath):\n","        socialConfig = LineConfig(conf['social.setup'])\n","        relation = []\n","        print('loading social data...')\n","        with open(filePath) as f:\n","            relations = f.readlines()\n","            # ignore the headline\n","        if socialConfig.contains('-header'):\n","            relations = relations[1:]\n","        # order of the columns\n","        order = socialConfig['-columns'].strip().split()\n","        if len(order) <= 2:\n","            print('The social file is not in a correct format.')\n","        for lineNo, line in enumerate(relations):\n","            items = split(' |,|\\t', line.strip())\n","            if len(order) < 2:\n","                print('The social file is not in a correct format. Error: Line num %d' % lineNo)\n","                exit(-1)\n","            userId1 = items[int(order[0])]\n","            userId2 = items[int(order[1])]\n","            if len(order) < 3:\n","                weight = 1\n","            else:\n","                weight = float(items[int(order[2])])\n","            relation.append([userId1, userId2, weight])\n","        return relation\n","\n","\n","    @staticmethod\n","    def loadLabels(filePath):\n","        labels = {}\n","        with open(filePath) as f:\n","            for line in f:\n","                items = split(' |,|\\t', line.strip())\n","                labels[items[0]] = items[1]\n","        return labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5j_Er3_ovqAS"},"source":["class DataSplit(object):\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def dataSplit(data,test_ratio = 0.3,output=False,path='./',order=1):\n","        if test_ratio>=1 or test_ratio <=0:\n","            test_ratio = 0.3\n","        testSet = {}\n","        trainingSet = {}\n","        for user in data:\n","            if random.random() < test_ratio:\n","                testSet[user] = data[user].copy()\n","            else:\n","                trainingSet[user] = data[user].copy()\n","\n","        if output:\n","            FileIO.writeFile(path,'testSet['+str(order)+']',testSet)\n","            FileIO.writeFile(path, 'trainingSet[' + str(order) + ']', trainingSet)\n","        return trainingSet,testSet\n","\n","    @staticmethod\n","    def crossValidation(data,k,output=False,path='./',order=1):\n","        if k<=1 or k>10:\n","            k=3\n","        for i in range(k):\n","            trainingSet = {}\n","            testSet = {}\n","            for ind,user in enumerate(data):\n","                if ind%k == i:\n","                    testSet[user] = data[user].copy()\n","                else:\n","                    trainingSet[user] = data[user].copy()\n","            yield trainingSet,testSet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8-Yh3snxF3o"},"source":["def drawLine(x,y,labels,xLabel,yLabel,title):\n","    f, ax = plt.subplots(1, 1, figsize=(10, 6), sharex=True)\n","\n","    #f.tight_layout()\n","    #sns.set(style=\"darkgrid\")\n","\n","    palette = ['blue','orange','red','green','purple','pink']\n","    # for i in range(len(ax)):\n","    #     x1 = range(0, len(x))\n","        #ax.set_xlim(min(x1)-0.2,max(x1)+0.2)\n","        # mini = 10000;max = -10000\n","        # for label in labels:\n","        #     if mini>min(y[i][label]):\n","        #         mini = min(y[i][label])\n","        #     if max<max(y[i][label]):\n","        #         max = max(y[i][label])\n","        # ax[i].set_ylim(mini-0.25*(max-mini),max+0.25*(max-mini))\n","        # for j,label in enumerate(labels):\n","        #     if j%2==1:\n","        #         ax[i].plot(x1, y[i][label], color=palette[j/2], marker='.', label=label, markersize=12)\n","        #     else:\n","        #         ax[i].plot(x1, y[i][label], color=palette[j/2], marker='.', label=label,markersize=12,linestyle='--')\n","        # ax[0].set_ylabel(yLabel,fontsize=20)\n","\n","    for xdata,ydata,lab,c in zip(x,y,labels,palette):\n","        ax.plot(xdata,ydata,color = c,label=lab)\n","    ind = np.arange(0,60,10)\n","    ax.set_xticks(ind)\n","    #ax.set_xticklabels(x)\n","    ax.set_xlabel(xLabel, fontsize=20)\n","    ax.set_ylabel(yLabel, fontsize=20)\n","    ax.tick_params(labelsize=16)\n","    #ax.tick_params(axs='y', labelsize=20)\n","\n","    ax.set_title(title,fontsize=24)\n","    plt.grid(True)\n","    handles, labels1 = ax.get_legend_handles_labels()\n","\n","    #ax[i].legend(handles, labels1, loc=2, fontsize=20)\n","    # ax.legend(loc=2,\n","    #        ncol=6,  borderaxespad=0.,fontsize=20)\n","    #ax[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,fontsize=20)\n","    ax.legend(loc='upper right',fontsize=20,shadow=True)\n","    plt.show()\n","    plt.close()\n","\n","paths = ['SVD.txt','PMF.txt','EE.txt','RDML.txt']\n","files = ['EE['+str(i)+'] iteration.txt' for i in range(2,9)]\n","x = []\n","y = []\n","\n","data = []\n","def normalize():\n","    for file in files:\n","        xdata = []\n","        with open(file) as f:\n","            for line in f:\n","                items = line.strip().split()\n","                rmse = items[2].split(':')[1]\n","                xdata.append(float(rmse))\n","        data.append(xdata)\n","    average = []\n","    for i in range(len(data[0])):\n","        total = 0\n","        for k in range(len(data)):\n","            total += data[k][i]\n","        average.append(str(i+1)+':'+str(float(total)/len(data))+'\\n')\n","    with open('EE.txt','w') as f:\n","        f.writelines(average)\n","\n","\n","\n","def readData():\n","    for file in paths:\n","        xdata = []\n","        ydata = []\n","        with open(file) as f:\n","            for line in f:\n","                items = line.strip().split(':')\n","                xdata.append(int(items[0]))\n","                rmse = float(items[1])\n","                ydata.append(float(rmse))\n","        x.append(xdata)\n","        y.append(ydata)\n","\n","\n","\n","\n","# x = [[1,2,3],[1,2,3]]\n","# y = [[1,2,3],[4,5,6]]\n","#normalize()\n","readData()\n","labels = ['SVD','PMF','EE','RDML',]\n","xlabel = 'Iteration'\n","ylabel = 'RMSE'\n","\n","drawLine(x,y,labels,xlabel,ylabel,'')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJqVx9j6xTGF"},"source":["def l1(x):\n","    return norm(x,ord=1)\n","\n","def l2(x):\n","    return norm(x)\n","\n","def common(x1,x2):\n","    # find common ratings\n","    common = (x1!=0)&(x2!=0)\n","    new_x1 = x1[common]\n","    new_x2 = x2[common]\n","    return new_x1,new_x2\n","\n","def cosine_sp(x1,x2):\n","    'x1,x2 are dicts,this version is for sparse representation'\n","    total = 0\n","    denom1 = 0\n","    denom2 =0\n","    for k in x1:\n","        if k in x2:\n","            total+=x1[k]*x2[k]\n","            denom1+=x1[k]**2\n","            denom2+=x2[k]**2\n","    try:\n","        return (total + 0.0) / (sqrt(denom1) * sqrt(denom2))\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def cosine(x1,x2):\n","    #find common ratings\n","    new_x1, new_x2 = common(x1,x2)\n","    #compute the cosine similarity between two vectors\n","    sum = new_x1.dot(new_x2)\n","    denom = sqrt(new_x1.dot(new_x1)*new_x2.dot(new_x2))\n","    try:\n","        return float(sum)/denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","    #return cosine_similarity(x1,x2)[0][0]\n","\n","def pearson_sp(x1,x2):\n","    total = 0\n","    denom1 = 0\n","    denom2 = 0\n","    overlapped=False\n","    try:\n","        mean1 = sum(x1.values())/(len(x1)+0.0)\n","        mean2 = sum(x2.values()) / (len(x2) + 0.0)\n","        for k in x1:\n","            if k in x2:\n","                total += (x1[k]-mean1) * (x2[k]-mean2)\n","                denom1 += (x1[k]-mean1) ** 2\n","                denom2 += (x2[k]-mean2) ** 2\n","                overlapped=True\n","\n","        return (total + 0.0) / (sqrt(denom1) * sqrt(denom2))\n","    except ZeroDivisionError:\n","        if overlapped:\n","            return 1\n","        else:\n","            return 0\n","\n","def euclidean(x1,x2):\n","    #find common ratings\n","    new_x1, new_x2 = common(x1, x2)\n","    #compute the euclidean between two vectors\n","    diff = new_x1-new_x2\n","    denom = sqrt((diff.dot(diff)))\n","    try:\n","        return 1/denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def pearson(x1,x2):\n","    #find common ratings\n","    new_x1, new_x2 = common(x1, x2)\n","    #compute the pearson similarity between two vectors\n","    ind1 = new_x1 > 0\n","    ind2 = new_x2 > 0\n","    try:\n","        mean_x1 = float(new_x1.sum())/ind1.sum()\n","        mean_x2 = float(new_x2.sum())/ind2.sum()\n","        new_x1 = new_x1 - mean_x1\n","        new_x2 = new_x2 - mean_x2\n","        sum = new_x1.dot(new_x2)\n","        denom = sqrt((new_x1.dot(new_x1))*(new_x2.dot(new_x2)))\n","        return float(sum) / denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def similarity(x1,x2,sim):\n","    if sim == 'pcc':\n","        return pearson_sp(x1,x2)\n","    if sim == 'euclidean':\n","        return euclidean(x1,x2)\n","    else:\n","        return cosine_sp(x1, x2)\n","\n","\n","def normalize(vec,maxVal,minVal):\n","    'get the normalized value using min-max normalization'\n","    if maxVal > minVal:\n","        return float(vec-minVal)/(maxVal-minVal)+0.01\n","    elif maxVal==minVal:\n","        return vec/maxVal\n","    else:\n","        print('error... maximum value is less than minimum value.')\n","        raise ArithmeticError\n","\n","def sigmoid(val):\n","    return 1/(1+exp(-val))\n","\n","\n","def denormalize(vec,maxVal,minVal):\n","    return minVal+(vec-0.01)*(maxVal-minVal)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EpwnOGs5uxrP"},"source":["## Shilling models"]},{"cell_type":"markdown","metadata":{"id":"Duy61lrku9Yc"},"source":["### Attack base class"]},{"cell_type":"code","metadata":{"id":"VNCgq5B-u_Rm"},"source":["class Attack(object):\n","    def __init__(self,conf):\n","        self.config = Config(conf)\n","        self.userProfile = FileIO.loadDataSet(self.config,self.config['ratings'])\n","        self.itemProfile = defaultdict(dict)\n","        self.attackSize = float(self.config['attackSize'])\n","        self.fillerSize = float(self.config['fillerSize'])\n","        self.selectedSize = float(self.config['selectedSize'])\n","        self.targetCount = int(self.config['targetCount'])\n","        self.targetScore = float(self.config['targetScore'])\n","        self.threshold = float(self.config['threshold'])\n","        self.minCount = int(self.config['minCount'])\n","        self.maxCount = int(self.config['maxCount'])\n","        self.minScore = float(self.config['minScore'])\n","        self.maxScore = float(self.config['maxScore'])\n","        self.outputDir = self.config['outputDir']\n","        if not os.path.exists(self.outputDir):\n","            os.makedirs(self.outputDir)\n","        for user in self.userProfile:\n","            for item in self.userProfile[user]:\n","                self.itemProfile[item][user] = self.userProfile[user][item]\n","        self.spamProfile = defaultdict(dict)\n","        self.spamItem = defaultdict(list) #items rated by spammers\n","        self.targetItems = []\n","        self.itemAverage = {}\n","        self.getAverageRating()\n","        self.selectTarget()\n","        self.startUserID = 0\n","\n","    def getAverageRating(self):\n","        for itemID in self.itemProfile:\n","            li = list(self.itemProfile[itemID].values())\n","            self.itemAverage[itemID] = float(sum(li)) / len(li)\n","\n","\n","    def selectTarget(self,):\n","        print('Selecting target items...')\n","        print('-'*80)\n","        print('Target item       Average rating of the item')\n","        itemList = list(self.itemProfile.keys())\n","        itemList.sort()\n","        while len(self.targetItems) < self.targetCount:\n","            target = np.random.randint(len(itemList)) #generate a target order at random\n","\n","            if len(self.itemProfile[str(itemList[target])]) < self.maxCount and len(self.itemProfile[str(itemList[target])]) > self.minCount \\\n","                    and str(itemList[target]) not in self.targetItems \\\n","                    and self.itemAverage[str(itemList[target])] <= self.threshold:\n","                self.targetItems.append(str(itemList[target]))\n","                print(str(itemList[target]),'                  ',self.itemAverage[str(itemList[target])])\n","\n","    def getFillerItems(self):\n","        mu = int(self.fillerSize*len(self.itemProfile))\n","        sigma = int(0.1*mu)\n","        markedItemsCount = abs(int(round(random.gauss(mu, sigma))))\n","        markedItems = np.random.randint(len(self.itemProfile), size=markedItemsCount)\n","        return markedItems.tolist()\n","\n","    def insertSpam(self,startID=0):\n","        pass\n","\n","    def loadTarget(self,filename):\n","        with open(filename) as f:\n","            for line in f:\n","                self.targetItems.append(line.strip())\n","\n","    def generateLabels(self,filename):\n","        labels = []\n","        path = self.outputDir + filename\n","        with open(path,'w') as f:\n","            for user in self.spamProfile:\n","                labels.append(user+' 1\\n')\n","            for user in self.userProfile:\n","                labels.append(user+' 0\\n')\n","            f.writelines(labels)\n","        print('User profiles have been output to '+abspath(self.config['outputDir'])+'.')\n","\n","    def generateProfiles(self,filename):\n","        ratings = []\n","        path = self.outputDir+filename\n","        with open(path, 'w') as f:\n","            for user in self.userProfile:\n","                for item in self.userProfile[user]:\n","                    ratings.append(user+' '+item+' '+str(self.userProfile[user][item])+'\\n')\n","\n","            for user in self.spamProfile:\n","                for item in self.spamProfile[user]:\n","                    ratings.append(user + ' ' + item + ' ' + str(self.spamProfile[user][item])+'\\n')\n","            f.writelines(ratings)\n","        print('User labels have been output to '+abspath(self.config['outputDir'])+'.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Frmemg_xCNnv"},"source":["### Relation attack"]},{"cell_type":"code","metadata":{"id":"gpCpBPg7CNkk"},"source":["class RelationAttack(Attack):\n","    def __init__(self,conf):\n","        super(RelationAttack, self).__init__(conf)\n","        self.spamLink = defaultdict(list)\n","        self.relation = FileIO.loadRelationship(self.config,self.config['social'])\n","        self.trustLink = defaultdict(list)\n","        self.trusteeLink = defaultdict(list)\n","        for u1,u2,t in self.relation:\n","            self.trustLink[u1].append(u2)\n","            self.trusteeLink[u2].append(u1)\n","        self.activeUser = {}  # 关注了虚假用户的正常用户\n","        self.linkedUser = {}  # 被虚假用户种植过链接的用户\n","\n","    # def reload(self):\n","    #     super(RelationAttack, self).reload()\n","    #     self.spamLink = defaultdict(list)\n","    #     self.trustLink, self.trusteeLink = loadTrusts(self.config['social'])\n","    #     self.activeUser = {}  # 关注了虚假用户的正常用户\n","    #     self.linkedUser = {}  # 被虚假用户种植过链接的用户\n","\n","    def farmLink(self):\n","        pass\n","\n","    def getReciprocal(self,target):\n","        #当前目标用户关注spammer的概率，依赖于粉丝数和关注数的交集\n","        reciprocal = float(2 * len(set(self.trustLink[target]).intersection(self.trusteeLink[target])) + 0.1) \\\n","                     / (len(set(self.trustLink[target]).union(self.trusteeLink[target])) + 1)\n","        reciprocal += (len(self.trustLink[target]) + 0.1) / (len(self.trustLink[target]) + len(self.trusteeLink[target]) + 1)\n","        reciprocal /= 2\n","        return reciprocal\n","\n","    def generateSocialConnections(self,filename):\n","        relations = []\n","        path = self.outputDir + filename\n","        with open(path, 'w') as f:\n","            for u1 in self.trustLink:\n","                for u2 in self.trustLink[u1]:\n","                    relations.append(u1 + ' ' + u2 + ' 1\\n')\n","\n","            for u1 in self.spamLink:\n","                for u2 in self.spamLink[u1]:\n","                    relations.append(u1 + ' ' + u2 + ' 1\\n')\n","            f.writelines(relations)\n","        print('Social relations have been output to ' + abspath(self.config['outputDir']) + '.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XmE9vaZvCark"},"source":["### Random relation attack"]},{"cell_type":"code","metadata":{"id":"e3SH9fJiCanT"},"source":["class RandomRelationAttack(RelationAttack):\n","    def __init__(self,conf):\n","        super(RandomRelationAttack, self).__init__(conf)\n","        self.scale = float(self.config['linkSize'])\n","\n","    def farmLink(self):  # 随机注入虚假关系\n","\n","        for spam in self.spamProfile:\n","\n","            #对购买了目标项目的用户种植链接\n","            for item in self.spamItem[spam]:\n","                if random.random() < 0.01:\n","                    for target in self.itemProfile[item]:\n","                        self.spamLink[spam].append(target)\n","                        response = np.random.random()\n","                        reciprocal = self.getReciprocal(target)\n","                        if response <= reciprocal:\n","                            self.trustLink[target].append(spam)\n","                            self.activeUser[target] = 1\n","                        else:\n","                            self.linkedUser[target] = 1\n","            #对其它用户以scale的比例种植链接\n","            for user in self.userProfile:\n","                if random.random() < self.scale:\n","                    self.spamLink[spam].append(user)\n","                    response = np.random.random()\n","                    reciprocal = self.getReciprocal(user)\n","                    if response < reciprocal:\n","                        self.trustLink[user].append(spam)\n","                        self.activeUser[user] = 1\n","                    else:\n","                        self.linkedUser[user] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Agh_VTYVCgSM"},"source":["### Random attack"]},{"cell_type":"code","metadata":{"id":"7AyNNzk5CgPR"},"source":["class RandomAttack(Attack):\n","    def __init__(self,conf):\n","        super(RandomAttack, self).__init__(conf)\n","\n","\n","    def insertSpam(self,startID=0):\n","        print('Modeling random attack...')\n","        itemList = list(self.itemProfile.keys())\n","        if startID == 0:\n","            self.startUserID = len(self.userProfile)\n","        else:\n","            self.startUserID = startID\n","\n","        for i in range(int(len(self.userProfile)*self.attackSize)):\n","            #fill 装填项目\n","            fillerItems = self.getFillerItems()\n","            for item in fillerItems:\n","                self.spamProfile[str(self.startUserID)][str(itemList[item])] = random.randint(self.minScore,self.maxScore)\n","\n","            #target 目标项目\n","            for j in range(self.targetCount):\n","                target = np.random.randint(len(self.targetItems))\n","                self.spamProfile[str(self.startUserID)][self.targetItems[target]] = self.targetScore\n","                self.spamItem[str(self.startUserID)].append(self.targetItems[target])\n","            self.startUserID += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAjlWWrXC389"},"source":["class RR_Attack(RandomRelationAttack,RandomAttack):\n","    def __init__(self,conf):\n","        super(RR_Attack, self).__init__(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uQ11CRfGxetw"},"source":["### Average attack"]},{"cell_type":"code","metadata":{"id":"uITd6vjhxgHV"},"source":["class AverageAttack(Attack):\n","    def __init__(self,conf):\n","        super(AverageAttack, self).__init__(conf)\n","\n","    def insertSpam(self,startID=0):\n","        print('Modeling average attack...')\n","        itemList = list(self.itemProfile.keys())\n","        if startID == 0:\n","            self.startUserID = len(self.userProfile)\n","        else:\n","            self.startUserID = startID\n","\n","        for i in range(int(len(self.userProfile)*self.attackSize)):\n","            #fill\n","            fillerItems = self.getFillerItems()\n","            for item in fillerItems:\n","                self.spamProfile[str(self.startUserID)][str(itemList[item])] = round(self.itemAverage[str(itemList[item])])\n","            #target\n","            for j in range(self.targetCount):\n","                target = np.random.randint(len(self.targetItems))\n","                self.spamProfile[str(self.startUserID)][self.targetItems[target]] = self.targetScore\n","                self.spamItem[str(self.startUserID)].append(self.targetItems[target])\n","            self.startUserID += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VsaKjYo1DPeY"},"source":["### Random average relation"]},{"cell_type":"code","metadata":{"id":"nTuGveE9DS85"},"source":["class RA_Attack(RandomRelationAttack,AverageAttack):\n","    def __init__(self,conf):\n","        super(RA_Attack, self).__init__(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aO63OdcrCgMZ"},"source":["### Bandwagon attack"]},{"cell_type":"code","metadata":{"id":"Hx0HaDEYC4AO"},"source":["class BandWagonAttack(Attack):\n","    def __init__(self,conf):\n","        super(BandWagonAttack, self).__init__(conf)\n","        self.hotItems = sorted(iter(self.itemProfile.items()), key=lambda d: len(d[1]), reverse=True)[\n","                   :int(self.selectedSize * len(self.itemProfile))]\n","\n","\n","    def insertSpam(self,startID=0):\n","        print('Modeling bandwagon attack...')\n","        itemList = list(self.itemProfile.keys())\n","        if startID == 0:\n","            self.startUserID = len(self.userProfile)\n","        else:\n","            self.startUserID = startID\n","\n","        for i in range(int(len(self.userProfile)*self.attackSize)):\n","            #fill 装填项目\n","            fillerItems = self.getFillerItems()\n","            for item in fillerItems:\n","                self.spamProfile[str(self.startUserID)][str(itemList[item])] = random.randint(self.minScore,self.maxScore)\n","            #selected 选择项目\n","            selectedItems = self.getSelectedItems()\n","            for item in selectedItems:\n","                self.spamProfile[str(self.startUserID)][item] = self.targetScore\n","            #target 目标项目\n","            for j in range(self.targetCount):\n","                target = np.random.randint(len(self.targetItems))\n","                self.spamProfile[str(self.startUserID)][self.targetItems[target]] = self.targetScore\n","                self.spamItem[str(self.startUserID)].append(self.targetItems[target])\n","            self.startUserID += 1\n","\n","    def getFillerItems(self):\n","        mu = int(self.fillerSize*len(self.itemProfile))\n","        sigma = int(0.1*mu)\n","        markedItemsCount = int(round(random.gauss(mu, sigma)))\n","        if markedItemsCount < 0:\n","            markedItemsCount = 0\n","        markedItems = np.random.randint(len(self.itemProfile), size=markedItemsCount)\n","        return markedItems\n","\n","    def getSelectedItems(self):\n","\n","        mu = int(self.selectedSize * len(self.itemProfile))\n","        sigma = int(0.1 * mu)\n","        markedItemsCount = abs(int(round(random.gauss(mu, sigma))))\n","        markedIndexes =  np.random.randint(len(self.hotItems), size=markedItemsCount)\n","        markedItems = [self.hotItems[index][0] for index in markedIndexes]\n","        return markedItems"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7fb5jn3DqLI"},"source":["### Random bandwagon relation"]},{"cell_type":"code","metadata":{"id":"ibXNF8aAC35s"},"source":["class RB_Attack(RandomRelationAttack,BandWagonAttack):\n","    def __init__(self,conf):\n","        super(RB_Attack, self).__init__(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SXLHTH2C32B"},"source":["### Hybrid attack"]},{"cell_type":"code","metadata":{"id":"KKNV8OoJD4Ee"},"source":["class HybridAttack(Attack):\n","    def __init__(self,conf):\n","        super(HybridAttack, self).__init__(conf)\n","        self.aveAttack = AverageAttack(conf)\n","        self.bandAttack = BandWagonAttack(conf)\n","        self.randAttack = RandomAttack(conf)\n","\n","\n","    def insertSpam(self,startID=0):\n","        self.aveAttack.insertSpam()\n","        self.bandAttack.insertSpam(self.aveAttack.startUserID+1)\n","        self.randAttack.insertSpam(self.bandAttack.startUserID+1)\n","        self.spamProfile = {}\n","        self.spamProfile.update(self.aveAttack.spamProfile)\n","        self.spamProfile.update(self.bandAttack.spamProfile)\n","        self.spamProfile.update(self.randAttack.spamProfile)\n","\n","    def generateProfiles(self,filename):\n","\n","        ratings = []\n","        path = self.outputDir + filename\n","        with open(path, 'w') as f:\n","            for user in self.userProfile:\n","                for item in self.userProfile[user]:\n","                    ratings.append(user + ' ' + item + ' ' + str(self.userProfile[user][item]) + '\\n')\n","\n","            for user in self.spamProfile:\n","                for item in self.spamProfile[user]:\n","                    ratings.append(user + ' ' + item + ' ' + str(self.spamProfile[user][item]) + '\\n')\n","            f.writelines(ratings)\n","        print('User labels have been output to ' + abspath(self.config['outputDir']) + '.')\n","\n","    def generateLabels(self,filename):\n","        labels = []\n","        path = self.outputDir + filename\n","        with open(path,'w') as f:\n","            for user in self.spamProfile:\n","                labels.append(user+' 1\\n')\n","            for user in self.userProfile:\n","                labels.append(user+' 0\\n')\n","            f.writelines(labels)\n","        print('User profiles have been output to '+abspath(self.config['outputDir'])+'.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60j93rEWD4Bn"},"source":["### Generate data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g54ZYLoSEEiQ","executionInfo":{"status":"ok","timestamp":1634220261087,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a77852a5-f1fa-4a8c-9b03-c5ff1f19a230"},"source":["%%writefile config.conf\n","ratings=dataset/filmtrust/ratings.txt\n","ratings.setup=-columns 0 1 2\n","social=dataset/filmtrust/trust.txt\n","social.setup=-columns 0 1 2\n","attackSize=0.1\n","fillerSize=0.05\n","selectedSize=0.005\n","targetCount=20\n","targetScore=4.0\n","threshold=3.0\n","maxScore=4.0\n","minScore=1.0\n","minCount=5\n","maxCount=50\n","linkSize=0.001\n","outputDir=output/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting config.conf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4A-JTXPHD39X","executionInfo":{"status":"ok","timestamp":1634219617594,"user_tz":-330,"elapsed":460,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"b4ec00a9-6efb-4e21-abc4-cd1b02833825"},"source":["attack = RR_Attack('config.conf')\n","attack.insertSpam()\n","attack.farmLink()\n","attack.generateLabels('labels.txt')\n","attack.generateProfiles('profiles.txt')\n","attack.generateSocialConnections('relations.txt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading training data...\n","Selecting target items...\n","--------------------------------------------------------------------------------\n","Target item       Average rating of the item\n","877                    2.875\n","472                    2.5833333333333335\n","715                    2.8\n","528                    2.7142857142857144\n","169                    2.25\n","442                    2.8055555555555554\n","270                    2.962962962962963\n","681                    2.75\n","843                    3.0\n","832                    1.8571428571428572\n","668                    2.7777777777777777\n","938                    2.9166666666666665\n","282                    2.642857142857143\n","489                    2.1666666666666665\n","927                    2.5833333333333335\n","577                    2.5\n","693                    2.6875\n","593                    2.7083333333333335\n","529                    2.5\n","872                    2.3333333333333335\n","loading social data...\n","Modeling random attack...\n","User profiles have been output to /content/output.\n","User labels have been output to /content/output.\n","Social relations have been output to /content/output.\n"]}]},{"cell_type":"markdown","metadata":{"id":"nL3xQOPY_Dc0"},"source":["## Data access objects"]},{"cell_type":"code","metadata":{"id":"M3o1XWEc0kFM"},"source":["class RatingDAO(object):\n","    'data access control'\n","    def __init__(self,config, trainingData, testData):\n","        self.config = config\n","        self.ratingConfig = LineConfig(config['ratings.setup'])\n","        self.user = {} #used to store the order of users in the training set\n","        self.item = {} #used to store the order of items in the training set\n","        self.id2user = {}\n","        self.id2item = {}\n","        self.all_Item = {}\n","        self.all_User = {}\n","        self.userMeans = {} #used to store the mean values of users's ratings\n","        self.itemMeans = {} #used to store the mean values of items's ratings\n","\n","\n","        self.globalMean = 0\n","        self.timestamp = {}\n","        # self.trainingMatrix = None\n","        # self.validationMatrix = None\n","        self.testSet_u = testData.copy() # used to store the test set by hierarchy user:[item,rating]\n","        self.testSet_i = defaultdict(dict) # used to store the test set by hierarchy item:[user,rating]\n","        self.trainingSet_u = trainingData.copy()\n","        self.trainingSet_i = defaultdict(dict)\n","        #self.rScale = []\n","\n","        self.trainingData = trainingData\n","        self.testData = testData\n","        self.__generateSet()\n","        self.__computeItemMean()\n","        self.__computeUserMean()\n","        self.__globalAverage()\n","\n","\n","\n","    def __generateSet(self):\n","        scale = set()\n","        # find the maximum rating and minimum value\n","        # for i, entry in enumerate(self.trainingData):\n","        #     userName, itemName, rating = entry\n","        #     scale.add(float(rating))\n","        # self.rScale = list(scale)\n","        # self.rScale.sort()\n","\n","        for i,user in enumerate(self.trainingData):\n","            for item in self.trainingData[user]:\n","\n","                # makes the rating within the range [0, 1].\n","                #rating = normalize(float(rating), self.rScale[-1], self.rScale[0])\n","                #self.trainingSet_u[userName][itemName] = float(rating)\n","                self.trainingSet_i[item][user] = self.trainingData[user][item]\n","                # order the user\n","                if user not in self.user:\n","                    self.user[user] = len(self.user)\n","                    self.id2user[self.user[user]] = user\n","                # order the item\n","                if item not in self.item:\n","                    self.item[item] = len(self.item)\n","                    self.id2item[self.item[item]] = item\n","                self.trainingSet_i[item][user] = self.trainingData[user][item]\n","                # userList.append\n","        #     triple.append([self.user[userName], self.item[itemName], rating])\n","        # self.trainingMatrix = new_sparseMatrix.SparseMatrix(triple)\n","\n","        self.all_User.update(self.user)\n","        self.all_Item.update(self.item)\n","\n","        for i, user in enumerate(self.testData):\n","            # order the user\n","            if user not in self.user:\n","                self.all_User[user] = len(self.all_User)\n","            for item in self.testData[user]:\n","                # order the item\n","                if item not in self.item:\n","                    self.all_Item[item] = len(self.all_Item)\n","                #self.testSet_u[userName][itemName] = float(rating)\n","                self.testSet_i[item][user] = self.testData[user][item]\n","\n","\n","    def __globalAverage(self):\n","        total = sum(self.userMeans.values())\n","        if total==0:\n","            self.globalMean = 0\n","        else:\n","            self.globalMean = total/len(self.userMeans)\n","\n","    def __computeUserMean(self):\n","        # for u in self.user:\n","        #     n = self.row(u) > 0\n","        #     mean = 0\n","        #\n","        #     if not self.containsUser(u):  # no data about current user in training set\n","        #         pass\n","        #     else:\n","        #         sum = float(self.row(u)[0].sum())\n","        #         try:\n","        #             mean =  sum/ n[0].sum()\n","        #         except ZeroDivisionError:\n","        #             mean = 0\n","        #     self.userMeans[u] = mean\n","        for u in self.trainingSet_u:\n","            self.userMeans[u] = sum(self.trainingSet_u[u].values())/(len(list(self.trainingSet_u[u].values()))+0.0)\n","        for u in self.testSet_u:\n","            self.userMeans[u] = sum(self.testSet_u[u].values())/(len(list(self.testSet_u[u].values()))+0.0)\n","\n","    def __computeItemMean(self):\n","        # for c in self.item:\n","        #     n = self.col(c) > 0\n","        #     mean = 0\n","        #     if not self.containsItem(c):  # no data about current user in training set\n","        #         pass\n","        #     else:\n","        #         sum = float(self.col(c)[0].sum())\n","        #         try:\n","        #             mean = sum / n[0].sum()\n","        #         except ZeroDivisionError:\n","        #             mean = 0\n","        #     self.itemMeans[c] = mean\n","        for item in self.trainingSet_i:\n","            self.itemMeans[item] = sum(self.trainingSet_i[item].values())/(len(list(self.trainingSet_i[item].values())) + 0.0)\n","        for item in self.testSet_i:\n","            self.itemMeans[item] = sum(self.testSet_i[item].values())/(len(list(self.testSet_i[item].values())) + 0.0)\n","\n","    def getUserId(self,u):\n","        if u in self.user:\n","            return self.user[u]\n","        else:\n","            return -1\n","\n","    def getItemId(self,i):\n","        if i in self.item:\n","            return self.item[i]\n","        else:\n","            return -1\n","\n","    def trainingSize(self):\n","        recordCount = 0\n","        for user in self.trainingData:\n","            recordCount+=len(self.trainingData[user])\n","        return (len(self.trainingSet_u),len(self.trainingSet_i),recordCount)\n","\n","\n","    def testSize(self):\n","        recordCount = 0\n","        for user in self.testData:\n","            recordCount += len(self.testData[user])\n","        return (len(self.testSet_u),len(self.testSet_i),recordCount)\n","\n","    def contains(self,u,i):\n","        'whether user u rated item i'\n","        if u in self.trainingSet_u and i in self.trainingSet_u[u]:\n","            return True\n","        return False\n","\n","    def containsUser(self,u):\n","        'whether user is in training set'\n","        return u in self.trainingSet_u\n","\n","    def containsItem(self,i):\n","        'whether item is in training set'\n","        return i in self.trainingSet_i\n","\n","    def allUserRated(self, u):\n","        if u in self.user:\n","            return list(self.trainingSet_u[u].keys()), list(self.trainingSet_u[u].values())\n","        else:\n","            return list(self.testSet_u[u].keys()), list(self.testSet_u[u].values())\n","    # def userRated(self,u):\n","    #     if self.trainingMatrix.matrix_User.has_key(self.getUserId(u)):\n","    #         itemIndex =  self.trainingMatrix.matrix_User[self.user[u]].keys()\n","    #         rating = self.trainingMatrix.matrix_User[self.user[u]].values()\n","    #         return (itemIndex,rating)\n","    #     return ([],[])\n","    #\n","    # def itemRated(self,i):\n","    #     if self.trainingMatrix.matrix_Item.has_key(self.getItemId(i)):\n","    #         userIndex = self.trainingMatrix.matrix_Item[self.item[i]].keys()\n","    #         rating = self.trainingMatrix.matrix_Item[self.item[i]].values()\n","    #         return (userIndex,rating)\n","    #     return ([],[])\n","\n","    # def row(self,u):\n","    #     return self.trainingMatrix.row(self.getUserId(u))\n","    #\n","    # def col(self,c):\n","    #     return self.trainingMatrix.col(self.getItemId(c))\n","    #\n","    # def sRow(self,u):\n","    #     return self.trainingMatrix.sRow(self.getUserId(u))\n","    #\n","    # def sCol(self,c):\n","    #     return self.trainingMatrix.sCol(self.getItemId(c))\n","    #\n","    # def rating(self,u,c):\n","    #     return self.trainingMatrix.elem(self.getUserId(u),self.getItemId(c))\n","    #\n","    # def ratingScale(self):\n","    #     return (self.rScale[0],self.rScale[1])\n","\n","    # def elemCount(self):\n","    #     return self.trainingMatrix.elemCount()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6t6Ec7Ve_Syj"},"source":["class SocialDAO(object):\n","    def __init__(self,conf,relation=list()):\n","        self.config = conf\n","        self.user = {} #used to store the order of users\n","        self.relation = relation\n","        self.followees = {}\n","        self.followers = {}\n","        self.trustMatrix = self.__generateSet()\n","\n","    def __generateSet(self):\n","        #triple = []\n","        for line in self.relation:\n","            userId1,userId2,weight = line\n","            #add relations to dict\n","            if userId1 not in self.followees:\n","                self.followees[userId1] = {}\n","            self.followees[userId1][userId2] = weight\n","            if userId2 not in self.followers:\n","                self.followers[userId2] = {}\n","            self.followers[userId2][userId1] = weight\n","            # order the user\n","            if userId1 not in self.user:\n","                self.user[userId1] = len(self.user)\n","            if userId2 not in self.user:\n","                self.user[userId2] = len(self.user)\n","            #triple.append([self.user[userId1], self.user[userId2], weight])\n","        #return new_sparseMatrix.SparseMatrix(triple)\n","\n","    # def row(self,u):\n","    #     #return user u's followees\n","    #     return self.trustMatrix.row(self.user[u])\n","    #\n","    # def col(self,u):\n","    #     #return user u's followers\n","    #     return self.trustMatrix.col(self.user[u])\n","    #\n","    # def elem(self,u1,u2):\n","    #     return self.trustMatrix.elem(u1,u2)\n","\n","    def weight(self,u1,u2):\n","        if u1 in self.followees and u2 in self.followees[u1]:\n","            return self.followees[u1][u2]\n","        else:\n","            return 0\n","\n","    # def trustSize(self):\n","    #     return self.trustMatrix.size\n","\n","    def getFollowers(self,u):\n","        if u in self.followers:\n","            return self.followers[u]\n","        else:\n","            return {}\n","\n","    def getFollowees(self,u):\n","        if u in self.followees:\n","            return self.followees[u]\n","        else:\n","            return {}\n","\n","    def hasFollowee(self,u1,u2):\n","        if u1 in self.followees:\n","            if u2 in self.followees[u1]:\n","                return True\n","            else:\n","                return False\n","        return False\n","\n","    def hasFollower(self,u1,u2):\n","        if u1 in self.followers:\n","            if u2 in self.followers[u1]:\n","                return True\n","            else:\n","                return False\n","        return False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8UD1B1i70O7T"},"source":["## Methods"]},{"cell_type":"markdown","metadata":{"id":"dAQny9vu_dDQ"},"source":["### BayesDetector"]},{"cell_type":"code","metadata":{"id":"yFpZGu1F_dA4"},"source":["#BayesDetector: Collaborative Shilling Detection Bridging Factorization and User Embedding\n","class BayesDetector(SDetection):\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]'):\n","        super(BayesDetector, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","    def readConfiguration(self):\n","        super(BayesDetector, self).readConfiguration()\n","        extraSettings = LineConfig(self.config['BayesDetector'])\n","        self.k = int(extraSettings['-k'])\n","        self.negCount = int(extraSettings['-negCount'])  # the number of negative samples\n","        if self.negCount < 1:\n","            self.negCount = 1\n","\n","        self.regR = float(extraSettings['-gamma'])\n","        self.filter = int(extraSettings['-filter'])\n","        self.delta = float(extraSettings['-delta'])\n","        learningRate = LineConfig(self.config['learnRate'])\n","        self.lRate = float(learningRate['-init'])\n","        self.maxLRate = float(learningRate['-max'])\n","        self.maxIter = int(self.config['num.max.iter'])\n","        regular = LineConfig(self.config['reg.lambda'])\n","        self.regU, self.regI = float(regular['-u']), float(regular['-i'])\n","        # self.delta = float(self.config['delta'])\n","    def printAlgorConfig(self):\n","        super(BayesDetector, self).printAlgorConfig()\n","        print('k: %d' % self.negCount)\n","        print('regR: %.5f' % self.regR)\n","        print('filter: %d' % self.filter)\n","        print('=' * 80)\n","\n","    def initModel(self):\n","        super(BayesDetector, self).initModel()\n","        # self.c = np.random.rand(len(self.dao.all_User) + 1) / 20  # bias value of context\n","        self.G = np.random.rand(len(self.dao.all_User)+1, self.k) / 100  # context embedding\n","        self.P = np.random.rand(len(self.dao.all_User)+1, self.k) / 100  # latent user matrix\n","        self.Q = np.random.rand(len(self.dao.all_Item)+1, self.k) / 100  # latent item matrix\n","\n","        # constructing SPPMI matrix\n","        self.SPPMI = defaultdict(dict)\n","        D = len(self.dao.user)\n","        print('Constructing SPPMI matrix...')\n","        # for larger data set has many items, the process will be time consuming\n","        occurrence = defaultdict(dict)\n","        for user1 in self.dao.all_User:\n","            iList1, rList1 = self.dao.allUserRated(user1)\n","            if len(iList1) < self.filter:\n","                continue\n","            for user2 in self.dao.all_User:\n","                if user1 == user2:\n","                    continue\n","                if user2 not in occurrence[user1]:\n","                    iList2, rList2 = self.dao.allUserRated(user2)\n","                    if len(iList2) < self.filter:\n","                        continue\n","                    count = len(set(iList1).intersection(set(iList2)))\n","                    if count > self.filter:\n","                        occurrence[user1][user2] = count\n","                        occurrence[user2][user1] = count\n","\n","        maxVal = 0\n","        frequency = {}\n","        for user1 in occurrence:\n","            frequency[user1] = sum(occurrence[user1].values()) * 1.0\n","        D = sum(frequency.values()) * 1.0\n","        # maxx = -1\n","        for user1 in occurrence:\n","            for user2 in occurrence[user1]:\n","                try:\n","                    val = max([log(occurrence[user1][user2] * D / (frequency[user1] * frequency[user2]), 2) - log(\n","                        self.negCount, 2), 0])\n","                except ValueError:\n","                    print(self.SPPMI[user1][user2])\n","                    print(self.SPPMI[user1][user2] * D / (frequency[user1] * frequency[user2]))\n","                if val > 0:\n","                    if maxVal < val:\n","                        maxVal = val\n","                    self.SPPMI[user1][user2] = val\n","                    self.SPPMI[user2][user1] = self.SPPMI[user1][user2]\n","\n","        # normalize\n","        for user1 in self.SPPMI:\n","            for user2 in self.SPPMI[user1]:\n","                self.SPPMI[user1][user2] = self.SPPMI[user1][user2] / maxVal\n","\n","    def buildModel(self):\n","        self.dao.ratings = dict(self.dao.trainingSet_u, **self.dao.testSet_u)\n","        #suspicous set\n","        print('Preparing sets...')\n","        self.sSet = defaultdict(dict)\n","        #normal set\n","        self.nSet = defaultdict(dict)\n","        # self.NegativeSet = defaultdict(list)\n","\n","        for user in self.dao.user:\n","            for item in self.dao.ratings[user]:\n","                # if self.dao.ratings[user][item] >= 5 and self.labels[user]=='1':\n","                if self.labels[user] =='1':\n","                    self.sSet[item][user] = 1\n","                # if self.dao.ratings[user][item] >= 5 and self.labels[user] == '0':\n","                if self.labels[user] == '0':\n","                    self.nSet[item][user] = 1\n","        # Jointly decompose R(ratings) and SPPMI with shared user latent factors P\n","        iteration = 0\n","        while iteration < self.maxIter:\n","            self.loss = 0\n","\n","            for item in self.sSet:\n","                i = self.dao.all_Item[item]\n","                if item not in self.nSet:\n","                    continue\n","                normalUserList = list(self.nSet[item].keys())\n","                for user in self.sSet[item]:\n","                    su = self.dao.all_User[user]\n","                    # if len(self.NegativeSet[user]) > 0:\n","                    #     item_j = choice(self.NegativeSet[user])\n","                    # else:\n","                    normalUser = choice(normalUserList)\n","                    nu = self.dao.all_User[normalUser]\n","\n","                    s = sigmoid(self.P[su].dot(self.Q[i]) - self.P[nu].dot(self.Q[i]))\n","                    self.Q[i] += (self.lRate * (1 - s) * (self.P[su] - self.P[nu]))\n","                    self.P[su] += (self.lRate * (1 - s) * self.Q[i])\n","                    self.P[nu] -= (self.lRate * (1 - s) * self.Q[i])\n","\n","                    self.Q[i] -= self.lRate * self.regI * self.Q[i]\n","                    self.P[su] -= self.lRate * self.regU * self.P[su]\n","                    self.P[nu] -= self.lRate * self.regU * self.P[nu]\n","\n","                    self.loss += (-log(s))\n","            #\n","            # for item in self.sSet:\n","            #     if not self.nSet.has_key(item):\n","            #         continue\n","            #     for user1 in self.sSet[item]:\n","            #         for user2 in self.sSet[item]:\n","            #             su1 = self.dao.all_User[user1]\n","            #             su2 = self.dao.all_User[user2]\n","            #             self.P[su1] += (self.lRate*(self.P[su1]-self.P[su2]))*self.delta\n","            #             self.P[su2] -= (self.lRate*(self.P[su1]-self.P[su2]))*self.delta\n","            #\n","            #             self.loss += ((self.P[su1]-self.P[su2]).dot(self.P[su1]-self.P[su2]))*self.delta\n","\n","\n","            for user in self.dao.ratings:\n","                for item in self.dao.ratings[user]:\n","                    rating = self.dao.ratings[user][item]\n","                    if rating < 5:\n","                        continue\n","                    error = rating - self.predictRating(user,item)\n","                    u = self.dao.all_User[user]\n","                    i = self.dao.all_Item[item]\n","                    p = self.P[u]\n","                    q = self.Q[i]\n","                    # self.loss += (error ** 2)*self.b\n","                    # update latent vectors\n","                    self.P[u] += (self.lRate * (error * q - self.regU * p))\n","                    self.Q[i] += (self.lRate * (error * p - self.regI * q))\n","\n","\n","            for user in self.SPPMI:\n","                u = self.dao.all_User[user]\n","                p = self.P[u]\n","                for context in self.SPPMI[user]:\n","                    v = self.dao.all_User[context]\n","                    m = self.SPPMI[user][context]\n","                    g = self.G[v]\n","                    diff = (m - p.dot(g))\n","                    self.loss += (diff ** 2)\n","                    # update latent vectors\n","                    self.P[u] += (self.lRate * diff * g)\n","                    self.G[v] += (self.lRate * diff * p)\n","            self.loss += self.regU * (self.P * self.P).sum() + self.regI * (self.Q * self.Q).sum()  + self.regR * (self.G * self.G).sum()\n","            iteration += 1\n","            print('iteration:',iteration)\n","\n","        # preparing examples\n","        self.training = []\n","        self.trainingLabels = []\n","        self.test = []\n","        self.testLabels = []\n","\n","        for user in self.dao.trainingSet_u:\n","            self.training.append(self.P[self.dao.all_User[user]])\n","            self.trainingLabels.append(self.labels[user])\n","        for user in self.dao.testSet_u:\n","            self.test.append(self.P[self.dao.all_User[user]])\n","            self.testLabels.append(self.labels[user])\n","        #\n","        # tsne = TSNE(n_components=2)\n","        # self.Y = tsne.fit_transform(self.P)\n","        #\n","        # self.normalUsers = []\n","        # self.spammers = []\n","        # for user in self.labels:\n","        #     if self.labels[user] == '0':\n","        #         self.normalUsers.append(user)\n","        #     else:\n","        #         self.spammers.append(user)\n","        #\n","        #\n","        # print len(self.spammers)\n","        # self.normalfeature = np.zeros((len(self.normalUsers), 2))\n","        # self.spamfeature = np.zeros((len(self.spammers), 2))\n","        # normal_index = 0\n","        # for normaluser in self.normalUsers:\n","        #     if normaluser in self.dao.all_User:\n","        #         self.normalfeature[normal_index] = self.Y[self.dao.all_User[normaluser]]\n","        #         normal_index += 1\n","        #\n","        # spam_index = 0\n","        # for spamuser in self.spammers:\n","        #     if spamuser in self.dao.all_User:\n","        #         self.spamfeature[spam_index] = self.Y[self.dao.all_User[spamuser]]\n","        #         spam_index += 1\n","        # self.randomNormal = np.zeros((500,2))\n","        # self.randomSpam = np.zeros((500,2))\n","        # # for i in range(500):\n","        # #     self.randomNormal[i] = self.normalfeature[random.randint(0,len(self.normalfeature)-1)]\n","        # #     self.randomSpam[i] = self.spamfeature[random.randint(0,len(self.spamfeature)-1)]\n","        # plt.scatter(self.normalfeature[:, 0], self.normalfeature[:, 1], c='red',s=8,marker='o',label='NormalUser')\n","        # plt.scatter(self.spamfeature[:, 0], self.spamfeature[:, 1], c='blue',s=8,marker='o',label='Spammer')\n","        # plt.legend(loc='lower left')\n","        # plt.xticks([])\n","        # plt.yticks([])\n","        # plt.savefig('9.png',dpi=500)\n","\n","\n","    def predictRating(self,user,item):\n","        u = self.dao.all_User[user]\n","        i = self.dao.all_Item[item]\n","        return self.P[u].dot(self.Q[i])\n","\n","    def predict(self):\n","        classifier =  RandomForestClassifier(n_estimators=12)\n","        # classifier = DecisionTreeClassifier(criterion='entropy')\n","        classifier.fit(self.training, self.trainingLabels)\n","        pred_labels = classifier.predict(self.test)\n","        print('Decision Tree:')\n","        return pred_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oMYfGVsl_c-Z"},"source":["### CoDetector"]},{"cell_type":"code","metadata":{"id":"2r1_ZpIT_c77"},"source":["#CoDetector: Collaborative Shilling Detection Bridging Factorization and User Embedding\n","class CoDetector(SDetection):\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]'):\n","        super(CoDetector, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","    def readConfiguration(self):\n","        super(CoDetector, self).readConfiguration()\n","        extraSettings = LineConfig(self.config['CoDetector'])\n","        self.k = int(extraSettings['-k'])\n","        self.negCount = int(extraSettings['-negCount'])  # the number of negative samples\n","        if self.negCount < 1:\n","            self.negCount = 1\n","\n","        self.regR = float(extraSettings['-gamma'])\n","        self.filter = int(extraSettings['-filter'])\n","\n","        learningRate = LineConfig(self.config['learnRate'])\n","        self.lRate = float(learningRate['-init'])\n","        self.maxLRate = float(learningRate['-max'])\n","        self.maxIter = int(self.config['num.max.iter'])\n","        regular = LineConfig(self.config['reg.lambda'])\n","        self.regU, self.regI = float(regular['-u']), float(regular['-i'])\n","\n","    def printAlgorConfig(self):\n","        super(CoDetector, self).printAlgorConfig()\n","        print('k: %d' % self.negCount)\n","        print('regR: %.5f' % self.regR)\n","        print('filter: %d' % self.filter)\n","        print('=' * 80)\n","\n","    def initModel(self):\n","        super(CoDetector, self).initModel()\n","        self.w = np.random.rand(len(self.dao.all_User)+1) / 20  # bias value of user\n","        self.c = np.random.rand(len(self.dao.all_User)+1)/ 20  # bias value of context\n","        self.G = np.random.rand(len(self.dao.all_User)+1, self.k) / 20  # context embedding\n","        self.P = np.random.rand(len(self.dao.all_User)+1, self.k) / 20  # latent user matrix\n","        self.Q = np.random.rand(len(self.dao.all_Item)+1, self.k) / 20  # latent item matrix\n","\n","\n","        # constructing SPPMI matrix\n","        self.SPPMI = defaultdict(dict)\n","        D = len(self.dao.user)\n","        print('Constructing SPPMI matrix...')\n","        # for larger data set has many items, the process will be time consuming\n","        occurrence = defaultdict(dict)\n","        for user1 in self.dao.all_User:\n","            iList1, rList1 = self.dao.allUserRated(user1)\n","            if len(iList1) < self.filter:\n","                continue\n","            for user2 in self.dao.all_User:\n","                if user1 == user2:\n","                    continue\n","                if user2 not in occurrence[user1]:\n","                    iList2, rList2 = self.dao.allUserRated(user2)\n","                    if len(iList2) < self.filter:\n","                        continue\n","                    count = len(set(iList1).intersection(set(iList2)))\n","                    if count > self.filter:\n","                        occurrence[user1][user2] = count\n","                        occurrence[user2][user1] = count\n","\n","        maxVal = 0\n","        frequency = {}\n","        for user1 in occurrence:\n","            frequency[user1] = sum(occurrence[user1].values()) * 1.0\n","        D = sum(frequency.values()) * 1.0\n","        # maxx = -1\n","        for user1 in occurrence:\n","            for user2 in occurrence[user1]:\n","                try:\n","                    val = max([log(occurrence[user1][user2] * D / (frequency[user1] * frequency[user2]), 2) - log(\n","                        self.negCount, 2), 0])\n","                except ValueError:\n","                    print(self.SPPMI[user1][user2])\n","                    print(self.SPPMI[user1][user2] * D / (frequency[user1] * frequency[user2]))\n","                if val > 0:\n","                    if maxVal < val:\n","                        maxVal = val\n","                    self.SPPMI[user1][user2] = val\n","                    self.SPPMI[user2][user1] = self.SPPMI[user1][user2]\n","\n","        # normalize\n","        for user1 in self.SPPMI:\n","            for user2 in self.SPPMI[user1]:\n","                self.SPPMI[user1][user2] = self.SPPMI[user1][user2] / maxVal\n","\n","    def buildModel(self):\n","        # Jointly decompose R(ratings) and SPPMI with shared user latent factors P\n","        iteration = 0\n","        while iteration < self.maxIter:\n","            self.loss = 0\n","\n","            self.dao.ratings = dict(self.dao.trainingSet_u, **self.dao.testSet_u)\n","            for user in self.dao.ratings:\n","                for item in self.dao.ratings[user]:\n","                    rating = self.dao.ratings[user][item]\n","                    error = rating - self.predictRating(user,item)\n","                    u = self.dao.all_User[user]\n","                    i = self.dao.all_Item[item]\n","                    p = self.P[u]\n","                    q = self.Q[i]\n","                    self.loss += error ** 2\n","                    # update latent vectors\n","                    self.P[u] += self.lRate * (error * q - self.regU * p)\n","                    self.Q[i] += self.lRate * (error * p - self.regI * q)\n","\n","\n","            for user in self.SPPMI:\n","                u = self.dao.all_User[user]\n","                p = self.P[u]\n","                for context in self.SPPMI[user]:\n","                    v = self.dao.all_User[context]\n","                    m = self.SPPMI[user][context]\n","                    g = self.G[v]\n","                    diff = (m - p.dot(g) - self.w[u] - self.c[v])\n","                    self.loss += diff ** 2\n","                    # update latent vectors\n","                    self.P[u] += self.lRate * diff * g\n","                    self.G[v] += self.lRate * diff * p\n","                    self.w[u] += self.lRate * diff\n","                    self.c[v] += self.lRate * diff\n","            self.loss += self.regU * (self.P * self.P).sum() + self.regI * (self.Q * self.Q).sum()  + self.regR * (self.G * self.G).sum()\n","            iteration += 1\n","            print('iteration:',iteration)\n","\n","        # preparing examples\n","        self.training = []\n","        self.trainingLabels = []\n","        self.test = []\n","        self.testLabels = []\n","\n","        for user in self.dao.trainingSet_u:\n","            self.training.append(self.P[self.dao.all_User[user]])\n","            self.trainingLabels.append(self.labels[user])\n","        for user in self.dao.testSet_u:\n","            self.test.append(self.P[self.dao.all_User[user]])\n","            self.testLabels.append(self.labels[user])\n","\n","    def predictRating(self,user,item):\n","        u = self.dao.all_User[user]\n","        i = self.dao.all_Item[item]\n","        return self.P[u].dot(self.Q[i])\n","\n","    def predict(self):\n","        classifier =  DecisionTreeClassifier(criterion='entropy')\n","        classifier.fit(self.training, self.trainingLabels)\n","        pred_labels = classifier.predict(self.test)\n","        print('Decision Tree:')\n","        return pred_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYM6GuD-0QgA"},"source":["### DegreeSAD"]},{"cell_type":"code","metadata":{"id":"SFuhZGNP0SCw"},"source":["class DegreeSAD(SDetection):\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]'):\n","        super(DegreeSAD, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","    def buildModel(self):\n","        self.MUD = {}\n","        self.RUD = {}\n","        self.QUD = {}\n","        # computing MUD,RUD,QUD for training set\n","        sList = sorted(iter(self.dao.trainingSet_i.items()), key=lambda d: len(d[1]), reverse=True)\n","        maxLength = len(sList[0][1])\n","        for user in self.dao.trainingSet_u:\n","            self.MUD[user] = 0\n","            for item in self.dao.trainingSet_u[user]:\n","                self.MUD[user] += len(self.dao.trainingSet_i[item]) #/ float(maxLength)\n","            self.MUD[user]/float(len(self.dao.trainingSet_u[user]))\n","            lengthList = [len(self.dao.trainingSet_i[item]) for item in self.dao.trainingSet_u[user]]\n","            lengthList.sort(reverse=True)\n","            self.RUD[user] = lengthList[0] - lengthList[-1]\n","\n","            lengthList = [len(self.dao.trainingSet_i[item]) for item in self.dao.trainingSet_u[user]]\n","            lengthList.sort()\n","            self.QUD[user] = lengthList[int((len(lengthList) - 1) / 4.0)]\n","\n","        # computing MUD,RUD,QUD for test set\n","        for user in self.dao.testSet_u:\n","            self.MUD[user] = 0\n","            for item in self.dao.testSet_u[user]:\n","                self.MUD[user] += len(self.dao.trainingSet_i[item]) #/ float(maxLength)\n","        for user in self.dao.testSet_u:\n","            lengthList = [len(self.dao.trainingSet_i[item]) for item in self.dao.testSet_u[user]]\n","            lengthList.sort(reverse=True)\n","            self.RUD[user] = lengthList[0] - lengthList[-1]\n","        for user in self.dao.testSet_u:\n","            lengthList = [len(self.dao.trainingSet_i[item]) for item in self.dao.testSet_u[user]]\n","            lengthList.sort()\n","            self.QUD[user] = lengthList[int((len(lengthList) - 1) / 4.0)]\n","\n","        # preparing examples\n","\n","        for user in self.dao.trainingSet_u:\n","            self.training.append([self.MUD[user], self.RUD[user], self.QUD[user]])\n","            self.trainingLabels.append(self.labels[user])\n","\n","        for user in self.dao.testSet_u:\n","            self.test.append([self.MUD[user], self.RUD[user], self.QUD[user]])\n","            self.testLabels.append(self.labels[user])\n","\n","    def predict(self):\n","        # classifier = LogisticRegression()\n","        # classifier.fit(self.training, self.trainingLabels)\n","        # pred_labels = classifier.predict(self.test)\n","        # print 'Logistic:'\n","        # print classification_report(self.testLabels, pred_labels)\n","        #\n","        # classifier = SVC()\n","        # classifier.fit(self.training, self.trainingLabels)\n","        # pred_labels = classifier.predict(self.test)\n","        # print 'SVM:'\n","        # print classification_report(self.testLabels, pred_labels)\n","\n","        classifier = DecisionTreeClassifier(criterion='entropy')\n","        classifier.fit(self.training, self.trainingLabels)\n","        pred_labels = classifier.predict(self.test)\n","        print('Decision Tree:')\n","        return pred_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qw1J9EML_c4B"},"source":["### FAP"]},{"cell_type":"code","metadata":{"id":"GI3xwj1V_c05"},"source":["class FAP(SDetection):\n","\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]'):\n","        super(FAP, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","    def readConfiguration(self):\n","        super(FAP, self).readConfiguration()\n","        # # s means the number of seedUser who be regarded as spammer in training\n","        self.s =int( self.config['seedUser'])\n","        # preserve the real spammer ID\n","        self.spammer = []\n","        for i in self.dao.user:\n","            if self.labels[i] == '1':\n","                self.spammer.append(self.dao.user[i])\n","        sThreshold = int(0.5 * len(self.spammer))\n","        if self.s > sThreshold :\n","            self.s = sThreshold\n","            print('*** seedUser is more than a half of spammer, so it is set to', sThreshold, '***')\n","\n","        # # predict top-k user as spammer\n","        self.k = int(self.config['topKSpam'])\n","        # 0.5 is the ratio of spammer to dataset, it can be changed according to different datasets\n","        kThreshold = int(0.5 * (len(self.dao.user) - self.s))\n","        if self.k > kThreshold:\n","            self.k = kThreshold\n","            print('*** the number of top-K users is more than threshold value, so it is set to', kThreshold, '***')\n","    # product transition probability matrix self.TPUI and self.TPIU\n","\n","    def __computeTProbability(self):\n","        # m--user count; n--item count\n","        m, n, tmp = self.dao.trainingSize()\n","        self.TPUI = np.zeros((m, n))\n","        self.TPIU = np.zeros((n, m))\n","\n","        self.userUserIdDic = {}\n","        self.itemItemIdDic = {}\n","        tmpUser = list(self.dao.user.values())\n","        tmpUserId = list(self.dao.user.keys())\n","        tmpItem = list(self.dao.item.values())\n","        tmpItemId = list(self.dao.item.keys())\n","        for users in range(0, m):\n","            self.userUserIdDic[tmpUser[users]] = tmpUserId[users]\n","        for items in range(0, n):\n","            self.itemItemIdDic[tmpItem[items]] = tmpItemId[items]\n","        for i in range(0, m):\n","            for j in range(0, n):\n","                user = self.userUserIdDic[i]\n","                item = self.itemItemIdDic[j]\n","                # if has edge in graph,set a value ;otherwise set 0\n","                if (user not in self.bipartiteGraphUI) or (item not in self.bipartiteGraphUI[user]):\n","                    continue\n","                else:\n","                    w = float(self.bipartiteGraphUI[user][item])\n","                    # to avoid positive feedback and reliability problem,we should Polish the w\n","                    otherItemW = 0\n","                    otherUserW = 0\n","                    for otherItem in self.bipartiteGraphUI[user]:\n","                        otherItemW += float(self.bipartiteGraphUI[user][otherItem])\n","                    for otherUser in self.dao.trainingSet_i[item]:\n","                        otherUserW += float(self.bipartiteGraphUI[otherUser][item])\n","                    # wPrime = w*1.0/(otherUserW * otherItemW)\n","                    wPrime = w\n","                    self.TPUI[i][j] = wPrime / otherItemW\n","                    self.TPIU[j][i] = wPrime / otherUserW\n","            if i % 100 == 0:\n","                print('progress: %d/%d' %(i,m))\n","\n","    def initModel(self):\n","        # construction of the bipartite graph\n","        print(\"constructing bipartite graph...\")\n","        self.bipartiteGraphUI = {}\n","        for user in self.dao.trainingSet_u:\n","            tmpUserItemDic = {}  # user-item-point\n","            for item in self.dao.trainingSet_u[user]:\n","                # tmpItemUserDic = {}#item-user-point\n","                recordValue = float(self.dao.trainingSet_u[user][item])\n","                w = 1 + abs((recordValue - self.dao.userMeans[user]) / self.dao.userMeans[user]) + abs(\n","                    (recordValue - self.dao.itemMeans[item]) / self.dao.itemMeans[item]) + abs(\n","                    (recordValue - self.dao.globalMean) / self.dao.globalMean)\n","                # tmpItemUserDic[user] = w\n","                tmpUserItemDic[item] = w\n","            # self.bipartiteGraphIU[item] = tmpItemUserDic\n","            self.bipartiteGraphUI[user] = tmpUserItemDic\n","        # we do the polish in computing the transition probability\n","        print(\"computing transition probability...\")\n","        self.__computeTProbability()\n","\n","    def isConvergence(self, PUser, PUserOld):\n","        if len(PUserOld) == 0:\n","            return True\n","        for i in range(0, len(PUser)):\n","            if (PUser[i] - PUserOld[i]) > 0.01:\n","                return True\n","        return False\n","\n","    def buildModel(self):\n","        # -------init--------\n","        m, n, tmp = self.dao.trainingSize()\n","        PUser = np.zeros(m)\n","        PItem = np.zeros(n)\n","        self.testLabels = [0 for i in range(m)]\n","        self.predLabels = [0 for i in range(m)]\n","\n","        # preserve seedUser Index\n","        self.seedUser = []\n","        randDict = {}\n","        for i in range(0, self.s):\n","            randNum = random.randint(0, len(self.spammer) - 1)\n","            while randNum in randDict:\n","                randNum = random.randint(0, len(self.spammer) - 1)\n","            randDict[randNum] = 0\n","            self.seedUser.append(int(self.spammer[randNum]))\n","            # print len(randDict), randDict\n","\n","        #initial user and item spam probability\n","        for j in range(0, m):\n","            if j in self.seedUser:\n","                #print type(j),j\n","                PUser[j] = 1\n","            else:\n","                PUser[j] = random.random()\n","        for tmp in range(0, n):\n","            PItem[tmp] = random.random()\n","\n","        # -------iterator-------\n","        PUserOld = []\n","        iterator = 0\n","        while self.isConvergence(PUser, PUserOld):\n","        #while iterator < 100:\n","            for j in self.seedUser:\n","                PUser[j] = 1\n","            PUserOld = PUser\n","            PItem = np.dot(self.TPIU, PUser)\n","            PUser = np.dot(self.TPUI, PItem)\n","            iterator += 1\n","            print(self.foldInfo,'iteration', iterator)\n","\n","        PUserDict = {}\n","        userId = 0\n","        for i in PUser:\n","            PUserDict[userId] = i\n","            userId += 1\n","        for j in self.seedUser:\n","            del PUserDict[j]\n","\n","        self.PSort = sorted(iter(PUserDict.items()), key=lambda d: d[1], reverse=True)\n","\n","\n","    def predict(self):\n","        # predLabels\n","        # top-k user as spammer\n","        spamList = []\n","        sIndex = 0\n","        while sIndex < self.k:\n","            spam = self.PSort[sIndex][0]\n","            spamList.append(spam)\n","            self.predLabels[spam] = 1\n","            sIndex += 1\n","\n","        # trueLabels\n","        for user in self.dao.trainingSet_u:\n","            userInd = self.dao.user[user]\n","            # print type(user), user, userInd\n","            self.testLabels[userInd] = int(self.labels[user])\n","\n","        # delete seedUser labels\n","        differ = 0\n","        for user in self.seedUser:\n","            user = int(user - differ)\n","            # print type(user)\n","            del self.predLabels[user]\n","            del self.testLabels[user]\n","            differ += 1\n","\n","        return self.predLabels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gdk4fDUP_cvp"},"source":["### PCASelectUsers"]},{"cell_type":"code","metadata":{"id":"R8d1wxY2_csN"},"source":["class PCASelectUsers(SDetection):\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]', k=None, n=None ):\n","        super(PCASelectUsers, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","\n","    def readConfiguration(self):\n","        super(PCASelectUsers, self).readConfiguration()\n","        # K = top-K vals of cov\n","        self.k = int(self.config['kVals'])\n","        self.userNum = len(self.dao.trainingSet_u)\n","        self.itemNum = len(self.dao.trainingSet_i)\n","        if self.k >= min(self.userNum, self.itemNum):\n","            self.k = 3\n","            print('*** k-vals is more than the number of user or item, so it is set to', self.k)\n","\n","        # n = attack size or the ratio of spammers to normal users\n","        self.n = float(self.config['attackSize'])\n","\n","\n","    def buildModel(self):\n","        #array initialization\n","        dataArray = np.zeros([self.userNum, self.itemNum], dtype=float)\n","        self.testLabels = np.zeros(self.userNum)\n","        self.predLabels = np.zeros(self.userNum)\n","\n","        #add data\n","        print('construct matrix')\n","        for user in self.dao.trainingSet_u:\n","            for item in list(self.dao.trainingSet_u[user].keys()):\n","                value = self.dao.trainingSet_u[user][item]\n","                a = self.dao.user[user]\n","                b = self.dao.item[item]\n","                dataArray[a][b] = value\n","\n","        sMatrix = csr_matrix(dataArray)\n","        # z-scores\n","        sMatrix = preprocessing.scale(sMatrix, axis=0, with_mean=False)\n","        sMT = np.transpose(sMatrix)\n","        # cov\n","        covSM = np.dot(sMT, sMatrix)\n","        # eigen-value-decomposition\n","        vals, vecs = scipy.sparse.linalg.eigs(covSM, k=self.k, which='LM')\n","\n","        newArray = np.dot(dataArray**2, np.real(vecs))\n","\n","        distanceDict = {}\n","        userId = 0\n","        for user in newArray:\n","            distance = 0\n","            for tmp in user:\n","                distance += tmp\n","            distanceDict[userId] = float(distance)\n","            userId += 1\n","\n","        print('sort distance ')\n","        self.disSort = sorted(iter(distanceDict.items()), key=lambda d: d[1], reverse=False)\n","\n","\n","    def predict(self):\n","        print('predict spammer')\n","        spamList = []\n","        i = 0\n","        while i < self.n * len(self.disSort):\n","            spam = self.disSort[i][0]\n","            spamList.append(spam)\n","            self.predLabels[spam] = 1\n","            i += 1\n","\n","        # trueLabels\n","        for user in self.dao.trainingSet_u:\n","            userInd = self.dao.user[user]\n","            self.testLabels[userInd] = int(self.labels[user])\n","\n","        return self.predLabels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KMHaQzDuAYY-"},"source":["### SemiSAD"]},{"cell_type":"code","metadata":{"id":"vn7EqiezAYUg"},"source":["class SemiSAD(SDetection):\n","    def __init__(self, conf, trainingSet=None, testSet=None, labels=None, fold='[1]'):\n","        super(SemiSAD, self).__init__(conf, trainingSet, testSet, labels, fold)\n","\n","    def readConfiguration(self):\n","        super(SemiSAD, self).readConfiguration()\n","        # K = top-K vals of cov\n","        self.k = int(self.config['topK'])\n","        # Lambda = λ参数\n","        self.Lambda = float(self.config['Lambda'])\n","\n","    def buildModel(self):\n","        self.H = {}\n","        self.DegSim = {}\n","        self.LengVar = {}\n","        self.RDMA = {}\n","        self.FMTD = {}\n","        print('Begin feature engineering...')\n","        # computing H,DegSim,LengVar,RDMA,FMTD for LabledData set\n","        trainingIndex = 0\n","        testIndex = 0\n","        trainingUserCount, trainingItemCount, trainingrecordCount = self.dao.trainingSize()\n","        testUserCount, testItemCount, testrecordCount = self.dao.testSize()\n","        for user in self.dao.trainingSet_u:\n","            trainingIndex += 1\n","            self.H[user] = 0\n","            for i in range(10,50,5):\n","                n = 0\n","                for item in self.dao.trainingSet_u[user]:\n","                    if(self.dao.trainingSet_u[user][item]==(i/10.0)):\n","                        n+=1\n","                if n==0:\n","                    self.H[user] += 0\n","                else:\n","                    self.H[user] += (-(n/(trainingUserCount*1.0))*math.log(n/(trainingUserCount*1.0),2))\n","\n","            SimList = []\n","            self.DegSim[user] = 0\n","            for user1 in self.dao.trainingSet_u:\n","                userA, userB, C, D, E, Count = 0,0,0,0,0,0\n","                for item in list(set(self.dao.trainingSet_u[user]).intersection(set(self.dao.trainingSet_u[user1]))):\n","                    userA += self.dao.trainingSet_u[user][item]\n","                    userB += self.dao.trainingSet_u[user1][item]\n","                    Count += 1\n","                if Count==0:\n","                    AverageA = 0\n","                    AverageB = 0\n","                else:\n","                    AverageA = userA/Count\n","                    AverageB = userB/Count\n","                for item in list(set(self.dao.trainingSet_u[user]).intersection(set(self.dao.trainingSet_u[user1]))):\n","                    C += (self.dao.trainingSet_u[user][item]-AverageA)*(self.dao.trainingSet_u[user1][item]-AverageB)\n","                    D += np.square(self.dao.trainingSet_u[user][item]-AverageA)\n","                    E += np.square(self.dao.trainingSet_u[user1][item]-AverageB)\n","                if C==0:\n","                    SimList.append(0.0)\n","                else:\n","                    SimList.append(C/(math.sqrt(D)*math.sqrt(E)))\n","            SimList.sort(reverse=True)\n","            for i in range(1,self.k+1):\n","                self.DegSim[user] += SimList[i] / (self.k)\n","\n","            GlobalAverage = 0\n","            F = 0\n","            for user2 in self.dao.trainingSet_u:\n","                GlobalAverage += len(self.dao.trainingSet_u[user2]) / (len(self.dao.trainingSet_u) + 0.0)\n","            for user3 in self.dao.trainingSet_u:\n","                F += pow(len(self.dao.trainingSet_u[user3])-GlobalAverage,2)\n","            self.LengVar[user] = abs(len(self.dao.trainingSet_u[user])-GlobalAverage)/(F*1.0)\n","\n","            Divisor = 0\n","            for item1 in self.dao.trainingSet_u[user]:\n","                Divisor += abs(self.dao.trainingSet_u[user][item1]-self.dao.itemMeans[item1])/len(self.dao.trainingSet_i[item1])\n","            self.RDMA[user] = Divisor/len(self.dao.trainingSet_u[user])\n","\n","            Minuend, index1, Subtrahend, index2 = 0, 0, 0, 0\n","            for item3 in self.dao.trainingSet_u[user]:\n","                if(self.dao.trainingSet_u[user][item3]==5.0 or self.dao.trainingSet_u[user][item3]==1.0) :\n","                    Minuend += sum(self.dao.trainingSet_i[item3].values())\n","                    index1 += len(self.dao.trainingSet_i[item3])\n","                else:\n","                    Subtrahend += sum(self.dao.trainingSet_i[item3].values())\n","                    index2 += len(self.dao.trainingSet_i[item3])\n","            if index1 == 0 and index2 == 0:\n","                self.FMTD[user] = 0\n","            elif index1 == 0:\n","                self.FMTD[user] = abs(Subtrahend / index2)\n","            elif index2 == 0:\n","                self.FMTD[user] = abs(Minuend / index1)\n","            else:\n","                self.FMTD[user] = abs(Minuend / index1 - Subtrahend / index2)\n","\n","            if trainingIndex==(trainingUserCount/5):\n","                print('trainingData Done 20%...')\n","            elif trainingIndex==(trainingUserCount/5*2):\n","                print('trainingData Done 40%...')\n","            elif trainingIndex==(trainingUserCount/5*3):\n","                print('trainingData Done 60%...')\n","            elif trainingIndex==(trainingUserCount/5*4):\n","                print('trainingData Done 80%...')\n","            elif trainingIndex==(trainingUserCount):\n","                print('trainingData Done 100%...')\n","\n","        # computing H,DegSim,LengVar,RDMA,FMTD for UnLabledData set\n","        for user in self.dao.testSet_u:\n","            testIndex += 1\n","            self.H[user] = 0\n","            for i in range(10,50,5):\n","                n = 0\n","                for item in self.dao.testSet_u[user]:\n","                    if(self.dao.testSet_u[user][item]==(i/10.0)):\n","                        n+=1\n","                if n==0:\n","                    self.H[user] += 0\n","                else:\n","                    self.H[user] += (-(n/(testUserCount*1.0))*math.log(n/(testUserCount*1.0),2))\n","\n","            SimList = []\n","            self.DegSim[user] = 0\n","            for user1 in self.dao.testSet_u:\n","                userA, userB, C, D, E, Count = 0,0,0,0,0,0\n","                for item in list(set(self.dao.testSet_u[user]).intersection(set(self.dao.testSet_u[user1]))):\n","                    userA += self.dao.testSet_u[user][item]\n","                    userB += self.dao.testSet_u[user1][item]\n","                    Count += 1\n","                if Count==0:\n","                    AverageA = 0\n","                    AverageB = 0\n","                else:\n","                    AverageA = userA/Count\n","                    AverageB = userB/Count\n","                for item in list(set(self.dao.testSet_u[user]).intersection(set(self.dao.testSet_u[user1]))):\n","                    C += (self.dao.testSet_u[user][item]-AverageA)*(self.dao.testSet_u[user1][item]-AverageB)\n","                    D += np.square(self.dao.testSet_u[user][item]-AverageA)\n","                    E += np.square(self.dao.testSet_u[user1][item]-AverageB)\n","                if C==0:\n","                    SimList.append(0.0)\n","                else:\n","                    SimList.append(C/(math.sqrt(D)*math.sqrt(E)))\n","            SimList.sort(reverse=True)\n","            for i in range(1,self.k+1):\n","                self.DegSim[user] += SimList[i] / self.k\n","\n","            GlobalAverage = 0\n","            F = 0\n","            for user2 in self.dao.testSet_u:\n","                GlobalAverage += len(self.dao.testSet_u[user2]) / (len(self.dao.testSet_u) + 0.0)\n","            for user3 in self.dao.testSet_u:\n","                F += pow(len(self.dao.testSet_u[user3])-GlobalAverage,2)\n","            self.LengVar[user] = abs(len(self.dao.testSet_u[user])-GlobalAverage)/(F*1.0)\n","\n","            Divisor = 0\n","            for item1 in self.dao.testSet_u[user]:\n","                Divisor += abs(self.dao.testSet_u[user][item1]-self.dao.itemMeans[item1])/len(self.dao.testSet_i[item1])\n","            self.RDMA[user] = Divisor/len(self.dao.testSet_u[user])\n","\n","            Minuend, index1, Subtrahend, index2= 0,0,0,0\n","            for item3 in self.dao.testSet_u[user]:\n","                if(self.dao.testSet_u[user][item3]==5.0 or self.dao.testSet_u[user][item3]==1.0):\n","                    Minuend += sum(self.dao.testSet_i[item3].values())\n","                    index1 += len(self.dao.testSet_i[item3])\n","                else:\n","                    Subtrahend += sum(self.dao.testSet_i[item3].values())\n","                    index2 += len(self.dao.testSet_i[item3])\n","            if index1 == 0 and index2 == 0:\n","                self.FMTD[user] = 0\n","            elif index1 == 0:\n","                self.FMTD[user] = abs(Subtrahend / index2)\n","            elif index2 == 0:\n","                self.FMTD[user] = abs(Minuend / index1)\n","            else:\n","                self.FMTD[user] = abs(Minuend / index1 - Subtrahend / index2)\n","\n","            if testIndex == testUserCount / 5:\n","                 print('testData Done 20%...')\n","            elif testIndex == testUserCount / 5 * 2:\n","                print('testData Done 40%...')\n","            elif testIndex == testUserCount / 5 * 3:\n","                print('testData Done 60%...')\n","            elif testIndex == testUserCount / 5 * 4:\n","                print('testData Done 80%...')\n","            elif testIndex == testUserCount:\n","                print('testData Done 100%...')\n","\n","        # preparing examples training for LabledData ,test for UnLableData\n","\n","        for user in self.dao.trainingSet_u:\n","            self.training.append([self.H[user], self.DegSim[user], self.LengVar[user],self.RDMA[user],self.FMTD[user]])\n","            self.trainingLabels.append(self.labels[user])\n","\n","        for user in self.dao.testSet_u:\n","            self.test.append([self.H[user], self.DegSim[user], self.LengVar[user],self.RDMA[user],self.FMTD[user]])\n","            self.testLabels.append(self.labels[user])\n","\n","    def predict(self):\n","            ClassifierN = 0\n","            classifier = GaussianNB()\n","            X_train,X_test,y_train,y_test = train_test_split(self.training,self.trainingLabels,test_size=0.75,random_state=33)\n","            classifier.fit(X_train, y_train)\n","            # predict UnLabledData\n","            #pred_labelsForTrainingUn = classifier.predict(X_test)\n","            print('Enhanced classifier...')\n","            while 1:\n","                if len(X_test)<=5: # min\n","                    break         #min\n","                proba_labelsForTrainingUn = classifier.predict_proba(X_test)\n","                X_test_labels = np.hstack((X_test, proba_labelsForTrainingUn))\n","                X_test_labels0_sort = sorted(X_test_labels,key=lambda x:x[5],reverse=True)\n","                if X_test_labels0_sort[4][5]>X_test_labels0_sort[4][6]:\n","                    a = [x[:5] for x in X_test_labels0_sort]\n","                    b = a[0:5]\n","                    classifier.partial_fit(b, ['0','0','0','0','0'], classes=['0', '1'],sample_weight=np.ones(len(b), dtype=np.float) * self.Lambda)\n","                    X_test_labels = X_test_labels0_sort[5:]\n","                    X_test = a[5:]\n","                if len(X_test)<6: # min\n","                    break         #min\n","\n","                X_test_labels0_sort = sorted(X_test_labels, key=lambda x: x[5], reverse=True)\n","                if X_test_labels0_sort[4][5]<=X_test_labels0_sort[4][6]: #min\n","                    a = [x[:5] for x in X_test_labels0_sort]\n","                    b = a[0:5]\n","                    classifier.partial_fit(b, ['1', '1', '1', '1', '1'], classes=['0', '1'],sample_weight=np.ones(len(b), dtype=np.float) * 1)\n","                    X_test_labels = X_test_labels0_sort[5:]  # min\n","                    X_test = a[5:]\n","                if len(X_test)<6:\n","                    break\n","            # while 1 :\n","            #     p1 = pred_labelsForTrainingUn\n","            #     # 将带λ参数的无标签数据拟合入分类器\n","            #     classifier.partial_fit(X_test, pred_labelsForTrainingUn,classes=['0','1'], sample_weight=np.ones(len(X_test),dtype=np.float)*self.Lambda)\n","            #     pred_labelsForTrainingUn = classifier.predict(X_test)\n","            #     p2 = pred_labelsForTrainingUn\n","            #     # 判断分类器是否稳定\n","            #     if list(p1)==list(p2) :\n","            #         ClassifierN += 1\n","            #     elif ClassifierN > 0:\n","            #         ClassifierN = 0\n","            #     if ClassifierN == 20:\n","            #         break\n","            pred_labels = classifier.predict(self.test)\n","            print('naive_bayes with EM algorithm:')\n","            return pred_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BJs1It7axh30"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"X7XKs5izyAzV"},"source":["class SDLib(object):\n","    def __init__(self,config):\n","        self.trainingData = []  # training data\n","        self.testData = []  # testData\n","        self.relation = []\n","        self.measure = []\n","        self.config =config\n","        self.ratingConfig = LineConfig(config['ratings.setup'])\n","        self.labels = FileIO.loadLabels(config['label'])\n","\n","        if self.config.contains('evaluation.setup'):\n","            self.evaluation = LineConfig(config['evaluation.setup'])\n","            \n","            if self.evaluation.contains('-testSet'):\n","                #specify testSet\n","                self.trainingData = FileIO.loadDataSet(config, config['ratings'])\n","                self.testData = FileIO.loadDataSet(config, self.evaluation['-testSet'], bTest=True)\n","\n","            elif self.evaluation.contains('-ap'):\n","                #auto partition\n","                self.trainingData = FileIO.loadDataSet(config,config['ratings'])\n","                self.trainingData,self.testData = DataSplit.\\\n","                    dataSplit(self.trainingData,test_ratio=float(self.evaluation['-ap']))\n","\n","            elif self.evaluation.contains('-cv'):\n","                #cross validation\n","                self.trainingData = FileIO.loadDataSet(config, config['ratings'])\n","                #self.trainingData,self.testData = DataSplit.crossValidation(self.trainingData,int(self.evaluation['-cv']))\n","\n","        else:\n","            print('Evaluation is not well configured!')\n","            exit(-1)\n","\n","        if config.contains('social'):\n","            self.socialConfig = LineConfig(self.config['social.setup'])\n","            self.relation = FileIO.loadRelationship(config,self.config['social'])\n","        print('preprocessing...')\n","\n","\n","    def execute(self):\n","        if self.evaluation.contains('-cv'):\n","            k = int(self.evaluation['-cv'])\n","            if k <= 1 or k > 10:\n","                k = 3\n","            #create the manager used to communication in multiprocess\n","            manager = Manager()\n","            m = manager.dict()\n","            i = 1\n","            tasks = []\n","            for train,test in DataSplit.crossValidation(self.trainingData,k):\n","                fold = '['+str(i)+']'\n","                if self.config.contains('social'):\n","                    method = self.config['methodName'] + \"(self.config,train,test,self.labels,self.relation,fold)\"\n","                else:\n","                    method = self.config['methodName'] + \"(self.config,train,test,self.labels,fold)\"\n","               #create the process\n","                p = Process(target=run,args=(m,eval(method),i))\n","                tasks.append(p)\n","                i+=1\n","            #start the processes\n","            for p in tasks:\n","                p.start()\n","            #wait until all processes are completed\n","            for p in tasks:\n","                p.join()\n","            #compute the mean error of k-fold cross validation\n","            self.measure = [dict(m)[i] for i in range(1,k+1)]\n","            res = []\n","            pattern = re.compile('(\\d+\\.\\d+)')\n","            countPattern = re.compile('\\d+\\\\n')\n","            labelPattern = re.compile('\\s\\d{1}[^\\.|\\n|\\d]')\n","            labels = re.findall(labelPattern, self.measure[0])\n","            values = np.array([0]*9,dtype=float)\n","            count = np.array([0,0,0],dtype=int)\n","            for report in self.measure:\n","                patterns = np.array(re.findall(pattern,report),dtype=float)\n","                values += patterns[:9]\n","                patterncounts = np.array(re.findall(countPattern,report),dtype=int)\n","                count += patterncounts[:3]\n","            values/=k\n","            values=np.around(values,decimals=4)\n","            res.append('             precision  recall  f1-score  support\\n\\n')\n","            res.append('         '+labels[0]+'  '+'    '.join(np.array(values[0:3],dtype=str).tolist())+'   '+str(count[0])+'\\n')\n","            res.append('         '+labels[1]+'  '+'    '.join(np.array(values[3:6],dtype=str).tolist())+'   '+str(count[1])+'\\n\\n')\n","            res.append('  avg/total   ' + '    '.join(np.array(values[6:9], dtype=str).tolist()) + '   ' + str(count[2]) + '\\n')\n","            print('Total:')\n","            print(''.join(res))\n","                # for line in lines[1:]:\n","                #\n","                # measure = self.measure[0][i].split(':')[0]\n","                # total = 0\n","                # for j in range(k):\n","                #     total += float(self.measure[j][i].split(':')[1])\n","                # res.append(measure+':'+str(total/k)+'\\n')\n","            #output result\n","            currentTime = strftime(\"%Y-%m-%d %H-%M-%S\", localtime(time()))\n","            outDir = LineConfig(self.config['output.setup'])['-dir']\n","            fileName = self.config['methodName'] +'@'+currentTime+'-'+str(k)+'-fold-cv' + '.txt'\n","            FileIO.writeFile(outDir,fileName,res)\n","            print('The results have been output to '+abspath(LineConfig(self.config['output.setup'])['-dir'])+'\\n')\n","        else:\n","            if self.config.contains('social'):\n","                method = self.config['methodName'] + '(self.config,self.trainingData,self.testData,self.labels,self.relation)'\n","            else:\n","                method = self.config['methodName'] + '(self.config,self.trainingData,self.testData,self.labels)'\n","            eval(method).execute()\n","\n","\n","def run(measure,algor,order):\n","    measure[order] = algor.execute()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUfH4niR1ZMR","executionInfo":{"status":"ok","timestamp":1634216477304,"user_tz":-330,"elapsed":2766,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ba9bfc59-3f50-49f9-95d0-67145a1f9e73"},"source":["conf = Config('DegreeSAD.conf')\n","sd = SDLib(conf)\n","sd.execute()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading training data...\n","preprocessing...\n","Algorithm: DegreeSAD\n","Ratings dataSet: /content/dataset/amazon/profiles.txt\n","Training set size: (user count: 3921, item count 14711, record count: 40730)\n","Test set size: (user count: 981, item count 6079, record count: 10368)\n","================================================================================\n","Initializing model [1]...\n","Building Model [1]...\n","Initializing model [2]...\n","Building Model [2]...\n","Initializing model [3]...\n","Building Model [3]...\n","Initializing model [4]...\n","Building Model [4]...\n","Initializing model [5]...\n","Building Model [5]...\n","Predicting [1]...\n","Decision Tree:\n","Predicting [2]...\n","              precision    recall  f1-score   support\n","\n","           0     0.7709    0.8498    0.8084       586\n","           1     0.7373    0.6253    0.6767       395\n","\n","    accuracy                         0.7594       981\n","   macro avg     0.7541    0.7376    0.7426       981\n","weighted avg     0.7574    0.7594    0.7554       981\n","\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7852    0.8425    0.8128       603\n","           1     0.7156    0.6323    0.6713       378\n","\n","    accuracy                         0.7615       981\n","   macro avg     0.7504    0.7374    0.7421       981\n","weighted avg     0.7583    0.7615    0.7583       981\n","\n","Predicting [3]...\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7658    0.8381    0.8003       593\n","           1     0.7100    0.6072    0.6546       387\n","\n","    accuracy                         0.7469       980\n","   macro avg     0.7379    0.7227    0.7275       980\n","weighted avg     0.7437    0.7469    0.7428       980\n","\n","Predicting [5]...\n","Predicting [4]...\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7876    0.8148    0.8010       610\n","           1     0.6762    0.6378    0.6565       370\n","\n","    accuracy                         0.7480       980\n","   macro avg     0.7319    0.7263    0.7287       980\n","weighted avg     0.7456    0.7480    0.7464       980\n","\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7929    0.8507    0.8208       603\n","           1     0.7297    0.6446    0.6845       377\n","\n","    accuracy                         0.7714       980\n","   macro avg     0.7613    0.7477    0.7527       980\n","weighted avg     0.7686    0.7714    0.7684       980\n","\n","Total:\n","             precision  recall  f1-score  support\n","\n","          0   0.7805    0.8392    0.8087   2995\n","          1   0.7138    0.6294    0.6687   1907\n","\n","  avg/total   0.7574    0.7471    0.7343   4902\n","\n","The results have been output to /content/results\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmqtChCayQJa","executionInfo":{"status":"ok","timestamp":1634220587417,"user_tz":-330,"elapsed":302460,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"095593d8-d3f2-4018-c213-1e1e8bb14f8f"},"source":["print('='*80)\n","print('Supervised Methods:')\n","print('1. DegreeSAD   2.CoDetector   3.BayesDetector\\n')\n","print('Semi-Supervised Methods:')\n","print('4. SemiSAD\\n')\n","print('Unsupervised Methods:')\n","print('5. PCASelectUsers    6. FAP   7.timeIndex\\n')\n","print('-'*80)\n","order = eval(input('please enter the num of the method to run it:'))\n","\n","algor = -1\n","conf = -1\n","\n","s = tm.clock()\n","\n","if order == 1:\n","    conf = Config('DegreeSAD.conf')\n","\n","elif order == 2:\n","    conf = Config('CoDetector.conf')\n","\n","elif order == 3:\n","    conf = Config('BayesDetector.conf')\n","\n","elif order == 4:\n","    conf = Config('SemiSAD.conf')\n","\n","elif order == 5:\n","    conf = Config('PCASelectUsers.conf')\n","\n","elif order == 6:\n","    conf = Config('FAP.conf')\n","elif order == 7:\n","    conf = Config('timeIndex.conf')\n","\n","else:\n","    print('Error num!')\n","    exit(-1)\n","\n","# conf = Config('DegreeSAD.conf')\n","\n","sd = SDLib(conf)\n","sd.execute()\n","e = tm.clock()\n","print(\"Run time: %f s\" % (e - s))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","Supervised Methods:\n","1. DegreeSAD   2.CoDetector   3.BayesDetector\n","\n","Semi-Supervised Methods:\n","4. SemiSAD\n","\n","Unsupervised Methods:\n","5. PCASelectUsers    6. FAP   7.timeIndex\n","\n","--------------------------------------------------------------------------------\n","please enter the num of the method to run it:2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","  \n"]},{"output_type":"stream","name":"stdout","text":["loading training data...\n","preprocessing...\n","Algorithm: CoDetector\n","Ratings dataSet: /content/dataset/amazon/profiles.txt\n","Training set size: (user count: 3501, item count 13751, record count: 36766)\n","Test set size: (user count: 1401, item count 7439, record count: 14332)\n","================================================================================\n","k: 256\n","regR: 1.00000\n","filter: 4\n","================================================================================\n","Initializing model [1]...\n","Constructing SPPMI matrix...\n","Building Model [1]...\n","iteration: 1\n","iteration: 2\n","iteration: 3\n","iteration: 4\n","iteration: 5\n","iteration: 6\n","iteration: 7\n","iteration: 8\n","iteration: 9\n","iteration: 10\n","iteration: 11\n","iteration: 12\n","iteration: 13\n","iteration: 14\n","iteration: 15\n","iteration: 16\n","iteration: 17\n","iteration: 18\n","iteration: 19\n","iteration: 20\n","iteration: 21\n","iteration: 22\n","iteration: 23\n","iteration: 24\n","iteration: 25\n","iteration: 26\n","iteration: 27\n","iteration: 28\n","iteration: 29\n","iteration: 30\n","iteration: 31\n","iteration: 32\n","iteration: 33\n","iteration: 34\n","iteration: 35\n","iteration: 36\n","iteration: 37\n","iteration: 38\n","iteration: 39\n","iteration: 40\n","iteration: 41\n","iteration: 42\n","iteration: 43\n","iteration: 44\n","iteration: 45\n","iteration: 46\n","iteration: 47\n","iteration: 48\n","iteration: 49\n","iteration: 50\n","iteration: 51\n","iteration: 52\n","iteration: 53\n","iteration: 54\n","iteration: 55\n","iteration: 56\n","iteration: 57\n","iteration: 58\n","iteration: 59\n","iteration: 60\n","iteration: 61\n","iteration: 62\n","iteration: 63\n","iteration: 64\n","iteration: 65\n","iteration: 66\n","iteration: 67\n","iteration: 68\n","iteration: 69\n","iteration: 70\n","iteration: 71\n","iteration: 72\n","iteration: 73\n","iteration: 74\n","iteration: 75\n","iteration: 76\n","iteration: 77\n","iteration: 78\n","iteration: 79\n","iteration: 80\n","iteration: 81\n","iteration: 82\n","iteration: 83\n","iteration: 84\n","iteration: 85\n","iteration: 86\n","iteration: 87\n","iteration: 88\n","iteration: 89\n","iteration: 90\n","iteration: 91\n","iteration: 92\n","iteration: 93\n","iteration: 94\n","iteration: 95\n","iteration: 96\n","iteration: 97\n","iteration: 98\n","iteration: 99\n","iteration: 100\n","iteration: 101\n","iteration: 102\n","iteration: 103\n","iteration: 104\n","iteration: 105\n","iteration: 106\n","iteration: 107\n","iteration: 108\n","iteration: 109\n","iteration: 110\n","iteration: 111\n","iteration: 112\n","iteration: 113\n","iteration: 114\n","iteration: 115\n","iteration: 116\n","iteration: 117\n","iteration: 118\n","iteration: 119\n","iteration: 120\n","iteration: 121\n","iteration: 122\n","iteration: 123\n","iteration: 124\n","iteration: 125\n","iteration: 126\n","iteration: 127\n","iteration: 128\n","iteration: 129\n","iteration: 130\n","iteration: 131\n","iteration: 132\n","iteration: 133\n","iteration: 134\n","iteration: 135\n","iteration: 136\n","iteration: 137\n","iteration: 138\n","iteration: 139\n","iteration: 140\n","iteration: 141\n","iteration: 142\n","iteration: 143\n","iteration: 144\n","iteration: 145\n","iteration: 146\n","iteration: 147\n","iteration: 148\n","iteration: 149\n","iteration: 150\n","iteration: 151\n","iteration: 152\n","iteration: 153\n","iteration: 154\n","iteration: 155\n","iteration: 156\n","iteration: 157\n","iteration: 158\n","iteration: 159\n","iteration: 160\n","iteration: 161\n","iteration: 162\n","iteration: 163\n","iteration: 164\n","iteration: 165\n","iteration: 166\n","iteration: 167\n","iteration: 168\n","iteration: 169\n","iteration: 170\n","iteration: 171\n","iteration: 172\n","iteration: 173\n","iteration: 174\n","iteration: 175\n","iteration: 176\n","iteration: 177\n","iteration: 178\n","iteration: 179\n","iteration: 180\n","iteration: 181\n","iteration: 182\n","iteration: 183\n","iteration: 184\n","iteration: 185\n","iteration: 186\n","iteration: 187\n","iteration: 188\n","iteration: 189\n","iteration: 190\n","iteration: 191\n","iteration: 192\n","iteration: 193\n","iteration: 194\n","iteration: 195\n","iteration: 196\n","iteration: 197\n","iteration: 198\n","iteration: 199\n","iteration: 200\n","Predicting [1]...\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.9139    0.8867    0.9001       874\n","           1     0.8210    0.8615    0.8407       527\n","\n","    accuracy                         0.8772      1401\n","   macro avg     0.8674    0.8741    0.8704      1401\n","weighted avg     0.8790    0.8772    0.8778      1401\n","\n","Run time: 312.447489 s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XitDi26yz0U7","executionInfo":{"status":"ok","timestamp":1634220613458,"user_tz":-330,"elapsed":8805,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"2c69731b-269b-4123-9516-dab8397f096d"},"source":["print('='*80)\n","print('Supervised Methods:')\n","print('1. DegreeSAD   2.CoDetector   3.BayesDetector\\n')\n","print('Semi-Supervised Methods:')\n","print('4. SemiSAD\\n')\n","print('Unsupervised Methods:')\n","print('5. PCASelectUsers    6. FAP   7.timeIndex\\n')\n","print('-'*80)\n","order = eval(input('please enter the num of the method to run it:'))\n","\n","algor = -1\n","conf = -1\n","\n","s = tm.clock()\n","\n","if order == 1:\n","    conf = Config('DegreeSAD.conf')\n","\n","elif order == 2:\n","    conf = Config('CoDetector.conf')\n","\n","elif order == 3:\n","    conf = Config('BayesDetector.conf')\n","\n","elif order == 4:\n","    conf = Config('SemiSAD.conf')\n","\n","elif order == 5:\n","    conf = Config('PCASelectUsers.conf')\n","\n","elif order == 6:\n","    conf = Config('FAP.conf')\n","elif order == 7:\n","    conf = Config('timeIndex.conf')\n","\n","else:\n","    print('Error num!')\n","    exit(-1)\n","\n","# conf = Config('DegreeSAD.conf')\n","\n","sd = SDLib(conf)\n","sd.execute()\n","e = tm.clock()\n","print(\"Run time: %f s\" % (e - s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","Supervised Methods:\n","1. DegreeSAD   2.CoDetector   3.BayesDetector\n","\n","Semi-Supervised Methods:\n","4. SemiSAD\n","\n","Unsupervised Methods:\n","5. PCASelectUsers    6. FAP   7.timeIndex\n","\n","--------------------------------------------------------------------------------\n","please enter the num of the method to run it:1\n","loading training data...\n","preprocessing...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Algorithm: DegreeSAD\n","Ratings dataSet: /content/dataset/amazon/profiles.txt\n","Training set size: (user count: 3921, item count 14711, record count: 40730)\n","Test set size: (user count: 981, item count 6079, record count: 10368)\n","================================================================================\n","Initializing model [1]...\n","Building Model [1]...\n","Initializing model [2]...\n","Building Model [2]...\n","Initializing model [3]...\n","Building Model [3]...\n","Predicting [1]...\n","Initializing model [4]...\n","Building Model [4]...\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7689    0.8515    0.8081       586\n","           1     0.7380    0.6203    0.6740       395\n","\n","    accuracy                         0.7584       981\n","   macro avg     0.7534    0.7359    0.7410       981\n","weighted avg     0.7564    0.7584    0.7541       981\n","\n","Initializing model [5]...\n","Building Model [5]...\n","Predicting [2]...\n","Decision Tree:\n","Predicting [3]...\n","              precision    recall  f1-score   support\n","\n","           0     0.7883    0.8458    0.8160       603\n","           1     0.7216    0.6376    0.6770       378\n","\n","    accuracy                         0.7655       981\n","   macro avg     0.7549    0.7417    0.7465       981\n","weighted avg     0.7626    0.7655    0.7624       981\n","\n","Predicting [4]...\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7673    0.8398    0.8019       593\n","           1     0.7130    0.6098    0.6574       387\n","\n","    accuracy                         0.7490       980\n","   macro avg     0.7402    0.7248    0.7297       980\n","weighted avg     0.7459    0.7490    0.7448       980\n","\n","Predicting [5]...\n","Decision Tree:\n","Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0     0.7950    0.8491    0.8212       603\n","           1     0.7292    0.6499    0.6872       377\n","\n","    accuracy                         0.7724       980\n","   macro avg     0.7621    0.7495    0.7542       980\n","weighted avg     0.7697    0.7724    0.7696       980\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7872    0.8246    0.8054       610\n","           1     0.6862    0.6324    0.6582       370\n","\n","    accuracy                         0.7520       980\n","   macro avg     0.7367    0.7285    0.7318       980\n","weighted avg     0.7491    0.7520    0.7499       980\n","\n","Total:\n","             precision  recall  f1-score  support\n","\n","          0   0.7813    0.8422    0.8105   2995\n","          1   0.7176    0.63    0.6708   1907\n","\n","  avg/total   0.7595    0.7495    0.7361   4902\n","\n","The results have been output to /content/results\n","\n","Run time: 1.097195 s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8ErpBwoILs-","executionInfo":{"status":"ok","timestamp":1634220649332,"user_tz":-330,"elapsed":21280,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"89be0fb4-a135-4c5e-99a6-6a840260fd1d"},"source":["print('='*80)\n","print('Supervised Methods:')\n","print('1. DegreeSAD   2.CoDetector   3.BayesDetector\\n')\n","print('Semi-Supervised Methods:')\n","print('4. SemiSAD\\n')\n","print('Unsupervised Methods:')\n","print('5. PCASelectUsers    6. FAP   7.timeIndex\\n')\n","print('-'*80)\n","order = eval(input('please enter the num of the method to run it:'))\n","\n","algor = -1\n","conf = -1\n","\n","s = tm.clock()\n","\n","if order == 1:\n","    conf = Config('DegreeSAD.conf')\n","\n","elif order == 2:\n","    conf = Config('CoDetector.conf')\n","\n","elif order == 3:\n","    conf = Config('BayesDetector.conf')\n","\n","elif order == 4:\n","    conf = Config('SemiSAD.conf')\n","\n","elif order == 5:\n","    conf = Config('PCASelectUsers.conf')\n","\n","elif order == 6:\n","    conf = Config('FAP.conf')\n","elif order == 7:\n","    conf = Config('timeIndex.conf')\n","\n","else:\n","    print('Error num!')\n","    exit(-1)\n","\n","# conf = Config('DegreeSAD.conf')\n","\n","sd = SDLib(conf)\n","sd.execute()\n","e = tm.clock()\n","print(\"Run time: %f s\" % (e - s))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","Supervised Methods:\n","1. DegreeSAD   2.CoDetector   3.BayesDetector\n","\n","Semi-Supervised Methods:\n","4. SemiSAD\n","\n","Unsupervised Methods:\n","5. PCASelectUsers    6. FAP   7.timeIndex\n","\n","--------------------------------------------------------------------------------\n","please enter the num of the method to run it:6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","  \n"]},{"output_type":"stream","name":"stdout","text":["loading training data...\n","preprocessing...\n","*** seedUser is more than a half of spammer, so it is set to 75 ***\n","*** the number of top-K users is more than threshold value, so it is set to 791 ***\n","Algorithm: FAP\n","Ratings dataSet: /content/dataset/averageattack/ratings.txt\n","Training set size: (user count: 1658, item count 2071, record count: 44825)\n","Test set size: (user count: 0, item count 0, record count: 0)\n","================================================================================\n","Initializing model [1]...\n","constructing bipartite graph...\n","computing transition probability...\n","progress: 0/1658\n","progress: 100/1658\n","progress: 200/1658\n","progress: 300/1658\n","progress: 400/1658\n","progress: 500/1658\n","progress: 600/1658\n","progress: 700/1658\n","progress: 800/1658\n","progress: 900/1658\n","progress: 1000/1658\n","progress: 1100/1658\n","progress: 1200/1658\n","progress: 1300/1658\n","progress: 1400/1658\n","progress: 1500/1658\n","progress: 1600/1658\n","Building Model [1]...\n","[1] iteration 1\n","[1] iteration 2\n","[1] iteration 3\n","[1] iteration 4\n","[1] iteration 5\n","[1] iteration 6\n","[1] iteration 7\n","[1] iteration 8\n","[1] iteration 9\n","[1] iteration 10\n","[1] iteration 11\n","[1] iteration 12\n","[1] iteration 13\n","[1] iteration 14\n","[1] iteration 15\n","[1] iteration 16\n","[1] iteration 17\n","[1] iteration 18\n","[1] iteration 19\n","[1] iteration 20\n","[1] iteration 21\n","Predicting [1]...\n","              precision    recall  f1-score   support\n","\n","           0     0.9448    0.5274    0.6770      1494\n","           1     0.0574    0.4831    0.1026        89\n","\n","    accuracy                         0.5250      1583\n","   macro avg     0.5011    0.5053    0.3898      1583\n","weighted avg     0.8950    0.5250    0.6447      1583\n","\n","Run time: 10.561271 s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdBA7drNI9GB","executionInfo":{"status":"ok","timestamp":1634220727329,"user_tz":-330,"elapsed":71038,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ce699c86-cc84-41d6-866c-afcee8e8c418"},"source":["print('='*80)\n","print('Supervised Methods:')\n","print('1. DegreeSAD   2.CoDetector   3.BayesDetector\\n')\n","print('Semi-Supervised Methods:')\n","print('4. SemiSAD\\n')\n","print('Unsupervised Methods:')\n","print('5. PCASelectUsers    6. FAP   7.timeIndex\\n')\n","print('-'*80)\n","order = eval(input('please enter the num of the method to run it:'))\n","\n","algor = -1\n","conf = -1\n","\n","s = tm.clock()\n","\n","if order == 1:\n","    conf = Config('DegreeSAD.conf')\n","\n","elif order == 2:\n","    conf = Config('CoDetector.conf')\n","\n","elif order == 3:\n","    conf = Config('BayesDetector.conf')\n","\n","elif order == 4:\n","    conf = Config('SemiSAD.conf')\n","\n","elif order == 5:\n","    conf = Config('PCASelectUsers.conf')\n","\n","elif order == 6:\n","    conf = Config('FAP.conf')\n","elif order == 7:\n","    conf = Config('timeIndex.conf')\n","\n","else:\n","    print('Error num!')\n","    exit(-1)\n","\n","# conf = Config('DegreeSAD.conf')\n","\n","sd = SDLib(conf)\n","sd.execute()\n","e = tm.clock()\n","print(\"Run time: %f s\" % (e - s))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","Supervised Methods:\n","1. DegreeSAD   2.CoDetector   3.BayesDetector\n","\n","Semi-Supervised Methods:\n","4. SemiSAD\n","\n","Unsupervised Methods:\n","5. PCASelectUsers    6. FAP   7.timeIndex\n","\n","--------------------------------------------------------------------------------\n","please enter the num of the method to run it:4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","  \n"]},{"output_type":"stream","name":"stdout","text":["loading training data...\n","preprocessing...\n","Algorithm: SemiSAD\n","Ratings dataSet: /content/dataset/averageattack/ratings.txt\n","Training set size: (user count: 1322, item count 2068, record count: 35286)\n","Test set size: (user count: 336, item count 1604, record count: 9539)\n","================================================================================\n","Initializing model [1]...\n","Building Model [1]...\n","Begin feature engineering...\n","trainingData Done 100%...\n","testData Done 100%...\n","Predicting [1]...\n","Enhanced classifier...\n","naive_bayes with EM algorithm:\n","              precision    recall  f1-score   support\n","\n","           0     0.9107    1.0000    0.9533       306\n","           1     0.0000    0.0000    0.0000        30\n","\n","    accuracy                         0.9107       336\n","   macro avg     0.4554    0.5000    0.4766       336\n","weighted avg     0.8294    0.9107    0.8682       336\n","\n","Run time: 65.108994 s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]}]}]}