{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_name = \"reco-tut-sor\"; branch = \"main\"; account = \"sparsh-ai\"\n",
    "project_path = os.path.join('/content', project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(project_path):\n",
    "    !cp /content/drive/MyDrive/mykeys.py /content\n",
    "    import mykeys\n",
    "    !rm /content/mykeys.py\n",
    "    path = \"/content/\" + project_name; \n",
    "    !mkdir \"{path}\"\n",
    "    %cd \"{path}\"\n",
    "    import sys; sys.path.append(path)\n",
    "    !git config --global user.email \"recotut@recohut.com\"\n",
    "    !git config --global user.name  \"reco-tut\"\n",
    "    !git init\n",
    "    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n",
    "    !git pull origin \"{branch}\"\n",
    "    !git checkout main\n",
    "else:\n",
    "    %cd \"{project_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add . && git commit -m 'commit' && git push origin \"{branch}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be building XGB model and check if the reccomendation engine can be improved by using other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating alternative model\n",
    "\n",
    "In this step dataset preprocessed in previous step is loaded and simple baseline model is tested.\n",
    "\n",
    "Each line in a dataset contains data about one user and his final action on the offer. \n",
    "Either offer has been ignored, viewed or completed (offer proved to be interesting to a customer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/silver/userdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset contains %s actions\" % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot the actions for one user\n",
    "\n",
    "From the output can be seen that user completed an offer `0b1e...` and viewed `ae26...`. Offer `2906..` had been ignored twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.id == 'e12aeaf2d47d42479ea1c4ac3d8286c6' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training\n",
    "Let's create user-offer matrix by encoding each id into categorical value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation matrix is very similar to embeddings. So we will leverage this and will train embedding along the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create additional user and offer details tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_specs = ['difficulty', 'duration', 'reward', 'web',\n",
    "       'mobile', 'social', 'bogo', 'discount', 'informational']\n",
    "user_specs = ['age', 'became_member_on', 'gender', 'income', 'memberdays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = int(0.8 * len(df['event']))\n",
    "N_test = 1000\n",
    "\n",
    "train_df = df[:N_train]\n",
    "test_df = df[N_train:]\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_data, train_true, test_data, test_true):\n",
    "    #hyper-paramater tuning\n",
    "    values = [25, 50, 100, 200]\n",
    "    clf = RandomForestClassifier(n_jobs = -1)\n",
    "    hyper_parameter = {\"n_estimators\": values}\n",
    "    best_parameter = GridSearchCV(clf, hyper_parameter, scoring = \"neg_mean_absolute_error\", cv = 3)\n",
    "    best_parameter.fit(train_data, train_true)\n",
    "    estimators = best_parameter.best_params_[\"n_estimators\"]\n",
    "    print(\"Best RF parameter is: \", estimators)\n",
    "    #applying random forest with best hyper-parameter\n",
    "    clf = RandomForestClassifier(n_estimators = estimators, n_jobs = -1)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    return clf\n",
    "\n",
    "def xgboost_model(train_data, train_true, test_data, test_true):\n",
    "    #hyper-parameter tuning\n",
    "    hyper_parameter = {\"max_depth\":[6, 8, 10, 16], \"n_estimators\":[60, 80, 100, 120]}\n",
    "    clf = xgb.XGBClassifier()\n",
    "    best_parameter = GridSearchCV(clf, hyper_parameter, scoring = \"neg_mean_absolute_error\", cv = 3)\n",
    "    best_parameter.fit(train_data, train_true)\n",
    "    estimators = best_parameter.best_params_[\"n_estimators\"]\n",
    "    depth = best_parameter.best_params_[\"max_depth\"]\n",
    "    print(\"Best XGB parameter is %s estimators and depth %s: \" % (estimators, depth))\n",
    "    clf = xgb.XGBClassifier(max_depth = depth, n_estimators = estimators)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = random_forest(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                       test_df['event'].values.ravel())\n",
    "\n",
    "pred_xgb = xgboost_model(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                        test_df['event'].values.ravel())\n",
    "\n",
    "# error_table_regressions = pd.DataFrame(columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"])\n",
    "# error_table_regressions = error_table_regressions.append(pd.DataFrame([[\"XGBoost Regressor\", trainMAPE_xgb*100, trainMSE_xgb, testMAPE_xgb*100, testMSE_xgb]], columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"]))\n",
    "# error_table_regressions = error_table_regressions.append(pd.DataFrame([[\"Random Forest Regression\", trainMAPE_rf*100, trainMSE_rf, testMAPE_rf*100, testMSE_rf]], columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"]))\n",
    "\n",
    "# error_table_regressions.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_data, train_true, test_data, test_true):\n",
    "    clf = RandomForestClassifier(n_estimators = 60, n_jobs = -1)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    return clf\n",
    "\n",
    "def xgboost_model(train_data, train_true, test_data, test_true):\n",
    "    #hyper-parameter tuning\n",
    "    clf = xgb.XGBClassifier(max_depth = 16, n_estimators = 6)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = random_forest(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                       test_df['event'].values.ravel())\n",
    "\n",
    "pred_xgb = xgboost_model(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                        test_df['event'].values.ravel())\n",
    "\n",
    "# error_table_regressions = pd.DataFrame(columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"])\n",
    "# error_table_regressions = error_table_regressions.append(pd.DataFrame([[\"XGBoost Regressor\", trainMAPE_xgb*100, trainMSE_xgb, testMAPE_xgb*100, testMSE_xgb]], columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"]))\n",
    "# error_table_regressions = error_table_regressions.append(pd.DataFrame([[\"Random Forest Regression\", trainMAPE_rf*100, trainMSE_rf, testMAPE_rf*100, testMSE_rf]], columns = [\"Model\", \"TrainMAPE(%)\", \"TrainMSE\", \"TestMAPE(%)\", \"TestMSE\"]))\n",
    "\n",
    "# error_table_regressions.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          save=False,\n",
    "                          figname='cm.png'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if save:\n",
    "        plt.savefig(figname, dpi=fig.dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pred_rf.predict(test_df[0:1000][user_specs + offer_specs])\n",
    "test_y = test_df[0:1000]['event'].values.ravel()\n",
    "#print(pred1)\n",
    "#print(test_y)\n",
    "cm = confusion_matrix(test_y, pred1)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes, save=True, figname='./outputs/Recommendation-cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred_xgb.predict(test_df[0:1000][user_specs + offer_specs])\n",
    "test_y = test_df[0:1000]['event'].values.ravel()\n",
    "#print(pred2)\n",
    "#print(test_y)\n",
    "cm = confusion_matrix(test_y, pred2)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes, save=True, figname='./outputs/RecommendationXGB-cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for RF model: \" + str(100*accuracy_score(test_y, pred1))+ \"%\" )\n",
    "print(\"Accuracy for XGB model: \" + str(100*accuracy_score(test_y, pred2))+ \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score for RF model: \" + str(f1_score(test_y, pred1, average='weighted')))\n",
    "print(\"Recall score for RF model: \" + str(recall_score(test_y, pred1, average='weighted')))\n",
    "print(\"Precision score for RF model: \" + str(precision_score(test_y, pred1, average='weighted')))\n",
    "\n",
    "print(\"\")\n",
    "print(\"F1 score for XGB model: \" + str(f1_score(test_y, pred2, average='weighted')) )\n",
    "print(\"Recall score for XGB model: \" + str(recall_score(test_y, pred2, average='weighted')) )\n",
    "print(\"Precision score for XGB model: \" + str(precision_score(test_y, pred2, average='weighted')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results seem to be promising.\n",
    "Let's try to improve them even more, and simplify data as from the correlation matrix it can be noticed that model has difficulties to differentiate if user will view an offer or even respond to it.\n",
    "This can be due to the fact that responding to an offer implies that user had definitely viewed an offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2. Remove outlier fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/silver/userdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['member_days'] = pd.to_datetime(df['became_member_on'], format=\"%Y%m%d\")\n",
    "df['member_days'] = df['member_days'] - df['member_days'].min()\n",
    "df['member_days'] = df['member_days'].apply(lambda x: int(x.days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check once again the correlation between gender and event response.\n",
    "We are interested in X and O genders. Where X is the customers with anonymized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender == 0]['event'].plot.hist()#.count_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender == 1]['event'].plot.hist()#.count_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender == 2]['event'].plot.hist()#.count_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender == 3]['event'].plot.hist()#.count_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.income == 0]['event'].plot.hist()#.count_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the model performance with removing rows where user with age and income as None\n",
    "They seem to view offer but rarely respond to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove them by index as it seems to be the easiest way\n",
    "indexes_to_drop = list(df[df.gender == 0].index) + list(df[df.income == 0].index)\n",
    "df = df.drop(df.index[indexes_to_drop]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['became_member_date'] = pd.to_datetime(df['became_member_on'], format=\"%Y%m%d\")\n",
    "df[df['member_days'] == 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode `event` field to be only binary value, with event ignored as 0, and offer completed - as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'] = df['event'].map({0:0, 1:0, 2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_specs = ['difficulty', 'duration', 'reward', 'web', 'email',\n",
    "       'mobile', 'social', 'bogo', 'discount', 'informational']\n",
    "user_specs = ['age', 'member_days', 'gender', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = int(0.8 * len(df['event']))\n",
    "N_test = 1000\n",
    "\n",
    "train_df = df[:N_train]\n",
    "test_df = df[N_train:]\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = random_forest(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                       test_df['event'].values.ravel())\n",
    "\n",
    "pred_xgb = xgboost_model(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                        test_df['event'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pred_rf.predict(test_df[user_specs + offer_specs])\n",
    "test_y = test_df['event'].values.ravel()\n",
    "print(pred1)\n",
    "print(test_y)\n",
    "\n",
    "print(\"Accuracy for RF model: \" + str(100*accuracy_score(test_y, pred1))+ \"%\" )\n",
    "cm = confusion_matrix(test_y, pred1)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred_xgb.predict(test_df[user_specs + offer_specs])\n",
    "test_y = test_df['event'].values.ravel()\n",
    "print(pred2)\n",
    "print(test_y)\n",
    "\n",
    "print(\"Accuracy for XGB model: \" + str(100*accuracy_score(test_y, pred2))+ \"%\" )\n",
    "cm = confusion_matrix(test_y, pred2)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem that results are the same.\n",
    "Let's try the model with encoding now \n",
    "an `event` field to be only binary value, with event ignored as 0, and offer completed - as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3. Building Performance optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/silver/userdata.csv')\n",
    "\n",
    "df['member_days'] = pd.to_datetime(df['became_member_on'], format=\"%Y%m%d\")\n",
    "df['member_days'] = df['member_days'] - df['member_days'].min()\n",
    "df['member_days'] = df['member_days'].apply(lambda x: int(x.days))\n",
    "\n",
    "df['event'] = df['event'].map({0:0, 1:1, 2:1})\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "offer_specs = ['difficulty', 'duration', 'reward', 'web', 'email',\n",
    "       'mobile', 'social', 'bogo', 'discount', 'informational']\n",
    "user_specs = ['age', 'member_days', 'gender', 'income']\n",
    "\n",
    "N_train = int(0.8 * len(df['event']))\n",
    "N_test = 1000\n",
    "\n",
    "train_df = df[:N_train]\n",
    "test_df = df[N_train:]\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "\n",
    "def random_forest(train_data, train_true, test_data, test_true):\n",
    "   \n",
    "    clf = RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def xgboost_model(train_data, train_true, test_data, test_true):\n",
    "    \n",
    "    clf = xgb.XGBClassifier(max_depth = 16, n_estimators = 60)\n",
    "    clf.fit(train_data, train_true)\n",
    "    #train_pred = clf.predict(train_data)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = random_forest(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                       test_df['event'].values.ravel())\n",
    "\n",
    "pred_xgb = xgboost_model(train_df[user_specs + offer_specs], \n",
    "                       train_df['event'].values.ravel(), \n",
    "                       test_df[user_specs + offer_specs],\n",
    "                        test_df['event'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pred_rf.predict(test_df[0:1000][user_specs + offer_specs])\n",
    "test_y = test_df[0:1000]['event'].values.ravel()\n",
    "#print(pred1)\n",
    "#print(test_y)\n",
    "\n",
    "print(\"Accuracy for RF model: \" + str(100*accuracy_score(test_y, pred1))+ \"%\" )\n",
    "cm = confusion_matrix(test_y, pred1)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes, save=True, figname='./outputs/RF-model-cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred_xgb.predict(test_df[0:1000][user_specs + offer_specs])\n",
    "test_y = test_df[0:1000]['event'].values.ravel()\n",
    "#print(pred2)\n",
    "#print(test_y)\n",
    "\n",
    "print(\"Accuracy for XGB model: \" + str(100*accuracy_score(test_y, pred2))+ \"%\" )\n",
    "cm = confusion_matrix(test_y, pred2)\n",
    "classes = [0,1,2]\n",
    "plot_confusion_matrix(cm, classes, save=True, figname='./outputs/XGB-model-cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a significant improve that can be used in production to save costs and send offers to those users who are going to be interested in companies offers without ignoring them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score for RF model: \" + str(f1_score(test_y, pred1, average='weighted')))\n",
    "print(\"Recall score for RF model: \" + str(recall_score(test_y, pred1, average='weighted')))\n",
    "print(\"Precision score for RF model: \" + str(precision_score(test_y, pred1, average='weighted')))\n",
    "\n",
    "print(\"\")\n",
    "print(\"F1 score for XGB model: \" + str(f1_score(test_y, pred2, average='weighted')) )\n",
    "print(\"Recall score for XGB model: \" + str(recall_score(test_y, pred2, average='weighted')) )\n",
    "print(\"Precision score for XGB model: \" + str(precision_score(test_y, pred2, average='weighted')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves to be a very good model for ad hoc predictions and predictions on subsections of customer by regions or cities."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoHWwaABNO/JJqde6Dc4TA",
   "collapsed_sections": [],
   "mount_file_id": "1tdJnw_ezXqbjwhJZB65d1HbGCnVIcnIW",
   "name": "reco-tut-sor-02-xgboost.ipynb",
   "provenance": [
    {
     "file_id": "1UuUa25pOjIh93SeHhRVnsmZgeohAt_qD",
     "timestamp": 1628782196217
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
