{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"T714933 | MetaTL for Cold-start users on Amazon Electronics dataset","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMsy0IRuxTLdiW+TsXFPmKI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I0vYn_6Ks2-h"},"source":["# MetaTL for Cold-start users on Amazon Electronics dataset"]},{"cell_type":"markdown","metadata":{"id":"HGt5M9GHvm_F"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"MEjeY5K_voyF"},"source":["A fundamental challenge for sequential recommenders is to capture the sequential patterns of users toward modeling how users transit among items. In many practical scenarios, however, there are a great number of cold-start users with only minimal logged interactions. As a result, existing sequential recommendation models will lose their predictive power due to the difficulties in learning sequential patterns over users with only limited interactions. In this work, we aim to improve sequential recommendation for cold-start users with a novel framework named MetaTL, which learns to model the transition patterns of users through meta-learning.\n","\n","Specifically, the proposed MetaTL:\n","\n","1. formulates sequential recommendation for cold-start users as a few-shot learning problem;\n","2. extracts the dynamic transition patterns among users with a translation-based architecture; and\n","3. adopts meta transitional learning to enable fast learning for cold-start users with only limited interactions, leading to accurate inference of sequential interactions."]},{"cell_type":"markdown","metadata":{"id":"yiZ8MmmCvhkG"},"source":["## Background"]},{"cell_type":"markdown","metadata":{"id":"W-phAZTyvsW-"},"source":["### Sequential Recommenders\n","\n","One of the first approaches for sequential recommendation is the use of Markov Chains to model the transitions of users among items. More recently, TransRec embeds items in a “transition space” and learns a translation vector for each user. With the advance in neural networks, many different neural structures including Recurrent Neural Networks, Convolutional Neural Networks, Transformers and Graph Neural Networks, have been adopted to model the dynamic preferences of users over their behavior sequences. While these methods aim to improve the overall performance via representation learning for sequences, they suffer from weak prediction power for cold-start users with short behavior sequences."]},{"cell_type":"markdown","metadata":{"id":"-Yy2uAfGwYBs"},"source":["### Meta Learning\n","\n","This line of research aims to learn a model which can adapt and generalize to new tasks and new environments with a few training samples. To achieve the goal of “learning-to-learn”, there are three types of different approaches. Metric-based methods are based on a similar idea to the nearest neighbors algorithm with a well-designed metric or distance function, prototypical networks or Siamese Neural Network. Model-based methods usually perform a rapid parameter update with an internal architecture or are controlled by another meta-learner model. As for the optimization-based approaches, by adjusting the optimization algorithm, the models can be efficiently updated with a few examples."]},{"cell_type":"markdown","metadata":{"id":"2Da77sgAwZl4"},"source":["### Cold-Start Meta Recommenders\n","\n","MetaRec proposes a meta-learning strategy to learn user-specific logistic regression. There are also methods including MetaCF, Warm-up and MeLU, adopting Model-Agnostic Meta-Learning (MAML) methods to learn a model to achieve fast adaptation for cold-start users."]},{"cell_type":"markdown","metadata":{"id":"y6fHnRMKwbZq"},"source":["### Cold-Start Meta Sequential Recommenders\n","\n","cold-start sequential recommendation targets a setting where no additional auxiliary knowledge can be accessed due to privacy issues, and more importantly, the user-item interactions are sequentially dependent. A user’s preferences and tastes may change over time and such dynamics are of great significance in sequential recommendation. Hence, it is necessary to develop a new sequential recommendation framework that can distill short-range item transitional dynamics, and make fast adaptation to those cold-start users with limited user-item interactions."]},{"cell_type":"markdown","metadata":{"id":"f8jhVM9EvvT9"},"source":["## Problem Statement\n","\n","Let $I = \\{𝑖_1,𝑖_2, \\dots,𝑖_𝑃\\}$ and $U = \\{u_1,u_2, \\dots,u_G\\}$ represent the item set and user set in the platform respectively. Each item is mapped to a trainable embedding associated with its ID. There is no auxiliary information for users or items. In sequential recommendation, given the sequence of items ${𝑆𝑒𝑞}_𝑢 = (𝑖_{𝑢,1},𝑖_{𝑢,2}, \\dots,𝑖_{𝑢,𝑛})$ that user 𝑢 has interacted with in chronological order, the model aims to infer the next interesting item $𝑖_{𝑢,𝑛+1}$. That is to say, we need to predict the preference score for each candidate item based on ${𝑆𝑒𝑞}_𝑢$ and thus recommend the top-N items with the highest scores.\n","\n","In our task, we train the model on $U_{𝑡𝑟𝑎𝑖𝑛}$, which contains users with various numbers of logged interactions. Then given 𝑢 in a separate test set $U_{𝑡𝑒𝑠𝑡},\\ U_{𝑡𝑟𝑎𝑖𝑛} ∩ U_{𝑡𝑒𝑠𝑡} = \\phi$, the model can quickly learn user transition patterns according to the 𝐾 initial interactions and thus infer the sequential interactions. Note that the size of a user’s initial interactions (i.e., 𝐾) is assumed to be a small number (e.g., 2, 3 or 4) considering the cold-start scenario."]},{"cell_type":"markdown","metadata":{"id":"zc6NiwbDXm5i"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"baVt4qbEl5yQ"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"8JV0JbNymEEe"},"source":["import os\n","import sys\n","import copy\n","import json\n","import random\n","import shutil\n","import logging\n","import numpy as np\n","from collections import defaultdict, Counter, OrderedDict\n","from multiprocessing import Process, Queue\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9Dgt2BOl_18"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"H6PGFIYtmA4s"},"source":["class Args:\n","    dataset = \"electronics\"\n","    seed = None\n","    K = 3 #NUMBER OF SHOT\n","    embed_dim = 100\n","    batch_size = 1024\n","    learning_rate = 0.001\n","    epoch = 1000\n","    print_epoch = 100\n","    eval_epoch = 100\n","    beta = 5\n","    margin = 1\n","    dropout_p = 0.5\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5MVLDKMrG2b","executionInfo":{"elapsed":8,"status":"ok","timestamp":1635840881817,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"4d27e948-c7d6-424d-ab4c-3f1c8a8cee8e"},"source":["params = dict(Args.__dict__)\n","params"],"execution_count":null,"outputs":[{"data":{"text/plain":["{'K': 3,\n"," '__dict__': <attribute '__dict__' of 'Args' objects>,\n"," '__doc__': None,\n"," '__module__': '__main__',\n"," '__weakref__': <attribute '__weakref__' of 'Args' objects>,\n"," 'batch_size': 1024,\n"," 'beta': 5,\n"," 'dataset': 'electronics',\n"," 'device': device(type='cuda', index=0),\n"," 'dropout_p': 0.5,\n"," 'embed_dim': 100,\n"," 'epoch': 1000,\n"," 'eval_epoch': 100,\n"," 'learning_rate': 0.001,\n"," 'margin': 1,\n"," 'print_epoch': 100,\n"," 'seed': None}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"1zh6XmmwnGFD"},"source":["if params['seed'] is not None:\n","    SEED = params['seed']\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    np.random.seed(SEED)\n","    random.seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21UavFIVl65C"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"3_iy2vErwCW5"},"source":["***Electronics*** is adopted from the public Amazon review dataset, which includes reviews ranging from May 1996 to July 2014 on Amazon products belonging to the “Electronics” category.\n","\n","We filter out items with fewer than 10 interactions. We split each dataset with a corresponding cutting timestamp 𝑇, such that we construct $U_{𝑡𝑟𝑎𝑖𝑛}$ with users who have interactions before 𝑇 and construct $U_{𝑡𝑒𝑠𝑡}$ with users who start their first interactions after 𝑇.\n","\n","When evaluating few-shot sequential recommendation for a choice of 𝐾 (i.e., the number of initial interactions), we keep 𝐾 interactions as initialization for each user in $U_{𝑡𝑒𝑠𝑡}$ and predict for the user’s next interactions."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_2jZQEYr6n2","executionInfo":{"elapsed":1389,"status":"ok","timestamp":1635840884082,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"d35e3a9a-00a2-4ff3-e4e6-ea064d4c3064"},"source":["!wget -q --show-progress https://github.com/sparsh-ai/coldstart-recsys/raw/main/data/electronics/electronics_train.csv\n","!wget -q --show-progress https://github.com/sparsh-ai/coldstart-recsys/raw/main/data/electronics/electronics_test_new_user.csv"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["electronics_train.c 100%[===================>]   7.41M  --.-KB/s    in 0.1s    \n","electronics_test_ne 100%[===================>] 892.31K  --.-KB/s    in 0.06s   \n"]}]},{"cell_type":"code","metadata":{"id":"yLznX0HIl9wH"},"source":["# sampler for batch generation\n","def random_neq(l, r, s):\n","    t = np.random.randint(l, r)\n","    while t in s:\n","        t = np.random.randint(l, r)\n","    return t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aewgHVUpa84"},"source":["def trans_to_cuda(variable):\n","    if torch.cuda.is_available():\n","        return variable.cuda()\n","    else:\n","        return variable\n","\n","\n","def trans_to_cpu(variable):\n","    if torch.cuda.is_available():\n","        return variable.cpu()\n","    else:\n","        return variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1pBm8_9pWGj"},"source":["# train/val/test data generation\n","def data_load(fname, num_sample):\n","    usernum = 0\n","    itemnum = 0\n","    user_train = defaultdict(list)\n","\n","    # assume user/item index starting from 1\n","    f = open('%s_train.csv' % (fname), 'r')\n","    for line in f:\n","        u, i, t = line.rstrip().split('\\t')\n","        u = int(u)\n","        i = int(i)\n","        usernum = max(u, usernum)\n","        itemnum = max(i, itemnum)\n","        user_train[u].append(i)\n","    f.close()\n","\n","    # read in new users for testing\n","    user_input_test = {}\n","    user_input_valid = {}\n","    user_valid = {}\n","    user_test = {}\n","\n","\n","    User_test_new = defaultdict(list)\n","    f = open('%s_test_new_user.csv' % (fname), 'r')\n","    for line in f:\n","        u, i, t = line.rstrip().split('\\t')\n","        u = int(u)\n","        i = int(i)\n","        User_test_new[u].append(i)\n","    f.close()\n","\n","    for user in User_test_new:\n","        if len(User_test_new[user]) > num_sample:\n","            if random.random()<0.3:\n","                user_input_valid[user] = User_test_new[user][:num_sample]\n","                user_valid[user] = []\n","                user_valid[user].append(User_test_new[user][num_sample])\n","            else:\n","                user_input_test[user] = User_test_new[user][:num_sample]\n","                user_test[user] = []\n","                user_test[user].append(User_test_new[user][num_sample])\n","    \n","\n","    return [user_train, usernum, itemnum, user_input_test, user_test, user_input_valid, user_valid]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nilscd6kpTek"},"source":["class DataLoader(object):\n","    def __init__(self, user_train, user_test, itemnum, parameter):\n","        self.curr_rel_idx = 0\n","        \n","        self.bs = parameter['batch_size']\n","        self.maxlen = parameter['K']\n","\n","        self.valid_user = []\n","        for u in user_train:\n","            if len(user_train[u]) < self.maxlen or len(user_test[u]) < 1: continue\n","            self.valid_user.append(u)\n","        \n","        self.num_tris = len(self.valid_user)\n","\n","        self.train = user_train\n","        self.test = user_test\n","        \n","        self.itemnum = itemnum\n","\n","    def next_one_on_eval(self):\n","        if self.curr_tri_idx == self.num_tris:\n","            return \"EOT\", \"EOT\"\n","\n","        u = self.valid_user[self.curr_tri_idx]\n","\n","        self.curr_tri_idx += 1\n","        \n","        seq = np.zeros([self.maxlen], dtype=np.int32)\n","        pos = np.zeros([self.maxlen - 1], dtype=np.int32)\n","        neg = np.zeros([self.maxlen - 1], dtype=np.int32)\n","        \n","        idx = self.maxlen - 1\n","\n","        ts = set(self.train[u])\n","        for i in reversed(self.train[u]):\n","            seq[idx] = i\n","            if idx > 0:\n","                pos[idx - 1] = i\n","                if i != 0: neg[idx - 1] = random_neq(1, self.itemnum + 1, ts)\n","            idx -= 1\n","            if idx == -1: break\n","\n","        curr_rel = u\n","        support_triples, support_negative_triples, query_triples, negative_triples = [], [], [], []\n","        for idx in range(self.maxlen-1):\n","            support_triples.append([seq[idx],curr_rel,pos[idx]])\n","            support_negative_triples.append([seq[idx],curr_rel,neg[idx]])\n","\n","        rated = ts\n","        rated.add(0)\n","        query_triples.append([seq[-1],curr_rel,self.test[u][0]])\n","        for _ in range(100):\n","            t = np.random.randint(1, self.itemnum + 1)\n","            while t in rated: t = np.random.randint(1, self.itemnum + 1)\n","            negative_triples.append([seq[-1],curr_rel,t])\n","\n","        support_triples = [support_triples]\n","        support_negative_triples = [support_negative_triples]\n","        query_triples = [query_triples]\n","        negative_triples = [negative_triples]\n","\n","        return [support_triples, support_negative_triples, query_triples, negative_triples], curr_rel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suxbalu2nPuW"},"source":["## Sampling"]},{"cell_type":"code","metadata":{"id":"lzXq4p-YnPrk"},"source":["def sample_function_mixed(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):\n","    def sample():\n","\n","        if random.random()<0.5:\n","            user = np.random.randint(1, usernum + 1)\n","            while len(user_train[user]) <= 1: user = np.random.randint(1, usernum + 1)\n","\n","            \n","            seq = np.zeros([maxlen], dtype=np.int32)\n","            pos = np.zeros([maxlen], dtype=np.int32)\n","            neg = np.zeros([maxlen], dtype=np.int32)\n","\n","            if len(user_train[user]) < maxlen:\n","                nxt_idx = len(user_train[user]) - 1\n","            else:\n","                nxt_idx = np.random.randint(maxlen,len(user_train[user]))\n","\n","            nxt = user_train[user][nxt_idx]\n","            idx = maxlen - 1\n","\n","            ts = set(user_train[user])\n","            for i in reversed(user_train[user][min(0, nxt_idx - 1 - maxlen) : nxt_idx - 1]):\n","                seq[idx] = i\n","                pos[idx] = nxt\n","                if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n","                nxt = i\n","                idx -= 1\n","                if idx == -1: break\n","\n","            curr_rel = user\n","            support_triples, support_negative_triples, query_triples, negative_triples = [], [], [], []\n","            for idx in range(maxlen-1):\n","                support_triples.append([seq[idx],curr_rel,pos[idx]])\n","                support_negative_triples.append([seq[idx],curr_rel,neg[idx]])\n","            query_triples.append([seq[-1],curr_rel,pos[-1]])\n","            negative_triples.append([seq[-1],curr_rel,neg[-1]])\n","\n","            return support_triples, support_negative_triples, query_triples, negative_triples, curr_rel\n","\n","        else:\n","            user = np.random.randint(1, usernum + 1)\n","            while len(user_train[user]) <= 1: user = np.random.randint(1, usernum + 1)\n","\n","            seq = np.zeros([maxlen], dtype=np.int32)\n","            pos = np.zeros([maxlen], dtype=np.int32)\n","            neg = np.zeros([maxlen], dtype=np.int32)\n","\n","            list_idx = random.sample([i for i in range(len(user_train[user]))], maxlen + 1)\n","            list_item = [user_train[user][i] for i in sorted(list_idx)]\n","\n","            nxt = list_item[-1]\n","            idx = maxlen - 1\n","\n","            ts = set(user_train[user])\n","            for i in reversed(list_item[:-1]):\n","                seq[idx] = i\n","                pos[idx] = nxt\n","                if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n","                nxt = i\n","                idx -= 1\n","                if idx == -1: break\n","\n","            curr_rel = user\n","            support_triples, support_negative_triples, query_triples, negative_triples = [], [], [], []\n","            for idx in range(maxlen-1):\n","                support_triples.append([seq[idx],curr_rel,pos[idx]])\n","                support_negative_triples.append([seq[idx],curr_rel,neg[idx]])\n","            query_triples.append([seq[-1],curr_rel,pos[-1]])\n","            negative_triples.append([seq[-1],curr_rel,neg[-1]])\n","\n","            return support_triples, support_negative_triples, query_triples, negative_triples, curr_rel\n","\n","    np.random.seed(SEED)\n","    \n","    while True:\n","        one_batch = []\n","        for i in range(batch_size):\n","            one_batch.append(sample())\n","\n","        support, support_negative, query, negative, curr_rel = zip(*one_batch)\n","\n","        result_queue.put(([support, support_negative, query, negative], curr_rel))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyBxylgHpvSr"},"source":["class WarpSampler(object):\n","    def __init__(self, User, usernum, itemnum, batch_size=64, maxlen=10, n_workers=1):\n","        self.result_queue = Queue(maxsize=n_workers * 10)\n","        self.processors = []\n","        for i in range(n_workers):\n","            self.processors.append(\n","                Process(target=sample_function_mixed, args=(User,\n","                                                      usernum,\n","                                                      itemnum,\n","                                                      batch_size,\n","                                                      maxlen,\n","                                                      self.result_queue,\n","                                                      np.random.randint(2e9)\n","                                                      )))\n","            self.processors[-1].daemon = True\n","            self.processors[-1].start()\n","\n","    def next_batch(self):\n","        return self.result_queue.get()\n","\n","    def close(self):\n","        for p in self.processors:\n","            p.terminate()\n","            p.join()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fkhFoNOunPo1"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"x0Vg_yHM0Q3m"},"source":["<p><center><img src='_images/T714933_1.png'></center></p>"]},{"cell_type":"code","metadata":{"id":"ax73L49BnPl7"},"source":["class Embedding(nn.Module):\n","    def __init__(self, num_ent, parameter):\n","        super(Embedding, self).__init__()\n","        self.device = parameter['device']\n","        self.es = parameter['embed_dim']\n","        \n","        self.embedding = nn.Embedding(num_ent + 1, self.es)\n","        nn.init.xavier_uniform_(self.embedding.weight)\n","\n","\n","    def forward(self, triples):\n","        idx = [[[t[0], t[2]] for t in batch] for batch in triples]\n","        idx = torch.LongTensor(idx).to(self.device)\n","        return self.embedding(idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQP6N9Eqp_Lr"},"source":["class MetaLearner(nn.Module):\n","    def __init__(self, K, embed_size=100, num_hidden1=500, num_hidden2=200, out_size=100, dropout_p=0.5):\n","        super(MetaLearner, self).__init__()\n","        self.embed_size = embed_size\n","        self.K = K\n","        self.out_size = out_size\n","        self.rel_fc1 = nn.Sequential(OrderedDict([\n","            ('fc',   nn.Linear(2*embed_size, num_hidden1)),\n","            ('bn',   nn.BatchNorm1d(K)),\n","            ('relu', nn.LeakyReLU()),\n","            ('drop', nn.Dropout(p=dropout_p)),\n","        ]))\n","        self.rel_fc2 = nn.Sequential(OrderedDict([\n","            ('fc',   nn.Linear(num_hidden1, num_hidden2)),\n","            ('bn',   nn.BatchNorm1d(K)),\n","            ('relu', nn.LeakyReLU()),\n","            ('drop', nn.Dropout(p=dropout_p)),\n","        ]))\n","        self.rel_fc3 = nn.Sequential(OrderedDict([\n","            ('fc', nn.Linear(num_hidden2, out_size)),\n","            ('bn', nn.BatchNorm1d(K)),\n","        ]))\n","        nn.init.xavier_normal_(self.rel_fc1.fc.weight)\n","        nn.init.xavier_normal_(self.rel_fc2.fc.weight)\n","        nn.init.xavier_normal_(self.rel_fc3.fc.weight)\n","\n","    def forward(self, inputs):\n","        size = inputs.shape\n","        x = inputs.contiguous().view(size[0], size[1], -1)\n","        x = self.rel_fc1(x)\n","        x = self.rel_fc2(x)\n","        x = self.rel_fc3(x)\n","        x = torch.mean(x, 1)\n","\n","        return x.view(size[0], 1, 1, self.out_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZ4h-PY8p-AK"},"source":["class EmbeddingLearner(nn.Module):\n","    def __init__(self):\n","        super(EmbeddingLearner, self).__init__()\n","\n","    def forward(self, h, t, r, pos_num):\n","        score = -torch.norm(h + r - t, 2, -1).squeeze(2)\n","        p_score = score[:, :pos_num]\n","        n_score = score[:, pos_num:]\n","        return p_score, n_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdPC2RHrp8uQ"},"source":["class MetaTL(nn.Module):\n","    def __init__(self, itemnum, parameter):\n","        super(MetaTL, self).__init__()\n","        self.device = parameter['device']\n","        self.beta = parameter['beta']\n","        self.dropout_p = parameter['dropout_p']\n","        self.embed_dim = parameter['embed_dim']\n","        self.margin = parameter['margin']\n","        self.embedding = Embedding(itemnum, parameter)\n","\n","        self.relation_learner = MetaLearner(parameter['K'] - 1, embed_size=100, num_hidden1=500,\n","                                                    num_hidden2=200, out_size=100, dropout_p=self.dropout_p)\n","\n","        self.embedding_learner = EmbeddingLearner()\n","        self.loss_func = nn.MarginRankingLoss(self.margin)\n","        self.rel_q_sharing = dict()\n","\n","    def split_concat(self, positive, negative):\n","        pos_neg_e1 = torch.cat([positive[:, :, 0, :],\n","                                negative[:, :, 0, :]], 1).unsqueeze(2)\n","        pos_neg_e2 = torch.cat([positive[:, :, 1, :],\n","                                negative[:, :, 1, :]], 1).unsqueeze(2)\n","        return pos_neg_e1, pos_neg_e2\n","\n","    def forward(self, task, iseval=False, curr_rel=''):\n","        # transfer task string into embedding\n","        support, support_negative, query, negative = [self.embedding(t) for t in task]\n","\n","        K = support.shape[1]              # num of K\n","        num_sn = support_negative.shape[1]  # num of support negative\n","        num_q = query.shape[1]              # num of query\n","        num_n = negative.shape[1]           # num of query negative\n","\n","        rel = self.relation_learner(support)\n","        rel.retain_grad()\n","\n","        rel_s = rel.expand(-1, K+num_sn, -1, -1)\n","\n","        if iseval and curr_rel != '' and curr_rel in self.rel_q_sharing.keys():\n","            rel_q = self.rel_q_sharing[curr_rel]\n","        else:\n","            sup_neg_e1, sup_neg_e2 = self.split_concat(support, support_negative)\n","\n","            p_score, n_score = self.embedding_learner(sup_neg_e1, sup_neg_e2, rel_s, K)\n","\n","            y = torch.Tensor([1]).to(self.device)\n","            self.zero_grad()\n","            loss = self.loss_func(p_score, n_score, y)\n","            loss.backward(retain_graph=True)\n","\n","            grad_meta = rel.grad\n","            rel_q = rel - self.beta*grad_meta\n","\n","\n","            self.rel_q_sharing[curr_rel] = rel_q\n","\n","        rel_q = rel_q.expand(-1, num_q + num_n, -1, -1)\n","\n","        que_neg_e1, que_neg_e2 = self.split_concat(query, negative)  \n","        p_score, n_score = self.embedding_learner(que_neg_e1, que_neg_e2, rel_q, num_q)\n","\n","        return p_score, n_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cW-_AcNcmHc9"},"source":["## Training and Inference"]},{"cell_type":"markdown","metadata":{"id":"kImSZhfqv3HE"},"source":["Meta-learning aims to learn a model which can adapt to new tasks (i.e., new users) with a few training samples. To enable meta-learning in sequential recommendation for cold-start users, we formulate training a sequential recommender as solving a new few-shot learning problem (i.e., meta-testing task) by training on many sampled similar tasks (i.e., the meta-training tasks). Each task includes a 𝑠𝑢𝑝𝑝𝑜𝑟𝑡 set S and a 𝑞𝑢𝑒𝑟𝑦 set Q, which can be regarded as the “training” set and “testing” set of the task. For example, while constructing a task $T_𝑛$, given user $𝑢_𝑗$ with initial interactions in sequence (e.g., $𝑖_𝐴 \\rightarrow_{u_j} i_B \\rightarrow_{u_j} i_C$), we will have the a set of transition pairs $\\{ 𝑖_𝐴 \\rightarrow_{u_j} i_B, i_B \\rightarrow_{u_j} i_C \\}$ as support and predict for the query $i_C \\rightarrow_{u_j} ?$.\n","\n","When testing on a new user $𝑢_{𝑡𝑒𝑠𝑡}$, we will firstly construct the support set $S_{𝑡𝑒𝑠𝑡}$ based on the user’s initial interactions. The model $𝑓_\\theta$ is fine-tuned with all the transition pairs in $S_{𝑡𝑒𝑠𝑡}$ and updated to $𝑓_{\\theta_{𝑡𝑒𝑠𝑡}'}$ , which can be used to generate the updated $tr_{𝑡𝑒𝑠𝑡}$. Given the test query $𝑖_𝑜 \\rightarrow_{u_{test}}?$, the preference score for item $𝑖_𝑝$ (as the next interaction) is calculated as −$∥i_𝑜 + tr_{𝑡𝑒𝑠𝑡} − i_𝑝 ∥^2$."]},{"cell_type":"code","metadata":{"id":"etxT15BbqMOp"},"source":["class Trainer:\n","    def __init__(self, data_loaders, itemnum, parameter):\n","        self.parameter = parameter\n","        # data loader\n","        self.train_data_loader = data_loaders[0]\n","        self.dev_data_loader = data_loaders[1]\n","        self.test_data_loader = data_loaders[2]\n","        # parameters\n","        self.batch_size = parameter['batch_size']\n","        self.learning_rate = parameter['learning_rate']\n","        self.epoch = parameter['epoch']\n","        self.print_epoch = parameter['print_epoch']\n","        self.eval_epoch = parameter['eval_epoch']\n","        self.device = parameter['device']\n","\n","        self.MetaTL = MetaTL(itemnum, parameter)\n","        self.MetaTL.to(self.device)\n","\n","        self.optimizer = torch.optim.Adam(self.MetaTL.parameters(), self.learning_rate)\n","\n","            \n","    def rank_predict(self, data, x, ranks):\n","        # query_idx is the idx of positive score\n","        query_idx = x.shape[0] - 1\n","        # sort all scores with descending, because more plausible triple has higher score\n","        _, idx = torch.sort(x, descending=True)\n","        rank = list(idx.cpu().numpy()).index(query_idx) + 1\n","        ranks.append(rank)\n","        # update data\n","        if rank <= 10:\n","            data['Hits@10'] += 1\n","            data['NDCG@10'] += 1 / np.log2(rank + 1)\n","        if rank <= 5:\n","            data['Hits@5'] += 1\n","            data['NDCG@5'] += 1 / np.log2(rank + 1)\n","        if rank == 1:\n","            data['Hits@1'] += 1\n","            data['NDCG@1'] += 1 / np.log2(rank + 1)\n","        data['MRR'] += 1.0 / rank\n","\n","    def do_one_step(self, task, iseval=False, curr_rel=''):\n","        loss, p_score, n_score = 0, 0, 0\n","        if not iseval:\n","            self.optimizer.zero_grad()\n","            p_score, n_score = self.MetaTL(task, iseval, curr_rel)\n","            y = torch.Tensor([1]).to(self.device)\n","            loss = self.MetaTL.loss_func(p_score, n_score, y)\n","            loss.backward()\n","            self.optimizer.step()\n","        elif curr_rel != '':\n","            p_score, n_score = self.MetaTL(task, iseval, curr_rel)\n","            y = torch.Tensor([1]).to(self.device)\n","            loss = self.MetaTL.loss_func(p_score, n_score, y)\n","        return loss, p_score, n_score\n","\n","    def train(self):\n","        # initialization\n","        best_epoch = 0\n","        best_value = 0\n","        bad_counts = 0\n","\n","        # training by epoch\n","        for e in range(self.epoch):\n","            # sample one batch from data_loader\n","            train_task, curr_rel = self.train_data_loader.next_batch()\n","            loss, _, _ = self.do_one_step(train_task, iseval=False, curr_rel=curr_rel)\n","            # print the loss on specific epoch\n","            if e % self.print_epoch == 0:\n","                loss_num = loss.item()\n","                print(\"Epoch: {}\\tLoss: {:.4f}\".format(e, loss_num))\n","            # do evaluation on specific epoch\n","            if e % self.eval_epoch == 0 and e != 0:\n","                print('Epoch  {} Validating...'.format(e))\n","                valid_data = self.eval(istest=False, epoch=e)\n","\n","                print('Epoch  {} Testing...'.format(e))\n","                test_data = self.eval(istest=True, epoch=e)\n","                \n","        print('Finish')\n","\n","    def eval(self, istest=False, epoch=None):\n","        self.MetaTL.eval()\n","        \n","        self.MetaTL.rel_q_sharing = dict()\n","\n","        if istest:\n","            data_loader = self.test_data_loader\n","        else:\n","            data_loader = self.dev_data_loader\n","        data_loader.curr_tri_idx = 0\n","\n","        # initial return data of validation\n","        data = {'MRR': 0, 'Hits@1': 0, 'Hits@5': 0, 'Hits@10': 0, 'NDCG@1': 0, 'NDCG@5': 0, 'NDCG@10': 0}\n","        ranks = []\n","\n","        t = 0\n","        temp = dict()\n","        while True:\n","            # sample all the eval tasks\n","            eval_task, curr_rel = data_loader.next_one_on_eval()\n","            # at the end of sample tasks, a symbol 'EOT' will return\n","            if eval_task == 'EOT':\n","                break\n","            t += 1\n","\n","            _, p_score, n_score = self.do_one_step(eval_task, iseval=True, curr_rel=curr_rel)\n","\n","            x = torch.cat([n_score, p_score], 1).squeeze()\n","\n","            self.rank_predict(data, x, ranks)\n","\n","            # print current temp data dynamically\n","            for k in data.keys():\n","                temp[k] = data[k] / t\n","            sys.stdout.write(\"{}\\tMRR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@5: {:.3f}\\tNDCG@1: {:.3f}\\tHits@10: {:.3f}\\tHits@5: {:.3f}\\tHits@1: {:.3f}\\r\".format(\n","                t, temp['MRR'], temp['NDCG@10'], temp['NDCG@5'], temp['NDCG@1'], temp['Hits@10'], temp['Hits@5'], temp['Hits@1']))\n","            sys.stdout.flush()\n","\n","        # print overall evaluation result and return it\n","        for k in data.keys():\n","            data[k] = round(data[k] / t, 3)\n","\n","        \n","        if istest:\n","            print(\"TEST: \\tMRR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@5: {:.3f}\\tNDCG@1: {:.3f}\\tHits@10: {:.3f}\\tHits@5: {:.3f}\\tHits@1: {:.3f}\\r\".format(\n","                    temp['MRR'], temp['NDCG@10'], temp['NDCG@5'], temp['NDCG@1'], temp['Hits@10'], temp['Hits@5'], temp['Hits@1']))\n","        else:\n","            print(\"VALID: \\tMRR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@5: {:.3f}\\tNDCG@1: {:.3f}\\tHits@10: {:.3f}\\tHits@5: {:.3f}\\tHits@1: {:.3f}\\r\".format(\n","                    temp['MRR'], temp['NDCG@10'], temp['NDCG@5'], temp['NDCG@1'], temp['Hits@10'], temp['Hits@5'], temp['Hits@1']))\n","\n","        return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"HVJ1u8VnmIup","executionInfo":{"elapsed":665242,"status":"ok","timestamp":1635841573128,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"b844e740-b9dd-410c-8df4-e19737dd6a40"},"source":["user_train, usernum_train, itemnum, user_input_test, user_test, user_input_valid, user_valid = data_load(params['dataset'], params['K'])    \n","\n","sampler = WarpSampler(user_train, usernum_train, itemnum, batch_size=params['batch_size'], maxlen=params['K'], n_workers=2)\n","sampler_test = DataLoader(user_input_test, user_test, itemnum, params)\n","sampler_valid = DataLoader(user_input_valid, user_valid, itemnum, params)\n","\n","trainer = Trainer([sampler, sampler_valid, sampler_test], itemnum, params)\n","trainer.train()\n","\n","sampler.close()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0\tLoss: 1.0004\n","Epoch: 100\tLoss: 0.7276\n","Epoch: 200\tLoss: 0.6102\n","Epoch: 300\tLoss: 0.6143\n","Epoch: 400\tLoss: 0.5779\n","Epoch: 500\tLoss: 0.5438\n","Epoch: 600\tLoss: 0.5271\n","Epoch: 700\tLoss: 0.5430\n","Epoch: 800\tLoss: 0.5642\n","Epoch: 900\tLoss: 0.5107\n","Epoch: 1000\tLoss: 0.5222\n","Epoch  1000 Validating...\n","VALID: \tMRR: 0.302\tNDCG@10: 0.345\tNDCG@5: 0.303\tNDCG@1: 0.187\tHits@10: 0.542\tHits@5: 0.410\tHits@1: 0.187\n","Epoch  1000 Testing...\n","TEST: \tMRR: 0.286\tNDCG@10: 0.327\tNDCG@5: 0.286\tNDCG@1: 0.172\tHits@10: 0.523\tHits@5: 0.397\tHits@1: 0.172\n","Epoch: 1100\tLoss: 0.5396\n","Epoch: 1200\tLoss: 0.5236\n","Epoch: 1300\tLoss: 0.4934\n","Epoch: 1400\tLoss: 0.4948\n","Epoch: 1500\tLoss: 0.5047\n","Epoch: 1600\tLoss: 0.4933\n","Epoch: 1700\tLoss: 0.5068\n","Epoch: 1800\tLoss: 0.4833\n","Epoch: 1900\tLoss: 0.5245\n","Epoch: 2000\tLoss: 0.4982\n","Epoch  2000 Validating...\n","VALID: \tMRR: 0.307\tNDCG@10: 0.353\tNDCG@5: 0.308\tNDCG@1: 0.188\tHits@10: 0.561\tHits@5: 0.422\tHits@1: 0.188\n","Epoch  2000 Testing...\n","TEST: \tMRR: 0.295\tNDCG@10: 0.338\tNDCG@5: 0.296\tNDCG@1: 0.177\tHits@10: 0.538\tHits@5: 0.406\tHits@1: 0.177\n","Epoch: 2100\tLoss: 0.4960\n","Epoch: 2200\tLoss: 0.4943\n","Epoch: 2300\tLoss: 0.4477\n","Epoch: 2400\tLoss: 0.4481\n","Epoch: 2500\tLoss: 0.4429\n","Epoch: 2600\tLoss: 0.4885\n","Epoch: 2700\tLoss: 0.4485\n","Epoch: 2800\tLoss: 0.4438\n","Epoch: 2900\tLoss: 0.4456\n","Epoch: 3000\tLoss: 0.4484\n","Epoch  3000 Validating...\n","VALID: \tMRR: 0.317\tNDCG@10: 0.360\tNDCG@5: 0.317\tNDCG@1: 0.197\tHits@10: 0.558\tHits@5: 0.425\tHits@1: 0.197\n","Epoch  3000 Testing...\n","TEST: \tMRR: 0.302\tNDCG@10: 0.347\tNDCG@5: 0.304\tNDCG@1: 0.182\tHits@10: 0.551\tHits@5: 0.418\tHits@1: 0.182\n","Epoch: 3100\tLoss: 0.4422\n","Epoch: 3200\tLoss: 0.4398\n","Epoch: 3300\tLoss: 0.4230\n","Epoch: 3400\tLoss: 0.3967\n","Epoch: 3500\tLoss: 0.4214\n","Epoch: 3600\tLoss: 0.4144\n","Epoch: 3700\tLoss: 0.3635\n","Epoch: 3800\tLoss: 0.3918\n","Epoch: 3900\tLoss: 0.4223\n","Epoch: 4000\tLoss: 0.4319\n","Epoch  4000 Validating...\n","VALID: \tMRR: 0.322\tNDCG@10: 0.371\tNDCG@5: 0.326\tNDCG@1: 0.195\tHits@10: 0.584\tHits@5: 0.445\tHits@1: 0.195\n","Epoch  4000 Testing...\n","TEST: \tMRR: 0.309\tNDCG@10: 0.357\tNDCG@5: 0.310\tNDCG@1: 0.189\tHits@10: 0.567\tHits@5: 0.423\tHits@1: 0.189\n","Epoch: 4100\tLoss: 0.3717\n","Epoch: 4200\tLoss: 0.3762\n","Epoch: 4300\tLoss: 0.3786\n","Epoch: 4400\tLoss: 0.3803\n","Epoch: 4500\tLoss: 0.3884\n","Epoch: 4600\tLoss: 0.3833\n","Epoch: 4700\tLoss: 0.3913\n","Epoch: 4800\tLoss: 0.4011\n","Epoch: 4900\tLoss: 0.3760\n","Epoch: 5000\tLoss: 0.4257\n","Epoch  5000 Validating...\n","VALID: \tMRR: 0.329\tNDCG@10: 0.378\tNDCG@5: 0.336\tNDCG@1: 0.200\tHits@10: 0.591\tHits@5: 0.462\tHits@1: 0.200\n","Epoch  5000 Testing...\n","TEST: \tMRR: 0.321\tNDCG@10: 0.367\tNDCG@5: 0.322\tNDCG@1: 0.201\tHits@10: 0.575\tHits@5: 0.435\tHits@1: 0.201\n","Epoch: 5100\tLoss: 0.3676\n","Epoch: 5200\tLoss: 0.3505\n","Epoch: 5300\tLoss: 0.3675\n","Epoch: 5400\tLoss: 0.3786\n","Epoch: 5500\tLoss: 0.3471\n","Epoch: 5600\tLoss: 0.3569\n","Epoch: 5700\tLoss: 0.3753\n","Epoch: 5800\tLoss: 0.3767\n","Epoch: 5900\tLoss: 0.3100\n","Epoch: 6000\tLoss: 0.3656\n","Epoch  6000 Validating...\n","VALID: \tMRR: 0.343\tNDCG@10: 0.392\tNDCG@5: 0.351\tNDCG@1: 0.216\tHits@10: 0.607\tHits@5: 0.479\tHits@1: 0.216\n","Epoch  6000 Testing...\n","TEST: \tMRR: 0.329\tNDCG@10: 0.377\tNDCG@5: 0.334\tNDCG@1: 0.207\tHits@10: 0.585\tHits@5: 0.452\tHits@1: 0.207\n","Epoch: 6100\tLoss: 0.3711\n","Epoch: 6200\tLoss: 0.3548\n","Epoch: 6300\tLoss: 0.3829\n","Epoch: 6400\tLoss: 0.3478\n","Epoch: 6500\tLoss: 0.3661\n","Epoch: 6600\tLoss: 0.3433\n","Epoch: 6700\tLoss: 0.3506\n","Epoch: 6800\tLoss: 0.3107\n","Epoch: 6900\tLoss: 0.3364\n","Epoch: 7000\tLoss: 0.3267\n","Epoch  7000 Validating...\n","VALID: \tMRR: 0.344\tNDCG@10: 0.395\tNDCG@5: 0.351\tNDCG@1: 0.216\tHits@10: 0.615\tHits@5: 0.479\tHits@1: 0.216\n","Epoch  7000 Testing...\n","TEST: \tMRR: 0.329\tNDCG@10: 0.378\tNDCG@5: 0.335\tNDCG@1: 0.204\tHits@10: 0.588\tHits@5: 0.458\tHits@1: 0.204\n","Epoch: 7100\tLoss: 0.3744\n","Epoch: 7200\tLoss: 0.3236\n","Epoch: 7300\tLoss: 0.3446\n","Epoch: 7400\tLoss: 0.3261\n","Epoch: 7500\tLoss: 0.3212\n","Epoch: 7600\tLoss: 0.3229\n","Epoch: 7700\tLoss: 0.3204\n","Epoch: 7800\tLoss: 0.3168\n","Epoch: 7900\tLoss: 0.3125\n","Epoch: 8000\tLoss: 0.3491\n","Epoch  8000 Validating...\n","VALID: \tMRR: 0.349\tNDCG@10: 0.398\tNDCG@5: 0.354\tNDCG@1: 0.228\tHits@10: 0.611\tHits@5: 0.473\tHits@1: 0.228\n","Epoch  8000 Testing...\n","TEST: \tMRR: 0.326\tNDCG@10: 0.375\tNDCG@5: 0.333\tNDCG@1: 0.197\tHits@10: 0.588\tHits@5: 0.457\tHits@1: 0.197\n","Epoch: 8100\tLoss: 0.3372\n","Epoch: 8200\tLoss: 0.3157\n","Epoch: 8300\tLoss: 0.3285\n","Epoch: 8400\tLoss: 0.3266\n","Epoch: 8500\tLoss: 0.3086\n","Epoch: 8600\tLoss: 0.3008\n","Epoch: 8700\tLoss: 0.3207\n","Epoch: 8800\tLoss: 0.3412\n","Epoch: 8900\tLoss: 0.3214\n","Epoch: 9000\tLoss: 0.3146\n","Epoch  9000 Validating...\n","VALID: \tMRR: 0.351\tNDCG@10: 0.401\tNDCG@5: 0.355\tNDCG@1: 0.229\tHits@10: 0.615\tHits@5: 0.474\tHits@1: 0.229\n","Epoch  9000 Testing...\n","TEST: \tMRR: 0.336\tNDCG@10: 0.383\tNDCG@5: 0.341\tNDCG@1: 0.214\tHits@10: 0.588\tHits@5: 0.458\tHits@1: 0.214\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zqr-aRykwP-V"},"source":["## Citations\n","\n","Sequential Recommendation for Cold-start Users with Meta Transitional Learning. Jianling Wang, Kaize Ding, James Caverlee. 2021. SIGIR. [https://arxiv.org/abs/2107.06427](https://arxiv.org/abs/2107.06427)"]}]}