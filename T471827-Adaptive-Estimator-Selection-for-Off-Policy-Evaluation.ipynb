{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T471827 | Adaptive Estimator Selection for Off-Policy Evaluation","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPwuNFPgoeWcz1NwOVVG5lG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JGjt45hAm_mo"},"source":["# Adaptive Estimator Selection for Off-Policy Evaluation"]},{"cell_type":"markdown","metadata":{"id":"lvWh9mRWgj-v"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"_OJRD7SEgrn1","executionInfo":{"status":"ok","timestamp":1633522603929,"user_tz":-330,"elapsed":5543,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import json\n","import copy\n","import argparse\n","import sys\n","import os\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","torch.set_default_tensor_type(torch.DoubleTensor)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aEuqCZj1grle"},"source":["## Params"]},{"cell_type":"code","metadata":{"id":"vBt2tpCXiBlN","executionInfo":{"status":"ok","timestamp":1633522603933,"user_tz":-330,"elapsed":30,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["# hs = [0.25,0.03125]\n","hs = [x for x in np.logspace(1, 7, num=7, base=0.5)]\n","# hs = [x for x in np.linspace(0.01, 0.5, 20)]\n","hs.reverse()\n","#hs = [0.02, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5]\n","\n","FRIENDLY = {'method': 'friendly', 'alpha': 0.7, 'beta': 0.2, 'l': 10}\n","ADVERSARIAL = {'method': 'adversarial', 'alpha': 0.3, 'beta': 0.2, 'l': 10}\n","NEUTRAL = {'method': 'neutral', 'alpha': 0., 'beta': 0., 'l': 10}\n","\n","\n","ns = [10, 30, 100, 300, 1000, 3000]\n","Replicates = 100\n","feat_dim=10\n","act_dim=2\n","lip=10"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQfQ0trXgrj8"},"source":["## CCB Env"]},{"cell_type":"code","metadata":{"id":"4aruo2F7grh_","executionInfo":{"status":"ok","timestamp":1633522610582,"user_tz":-330,"elapsed":1025,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class NNPredictor(object):\n","    class NNModel(nn.Module):\n","        def __init__(self,input_dim,output_dim):\n","            super(NNPredictor.NNModel,self).__init__()\n","            self.network = nn.Sequential(nn.Linear(input_dim,output_dim,bias=False),\n","                                         nn.Sigmoid())\n","        def forward(self,x):\n","            return (self.network(x))\n","\n","    def __init__(self, input_dim, output_dim):\n","        self.model = NNPredictor.NNModel(input_dim, output_dim)\n","        self.criterion = nn.MSELoss()\n","\n","    def fit(self, X, y):\n","        optimizer = optim.Adagrad(self.model.parameters(), lr = 0.1)\n","        prev_loss = 0.0\n","        for i in range(5000):\n","            total_loss = 0.0\n","            for a in range(y.shape[1]):\n","                optimizer.zero_grad()\n","                preds = self.model(torch.tensor(X))\n","                loss = self.criterion(preds[:,a], torch.tensor(y[:,a]))\n","                total_loss += loss\n","                loss.backward()\n","                optimizer.step()\n","            if np.mod(i,100) == 0:\n","                x = total_loss.detach().numpy()\n","                if np.round(x,3) == np.round(prev_loss,3):\n","                    break\n","                prev_loss = x\n","\n","    def predict(self, x):\n","        return self.model(torch.tensor(x)).detach().numpy()\n","\n","\n","\n","class CCBPolicy(object):\n","    def __init__(self,act_dim,model=None):\n","        self.model=model\n","        self.act_dim=act_dim\n","    \n","    \n","    def friendly_soften(self, action, soften_params):\n","        alpha = soften_params['alpha']\n","        beta = soften_params['beta']\n","        n_bins = soften_params['l']\n","        soft_action = []\n","        probs = []\n","        for act in action[0]:\n","            bin_id = np.ceil(act * n_bins)\n","            tau_low = (bin_id-1.)/n_bins\n","            tau_high = bin_id*1./n_bins\n","\n","            u = np.random.uniform(-0.5, 0.5)\n","            explore_prob = alpha+beta*u\n","            if np.random.uniform(0,1) > explore_prob:\n","                bin_id = np.random.choice(list(set(np.arange(1,n_bins+1))-set([bin_id])))\n","            chosen_act = np.random.uniform((bin_id-1.)/n_bins,bin_id*1./n_bins)\n","            soft_action.append(chosen_act)\n","            \n","            rho_o = ((1 - explore_prob) * (n_bins/(n_bins - 1)))\n","            rho_i = (explore_prob * n_bins)\n","            \n","            prob_data = {'tau_low': tau_low, 'tau_high': tau_high, 'rho_o': rho_o, 'rho_i': rho_i}\n","            probs.append(prob_data)\n","            \n","        return soft_action, probs\n","\n","    def adversarial_soften(self, action, soften_params):\n","        alpha = soften_params['alpha']\n","        beta = soften_params['beta']\n","        n_bins = soften_params['l']\n","        soft_action = []\n","        probs = []\n","        for act in action[0]:\n","            \"\"\"\n","            1. tau_low and tau_high are the lower and upper bounds of the bin in \n","            which the unsoftened action falls.\n","            2. rho_o is the density outside (tau_low, tau_high) after softening\n","            and rho_i is the density inside (tau_low, tau_high) after softening\n","            \"\"\"\n","\n","            bin_id = np.ceil(act * n_bins)\n","            tau_low = (bin_id-1.)/n_bins\n","            tau_high = bin_id*1./n_bins\n","            \n","            u = np.random.uniform(-0.5, 0.5)\n","            explore_prob = alpha+beta*u\n","            if np.random.uniform(0,1) < alpha+beta*u:\n","                bin_id = np.random.choice(list(set(np.arange(1,n_bins+1))-set([bin_id])))\n","            else:\n","                bin_id = np.random.choice(list(set(np.arange(1,n_bins+1))))\n","            chosen_act = np.random.uniform((bin_id-1.)/n_bins, bin_id*1./n_bins)\n","            soft_action.append(chosen_act)\n","            \n","            rho_o = (explore_prob * (n_bins/(n_bins - 1))) + (1-explore_prob)\n","            rho_i = (1 - explore_prob)\n","            \n","            prob_data = {'tau_low': tau_low, 'tau_high': tau_high, 'rho_o': rho_o, 'rho_i': rho_i}\n","            probs.append(prob_data)\n","            \n","        return soft_action, probs\n","    \n","    def neutral_soften(self, action, soften_params):\n","        soft_action = np.random.uniform(0,1,[1,self.act_dim])[0]\n","        probs = []\n","        for i in range(self.act_dim):\n","            prob_data = {'tau_low': 0, 'tau_high': 1, 'rho_o': 0, 'rho_i': 1}\n","            probs.append(prob_data)\n","        return soft_action, probs\n","    \n","    def get_soften_action(self, action, soften_params):\n","        if soften_params != None:\n","            soft_action = []\n","            if soften_params['method'] == \"friendly\":\n","                soft_action, probs = self.friendly_soften(action, soften_params)\n","            elif soften_params['method'] == \"adversarial\":\n","                soft_action, probs = self.adversarial_soften(action, soften_params)\n","            elif soften_params['method'] == \"neutral\":\n","                soft_action, probs = self.neutral_soften(action, soften_params)\n","            return {\"action\": [soft_action], \"prob\": probs}\n","        else:\n","            probs = []\n","            for i in range(self.act_dim):\n","                prob_data = {'tau_low': 0, 'tau_high': 1, 'rho_o': 0, 'rho_i': 1}\n","                probs.append(prob_data)\n","            return {\"action\": action, \"prob\": probs}\n","\n","    def get_action(self, x, soften=None):\n","        \n","        if soften == \"friendly\":\n","            soften_params = FRIENDLY\n","        elif soften == \"adversarial\":\n","            soften_params = ADVERSARIAL\n","        elif soften == \"neutral\":\n","            soften_params = NEUTRAL\n","        else:\n","            soften_params = None\n","            \n","        if self.model is None:\n","            act = np.random.uniform(0,1,[1,self.act_dim])\n","        else:\n","            if self.act_dim == 1:\n","                act = self.model.predict(x).reshape(-1,1)\n","            else:\n","                act = self.model.predict(x)\n","            act = torch.clamp(torch.Tensor(act),0,1).detach().numpy()\n","        act_prob = self.get_soften_action(act, soften_params)\n","        return act_prob\n","\n","class CCBSimulatedEnv(object):\n","    def __init__(self, lip=1, feat_dim=5, act_dim = 1, target_model_name = \"NNPredictor\", logging_model_name = None, loss_type=\"triangular\", soften=None):\n","        self.feat_dim=feat_dim\n","        self.act_dim=act_dim\n","        self.logging_model = self.get_model(logging_model_name)\n","        self.target_model = self.get_model(target_model_name)\n","        self.lip=lip\n","        self.opt=np.random.normal(0,1,(self.feat_dim,self.act_dim))\n","        self.loss_type = loss_type\n","        self.soften=soften\n","\n","    def get_model(self, model_name):\n","        if model_name == \"NNPredictor\":\n","            return NNPredictor(self.feat_dim,self.act_dim)\n","        elif model_name == \"Tree\":\n","            #return DecisionTreeRegressor(max_depth=5, min_samples_split = 5, min_samples_leaf = 5)\n","            return RandomForestRegressor(random_state=1, n_estimators=10, min_samples_split=5)\n","        else:\n","            return None\n","        \n","    def train_logger(self, n=0, sig=0.5):\n","        \"\"\"\n","        Uniform logging policy for now\n","        \"\"\"\n","        if self.soften:\n","            if self.logging_model != None:\n","                X = np.zeros((n, self.feat_dim))\n","                Y = np.zeros((n, self.act_dim))\n","                for i in range(n):\n","                    x = self.context()\n","                    X[i,:] = x\n","                    Y[i,:]= self.get_center(x) + np.random.normal(0,sig,(1,self.act_dim))\n","        \n","                self.logging_model.fit(X,Y)\n","            else:\n","                raise ValueError(\"soften without model?!! can't do!!!\")\n","            self.logger = CCBPolicy(self.act_dim, model = self.logging_model)\n","        else:\n","            self.logger = CCBPolicy(self.act_dim)\n","\n","    def train_target(self, n,sig=0.5):\n","        \"\"\"\n","        Good target policy trained via logistic regression (effectively)\n","        \"\"\"\n","        X = np.zeros((n, self.feat_dim))\n","        Y = np.zeros((n, self.act_dim))\n","        for i in range(n):\n","            x = self.context()\n","            X[i,:] = x\n","            Y[i,:]= self.get_center(x) + np.random.normal(0,sig,(1,self.act_dim))\n","\n","        self.target_model.fit(X,Y)\n","        self.target = CCBPolicy(self.act_dim,model=self.target_model)\n","\n","    def ground_truth(self,n):\n","        '''\n","        if self.soften == \"friendly\":\n","            soften_params = FRIENDLY\n","        elif self.soften == \"adversarial\":\n","            soften_params = ADVERSARIAL\n","        elif self.soften == \"neutral\":\n","            soften_params = NEUTRAL\n","        else:\n","            soften_params = None'''\n","        soften_params = None\n","        l = 0\n","        for i in range(n):\n","            x = self.context()\n","            a = self.target.get_action(x,soften_params)['action']\n","            l += self.loss(x,a)\n","        return(l/n)\n","\n","    def get_center(self,x):\n","        return np.exp(np.dot(x,self.opt))/(1+np.exp(np.dot(x,self.opt)))\n","\n","    def loss(self, x, a):\n","        center = self.get_center(x)\n","        if self.loss_type == \"triangular\":\n","            loss = min(np.sum(self.lip*np.abs(a - center)),1)\n","        elif self.loss_type == \"parabolic\":\n","            loss = min(np.sum((self.lip**2/4)*np.abs(a-center)),1)\n","        else:\n","            loss = 1.\n","        return loss\n","\n","    def context(self):\n","        x = np.random.normal(0,1,[1,self.feat_dim])\n","        return(x)\n","\n","    def gen_logging_data(self,n):\n","        \"\"\"\n","        @akshay: only supports uniform logging for now\n","        \"\"\"\n","        data = []\n","        for i in range(n):\n","            x = self.context()\n","            act_prob = self.logger.get_action(x, self.soften)\n","            a = act_prob[\"action\"]\n","            p = act_prob[\"prob\"]\n","            #print(\"prob: \", p)\n","            l = self.loss(x,a)\n","            data.append((x,a,l,p))\n","        return (data)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIalPBjthlGD","executionInfo":{"status":"ok","timestamp":1633522636200,"user_tz":-330,"elapsed":1192,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"1e51ae05-932a-44f0-99c6-f34c55775a27"},"source":["Env = CCBSimulatedEnv(lip=3,act_dim=2)\n","Env.train_logger()\n","Env.train_target(100)\n","print(\"Ground truth loss: %0.2f\" % (Env.ground_truth(1000)))\n","\n","data = Env.gen_logging_data(10000)\n","print(\"Uniform exploration average loss: %0.2f\" % (np.mean([tup[2] for tup in data])))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ground truth loss: 0.55\n","Uniform exploration average loss: 0.94\n"]}]},{"cell_type":"code","metadata":{"id":"LEz0y8G0iUHX"},"source":["\"\"\"\n","Env = CCBSimulatedEnv(lip=3, act_dim=2, target_model_name = \"NNPredictor\", logging_model_name = \"NNPredictor\")\n","Env.train_logger(10000)\n","Env.train_target(3000)\n","soften_target_params = None\n","soften_logging_params = {'method': 'friendly', 'alpha': 0.7, 'beta': 0.2, 'l': 10}\n","print(\"Ground truth loss: %0.2f\" % (Env.ground_truth(100000, soften_target_params)))\n","data = Env.gen_logging_data(1000, soften_logging_params)\n","print(\"Uniform exploration average loss: %0.2f\" % (np.mean([tup[2] for tup in data])))\n","\"\"\"\n","\n","#import SmoothEval\n","#print(\"Off policy estimate: %0.2f\" % (SmoothEval.smooth_eval(Env.target, data, 0.1)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eBVVtRehgrfW"},"source":["## Estimators"]},{"cell_type":"code","metadata":{"id":"zZnLkCz7grdG","executionInfo":{"status":"ok","timestamp":1633522640355,"user_tz":-330,"elapsed":476,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class Estimator(object):\n","\n","    def __init__(self,params=None):\n","        self.params=params\n","\n","    def estimate(self,target,data):\n","        return 0\n","    \n","    def variance(self,target,data):\n","        return 0\n","\n","\n","class SmoothedEstimator(Estimator):\n","    def __init__(self,h, soften=False, kernel = None):\n","        super(Estimator).__init__()\n","        self.h = h\n","        self.soften = soften\n","        self.kernel = kernel\n","        \n","    def epanechnikov_kernel(self, u):\n","        return 0.75*(1-u**2)*(1 if abs(u) <= 1 else 0)\n","\n","    def epanechnikov_int(self,lo,hi):\n","        '''\n","        :return: Definite integral of the kernel from between lo and hi. Assumes that they are within bounds.\n","        '''\n","        return 0.75*(hi-hi**3/3.0) - 0.75*(lo-lo**3/3.0)\n","    \n","    def boxcar_kernel(self, u):\n","        return 0.5*(1 if abs(u) <= 1 else 0)\n","    \n","    def boxcar_int(self,lo,hi):\n","        '''\n","        :return: Definite integral of the kernel from between lo and hi. Assumes that they are within bounds.\n","        '''\n","        return abs(hi -lo)/2.\n","    \n","    def get_density(self,a,p):\n","        if a >= p['tau_low'] and a <= p['tau_high']:\n","            return p['rho_i']\n","        else:\n","            return p['rho_o']\n","        \n","    def estimate(self,target,data):\n","        val = 0\n","        rewards = []\n","        for tup in data:\n","            (x,a,l,p) = tup\n","            target_action = target.get_action(x)['action']\n","            if self.kernel == None:\n","                # boundary bias not handled here, experiment at your own risk\n","                if np.all(np.abs(a - target_action) <= self.h):\n","                    val += l/self.get_prob(target_action, p)\n","            elif self.kernel == \"epanechnikov\":\n","                den = 1.\n","                num = l\n","                for d in range(target_action.shape[1]): \n","                    delta = (a[0][d] - target_action[0,d])/self.h\n","                    num *= self.epanechnikov_kernel(delta)\n","                    t_lo = max(target_action[0,d]-self.h, -1)\n","                    t_hi = min(target_action[0,d]+self.h, 1)\n","                    lo = (t_lo - target_action[0,d])/self.h\n","                    hi = (t_hi - target_action[0,d])/self.h\n","                    den *= self.get_density(target_action[0,d],p[d]) * self.h * self.epanechnikov_int(lo, hi)\n","                val += num/den\n","                rewards.append(num/den)\n","            elif self.kernel == \"boxcar\":\n","                den = 1.\n","                num = l\n","                for d in range(target_action.shape[1]):\n","                    delta = (a[0][d] - target_action[0,d])/self.h\n","                    num *= self.boxcar_kernel(delta)\n","                    t_lo = max(target_action[0,d]-self.h, -1)\n","                    t_hi = min(target_action[0,d]+self.h, 1)\n","                    lo = (t_lo - target_action[0,d])/self.h\n","                    hi = (t_hi - target_action[0,d])/self.h\n","                    den *= self.get_density(target_action[0,d],p[d]) * self.boxcar_int(lo,hi) * self.h\n","                val += num/den\n","                rewards.append(num/den)\n","        #print(\"losses \", losses)\n","        return val/len(data)#, rewards\n","    \n","    def interval_overlap(self,sa_l, sa_h, b_l, b_h):\n","        '''\n","        Returns how much the interval (sa_l, sa_h) overlaps the interval (b_l, b_h)\n","        '''\n","        return max(min(sa_h,b_h)-max(sa_l, b_l), 0)\n","\n","    def get_prob(self,a,p):\n","        if self.soften:\n","            prob = 1.\n","            for d in range(a.shape[1]):\n","                part1 = p[d]['rho_o'] * self.interval_overlap(a[0,d]-self.h, a[0,d]+self.h,0, p[d]['tau_low'])\n","                part2 = p[d]['rho_i'] * self.interval_overlap(a[0,d]-self.h, a[0,d]+self.h, p[d]['tau_low'], p[d]['tau_high'])\n","                part3 = p[d]['rho_o'] * self.interval_overlap(a[0,d]-self.h, a[0,d]+self.h, p[d]['tau_high'], 1)\n","                prob *= part1 + part2 + part3\n","            return prob\n","        else:\n","            \"\"\"\n","            Get uniform density for the box of length h around a.\n","            This is complicated due to edge effects\n","            \"\"\"\n","            total = 1\n","            for d in range(a.shape[1]):\n","                total *= min(a[0,d]+self.h,1)-max(a[0,d]-self.h,0)\n","            return total\n","\n","\n","    def variance(self,target,data):\n","        mean = 0\n","        zs = []\n","        for tup in data:\n","            (x,a,l,p) = tup\n","            target_action = target.get_action(x)['action']\n","            tmp = 0\n","            if self.kernel == None and np.all(np.abs(a - target_action) <= self.h):\n","                # boundary biasnot handled here, experiment at your own risk\n","                tmp = l/self.get_prob(target_action, p)\n","            elif self.kernel == \"epanechnikov\":\n","                den = 1.\n","                num = l\n","                for d in range(target_action.shape[1]): \n","                    delta = (a[0][d] - target_action[0,d])/self.h\n","                    num *= self.epanechnikov_kernel(delta)\n","                    t_lo = max(target_action[0,d]-self.h, -1)\n","                    t_hi = min(target_action[0,d]+self.h, 1)\n","                    lo = (t_lo - target_action[0,d])/self.h\n","                    hi = (t_hi - target_action[0,d])/self.h\n","                    den *= self.get_density(target_action[0,d],p[d]) * self.h * self.epanechnikov_int(lo, hi)\n","                tmp += num/den\n","            elif self.kernel == \"boxcar\":\n","                den = 1.\n","                num = l\n","                for d in range(target_action.shape[1]):\n","                    delta = (a[0][d] - target_action[0,d])/self.h\n","                    num *= self.boxcar_kernel(delta)\n","                    t_lo = max(target_action[0,d]-self.h, -1)\n","                    t_hi = min(target_action[0,d]+self.h, 1)\n","                    lo = (t_lo - target_action[0,d])/self.h\n","                    hi = (t_hi - target_action[0,d])/self.h\n","                    den *= self.get_density(target_action[0,d],p[d]) * self.boxcar_int(lo,hi) * self.h\n","                tmp += num/den\n","            mean += tmp\n","            zs.append(tmp)\n","        mean = mean/len(data)\n","        return(np.mean([(z-mean)**2 for z in zs])/(len(zs)-1))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vm0fU42ngrZN"},"source":["## SLOPE"]},{"cell_type":"code","metadata":{"id":"WE5fgYk1gvFo","executionInfo":{"status":"ok","timestamp":1633522651519,"user_tz":-330,"elapsed":468,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class Slope(Estimator):\n","    \"\"\"\n","    The assumption is that hyperparams is a sequence for which\n","    variance is decreasing.\n","    \"\"\"\n","    def __init__(self,params=None):\n","        if params is None:\n","            raise Exception(\"Slope requires two parameters\")\n","\n","        self.estimator = None\n","        self.hyperparams = None\n","        if 'estimator' in params.keys():\n","            self.estimator = params['estimator']\n","        if 'hyperparams' in params.keys():\n","            self.hyperparams = params['hyperparams']\n","        if 'soften' in params.keys():\n","            self.soften = params['soften']\n","        if 'kernel' in params.keys():\n","            self.kernel = params['kernel']\n","\n","        if self.estimator is None or self.hyperparams is None:\n","            raise Exception(\"Slope requires base estimator and set of hyperparameters\")\n","        \n","        self.plot = False\n","        if 'plot' in params.keys():\n","            self.plot=True\n","\n","    def estimate(self,target,data):\n","        means = []\n","        widths = []\n","        for h in self.hyperparams: # assumption: hs are ordered ascending\n","            E = self.estimator(h, self.soften, self.kernel)\n","            mean = E.estimate(target,data)\n","            means.append(mean)\n","            var = E.variance(target,data)\n","            widths.append(np.sqrt(var))\n","        intervals = []\n","        for i in range(len(self.hyperparams)):\n","            if i < len(self.hyperparams)-1:\n","                width = max(widths[i], max(widths[i+1:]))\n","            else:\n","                width = widths[i]\n","            intervals.append((means[i] - 2*width, means[i] + 2*width))\n","            print(\"[Slope] h = %0.2f, mean = %0.2f, low = %0.2f, high = %0.2f\" % (self.hyperparams[i], means[i], intervals[-1][0], intervals[-1][1]), flush=True) \n","        index = 0\n","        curr = [intervals[0][0], intervals[0][1]]\n","        for i in range(len(intervals)):\n","            if intervals[i][0] > curr[1] or intervals[i][1] < curr[0]:\n","                ### Current interval is not overlapping with previous ones, return previous index\n","                break\n","            else:\n","                ### Take intersection\n","                curr[0] = max(curr[0], intervals[i][0])\n","                curr[1] = min(curr[1], intervals[i][1])\n","                index = i\n","            print(\"[Slope] curr_low = %0.2f, curr_high = %0.2f\" % (curr[0], curr[1]))\n","        print(\"[Slope] returning index %d\" % (index), flush=True)\n","        self.means = means\n","        self.intervals = intervals\n","        self.index = index\n","        return means[index]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":608},"id":"HQ7WAkmJg4o8","executionInfo":{"status":"ok","timestamp":1633523295134,"user_tz":-330,"elapsed":2094,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5787e2fa-7c11-4583-e928-6fb9820625b7"},"source":["Env = CCBSimulatedEnv(lip=5,act_dim=1)\n","Env.train_logger()\n","Env.train_target(100)\n","hs = np.logspace(-8,0,9,base=2)\n","print(hs)\n","n = 1000\n","\n","data = Env.gen_logging_data(n)\n","estimator = Slope(params={'estimator':SmoothedEstimator,'hyperparams': hs,\n","                          'soften':'friendly', 'kernel':'boxcar'})\n","estimator.estimate(Env.target, data)\n","\n","print([estimator.intervals[i][1] - estimator.intervals[i][0] for i in range(len(hs))], flush=True)\n","\n","errors = np.zeros((2,len(hs)))\n","errors[0,:] = [estimator.means[i] - estimator.intervals[i][0] for i in range(len(hs))]\n","errors[1,:] = [estimator.intervals[i][1]-estimator.means[i] for i in range(len(hs))]\n","\n","plt.errorbar(hs, estimator.means, errors)\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.00390625 0.0078125  0.015625   0.03125    0.0625     0.125\n"," 0.25       0.5        1.        ]\n","[Slope] h = 0.00, mean = 0.25, low = -0.04, high = 0.53\n","[Slope] h = 0.01, mean = 0.28, low = 0.08, high = 0.48\n","[Slope] h = 0.02, mean = 0.33, low = 0.19, high = 0.47\n","[Slope] h = 0.03, mean = 0.32, low = 0.22, high = 0.41\n","[Slope] h = 0.06, mean = 0.38, low = 0.30, high = 0.45\n","[Slope] h = 0.12, mean = 0.47, low = 0.40, high = 0.53\n","[Slope] h = 0.25, mean = 0.59, low = 0.54, high = 0.64\n","[Slope] h = 0.50, mean = 0.68, low = 0.64, high = 0.71\n","[Slope] h = 1.00, mean = 0.58, low = 0.56, high = 0.60\n","[Slope] curr_low = -0.04, curr_high = 0.53\n","[Slope] curr_low = 0.08, curr_high = 0.48\n","[Slope] curr_low = 0.19, curr_high = 0.47\n","[Slope] curr_low = 0.22, curr_high = 0.41\n","[Slope] curr_low = 0.30, curr_high = 0.41\n","[Slope] curr_low = 0.40, curr_high = 0.41\n","[Slope] returning index 5\n","[0.5614697143179493, 0.4058911936714811, 0.27863378956499896, 0.1902802142473463, 0.15564567751178704, 0.1286471679836968, 0.106658862699472, 0.07029282184273722, 0.03174689855369506]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"kHq-Cf_qlVc2"},"source":["def parse_args():\n","    parser=argparse.ArgumentParser(description='Continuous CB Simulations')\n","    parser.add_argument('--seed', type=int, default=577, metavar='N',\n","                        help='random seed (default: 577)')\n","    parser.add_argument('--start_iter', type=int, default=1,\n","                        help='Which replicate number to start at')\n","    parser.add_argument('--total_iter', type=int, default=5,\n","                        help='Number of iterations')\n","    parser.add_argument('--feat_dim', type=int, default=5,\n","                        help='Dimensionality of feature space')\n","    parser.add_argument('--act_dim', type=int, default=1,\n","                        help='Dimensionality of action space')\n","    parser.add_argument('--lip', type=float, default=10,\n","                        help='Lipschitz constant for losses')\n","    parser.add_argument('--samples', type=int, default=100,\n","                        help='Number of samples')\n","    parser.add_argument('--kernel', type=str, default=None,\n","                        help='kernel function to use for smoothing: boxcar or epanechnikov')\n","    parser.add_argument('--soften', type=str, default=None,\n","                        help='stochastic tranformation for policy: freindly, adversarial, Neutral or None')\n","    parser.add_argument('--loss', type=str, default='triangular',\n","                        help='specify loss function: triangular or parabolic')\n","    parser.add_argument('--logging_model_name', type=str, default=None,\n","                        help='specify model type for logging policy: NNPredictor or Tree or None')\n","    parser.add_argument('--target_model_name', type=str, default='NNPredictor',\n","                        help='specify model type for target policy: NNPredictor or Tree or None')\n","    parser.add_argument('--command_num', type=int, default=0,\n","                        help='command line number from commands_list.txt')\n","    parser.add_argument('--expt_name', type=str, default=\"slope-results\",\n","                        help='results will be stored in a folder expt_name in azure storage')\n","    args=parser.parse_args(args={})\n","    return(args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sqdrq21ghz3J","executionInfo":{"status":"ok","timestamp":1633523568266,"user_tz":-330,"elapsed":12331,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"34fae2b1-daee-44b0-ac24-b181630201bf"},"source":["Args = parse_args()\n","print(Args, flush=True)\n","np.random.seed(Args.seed)\n","random.seed(Args.seed)\n","torch.manual_seed(Args.seed)\n","\n","Env = CCBSimulatedEnv(lip=Args.lip,feat_dim=Args.feat_dim,act_dim=Args.act_dim, target_model_name=Args.target_model_name,logging_model_name=Args.logging_model_name, loss_type=Args.loss, soften = Args.soften)\n","Env.train_logger(10000)\n","Env.train_target(100)\n","ground_truth=Env.ground_truth(100000)\n","print(\"ground truth: \", ground_truth)\n","\n","print(\"[Experiment] Bandwidths: %s\" % (\",\".join([str(x) for x in hs])), flush=True)\n","for i in range(Args.start_iter, Args.start_iter+Args.total_iter):\n","    np.random.seed(Args.seed+37*i)\n","    random.seed(Args.seed+37*i)\n","    print(\"generating logging data\")\n","    data = Env.gen_logging_data(Args.samples)\n","    mses = []\n","    mses_dict = {}\n","    for h in hs:\n","        #print(\"\\nh \", h)\n","        estimator = SmoothedEstimator(h, Args.soften, Args.kernel)\n","        estimate = estimator.estimate(Env.target, data)\n","        mses.append((estimate-ground_truth)**2)\n","        mses_dict[h] = mses[-1]\n","    estimator=Slope(params={'estimator': SmoothedEstimator, 'hyperparams': hs, 'soften': Args.soften, 'kernel':Args.kernel})\n","    estimate = estimator.estimate(Env.target, data)\n","    mses.append((estimate-ground_truth)**2)\n","    mses_dict['slope'] = mses[-1]\n","    \n","    \n","    print({k: v for k, v in sorted(mses_dict.items(), key=lambda item: item[1])}, flush=True)\n","    f = open('./command_num=%s_replicate=%d.json' % (Args.command_num,i), 'w')\n","    results = {}\n","    for j in range(len(hs)):\n","        results[hs[j]] = mses[j]\n","    results['Slope'] = mses[-1]\n","    results['index'] = estimator.index\n","    results['command_num'] = Args.command_num\n","    results['replicate'] = i\n","    results['ground_truth'] = ground_truth\n","    results['logging_model'] = Args.logging_model_name\n","    results['target_model'] = Args.target_model_name\n","    results['soften'] = Args.soften\n","    results['kernel'] = Args.kernel\n","    results['lip'] = Args.lip\n","    results['samples'] = Args.samples\n","    results['loss'] = Args.loss\n","    f.write(json.dumps(results))\n","    f.close()"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(act_dim=1, command_num=0, expt_name='slope-results', feat_dim=5, kernel=None, lip=10, logging_model_name=None, loss='triangular', samples=100, seed=577, soften=None, start_iter=1, target_model_name='NNPredictor', total_iter=5)\n","ground truth:  0.5671172485946827\n","[Experiment] Bandwidths: 0.00390625,0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5,1.0\n","generating logging data\n","[Slope] h = 0.00, mean = 2.22, low = -0.94, high = 5.39\n","[Slope] h = 0.01, mean = 1.11, low = -0.47, high = 2.69\n","[Slope] h = 0.02, mean = 0.56, low = -0.24, high = 1.35\n","[Slope] h = 0.03, mean = 0.54, low = 0.03, high = 1.06\n","[Slope] h = 0.06, mean = 0.69, low = 0.28, high = 1.10\n","[Slope] h = 0.12, mean = 0.68, low = 0.36, high = 0.99\n","[Slope] h = 0.25, mean = 0.74, low = 0.51, high = 0.98\n","[Slope] h = 0.50, mean = 0.75, low = 0.60, high = 0.91\n","[Slope] h = 1.00, mean = 0.89, low = 0.84, high = 0.94\n","[Slope] curr_low = -0.94, curr_high = 5.39\n","[Slope] curr_low = -0.47, curr_high = 2.69\n","[Slope] curr_low = -0.24, curr_high = 1.35\n","[Slope] curr_low = 0.03, curr_high = 1.06\n","[Slope] curr_low = 0.28, curr_high = 1.06\n","[Slope] curr_low = 0.36, curr_high = 0.99\n","[Slope] curr_low = 0.51, curr_high = 0.98\n","[Slope] curr_low = 0.60, curr_high = 0.91\n","[Slope] curr_low = 0.84, curr_high = 0.91\n","[Slope] returning index 8\n","{0.015625: 0.00013095939363468314, 0.03125: 0.000514313405202113, 0.125: 0.011998182457015729, 0.0625: 0.015013637721898761, 0.25: 0.030974383995642913, 0.5: 0.0347929041636019, 1.0: 0.10522769589853825, 'slope': 0.10522769589853825, 0.0078125: 0.2961860211984006, 0.00390625: 2.7409343730021356}\n","generating logging data\n","[Slope] h = 0.00, mean = 0.00, low = -1.28, high = 1.28\n","[Slope] h = 0.01, mean = 0.64, low = -0.64, high = 1.92\n","[Slope] h = 0.02, mean = 0.77, low = -0.17, high = 1.70\n","[Slope] h = 0.03, mean = 0.55, low = -0.01, high = 1.11\n","[Slope] h = 0.06, mean = 0.41, low = 0.07, high = 0.75\n","[Slope] h = 0.12, mean = 0.50, low = 0.24, high = 0.76\n","[Slope] h = 0.25, mean = 0.66, low = 0.44, high = 0.89\n","[Slope] h = 0.50, mean = 0.76, low = 0.60, high = 0.91\n","[Slope] h = 1.00, mean = 0.95, low = 0.92, high = 0.99\n","[Slope] curr_low = -1.28, curr_high = 1.28\n","[Slope] curr_low = -0.64, curr_high = 1.28\n","[Slope] curr_low = -0.17, curr_high = 1.28\n","[Slope] curr_low = -0.01, curr_high = 1.11\n","[Slope] curr_low = 0.07, curr_high = 0.75\n","[Slope] curr_low = 0.24, curr_high = 0.75\n","[Slope] curr_low = 0.44, curr_high = 0.75\n","[Slope] curr_low = 0.60, curr_high = 0.75\n","[Slope] returning index 7\n","{0.03125: 0.0003615802953336617, 0.125: 0.004836182394032767, 0.0078125: 0.0053118954524092815, 0.25: 0.009375573176801098, 0.0625: 0.024582905962178287, 0.5: 0.03646418340203113, 'slope': 0.03646418340203113, 0.015625: 0.03976604070261362, 1.0: 0.14753559139879488, 0.00390625: 0.3216219736536031}\n","generating logging data\n","[Slope] h = 0.00, mean = 0.00, low = -1.28, high = 1.28\n","[Slope] h = 0.01, mean = 0.64, low = -0.64, high = 1.92\n","[Slope] h = 0.02, mean = 0.64, low = -0.26, high = 1.54\n","[Slope] h = 0.03, mean = 0.65, low = 0.05, high = 1.26\n","[Slope] h = 0.06, mean = 1.03, low = 0.55, high = 1.51\n","[Slope] h = 0.12, mean = 0.98, low = 0.63, high = 1.33\n","[Slope] h = 0.25, mean = 0.85, low = 0.63, high = 1.08\n","[Slope] h = 0.50, mean = 0.81, low = 0.66, high = 0.95\n","[Slope] h = 1.00, mean = 0.91, low = 0.86, high = 0.95\n","[Slope] curr_low = -1.28, curr_high = 1.28\n","[Slope] curr_low = -0.64, curr_high = 1.28\n","[Slope] curr_low = -0.26, curr_high = 1.28\n","[Slope] curr_low = 0.05, curr_high = 1.26\n","[Slope] curr_low = 0.55, curr_high = 1.26\n","[Slope] curr_low = 0.63, curr_high = 1.26\n","[Slope] curr_low = 0.63, curr_high = 1.08\n","[Slope] curr_low = 0.66, curr_high = 0.95\n","[Slope] curr_low = 0.86, curr_high = 0.95\n","[Slope] returning index 8\n","{0.0078125: 0.0053118954524092815, 0.015625: 0.0053118954524092815, 0.03125: 0.0074437010536776834, 0.5: 0.05787883691061838, 0.25: 0.08029935589167382, 1.0: 0.11526784045324477, 'slope': 0.11526784045324477, 0.125: 0.16955712388432934, 0.0625: 0.21367298595181078, 0.00390625: 0.3216219736536031}\n","generating logging data\n","[Slope] h = 0.00, mean = 0.00, low = -0.48, high = 0.48\n","[Slope] h = 0.01, mean = 0.00, low = -0.48, high = 0.48\n","[Slope] h = 0.02, mean = 0.29, low = -0.19, high = 0.77\n","[Slope] h = 0.03, mean = 0.19, low = -0.09, high = 0.47\n","[Slope] h = 0.06, mean = 0.10, low = -0.18, high = 0.38\n","[Slope] h = 0.12, mean = 0.48, low = 0.20, high = 0.77\n","[Slope] h = 0.25, mean = 0.69, low = 0.43, high = 0.94\n","[Slope] h = 0.50, mean = 0.96, low = 0.79, high = 1.12\n","[Slope] h = 1.00, mean = 0.90, low = 0.86, high = 0.95\n","[Slope] curr_low = -0.48, curr_high = 0.48\n","[Slope] curr_low = -0.48, curr_high = 0.48\n","[Slope] curr_low = -0.19, curr_high = 0.48\n","[Slope] curr_low = -0.09, curr_high = 0.47\n","[Slope] curr_low = -0.09, curr_high = 0.38\n","[Slope] curr_low = 0.20, curr_high = 0.38\n","[Slope] returning index 5\n","{0.125: 0.0067708321286613134, 'slope': 0.0067708321286613134, 0.25: 0.014038984080709586, 0.015625: 0.07702210665889857, 1.0: 0.1130001532518636, 0.03125: 0.14253043238646174, 0.5: 0.15188074082925326, 0.0625: 0.21688290139461727, 0.00390625: 0.3216219736536031, 0.0078125: 0.3216219736536031}\n","generating logging data\n","[Slope] h = 0.00, mean = 1.55, low = -0.97, high = 4.07\n","[Slope] h = 0.01, mean = 0.77, low = -0.48, high = 2.03\n","[Slope] h = 0.02, mean = 0.39, low = -0.24, high = 1.02\n","[Slope] h = 0.03, mean = 0.40, low = -0.01, high = 0.82\n","[Slope] h = 0.06, mean = 0.60, low = 0.22, high = 0.99\n","[Slope] h = 0.12, mean = 0.70, low = 0.40, high = 1.01\n","[Slope] h = 0.25, mean = 0.81, low = 0.57, high = 1.05\n","[Slope] h = 0.50, mean = 0.85, low = 0.70, high = 1.01\n","[Slope] h = 1.00, mean = 0.89, low = 0.84, high = 0.94\n","[Slope] curr_low = -0.97, curr_high = 4.07\n","[Slope] curr_low = -0.48, curr_high = 2.03\n","[Slope] curr_low = -0.24, curr_high = 1.02\n","[Slope] curr_low = -0.01, curr_high = 0.82\n","[Slope] curr_low = 0.22, curr_high = 0.82\n","[Slope] curr_low = 0.40, curr_high = 0.82\n","[Slope] curr_low = 0.57, curr_high = 0.82\n","[Slope] curr_low = 0.70, curr_high = 0.82\n","[Slope] returning index 7\n","{0.0625: 0.001388184323038319, 0.125: 0.018561568778561095, 0.03125: 0.026705753650189963, 0.015625: 0.03234386814647565, 0.0078125: 0.0430268843826697, 0.25: 0.060158880349553814, 0.5: 0.08268841770419147, 'slope': 0.08268841770419147, 1.0: 0.1034655938994113, 0.00390625: 0.9642762820850225}\n"]}]},{"cell_type":"code","metadata":{"id":"WpImjdREhL-p","executionInfo":{"status":"ok","timestamp":1633522941830,"user_tz":-330,"elapsed":474,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["i = 0\n","f = open('commands.sh', 'w')\n","for logging_model_name in [\"NNPredictor\", \"Tree\"]:\n","    for target_model_name in [\"NNPredictor\", \"Tree\"]:\n","        for soften in [\"friendly\", \"adversarial\"]:\n","            for kernel in [\"boxcar\"]:\n","                for loss in [\"triangular\"]:\n","                    for lip in [0.1, 1, 10]:\n","                        for samples in [10,100,1000]:\n","                            f.write(\"python3 ./src/Experiment.py --logging_model_name \"+str(logging_model_name)+\" --target_model_name \"+str(target_model_name)+\" --soften \"+str(soften)+\" --kernel \"+str(kernel)+\" --loss \"+str(loss)+\" --lip \"+str(lip)+\" --samples \"+str(samples)+\" --command_num \"+str(i)+\"\\n\")\n","                            i+=1\n","f.close()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcNaOIzhjgXV","executionInfo":{"status":"ok","timestamp":1633522953757,"user_tz":-330,"elapsed":464,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"f9ae8e2f-d1c1-4495-c93e-6a9760423c49"},"source":["!cat commands.sh"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 0\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 1\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 2\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 3\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 4\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 5\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 6\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 7\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 8\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 9\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 10\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 11\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 12\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 13\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 14\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 15\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 16\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 17\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 18\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 19\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 20\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 21\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 22\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 23\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 24\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 25\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 26\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 27\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 28\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 29\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 30\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 31\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 32\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 33\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 34\n","python3 ./src/Experiment.py --logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 35\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 36\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 37\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 38\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 39\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 40\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 41\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 42\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 43\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 44\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 45\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 46\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 47\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 48\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 49\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 50\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 51\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 52\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 53\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 54\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 55\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 56\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 57\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 58\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 59\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 60\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 61\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 62\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 10 --command_num 63\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 100 --command_num 64\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 0.1 --samples 1000 --command_num 65\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10 --command_num 66\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100 --command_num 67\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000 --command_num 68\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10 --command_num 69\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100 --command_num 70\n","python3 ./src/Experiment.py --logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000 --command_num 71\n"]}]},{"cell_type":"code","metadata":{"id":"4hhL7Qx-hTHh","executionInfo":{"status":"ok","timestamp":1633523621968,"user_tz":-330,"elapsed":943,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["f = open('commands_list_test.txt', 'w')\n","for logging_model_name in [\"NNPredictor\", \"Tree\"]:\n","    for target_model_name in [\"NNPredictor\", \"Tree\"]:\n","        for soften in [\"friendly\", \"adversarial\"]:\n","            for kernel in [\"boxcar\", \"epanechnikov\"]:\n","                for loss in [\"triangular\", \"parabolic\"]:\n","                    for lip in [1, 3, 10]:\n","                        for samples in [100,1000,10000,100000]:\n","                            f.write(\"--logging_model_name \"+str(logging_model_name)+\" --target_model_name \"+str(target_model_name)+\" --soften \"+str(soften)+\" --kernel \"+str(kernel)+\" --loss \"+str(loss)+\" --lip \"+str(lip)+\" --samples \"+str(samples)+\"\\n\")\n","f.close()\n","\n","f = open('commands_list_test.txt', 'a')\n","for logging_model_name in [\"NNPredictor\", \"Tree\"]:\n","    for target_model_name in [\"NNPredictor\", \"Tree\"]:\n","        for loss in [\"triangular\", \"parabolic\"]:\n","            for lip in [1, 3, 10]:\n","                for kernel in [\"boxcar\", \"epanechnikov\"]:\n","                    for samples in [100,1000,10000,100000]:\n","                        f.write(\"--logging_model_name \"+str(logging_model_name)+\" --target_model_name \"+str(target_model_name)+\" --loss \"+str(loss)+\" --lip \"+str(lip)+\" --samples \"+str(samples)+\" --kernel \"+str(kernel)+\"\\n\")\n","f.close()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWKS9bZnmDOk","executionInfo":{"status":"ok","timestamp":1633523622454,"user_tz":-330,"elapsed":23,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"1f4ecdec-907e-4cad-89e0-d8b976f5f63b"},"source":["!cat commands_list_test.txt"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name NNPredictor --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name NNPredictor --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften friendly --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel boxcar --loss parabolic --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss triangular --lip 10 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 1 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 3 --samples 100000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 1000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 10000\n","--logging_model_name Tree --target_model_name Tree --soften adversarial --kernel epanechnikov --loss parabolic --lip 10 --samples 100000\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss triangular --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss triangular --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name NNPredictor --target_model_name Tree --loss parabolic --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss triangular --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name NNPredictor --loss parabolic --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss triangular --lip 10 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 1 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 3 --samples 100000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 100 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 1000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 10000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 100000 --kernel boxcar\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 100 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 1000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 10000 --kernel epanechnikov\n","--logging_model_name Tree --target_model_name Tree --loss parabolic --lip 10 --samples 100000 --kernel epanechnikov\n"]}]},{"cell_type":"markdown","metadata":{"id":"VpnnOdHdhEgR"},"source":["## Plot JSON"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"LrbpRGwAhEds","executionInfo":{"status":"ok","timestamp":1633523738236,"user_tz":-330,"elapsed":1202,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"cf8a3476-86c1-4960-efb8-e739c6e940c1"},"source":["# commands = [0,1,2,3,4,5,6,7,8,9]\n","# iters = 100\n","\n","commands = [0]\n","iters = 6\n","\n","\n","data_dict = {\n","    'Slope': [],\n","    '0.25': [],\n","    '0.03125': [],\n","    }\n","\n","K = [\n","'Slope', \n","'0.25', \n","'0.03125']\n","ns = []\n","\n","data = {\n","    \n","    }\n","\n","for c in commands:\n","    for i in range(1,iters):\n","        x = json.loads(open('./command_num=%d_replicate=%d.json' % (c, i), 'r').readlines()[0])\n","        n = x['samples']\n","        if n not in data.keys():\n","            data[n] = copy.deepcopy(data_dict)\n","            ns.append(n)\n","        for k in K:\n","            data[n][k].append(x[k])\n","\n","ns.sort()\n","\n","fig = plt.figure()\n","ls = []\n","for k in K:\n","    x = np.array([np.mean(data[n][k]) for n in ns])\n","    z = np.array([np.std(data[n][k]) for n in ns])\n","    ls.append(plt.plot(ns, x,linewidth=2))\n","    plt.fill_between(ns, x - 2/np.sqrt(iters)*z, x + 2/np.sqrt(iters)*z,alpha=0.2)\n","\n","ax = plt.gca()\n","ax.set_xscale('log')\n","ax.set_yscale('log')\n","ax.set_ylabel('MSE')\n","ax.set_xlabel('Number of samples')\n","\n","K[K.index('Slope')] = 'Slope'\n","plt.legend(K)\n","\n","plt.savefig('./cb_learning_curve.pdf', format='pdf', dpi=100,bbox_inches='tight')\n","plt.show()"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}]}