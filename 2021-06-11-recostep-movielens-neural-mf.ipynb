{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-06-11-recostep-movielens-neural-mf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UimO_-U1n7wvwpjwSBD7IHmPy2qGd2xD",
      "authorship_tag": "ABX9TyOAjENRVhXJ9lyLF0YKvmuh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxWgUAp7vnIM"
      },
      "source": [
        "# Neural Matrix Factorization on Movielens\n",
        "> Experiments with different variations of Neural matrix factorization model in PyTorch on movielens dataset\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [movie, pytorch]\n",
        "- image: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfac3W-Z4yEs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "74OaJCfn5H4Z",
        "outputId": "9ec26cd4-a004-49cf-aefb-9a24c670bf11"
      },
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/sparsh-ai/reco-data/master/MovieLens_LatestSmall_ratings.csv\")\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0Irmpk2oUna",
        "outputId": "082a3deb-3f36-4d93-8917-77c27db5fc55"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100836, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSMbrTG6LQr"
      },
      "source": [
        "Data encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_wEgrHx5U93"
      },
      "source": [
        "np.random.seed(3)\n",
        "msk = np.random.rand(len(data)) < 0.8\n",
        "train = data[msk].copy()\n",
        "valid = data[~msk].copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmeQCQXP6Vtv"
      },
      "source": [
        "# here is a handy function modified from fast.ai\n",
        "def proc_col(col, train_col=None):\n",
        "    \"\"\"Encodes a pandas column with continous ids. \n",
        "    \"\"\"\n",
        "    if train_col is not None:\n",
        "        uniq = train_col.unique()\n",
        "    else:\n",
        "        uniq = col.unique()\n",
        "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
        "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUfpCvFJ6W72"
      },
      "source": [
        "def encode_data(df, train=None):\n",
        "    \"\"\" Encodes rating data with continous user and movie ids. \n",
        "    If train is provided, encodes df with the same encoding as train.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col_name in [\"userId\", \"movieId\"]:\n",
        "        train_col = None\n",
        "        if train is not None:\n",
        "            train_col = train[col_name]\n",
        "        _,col,_ = proc_col(df[col_name], train_col)\n",
        "        df[col_name] = col\n",
        "        df = df[df[col_name] >= 0]\n",
        "    return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZDUY2rt6Z9B"
      },
      "source": [
        "# encoding the train and validation data\n",
        "df_train = encode_data(train)\n",
        "df_valid = encode_data(valid, train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c9VIAfR6otTe",
        "outputId": "dc5ad891-2004-4fda-acfa-22d04525df3b"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       0        0     4.0  964982703\n",
              "1       0        1     4.0  964981247\n",
              "2       0        2     4.0  964982224\n",
              "3       0        3     5.0  964983815\n",
              "6       0        4     5.0  964980868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy77qSeCo2WY",
        "outputId": "c4ce1748-6c39-44f6-c094-476873135fdb"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80450, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sOSEDMQPo2Tq",
        "outputId": "4327e4a5-b01b-4d03-c829-0220e7c8b36c"
      },
      "source": [
        "df_valid.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>388</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>995</td>\n",
              "      <td>3.0</td>\n",
              "      <td>964982400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>841</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>567</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>402</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  movieId  rating  timestamp\n",
              "4        0      388     5.0  964982931\n",
              "5        0      995     3.0  964982400\n",
              "29       0      841     4.0  964981179\n",
              "30       0      567     4.0  964982653\n",
              "32       0      402     4.0  964982546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uiymy6po2Lo",
        "outputId": "f1ebfdf2-a139-46d4-d8e7-850701cb57a2"
      },
      "source": [
        "df_valid.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19591, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3QSDyZj61Iy"
      },
      "source": [
        "Matrix factorization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBPnUZl-6z1g"
      },
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
        "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.item_emb(v)\n",
        "        return (u*v).sum(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dBQhfy2l7AAn",
        "outputId": "d667d3a3-2baa-467b-e8ab-905c3282780f"
      },
      "source": [
        "# unit testing the architecture\n",
        "sample = encode_data(train.sample(5))\n",
        "display(sample)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63234</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>961596392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96012</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>840875700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31417</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>955944735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17473</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1516141230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66983</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1328232721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating   timestamp\n",
              "63234       0        0     3.0   961596392\n",
              "96012       1        1     3.0   840875700\n",
              "31417       2        2     2.0   955944735\n",
              "17473       3        3     0.5  1516141230\n",
              "66983       4        4     4.0  1328232721"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmmtDTuqnIB"
      },
      "source": [
        "num_users = 5\n",
        "num_items = 5\n",
        "emb_size = 3\n",
        "\n",
        "user_emb = nn.Embedding(num_users, emb_size)\n",
        "item_emb = nn.Embedding(num_items, emb_size)\n",
        "\n",
        "users = torch.LongTensor(sample.userId.values)\n",
        "items = torch.LongTensor(sample.movieId.values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "H557JwqSqimK",
        "outputId": "b45ad07e-0cf7-4cb0-f9ad-5de2f8a86c08"
      },
      "source": [
        "U = user_emb(users)\n",
        "display(U)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[ 2.2694,  0.9679,  0.3305],\n",
              "        [-1.1478, -0.7004, -0.8113],\n",
              "        [-1.2287, -0.7210,  0.3875],\n",
              "        [ 0.9106,  0.0427, -0.7128],\n",
              "        [-1.0396, -0.2739,  0.7271]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "IsdtlmtBq3cj",
        "outputId": "418f529d-1481-475e-ad2c-39578baa4cdf"
      },
      "source": [
        "V = item_emb(items)\n",
        "display(V)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-1.9371, -1.1172, -1.5967],\n",
              "        [-2.4336, -1.1177,  0.6197],\n",
              "        [ 0.5889,  1.4830, -1.0103],\n",
              "        [-0.8294,  0.5744, -1.7315],\n",
              "        [-1.6733, -0.2447, -0.2630]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "TKtMvkNfq0q2",
        "outputId": "c7bb19a7-3a7b-45db-f4c1-b95f0994750f"
      },
      "source": [
        "display(U*V) # element wise multiplication"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[-4.3959, -1.0813, -0.5278],\n",
              "        [ 2.7932,  0.7828, -0.5027],\n",
              "        [-0.7236, -1.0693, -0.3915],\n",
              "        [-0.7552,  0.0246,  1.2343],\n",
              "        [ 1.7397,  0.0670, -0.1912]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5_AN_dhQq0nE",
        "outputId": "7cc9d053-c9f3-49d0-e2a6-f0ea809ecd8f"
      },
      "source": [
        "display((U*V).sum(1))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([-6.0050,  3.0733, -2.1844,  0.5036,  1.6155], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W01e58dr86WY"
      },
      "source": [
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC5vARcP7QAc",
        "outputId": "b4cea803-bbac-4301-bb1c-12683689948d"
      },
      "source": [
        "num_users = len(df_train.userId.unique())\n",
        "num_items = len(df_train.movieId.unique())\n",
        "print(\"{} users and {} items in the training set\".format(num_users, num_items))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610 users and 8998 items in the training set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRi5sy-K8-fr"
      },
      "source": [
        "model = MF(num_users, num_items, emb_size=100) # .cuda() if you have a GPU"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nAGJ4l08_83"
      },
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        users = torch.LongTensor(df_train.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train.rating.values) #.cuda()\n",
        "        if unsqueeze:\n",
        "            ratings = ratings.unsqueeze(1)\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item()) \n",
        "    test_loss(model, unsqueeze)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l_3G5gn9GH3"
      },
      "source": [
        "def test_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_valid.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_valid.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_valid.rating.values) #.cuda()\n",
        "    if unsqueeze:\n",
        "        ratings = ratings.unsqueeze(1)\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EztQtZKl9M53",
        "outputId": "25713f3c-edff-4333-e45b-ffb2c79375fb"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.914263725280762\n",
            "4.8582916259765625\n",
            "2.5804786682128906\n",
            "3.109440565109253\n",
            "0.850287139415741\n",
            "1.819737195968628\n",
            "2.657919406890869\n",
            "2.138274908065796\n",
            "1.0904945135116577\n",
            "0.9722878932952881\n",
            "test loss 1.851 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoSgUhWV9O1q",
        "outputId": "48e887fa-b55c-4465-e2d0-05789b5a7419"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6430705785751343\n",
            "1.0046814680099487\n",
            "0.712002694606781\n",
            "0.6611021757125854\n",
            "0.7258523106575012\n",
            "0.803934633731842\n",
            "0.843424379825592\n",
            "0.8351688981056213\n",
            "0.7928505539894104\n",
            "0.737376868724823\n",
            "test loss 0.827 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erRnsApY9Q7e",
        "outputId": "1e6a68f3-13b1-4963-b187-5d1b1bc3e438"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6877127289772034\n",
            "0.6256141066551208\n",
            "0.6374999284744263\n",
            "0.6272100210189819\n",
            "0.6171814799308777\n",
            "0.614914059638977\n",
            "0.6113061308860779\n",
            "0.6033822298049927\n",
            "0.595890998840332\n",
            "0.592114269733429\n",
            "test loss 0.764 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAwA9Rts9UI1"
      },
      "source": [
        "MF with bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dur1n3lo9S3C"
      },
      "source": [
        "class MF_bias(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF_bias, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.user_bias = nn.Embedding(num_users, 1)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.item_bias = nn.Embedding(num_items, 1)\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.item_emb.weight.data.uniform_(0,0.05)\n",
        "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        b_u = self.user_bias(u).squeeze()\n",
        "        b_v = self.item_bias(v).squeeze()\n",
        "        return (U*V).sum(1) +  b_u  + b_v"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAyaietL9ZAq"
      },
      "source": [
        "model = MF_bias(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nEO-IVp9acn",
        "outputId": "773ee576-ea2e-40ac-97c7-7d78606595e1"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.05, wd=1e-5)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.91020393371582\n",
            "9.150527954101562\n",
            "4.3840012550354\n",
            "1.1575191020965576\n",
            "2.46807861328125\n",
            "3.7430803775787354\n",
            "2.4481022357940674\n",
            "1.0781667232513428\n",
            "0.816169023513794\n",
            "1.3183783292770386\n",
            "test loss 2.069 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD2fD5A59cK4",
        "outputId": "03df230c-70ff-4767-e088-928d54f6cd37"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8935126066207886\n",
            "1.3250681161880493\n",
            "0.9350242614746094\n",
            "0.7446779012680054\n",
            "0.722224235534668\n",
            "0.7774652242660522\n",
            "0.8231741189956665\n",
            "0.8222126364707947\n",
            "0.7816660404205322\n",
            "0.727698802947998\n",
            "test loss 0.798 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os53hZxr9e_T",
        "outputId": "d9bf93d3-8411-4535-dcc7-ebcf4a3fbc48"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6853442788124084\n",
            "0.6711287498474121\n",
            "0.6592414975166321\n",
            "0.6495122909545898\n",
            "0.6417150497436523\n",
            "0.6356027722358704\n",
            "0.6309247612953186\n",
            "0.6274365186691284\n",
            "0.6249085068702698\n",
            "0.6231329441070557\n",
            "test loss 0.751 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XhFy6bU9h48"
      },
      "source": [
        "Note that these models are susceptible to weight initialization, optimization algorithm and regularization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NugoowzF9kCk"
      },
      "source": [
        "### Neural Network Model\n",
        "Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes. Here we could get better results by keep playing with regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLVWHOxQ9fVX"
      },
      "source": [
        "class CollabFNet(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
        "        super(CollabFNet, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljjju7Yy9x7b"
      },
      "source": [
        "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuG2Hz5e9yyl",
        "outputId": "67b716ed-84e4-4dcf-eaf0-f06609542d0d"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.05, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.657201766967773\n",
            "2.586819648742676\n",
            "6.025796890258789\n",
            "2.89852237701416\n",
            "1.1256697177886963\n",
            "2.0860772132873535\n",
            "2.9243881702423096\n",
            "2.806140422821045\n",
            "1.9981783628463745\n",
            "1.1265769004821777\n",
            "0.8947575092315674\n",
            "1.4373805522918701\n",
            "1.795198678970337\n",
            "1.4024922847747803\n",
            "0.8697773218154907\n",
            "test loss 0.797 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYyXb1qO90vb",
        "outputId": "b3bcc463-51a8-4625-f547-38ebbf105a7f"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7495059967041016\n",
            "0.7382366061210632\n",
            "0.731941282749176\n",
            "0.7295416593551636\n",
            "0.7321946024894714\n",
            "0.7312469482421875\n",
            "0.731982409954071\n",
            "0.7298287153244019\n",
            "0.7264290452003479\n",
            "0.7244617938995361\n",
            "test loss 0.774 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0d-WRvW92h-",
        "outputId": "20f81203-7fbb-44db-b421-c6c20239cd22"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7242854833602905\n",
            "0.7213587760925293\n",
            "0.7197834849357605\n",
            "0.7182263135910034\n",
            "0.7177621722221375\n",
            "0.7155387997627258\n",
            "0.7147852182388306\n",
            "0.7143447995185852\n",
            "0.7133223414421082\n",
            "0.712261974811554\n",
            "test loss 0.766 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fpmHCaYAn2d"
      },
      "source": [
        "### Neural network model - different approach\n",
        "> youtube: https://youtu.be/MVB1cbe923A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMuCwuPWPfGz"
      },
      "source": [
        "### Ethan Rosenthal\n",
        "\n",
        "Ref - https://github.com/EthanRosenthal/torchmf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J31f-camBorB"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data as data\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahu8EWCGQJkI"
      },
      "source": [
        "def _get_data_path():\n",
        "    \"\"\"\n",
        "    Get path to the movielens dataset file.\n",
        "    \"\"\"\n",
        "    data_path = '/content/data'\n",
        "    if not os.path.exists(data_path):\n",
        "        print('Making data path')\n",
        "        os.mkdir(data_path)\n",
        "    return data_path\n",
        "\n",
        "\n",
        "def _download_movielens(dest_path):\n",
        "    \"\"\"\n",
        "    Download the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
        "    req = requests.get(url, stream=True)\n",
        "\n",
        "    print('Downloading MovieLens data')\n",
        "\n",
        "    with open(os.path.join(dest_path, 'ml-100k.zip'), 'wb') as fd:\n",
        "        for chunk in req.iter_content(chunk_size=None):\n",
        "            fd.write(chunk)\n",
        "\n",
        "    with zipfile.ZipFile(os.path.join(dest_path, 'ml-100k.zip'), 'r') as z:\n",
        "        z.extractall(dest_path)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DouK7x1nPsNb"
      },
      "source": [
        "def read_movielens_df():\n",
        "    path = _get_data_path()\n",
        "    zipfile = os.path.join(path, 'ml-100k.zip')\n",
        "    if not os.path.isfile(zipfile):\n",
        "        _download_movielens(path)\n",
        "    fname = os.path.join(path, 'ml-100k', 'u.data')\n",
        "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "    df = pd.read_csv(fname, sep='\\t', names=names)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_movielens_interactions():\n",
        "    df = read_movielens_df()\n",
        "\n",
        "    n_users = df.user_id.unique().shape[0]\n",
        "    n_items = df.item_id.unique().shape[0]\n",
        "\n",
        "    interactions = np.zeros((n_users, n_items))\n",
        "    for row in df.itertuples():\n",
        "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
        "    return interactions\n",
        "\n",
        "\n",
        "def train_test_split(interactions, n=10):\n",
        "    \"\"\"\n",
        "    Split an interactions matrix into training and test sets.\n",
        "    Parameters\n",
        "    ----------\n",
        "    interactions : np.ndarray\n",
        "    n : int (default=10)\n",
        "        Number of items to select / row to place into test.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train : np.ndarray\n",
        "    test : np.ndarray\n",
        "    \"\"\"\n",
        "    test = np.zeros(interactions.shape)\n",
        "    train = interactions.copy()\n",
        "    for user in range(interactions.shape[0]):\n",
        "        if interactions[user, :].nonzero()[0].shape[0] > n:\n",
        "            test_interactions = np.random.choice(interactions[user, :].nonzero()[0],\n",
        "                                                 size=n,\n",
        "                                                 replace=False)\n",
        "            train[user, test_interactions] = 0.\n",
        "            test[user, test_interactions] = interactions[user, test_interactions]\n",
        "\n",
        "    # Test and training are truly disjoint\n",
        "    assert(np.all((train * test) == 0))\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def get_movielens_train_test_split(implicit=False):\n",
        "    interactions = get_movielens_interactions()\n",
        "    if implicit:\n",
        "        interactions = (interactions >= 4).astype(np.float32)\n",
        "    train, test = train_test_split(interactions)\n",
        "    train = sp.coo_matrix(train)\n",
        "    test = sp.coo_matrix(test)\n",
        "    return train, test"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x9xMyW6PsK6",
        "outputId": "00096a84-7542-4d07-920d-48830410244e"
      },
      "source": [
        "%%writefile metrics.py\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch import multiprocessing as mp\n",
        "import torch\n",
        "\n",
        "def get_row_indices(row, interactions):\n",
        "    start = interactions.indptr[row]\n",
        "    end = interactions.indptr[row + 1]\n",
        "    return interactions.indices[start:end]\n",
        "\n",
        "\n",
        "def auc(model, interactions, num_workers=1):\n",
        "    aucs = []\n",
        "    processes = []\n",
        "    n_users = interactions.shape[0]\n",
        "    mp_batch = int(np.ceil(n_users / num_workers))\n",
        "\n",
        "    queue = mp.Queue()\n",
        "    rows = np.arange(n_users)\n",
        "    np.random.shuffle(rows)\n",
        "    for rank in range(num_workers):\n",
        "        start = rank * mp_batch\n",
        "        end = np.min((start + mp_batch,  n_users))\n",
        "        p = mp.Process(target=batch_auc,\n",
        "                       args=(queue, rows[start:end], interactions, model))\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "\n",
        "    while True:\n",
        "        is_alive = False\n",
        "        for p in processes:\n",
        "            if p.is_alive():\n",
        "                is_alive = True\n",
        "                break\n",
        "        if not is_alive and queue.empty():\n",
        "            break\n",
        "\n",
        "        while not queue.empty():\n",
        "            aucs.append(queue.get())\n",
        "\n",
        "    queue.close()\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "    return np.mean(aucs)\n",
        "\n",
        "\n",
        "def batch_auc(queue, rows, interactions, model):\n",
        "    n_items = interactions.shape[1]\n",
        "    items = torch.arange(0, n_items).long()\n",
        "    users_init = torch.ones(n_items).long()\n",
        "    for row in rows:\n",
        "        row = int(row)\n",
        "        users = users_init.fill_(row)\n",
        "\n",
        "        preds = model.predict(users, items)\n",
        "        actuals = get_row_indices(row, interactions)\n",
        "\n",
        "        if len(actuals) == 0:\n",
        "            continue\n",
        "        y_test = np.zeros(n_items)\n",
        "        y_test[actuals] = 1\n",
        "        queue.put(roc_auc_score(y_test, preds.data.numpy()))\n",
        "\n",
        "\n",
        "def patk(model, interactions, num_workers=1, k=5):\n",
        "    patks = []\n",
        "    processes = []\n",
        "    n_users = interactions.shape[0]\n",
        "    mp_batch = int(np.ceil(n_users / num_workers))\n",
        "\n",
        "    queue = mp.Queue()\n",
        "    rows = np.arange(n_users)\n",
        "    np.random.shuffle(rows)\n",
        "    for rank in range(num_workers):\n",
        "        start = rank * mp_batch\n",
        "        end = np.min((start + mp_batch, n_users))\n",
        "        p = mp.Process(target=batch_patk,\n",
        "                       args=(queue, rows[start:end], interactions, model),\n",
        "                       kwargs={'k': k})\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "\n",
        "    while True:\n",
        "        is_alive = False\n",
        "        for p in processes:\n",
        "            if p.is_alive():\n",
        "                is_alive = True\n",
        "                break\n",
        "        if not is_alive and queue.empty():\n",
        "            break\n",
        "\n",
        "        while not queue.empty():\n",
        "            patks.append(queue.get())\n",
        "\n",
        "    queue.close()\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "    return np.mean(patks)\n",
        "\n",
        "\n",
        "def batch_patk(queue, rows, interactions, model, k=5):\n",
        "    n_items = interactions.shape[1]\n",
        "\n",
        "    items = torch.arange(0, n_items).long()\n",
        "    users_init = torch.ones(n_items).long()\n",
        "    for row in rows:\n",
        "        row = int(row)\n",
        "        users = users_init.fill_(row)\n",
        "\n",
        "        preds = model.predict(users, items)\n",
        "        actuals = get_row_indices(row, interactions)\n",
        "\n",
        "        if len(actuals) == 0:\n",
        "            continue\n",
        "\n",
        "        top_k = np.argpartition(-np.squeeze(preds.data.numpy()), k)\n",
        "        top_k = set(top_k[:k])\n",
        "        true_pids = set(actuals)\n",
        "        if true_pids:\n",
        "            queue.put(len(top_k & true_pids) / float(k))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing metrics.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6IqWKWFhAQh",
        "outputId": "3bef0869-34b5-488c-ede7-bf9be08c115f"
      },
      "source": [
        "import metrics\n",
        "import importlib\n",
        "importlib.reload(metrics)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'metrics' from '/content/metrics.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEhEE_GhPsH2"
      },
      "source": [
        "class Interactions(data.Dataset):\n",
        "    \"\"\"\n",
        "    Hold data in the form of an interactions matrix.\n",
        "    Typical use-case is like a ratings matrix:\n",
        "    - Users are the rows\n",
        "    - Items are the columns\n",
        "    - Elements of the matrix are the ratings given by a user for an item.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mat):\n",
        "        self.mat = mat.astype(np.float32).tocoo()\n",
        "        self.n_users = self.mat.shape[0]\n",
        "        self.n_items = self.mat.shape[1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.mat.row[index]\n",
        "        col = self.mat.col[index]\n",
        "        val = self.mat.data[index]\n",
        "        return (row, col), val\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mat.nnz\n",
        "\n",
        "\n",
        "class PairwiseInteractions(data.Dataset):\n",
        "    \"\"\"\n",
        "    Sample data from an interactions matrix in a pairwise fashion. The row is\n",
        "    treated as the main dimension, and the columns are sampled pairwise.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mat):\n",
        "        self.mat = mat.astype(np.float32).tocoo()\n",
        "\n",
        "        self.n_users = self.mat.shape[0]\n",
        "        self.n_items = self.mat.shape[1]\n",
        "\n",
        "        self.mat_csr = self.mat.tocsr()\n",
        "        if not self.mat_csr.has_sorted_indices:\n",
        "            self.mat_csr.sort_indices()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.mat.row[index]\n",
        "        found = False\n",
        "\n",
        "        while not found:\n",
        "            neg_col = np.random.randint(self.n_items)\n",
        "            if self.not_rated(row, neg_col, self.mat_csr.indptr,\n",
        "                              self.mat_csr.indices):\n",
        "                found = True\n",
        "\n",
        "        pos_col = self.mat.col[index]\n",
        "        val = self.mat.data[index]\n",
        "\n",
        "        return (row, (pos_col, neg_col)), val\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mat.nnz\n",
        "\n",
        "    @staticmethod\n",
        "    def not_rated(row, col, indptr, indices):\n",
        "        # similar to use of bsearch in lightfm\n",
        "        start = indptr[row]\n",
        "        end = indptr[row + 1]\n",
        "        searched = np.searchsorted(indices[start:end], col, 'right')\n",
        "        if searched >= (end - start):\n",
        "            # After the array\n",
        "            return False\n",
        "        return col != indices[searched]  # Not found\n",
        "\n",
        "    def get_row_indices(self, row):\n",
        "        start = self.mat_csr.indptr[row]\n",
        "        end = self.mat_csr.indptr[row + 1]\n",
        "        return self.mat_csr.indices[start:end]\n",
        "\n",
        "\n",
        "class BaseModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Base module for explicit matrix factorization.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 n_users,\n",
        "                 n_items,\n",
        "                 n_factors=40,\n",
        "                 dropout_p=0,\n",
        "                 sparse=False):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_users : int\n",
        "            Number of users\n",
        "        n_items : int\n",
        "            Number of items\n",
        "        n_factors : int\n",
        "            Number of latent factors (or embeddings or whatever you want to\n",
        "            call it).\n",
        "        dropout_p : float\n",
        "            p in nn.Dropout module. Probability of dropout.\n",
        "        sparse : bool\n",
        "            Whether or not to treat embeddings as sparse. NOTE: cannot use\n",
        "            weight decay on the optimizer if sparse=True. Also, can only use\n",
        "            Adagrad.\n",
        "        \"\"\"\n",
        "        super(BaseModule, self).__init__()\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "        self.user_biases = nn.Embedding(n_users, 1, sparse=sparse)\n",
        "        self.item_biases = nn.Embedding(n_items, 1, sparse=sparse)\n",
        "        self.user_embeddings = nn.Embedding(n_users, n_factors, sparse=sparse)\n",
        "        self.item_embeddings = nn.Embedding(n_items, n_factors, sparse=sparse)\n",
        "        \n",
        "        self.dropout_p = dropout_p\n",
        "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
        "\n",
        "        self.sparse = sparse\n",
        "        \n",
        "    def forward(self, users, items):\n",
        "        \"\"\"\n",
        "        Forward pass through the model. For a single user and item, this\n",
        "        looks like:\n",
        "\n",
        "        user_bias + item_bias + user_embeddings.dot(item_embeddings)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        users : np.ndarray\n",
        "            Array of user indices\n",
        "        items : np.ndarray\n",
        "            Array of item indices\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        preds : np.ndarray\n",
        "            Predicted ratings.\n",
        "\n",
        "        \"\"\"\n",
        "        ues = self.user_embeddings(users)\n",
        "        uis = self.item_embeddings(items)\n",
        "\n",
        "        preds = self.user_biases(users)\n",
        "        preds += self.item_biases(items)\n",
        "        preds += (self.dropout(ues) * self.dropout(uis)).sum(dim=1, keepdim=True)\n",
        "\n",
        "        return preds.squeeze()\n",
        "    \n",
        "    def __call__(self, *args):\n",
        "        return self.forward(*args)\n",
        "\n",
        "    def predict(self, users, items):\n",
        "        return self.forward(users, items)\n",
        "\n",
        "\n",
        "def bpr_loss(preds, vals):\n",
        "    sig = nn.Sigmoid()\n",
        "    return (1.0 - sig(preds)).pow(2).sum()\n",
        "\n",
        "\n",
        "class BPRModule(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 n_users,\n",
        "                 n_items,\n",
        "                 n_factors=40,\n",
        "                 dropout_p=0,\n",
        "                 sparse=False,\n",
        "                 model=BaseModule):\n",
        "        super(BPRModule, self).__init__()\n",
        "\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "        self.dropout_p = dropout_p\n",
        "        self.sparse = sparse\n",
        "        self.pred_model = model(\n",
        "            self.n_users,\n",
        "            self.n_items,\n",
        "            n_factors=n_factors,\n",
        "            dropout_p=dropout_p,\n",
        "            sparse=sparse\n",
        "        )\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        assert isinstance(items, tuple), \\\n",
        "            'Must pass in items as (pos_items, neg_items)'\n",
        "        # Unpack\n",
        "        (pos_items, neg_items) = items\n",
        "        pos_preds = self.pred_model(users, pos_items)\n",
        "        neg_preds = self.pred_model(users, neg_items)\n",
        "        return pos_preds - neg_preds\n",
        "\n",
        "    def predict(self, users, items):\n",
        "        return self.pred_model(users, items)\n",
        "\n",
        "\n",
        "class BasePipeline:\n",
        "    \"\"\"\n",
        "    Class defining a training pipeline. Instantiates data loaders, model,\n",
        "    and optimizer. Handles training for multiple epochs and keeping track of\n",
        "    train and test loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 train,\n",
        "                 test=None,\n",
        "                 model=BaseModule,\n",
        "                 n_factors=40,\n",
        "                 batch_size=32,\n",
        "                 dropout_p=0.02,\n",
        "                 sparse=False,\n",
        "                 lr=0.01,\n",
        "                 weight_decay=0.,\n",
        "                 optimizer=torch.optim.Adam,\n",
        "                 loss_function=nn.MSELoss(reduction='sum'),\n",
        "                 n_epochs=10,\n",
        "                 verbose=False,\n",
        "                 random_seed=None,\n",
        "                 interaction_class=Interactions,\n",
        "                 hogwild=False,\n",
        "                 num_workers=0,\n",
        "                 eval_metrics=None,\n",
        "                 k=5):\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "\n",
        "        if hogwild:\n",
        "            num_loader_workers = 0\n",
        "        else:\n",
        "            num_loader_workers = num_workers\n",
        "        self.train_loader = data.DataLoader(\n",
        "            interaction_class(train), batch_size=batch_size, shuffle=True,\n",
        "            num_workers=num_loader_workers)\n",
        "        if self.test is not None:\n",
        "            self.test_loader = data.DataLoader(\n",
        "                interaction_class(test), batch_size=batch_size, shuffle=True,\n",
        "                num_workers=num_loader_workers)\n",
        "        self.num_workers = num_workers\n",
        "        self.n_users = self.train.shape[0]\n",
        "        self.n_items = self.train.shape[1]\n",
        "        self.n_factors = n_factors\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.loss_function = loss_function\n",
        "        self.n_epochs = n_epochs\n",
        "        if sparse:\n",
        "            assert weight_decay == 0.0\n",
        "        self.model = model(self.n_users,\n",
        "                           self.n_items,\n",
        "                           n_factors=self.n_factors,\n",
        "                           dropout_p=self.dropout_p,\n",
        "                           sparse=sparse)\n",
        "        self.optimizer = optimizer(self.model.parameters(),\n",
        "                                   lr=self.lr,\n",
        "                                   weight_decay=self.weight_decay)\n",
        "        self.warm_start = False\n",
        "        self.losses = collections.defaultdict(list)\n",
        "        self.verbose = verbose\n",
        "        self.hogwild = hogwild\n",
        "        if random_seed is not None:\n",
        "            if self.hogwild:\n",
        "                random_seed += os.getpid()\n",
        "            torch.manual_seed(random_seed)\n",
        "            np.random.seed(random_seed)\n",
        "\n",
        "        if eval_metrics is None:\n",
        "            eval_metrics = []\n",
        "        self.eval_metrics = eval_metrics\n",
        "        self.k = k\n",
        "\n",
        "    def break_grads(self):\n",
        "        for param in self.model.parameters():\n",
        "            # Break gradient sharing\n",
        "            if param.grad is not None:\n",
        "                param.grad.data = param.grad.data.clone()\n",
        "\n",
        "    def fit(self):\n",
        "        for epoch in range(1, self.n_epochs + 1):\n",
        "\n",
        "            if self.hogwild:\n",
        "                self.model.share_memory()\n",
        "                processes = []\n",
        "                train_losses = []\n",
        "                queue = mp.Queue()\n",
        "                for rank in range(self.num_workers):\n",
        "                    p = mp.Process(target=self._fit_epoch,\n",
        "                                   kwargs={'epoch': epoch,\n",
        "                                           'queue': queue})\n",
        "                    p.start()\n",
        "                    processes.append(p)\n",
        "                for p in processes:\n",
        "                    p.join()\n",
        "\n",
        "                while True:\n",
        "                    is_alive = False\n",
        "                    for p in processes:\n",
        "                        if p.is_alive():\n",
        "                            is_alive = True\n",
        "                            break\n",
        "                    if not is_alive and queue.empty():\n",
        "                        break\n",
        "\n",
        "                    while not queue.empty():\n",
        "                        train_losses.append(queue.get())\n",
        "                queue.close()\n",
        "                train_loss = np.mean(train_losses)\n",
        "            else:\n",
        "                train_loss = self._fit_epoch(epoch)\n",
        "\n",
        "            self.losses['train'].append(train_loss)\n",
        "            row = 'Epoch: {0:^3}  train: {1:^10.5f}'.format(epoch, self.losses['train'][-1])\n",
        "            if self.test is not None:\n",
        "                self.losses['test'].append(self._validation_loss())\n",
        "                row += 'val: {0:^10.5f}'.format(self.losses['test'][-1])\n",
        "                for metric in self.eval_metrics:\n",
        "                    func = getattr(metrics, metric)\n",
        "                    res = func(self.model, self.test_loader.dataset.mat_csr,\n",
        "                               num_workers=self.num_workers)\n",
        "                    self.losses['eval-{}'.format(metric)].append(res)\n",
        "                    row += 'eval-{0}: {1:^10.5f}'.format(metric, res)\n",
        "            self.losses['epoch'].append(epoch)\n",
        "            if self.verbose:\n",
        "                print(row)\n",
        "\n",
        "    def _fit_epoch(self, epoch=1, queue=None):\n",
        "        if self.hogwild:\n",
        "            self.break_grads()\n",
        "\n",
        "        self.model.train()\n",
        "        total_loss = torch.Tensor([0])\n",
        "        pbar = tqdm(enumerate(self.train_loader),\n",
        "                    total=len(self.train_loader),\n",
        "                    desc='({0:^3})'.format(epoch))\n",
        "        for batch_idx, ((row, col), val) in pbar:\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            row = row.long()\n",
        "            # TODO: turn this into a collate_fn like the data_loader\n",
        "            if isinstance(col, list):\n",
        "                col = tuple(c.long() for c in col)\n",
        "            else:\n",
        "                col = col.long()\n",
        "            val = val.float()\n",
        "\n",
        "            preds = self.model(row, col)\n",
        "            loss = self.loss_function(preds, val)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_loss = loss.item() / row.size()[0]\n",
        "            pbar.set_postfix(train_loss=batch_loss)\n",
        "        total_loss /= self.train.nnz\n",
        "        if queue is not None:\n",
        "            queue.put(total_loss[0])\n",
        "        else:\n",
        "            return total_loss[0]\n",
        "\n",
        "    def _validation_loss(self):\n",
        "        self.model.eval()\n",
        "        total_loss = torch.Tensor([0])\n",
        "        for batch_idx, ((row, col), val) in enumerate(self.test_loader):\n",
        "            row = row.long()\n",
        "            if isinstance(col, list):\n",
        "                col = tuple(c.long() for c in col)\n",
        "            else:\n",
        "                col = col.long()\n",
        "            val = val.float()\n",
        "\n",
        "            preds = self.model(row, col)\n",
        "            loss = self.loss_function(preds, val)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        total_loss /= self.test.nnz\n",
        "        return total_loss[0]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKeUFiRNPsFY"
      },
      "source": [
        "def explicit():\n",
        "    train, test = get_movielens_train_test_split()\n",
        "    pipeline = BasePipeline(train, test=test, model=BaseModule,\n",
        "                            n_factors=10, batch_size=1024, dropout_p=0.02,\n",
        "                            lr=0.02, weight_decay=0.1,\n",
        "                            optimizer=torch.optim.Adam, n_epochs=40,\n",
        "                            verbose=True, random_seed=2017)\n",
        "    pipeline.fit()\n",
        "\n",
        "\n",
        "def implicit():\n",
        "    train, test = get_movielens_train_test_split(implicit=True)\n",
        "\n",
        "    pipeline = BasePipeline(train, test=test, verbose=True,\n",
        "                           batch_size=1024, num_workers=4,\n",
        "                           n_factors=20, weight_decay=0,\n",
        "                           dropout_p=0., lr=.2, sparse=True,\n",
        "                           optimizer=torch.optim.SGD, n_epochs=40,\n",
        "                           random_seed=2017, loss_function=bpr_loss,\n",
        "                           model=BPRModule,\n",
        "                           interaction_class=PairwiseInteractions,\n",
        "                           eval_metrics=('auc', 'patk'))\n",
        "    pipeline.fit()\n",
        "\n",
        "\n",
        "def hogwild():\n",
        "    train, test = get_movielens_train_test_split(implicit=True)\n",
        "\n",
        "    pipeline = BasePipeline(train, test=test, verbose=True,\n",
        "                            batch_size=1024, num_workers=4,\n",
        "                            n_factors=20, weight_decay=0,\n",
        "                            dropout_p=0., lr=.2, sparse=True,\n",
        "                            optimizer=torch.optim.SGD, n_epochs=40,\n",
        "                            random_seed=2017, loss_function=bpr_loss,\n",
        "                            model=BPRModule, hogwild=True,\n",
        "                            interaction_class=PairwiseInteractions,\n",
        "                            eval_metrics=('auc', 'patk'))\n",
        "    pipeline.fit()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPQaj1FjPsCo",
        "outputId": "42275f83-f4e9-43cc-a105-3ecde82efaa4"
      },
      "source": [
        "explicit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making data path\n",
            "Downloading MovieLens data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 1 ): 100%|██████████| 89/89 [00:01<00:00, 53.63it/s, train_loss=6.88]\n",
            "( 2 ):   7%|▋         | 6/89 [00:00<00:01, 57.03it/s, train_loss=6.06]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1   train:  14.42120 val:  8.68083  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 2 ): 100%|██████████| 89/89 [00:01<00:00, 63.13it/s, train_loss=2.27]\n",
            "( 3 ):   8%|▊         | 7/89 [00:00<00:01, 62.84it/s, train_loss=2.23]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  2   train:  4.15028  val:  3.99969  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 3 ): 100%|██████████| 89/89 [00:01<00:00, 59.57it/s, train_loss=1.67]\n",
            "( 4 ):   7%|▋         | 6/89 [00:00<00:01, 59.43it/s, train_loss=1.33]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  3   train:  1.84903  val:  2.41240  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 4 ): 100%|██████████| 89/89 [00:01<00:00, 59.96it/s, train_loss=1.05]\n",
            "( 5 ):   8%|▊         | 7/89 [00:00<00:01, 61.59it/s, train_loss=0.982]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  4   train:  1.20266  val:  1.78271  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 5 ): 100%|██████████| 89/89 [00:01<00:00, 57.47it/s, train_loss=0.917]\n",
            "( 6 ):   8%|▊         | 7/89 [00:00<00:01, 62.99it/s, train_loss=0.861]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  5   train:  0.98022  val:  1.48147  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 6 ): 100%|██████████| 89/89 [00:01<00:00, 61.39it/s, train_loss=0.9]\n",
            "( 7 ):   8%|▊         | 7/89 [00:00<00:01, 65.11it/s, train_loss=0.77] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  6   train:  0.88477  val:  1.32482  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 7 ): 100%|██████████| 89/89 [00:01<00:00, 62.83it/s, train_loss=0.806]\n",
            "( 8 ):   7%|▋         | 6/89 [00:00<00:01, 54.86it/s, train_loss=0.766]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  7   train:  0.83306  val:  1.22818  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 8 ): 100%|██████████| 89/89 [00:01<00:00, 58.63it/s, train_loss=0.776]\n",
            "( 9 ):   3%|▎         | 3/89 [00:00<00:03, 25.32it/s, train_loss=0.722]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  8   train:  0.80015  val:  1.16457  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 9 ): 100%|██████████| 89/89 [00:01<00:00, 59.21it/s, train_loss=0.871]\n",
            "(10 ):   2%|▏         | 2/89 [00:00<00:04, 19.07it/s, train_loss=0.708]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  9   train:  0.77529  val:  1.12250  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(10 ): 100%|██████████| 89/89 [00:01<00:00, 60.45it/s, train_loss=0.749]\n",
            "(11 ):   2%|▏         | 2/89 [00:00<00:04, 19.87it/s, train_loss=0.735]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10   train:  0.75322  val:  1.09408  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(11 ): 100%|██████████| 89/89 [00:01<00:00, 60.82it/s, train_loss=0.728]\n",
            "(12 ):   8%|▊         | 7/89 [00:00<00:01, 62.74it/s, train_loss=0.655]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11   train:  0.73431  val:  1.06755  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(12 ): 100%|██████████| 89/89 [00:01<00:00, 64.48it/s, train_loss=0.729]\n",
            "(13 ):   8%|▊         | 7/89 [00:00<00:01, 61.52it/s, train_loss=0.706]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12   train:  0.71816  val:  1.05441  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(13 ): 100%|██████████| 89/89 [00:01<00:00, 63.59it/s, train_loss=0.804]\n",
            "(14 ):   7%|▋         | 6/89 [00:00<00:01, 57.44it/s, train_loss=0.658]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13   train:  0.70331  val:  1.04291  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(14 ): 100%|██████████| 89/89 [00:01<00:00, 62.10it/s, train_loss=0.648]\n",
            "(15 ):   7%|▋         | 6/89 [00:00<00:01, 55.63it/s, train_loss=0.662]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14   train:  0.69230  val:  1.03409  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(15 ): 100%|██████████| 89/89 [00:01<00:00, 59.82it/s, train_loss=0.71]\n",
            "(16 ):   8%|▊         | 7/89 [00:00<00:01, 63.50it/s, train_loss=0.648]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15   train:  0.68174  val:  1.02946  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(16 ): 100%|██████████| 89/89 [00:01<00:00, 63.41it/s, train_loss=0.762]\n",
            "(17 ):   8%|▊         | 7/89 [00:00<00:01, 66.62it/s, train_loss=0.6]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16   train:  0.67185  val:  1.02574  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(17 ): 100%|██████████| 89/89 [00:01<00:00, 61.57it/s, train_loss=0.709]\n",
            "(18 ):   7%|▋         | 6/89 [00:00<00:01, 59.98it/s, train_loss=0.647]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17   train:  0.66559  val:  1.01690  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(18 ): 100%|██████████| 89/89 [00:01<00:00, 59.60it/s, train_loss=0.657]\n",
            "(19 ):   7%|▋         | 6/89 [00:00<00:01, 58.13it/s, train_loss=0.609]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18   train:  0.65754  val:  1.01814  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(19 ): 100%|██████████| 89/89 [00:01<00:00, 58.23it/s, train_loss=0.609]\n",
            "(20 ):   8%|▊         | 7/89 [00:00<00:01, 64.70it/s, train_loss=0.636]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19   train:  0.65179  val:  1.01196  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(20 ): 100%|██████████| 89/89 [00:01<00:00, 58.38it/s, train_loss=0.693]\n",
            "(21 ):   8%|▊         | 7/89 [00:00<00:01, 68.79it/s, train_loss=0.607]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20   train:  0.64911  val:  1.00926  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(21 ): 100%|██████████| 89/89 [00:01<00:00, 60.85it/s, train_loss=0.75]\n",
            "(22 ):   7%|▋         | 6/89 [00:00<00:01, 52.77it/s, train_loss=0.635]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21   train:  0.64537  val:  1.01296  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(22 ): 100%|██████████| 89/89 [00:01<00:00, 59.46it/s, train_loss=0.702]\n",
            "(23 ):   4%|▍         | 4/89 [00:00<00:02, 39.91it/s, train_loss=0.588]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22   train:  0.64303  val:  1.00838  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(23 ): 100%|██████████| 89/89 [00:01<00:00, 56.49it/s, train_loss=0.683]\n",
            "(24 ):   7%|▋         | 6/89 [00:00<00:01, 59.61it/s, train_loss=0.633]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23   train:  0.63932  val:  0.99910  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(24 ): 100%|██████████| 89/89 [00:01<00:00, 58.42it/s, train_loss=0.709]\n",
            "(25 ):   7%|▋         | 6/89 [00:00<00:01, 52.67it/s, train_loss=0.594]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24   train:  0.63549  val:  1.01004  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(25 ): 100%|██████████| 89/89 [00:01<00:00, 57.48it/s, train_loss=0.786]\n",
            "(26 ):   7%|▋         | 6/89 [00:00<00:01, 58.84it/s, train_loss=0.59] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25   train:  0.63468  val:  1.00146  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(26 ): 100%|██████████| 89/89 [00:01<00:00, 55.84it/s, train_loss=0.64]\n",
            "(27 ):   7%|▋         | 6/89 [00:00<00:01, 58.98it/s, train_loss=0.603]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26   train:  0.63316  val:  1.00257  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(27 ): 100%|██████████| 89/89 [00:01<00:00, 60.23it/s, train_loss=0.682]\n",
            "(28 ):   8%|▊         | 7/89 [00:00<00:01, 67.37it/s, train_loss=0.584]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27   train:  0.63269  val:  1.00099  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(28 ): 100%|██████████| 89/89 [00:01<00:00, 59.51it/s, train_loss=0.721]\n",
            "(29 ):   7%|▋         | 6/89 [00:00<00:01, 57.41it/s, train_loss=0.573]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28   train:  0.63194  val:  0.99549  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(29 ): 100%|██████████| 89/89 [00:01<00:00, 58.52it/s, train_loss=0.759]\n",
            "(30 ):   7%|▋         | 6/89 [00:00<00:01, 58.95it/s, train_loss=0.564]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29   train:  0.63050  val:  1.00029  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(30 ): 100%|██████████| 89/89 [00:01<00:00, 59.03it/s, train_loss=0.718]\n",
            "(31 ):   8%|▊         | 7/89 [00:00<00:01, 65.42it/s, train_loss=0.563]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30   train:  0.63016  val:  0.99232  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(31 ): 100%|██████████| 89/89 [00:01<00:00, 57.36it/s, train_loss=0.699]\n",
            "(32 ):   8%|▊         | 7/89 [00:00<00:01, 62.85it/s, train_loss=0.58] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31   train:  0.63022  val:  0.99609  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(32 ): 100%|██████████| 89/89 [00:01<00:00, 56.56it/s, train_loss=0.743]\n",
            "(33 ):   7%|▋         | 6/89 [00:00<00:01, 59.53it/s, train_loss=0.576]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32   train:  0.63043  val:  0.99635  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(33 ): 100%|██████████| 89/89 [00:01<00:00, 57.91it/s, train_loss=0.643]\n",
            "(34 ):   8%|▊         | 7/89 [00:00<00:01, 64.98it/s, train_loss=0.625]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33   train:  0.63210  val:  0.99697  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(34 ): 100%|██████████| 89/89 [00:01<00:00, 58.12it/s, train_loss=0.641]\n",
            "(35 ):   6%|▌         | 5/89 [00:00<00:01, 49.84it/s, train_loss=0.546]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34   train:  0.63177  val:  0.99458  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(35 ): 100%|██████████| 89/89 [00:01<00:00, 54.93it/s, train_loss=0.654]\n",
            "(36 ):   7%|▋         | 6/89 [00:00<00:01, 57.96it/s, train_loss=0.543]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35   train:  0.63137  val:  1.00267  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(36 ): 100%|██████████| 89/89 [00:01<00:00, 58.59it/s, train_loss=0.742]\n",
            "(37 ):   7%|▋         | 6/89 [00:00<00:01, 59.93it/s, train_loss=0.553]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36   train:  0.63002  val:  0.99718  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(37 ): 100%|██████████| 89/89 [00:01<00:00, 58.76it/s, train_loss=0.733]\n",
            "(38 ):   7%|▋         | 6/89 [00:00<00:01, 57.61it/s, train_loss=0.56]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37   train:  0.62959  val:  0.99938  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(38 ): 100%|██████████| 89/89 [00:01<00:00, 59.98it/s, train_loss=0.638]\n",
            "(39 ):   8%|▊         | 7/89 [00:00<00:01, 61.75it/s, train_loss=0.599]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38   train:  0.63083  val:  1.00133  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(39 ): 100%|██████████| 89/89 [00:01<00:00, 61.77it/s, train_loss=0.724]\n",
            "(40 ):   8%|▊         | 7/89 [00:00<00:01, 60.35it/s, train_loss=0.573]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39   train:  0.63185  val:  0.99541  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(40 ): 100%|██████████| 89/89 [00:01<00:00, 61.02it/s, train_loss=0.69]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40   train:  0.63168  val:  0.99467  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtI0DewsPr_0",
        "outputId": "6cc428e1-211f-4e7e-8264-e8332ad47e8b"
      },
      "source": [
        "implicit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "( 1 ): 100%|██████████| 46/46 [00:02<00:00, 21.50it/s, train_loss=0.361]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1   train:  0.42040  val:  0.40008  eval-auc:  0.55278  eval-patk:  0.00776  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 2 ): 100%|██████████| 46/46 [00:02<00:00, 22.72it/s, train_loss=0.298]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  2   train:  0.34066  val:  0.35044  eval-auc:  0.60807  eval-patk:  0.01164  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 3 ): 100%|██████████| 46/46 [00:02<00:00, 22.89it/s, train_loss=0.303]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  3   train:  0.27492  val:  0.31180  eval-auc:  0.65543  eval-patk:  0.01804  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 4 ): 100%|██████████| 46/46 [00:01<00:00, 23.75it/s, train_loss=0.192]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  4   train:  0.22703  val:  0.29160  eval-auc:  0.69006  eval-patk:  0.02694  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 5 ): 100%|██████████| 46/46 [00:02<00:00, 21.58it/s, train_loss=0.17]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  5   train:  0.19465  val:  0.27365  eval-auc:  0.71412  eval-patk:  0.03265  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 6 ): 100%|██████████| 46/46 [00:02<00:00, 22.30it/s, train_loss=0.176]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  6   train:  0.17487  val:  0.25775  eval-auc:  0.73276  eval-patk:  0.03973  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 7 ): 100%|██████████| 46/46 [00:02<00:00, 22.14it/s, train_loss=0.202]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  7   train:  0.16267  val:  0.25430  eval-auc:  0.74666  eval-patk:  0.04201  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 8 ): 100%|██████████| 46/46 [00:02<00:00, 22.22it/s, train_loss=0.17]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  8   train:  0.15176  val:  0.24547  eval-auc:  0.75858  eval-patk:  0.04429  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "( 9 ): 100%|██████████| 46/46 [00:02<00:00, 22.55it/s, train_loss=0.141]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  9   train:  0.14359  val:  0.23771  eval-auc:  0.76822  eval-patk:  0.04589  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(10 ): 100%|██████████| 46/46 [00:01<00:00, 23.32it/s, train_loss=0.151]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10   train:  0.13715  val:  0.22593  eval-auc:  0.77713  eval-patk:  0.04361  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(11 ): 100%|██████████| 46/46 [00:01<00:00, 23.04it/s, train_loss=0.115]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11   train:  0.13167  val:  0.22131  eval-auc:  0.78402  eval-patk:  0.04772  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(12 ): 100%|██████████| 46/46 [00:02<00:00, 22.63it/s, train_loss=0.134]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12   train:  0.12781  val:  0.22118  eval-auc:  0.79055  eval-patk:  0.04749  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(13 ): 100%|██████████| 46/46 [00:01<00:00, 23.33it/s, train_loss=0.128]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13   train:  0.12185  val:  0.21263  eval-auc:  0.79726  eval-patk:  0.05228  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(14 ): 100%|██████████| 46/46 [00:02<00:00, 22.32it/s, train_loss=0.109]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14   train:  0.11865  val:  0.20135  eval-auc:  0.80326  eval-patk:  0.04977  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(15 ): 100%|██████████| 46/46 [00:01<00:00, 23.13it/s, train_loss=0.117]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15   train:  0.11352  val:  0.20501  eval-auc:  0.80805  eval-patk:  0.05434  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(16 ): 100%|██████████| 46/46 [00:01<00:00, 23.17it/s, train_loss=0.113]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16   train:  0.11156  val:  0.20189  eval-auc:  0.81208  eval-patk:  0.05753  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(17 ): 100%|██████████| 46/46 [00:02<00:00, 22.15it/s, train_loss=0.127]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17   train:  0.10898  val:  0.19678  eval-auc:  0.81534  eval-patk:  0.05936  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(18 ): 100%|██████████| 46/46 [00:01<00:00, 23.03it/s, train_loss=0.13]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18   train:  0.10363  val:  0.19250  eval-auc:  0.81967  eval-patk:  0.05890  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(19 ): 100%|██████████| 46/46 [00:02<00:00, 22.78it/s, train_loss=0.121]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19   train:  0.10260  val:  0.18791  eval-auc:  0.82216  eval-patk:  0.06416  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(20 ): 100%|██████████| 46/46 [00:02<00:00, 22.97it/s, train_loss=0.121]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20   train:  0.10081  val:  0.18382  eval-auc:  0.82357  eval-patk:  0.06370  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(21 ): 100%|██████████| 46/46 [00:02<00:00, 22.89it/s, train_loss=0.0978]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21   train:  0.09957  val:  0.18360  eval-auc:  0.82604  eval-patk:  0.06667  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(22 ): 100%|██████████| 46/46 [00:02<00:00, 22.88it/s, train_loss=0.105]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22   train:  0.09936  val:  0.17989  eval-auc:  0.82805  eval-patk:  0.06667  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(23 ): 100%|██████████| 46/46 [00:01<00:00, 23.03it/s, train_loss=0.102]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23   train:  0.09896  val:  0.17684  eval-auc:  0.83031  eval-patk:  0.07123  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(24 ): 100%|██████████| 46/46 [00:01<00:00, 23.09it/s, train_loss=0.116]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24   train:  0.09503  val:  0.18290  eval-auc:  0.83277  eval-patk:  0.06758  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(25 ): 100%|██████████| 46/46 [00:02<00:00, 22.64it/s, train_loss=0.081]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25   train:  0.09565  val:  0.17506  eval-auc:  0.83462  eval-patk:  0.07511  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(26 ): 100%|██████████| 46/46 [00:02<00:00, 22.48it/s, train_loss=0.102]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26   train:  0.09337  val:  0.17530  eval-auc:  0.83571  eval-patk:  0.07169  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(27 ): 100%|██████████| 46/46 [00:02<00:00, 21.46it/s, train_loss=0.0837]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27   train:  0.09035  val:  0.17689  eval-auc:  0.83655  eval-patk:  0.07420  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(28 ): 100%|██████████| 46/46 [00:02<00:00, 20.81it/s, train_loss=0.0846]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28   train:  0.08635  val:  0.17874  eval-auc:  0.83849  eval-patk:  0.07420  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(29 ): 100%|██████████| 46/46 [00:02<00:00, 21.13it/s, train_loss=0.107]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29   train:  0.08961  val:  0.17910  eval-auc:  0.83905  eval-patk:  0.07237  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(30 ): 100%|██████████| 46/46 [00:02<00:00, 21.09it/s, train_loss=0.0935]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30   train:  0.08822  val:  0.17294  eval-auc:  0.84065  eval-patk:  0.07717  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(31 ): 100%|██████████| 46/46 [00:02<00:00, 21.52it/s, train_loss=0.0926]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31   train:  0.08964  val:  0.16762  eval-auc:  0.84098  eval-patk:  0.07466  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(32 ): 100%|██████████| 46/46 [00:02<00:00, 21.57it/s, train_loss=0.0708]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32   train:  0.08982  val:  0.16215  eval-auc:  0.84217  eval-patk:  0.07055  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(33 ): 100%|██████████| 46/46 [00:02<00:00, 20.14it/s, train_loss=0.106]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33   train:  0.08753  val:  0.16941  eval-auc:  0.84282  eval-patk:  0.07352  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(34 ): 100%|██████████| 46/46 [00:02<00:00, 20.73it/s, train_loss=0.0781]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34   train:  0.08659  val:  0.17334  eval-auc:  0.84284  eval-patk:  0.07489  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(35 ): 100%|██████████| 46/46 [00:02<00:00, 20.66it/s, train_loss=0.0971]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35   train:  0.08623  val:  0.17476  eval-auc:  0.84393  eval-patk:  0.07443  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(36 ): 100%|██████████| 46/46 [00:02<00:00, 20.77it/s, train_loss=0.0864]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36   train:  0.08559  val:  0.17291  eval-auc:  0.84470  eval-patk:  0.07397  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(37 ): 100%|██████████| 46/46 [00:02<00:00, 20.11it/s, train_loss=0.0751]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37   train:  0.08506  val:  0.16872  eval-auc:  0.84690  eval-patk:  0.07648  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(38 ): 100%|██████████| 46/46 [00:02<00:00, 18.27it/s, train_loss=0.0964]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38   train:  0.08522  val:  0.16541  eval-auc:  0.84715  eval-patk:  0.07991  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(39 ): 100%|██████████| 46/46 [00:02<00:00, 19.55it/s, train_loss=0.0962]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39   train:  0.08316  val:  0.16021  eval-auc:  0.84812  eval-patk:  0.07991  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "(40 ): 100%|██████████| 46/46 [00:02<00:00, 19.17it/s, train_loss=0.0943]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40   train:  0.08459  val:  0.16542  eval-auc:  0.84809  eval-patk:  0.07237  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}