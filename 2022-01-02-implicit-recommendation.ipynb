{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-02-implicit-recommendation.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/3d1e538d-8b3b-4ddb-8f66-6e2ccc282ae6.ipynb","timestamp":1644426616490}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMIJY5yNAWONv4vHeq8UOdd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Implicit Recommendation"],"metadata":{"id":"OFSvPOkId0aZ"}},{"cell_type":"markdown","metadata":{"id":"ZhFt8K-vHVE3"},"source":["### Framework\n","1. Data type : 'Unary & Implicit data'\n","  - Be careful not to confuse binary and unary data: unary data means that you have information that a user consumed something (which is coded as 1, much like binary data), but you have no information about whether a user didn't like or consume something (which is coded as NULL instead of binary data's 0).\n","  - Implicit data is data we gather from the users behaviour, with no ratings or specific actions needed. It could be what items a user purchased, how many times they played a song or watched a movie, how long they’ve spent reading a specific article etc. \n","2. Algorithms\n"," 1. Traditional algorithm - Item-item nearest neighbor models - a. Cosine distance metric, b. TF IDF, c.\tBM25, Popularity based recommendation (baseline).\n"," 2. ALS (Alternating Least Squares) Matrix Factorization\n","    - Original paper: http://yifanhu.net/PUB/cf.pdf \n","    - We can use matrix factorization to mathematically reduce the dimensionality of our original “all users by all items” matrix into something much smaller that represents “all items by some taste dimensions” and “all users by some taste dimensions”. These dimensions are called latent or hidden features and we learn them from our data.\n","    - There are different ways to factor a matrix, like Singular Value Decomposition (SVD) or Probabilistic Latent Semantic Analysis (PLSA) if we’re dealing with explicit data.With implicit data the difference lies in how we deal with all the missing data in our very sparse matrix. For explicit data we treat them as just unknown fields that we should assign some predicted rating to. But for implicit we can’t just assume the same since there is information in these unknown values as well. As stated before we don’t know if a missing value means the user disliked something, or if it means they love it but just don’t know about it. Basically we need some way to learn from the missing data. So we’ll need a different approach to get us there.\n","    - <img src='https://jessesw.com/images/Rec_images/ALS_Image_Test.png' width=600>\n","  3. Bayesian Personalized Ranking (BPR)\n","     - Original paper: https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf\n","  4. Logistic Matrix Factorization\n","     - Original paper: http://stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf\n","  5. Collaborative Less-Is-More Filtering\n","     - Original paper: https://www.ijcai.org/Proceedings/13/Papers/460.pdf \n","\n","    "]},{"cell_type":"code","metadata":{"id":"RNVoFwWx1Ml_"},"source":["!pip install implicit\n","\n","import numpy as np\n","import pandas as pd\n","import scipy.sparse as sparse\n","from scipy.sparse.linalg import spsolve\n","from sklearn import metrics\n","import time\n","import random\n","\n","from implicit.als import AlternatingLeastSquares\n","from implicit.bpr import BayesianPersonalizedRanking"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dx6FW6dxKley","outputId":"2079ad12-46eb-44f5-dda5-c71cb88f18bd","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data = pd.read_csv('https://raw.githubusercontent.com/sparsh9012/Recommendation-Engine/master/data/data.csv')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>item_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5000034025459</td>\n","      <td>55649</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8000040000000</td>\n","      <td>52535</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000000000000</td>\n","      <td>76125</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8000039034732</td>\n","      <td>50489</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8000027039444</td>\n","      <td>56215</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     customer_id  item_id\n","0  5000034025459    55649\n","1  8000040000000    52535\n","2  1000000000000    76125\n","3  8000039034732    50489\n","4  8000027039444    56215"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"BAzjx2jtK72h","outputId":"2dabdd2a-e0ec-48ff-fef6-544a249fd7c3","colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["matrix = pd.crosstab(data.customer_id, data.item_id)\n","sparsed = sparse.csr_matrix(matrix.values)\n","print('matrix shape: ',matrix.shape)\n","print('sparse shape: ',sparsed.shape)\n","matrix.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["matrix shape:  (1252, 4978)\n","sparse shape:  (1252, 4978)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>item_id</th>\n","      <th>50009</th>\n","      <th>50093</th>\n","      <th>50096</th>\n","      <th>50098</th>\n","      <th>50104</th>\n","      <th>50108</th>\n","      <th>50112</th>\n","      <th>50116</th>\n","      <th>50119</th>\n","      <th>50124</th>\n","      <th>...</th>\n","      <th>91679</th>\n","      <th>91740</th>\n","      <th>91742</th>\n","      <th>91766</th>\n","      <th>91768</th>\n","      <th>91770</th>\n","      <th>91785</th>\n","      <th>91790</th>\n","      <th>91795</th>\n","      <th>91798</th>\n","    </tr>\n","    <tr>\n","      <th>customer_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1000000000000</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1000000201799</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1000000216930</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1000000220674</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1000000237993</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 4978 columns</p>\n","</div>"],"text/plain":["item_id        50009  50093  50096  50098  50104  50108  50112  50116  50119  \\\n","customer_id                                                                    \n","1000000000000      0      0      0      0      1      0      0      1      1   \n","1000000201799      0      0      0      0      0      0      0      0      0   \n","1000000216930      0      0      0      0      0      0      0      0      0   \n","1000000220674      0      0      0      0      0      0      0      0      0   \n","1000000237993      0      0      0      0      0      0      0      0      0   \n","\n","item_id        50124  ...  91679  91740  91742  91766  91768  91770  91785  \\\n","customer_id           ...                                                    \n","1000000000000      1  ...      1      0      0      0      0      0      0   \n","1000000201799      0  ...      0      0      0      0      0      0      0   \n","1000000216930      0  ...      0      0      0      0      0      0      0   \n","1000000220674      0  ...      0      0      0      0      0      0      0   \n","1000000237993      0  ...      0      0      0      0      0      0      0   \n","\n","item_id        91790  91795  91798  \n","customer_id                         \n","1000000000000      0      0      0  \n","1000000201799      0      0      0  \n","1000000216930      0      0      0  \n","1000000220674      0      0      0  \n","1000000237993      0      0      0  \n","\n","[5 rows x 4978 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"GqFo9H8bMWx9","outputId":"b54fc9d6-04cf-4725-8ce9-5018da449a79","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#dropping customers with very-high-frequency purchase\n","matrix1 = matrix.loc[matrix.sum(axis=1).values<5000,:]\n","\n","#dropping customers with very-low-frequency purchase\n","matrix1 = matrix1.loc[matrix1.sum(axis=1).values>2,:]\n","\n","#dropping products with very-low-frequency purchase\n","matrix1 = matrix1.loc[:,matrix1.sum(axis=0).values>2]\n","\n","sparsed1 = sparse.csr_matrix(matrix1.values)\n","matrix1.shape\n","sparsed1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(419, 2359)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"VOPWzjCHtV43","outputId":"63270596-541d-435b-99d6-3e4dabc02ba6","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#check sparsity\n","sparsity = round(1.0 - len(data) / float(matrix.shape[0] * matrix.shape[1]), 3)\n","print('The sparsity level of dataset is ' +  str(sparsity * 100) + '%')\n","\n","sparsity = round(1.0 - len(data) / float(matrix1.shape[0] * matrix1.shape[1]), 3)\n","print('The sparsity level of filtered dataset is ' +  str(sparsity * 100) + '%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The sparsity level of dataset is 99.7%\n","The sparsity level of filtered dataset is 98.1%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"crEk0SRQF3vt"},"source":["item_dictionary = { i : matrix.columns[i] for i in range(0, len(matrix.columns) ) }\n","customer_dictionary = { i : matrix.index[i] for i in range(0, len(matrix.index) ) }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8cbODa4BMtD"},"source":["def calculate_recommendations(df_new, model_name='als', factors=32, regularization=0.01, iterations=10):\n","    \n","    # initialize models\n","    if model_name=='als':\n","        model = AlternatingLeastSquares(factors=32, regularization = 0.02, iterations = 50)\n","    elif model_name=='bpr':\n","        model = BayesianPersonalizedRanking(factors=factors, learning_rate=0.01, regularization=regularization, iterations=iterations)\n","    \n","    '''item_users (csr_matrix) – Matrix of confidences for the liked items. \n","    This matrix should be a csr_matrix where the rows of the matrix are the item, \n","    the columns are the users that liked that item, and the value is the confidence \n","    that the user liked the item.'''\n","    \n","    model.fit(sparsed.T)\n","    \n","    '''user_items (csr_matrix) – A sparse matrix of shape (number_users, number_items). \n","    This lets us look up the liked items and their weights for the user. \n","    This is used to filter out items that have already been liked from the output, \n","    and to also potentially calculate the best items for this user.'''\n","    \n","    user_items = sparsed.tocsr()\n","    \n","    result = pd.DataFrame(columns=['customer_id', 'recommendation'])\n","\n","    # Calculates the N best recommendations for a user, and returns a list of itemids, score\n","    for i in range(matrix.shape[0]):\n","        rc = model.recommend(i, user_items, N=10)\n","          result.loc[i,'customer_id'] = matrix.index[i]\n","        result.loc[i,'recommendation'] = rc\n","\n","    x = pd.DataFrame(result.recommendation.tolist(), index=result.customer_id).stack().reset_index(level=1, drop=True).reset_index(name='recommendation')\n","    df_new['customer_id '+model_name] = x['customer_id']\n","    df_new['recommendation '+model_name] = x['recommendation'].apply(lambda x: x[0])\n","    df_new['score '+model_name] = x['recommendation'].apply(lambda x: x[1])\n","\n","    df_new = df_new.replace({'recommendation '+model_name: item_dictionary})\n","    return df_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGdme_RVZmq4","outputId":"7c5866d7-3ab9-47c3-bea4-9344ca07efef","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["calculate_recommendations(pd.DataFrame(), model_name='als').head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 104.95it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id als</th>\n","      <th>recommendation als</th>\n","      <th>score als</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000000000000</td>\n","      <td>55659</td>\n","      <td>0.010661</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000000000000</td>\n","      <td>54310</td>\n","      <td>0.008409</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000000000000</td>\n","      <td>63087</td>\n","      <td>0.007403</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000000000000</td>\n","      <td>56780</td>\n","      <td>0.006668</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000000000000</td>\n","      <td>51966</td>\n","      <td>0.006610</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id als  recommendation als  score als\n","0    1000000000000               55659   0.010661\n","1    1000000000000               54310   0.008409\n","2    1000000000000               63087   0.007403\n","3    1000000000000               56780   0.006668\n","4    1000000000000               51966   0.006610"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"-c53tFWrQBHO","outputId":"95edf1bf-259c-4049-ea6c-64314680d2eb","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["df_n = pd.DataFrame()\n","df_n = calculate_recommendations(df_n, model_name='als')\n","df_n = calculate_recommendations(df_n, model_name='bpr')\n","df_n.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 109.66it/s]\n","100%|██████████| 100/100 [00:00<00:00, 142.15it/s, correct=68.43%, skipped=33.39%]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id als</th>\n","      <th>recommendation als</th>\n","      <th>score als</th>\n","      <th>customer_id bpr</th>\n","      <th>recommendation bpr</th>\n","      <th>score bpr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000000000000</td>\n","      <td>55659</td>\n","      <td>0.007136</td>\n","      <td>1000000000000</td>\n","      <td>89962</td>\n","      <td>0.708574</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000000000000</td>\n","      <td>73975</td>\n","      <td>0.007122</td>\n","      <td>1000000000000</td>\n","      <td>50559</td>\n","      <td>0.700179</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000000000000</td>\n","      <td>66134</td>\n","      <td>0.006804</td>\n","      <td>1000000000000</td>\n","      <td>64293</td>\n","      <td>0.697164</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000000000000</td>\n","      <td>65875</td>\n","      <td>0.006423</td>\n","      <td>1000000000000</td>\n","      <td>64181</td>\n","      <td>0.676541</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000000000000</td>\n","      <td>56780</td>\n","      <td>0.006374</td>\n","      <td>1000000000000</td>\n","      <td>51507</td>\n","      <td>0.666476</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id als  recommendation als  score als  customer_id bpr  \\\n","0    1000000000000               55659   0.007136    1000000000000   \n","1    1000000000000               73975   0.007122    1000000000000   \n","2    1000000000000               66134   0.006804    1000000000000   \n","3    1000000000000               65875   0.006423    1000000000000   \n","4    1000000000000               56780   0.006374    1000000000000   \n","\n","   recommendation bpr  score bpr  \n","0               89962   0.708574  \n","1               50559   0.700179  \n","2               64293   0.697164  \n","3               64181   0.676541  \n","4               51507   0.666476  "]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"Upz1WgvsOMjD"},"source":["### Model Evaluation\n","- It is important to realize that we do not have a reliable feedback regarding which items are disliked. The absence of a favorite item indicator can be related to multiple reasons. We also can't track user reactions to our recommendations. Thus, precision based metrics, such as RMSE and MSE, are not very appropriate, as they require knowing which items users dislike for it to make sense. \n","In addition, we are currently unable to track user reactions to our recommendations. Thus, precision based metrics are not very appropriate, as they require knowing which programs are undesired to a user. However, watching a program is an indication of liking it, making recall-oriented measures applicable.\n","1.\tRandom masking and measuring predicted vs. actual values of masked values – ROC AUC score\n","   <img src='https://jessesw.com/images/Rec_images/MaskTrain.png' width=600>\n","2.\tRecall based evaluation ranking – **Mean Percentage Ranking (MPR)** a.k.a. expected percentile ranking.  Lower values of MPR are more desirable. The expected value of MPR for random predictions is 50%, and thus MPR > 50% indicates an algorithm no better than random.\n"]},{"cell_type":"code","metadata":{"id":"fpnoGvWz2JiU"},"source":["def make_train(ratings, pct_test = 0.2):\n","    '''\n","    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n","    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n","    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n","    \n","    parameters: \n","    \n","    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n","    copy of the original set. This is in the form of a sparse csr_matrix. \n","    \n","    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n","    training set for later comparison to the test set, which contains all of the original ratings. \n","    \n","    returns:\n","    \n","    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n","    that originally had interaction set back to zero.\n","    \n","    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n","    compares with the actual interactions.\n","    \n","    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n","    This will be necessary later when evaluating the performance via AUC.\n","    '''\n","    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n","    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n","    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n","    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n","    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n","    random.seed(0) # Set the random seed to zero for reproducibility\n","    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n","    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n","    user_inds = [index[0] for index in samples] # Get the user row indices\n","    item_inds = [index[1] for index in samples] # Get the item column indices\n","    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n","    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n","    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruzywaoFCJ2r"},"source":["def auc_score(predictions, test):\n","    '''\n","    This simple function will output the area under the curve using sklearn's metrics. \n","    \n","    parameters:\n","    \n","    - predictions: your prediction output\n","    \n","    - test: the actual target result you are comparing to\n","    \n","    returns:\n","    \n","    - AUC (area under the Receiver Operating Characterisic curve)\n","    '''\n","    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n","    return metrics.auc(fpr, tpr)\n","  \n","\n","  \n","def calc_mean_auc(training_set, altered_users, predictions, test_set):\n","    '''\n","    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n","    \n","    parameters:\n","    \n","    training_set - The training set resulting from make_train, where a certain percentage of the original\n","    user/item interactions are reset to zero to hide them from the model \n","    \n","    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n","    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n","    \n","    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n","    \n","    test_set - The test set constucted earlier from make_train function\n","    \n","    \n","\n","    returns:\n","    \n","    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n","    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n","    '''\n","    \n","    \n","    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n","    popularity_auc = [] # To store popular AUC scores\n","    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n","    item_vecs = predictions[1]\n","    for user in altered_users: # Iterate through each user that had an item altered\n","        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n","        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n","        # Get the predicted values based on our user/item vectors\n","        user_vec = predictions[0][user,:]\n","        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n","        # Get only the items that were originally zero\n","        # Select all ratings from the MF prediction for this user that originally had no iteraction\n","        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n","        # Select the binarized yes/no interaction pairs from the original full data\n","        # that align with the same pairs in training \n","        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n","        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n","        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n","    # End users iteration\n","    \n","    # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n","    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oga2G5W6kFR","outputId":"0b50bac1-d680-4dbc-d4b7-481d928ef3be","colab":{"base_uri":"https://localhost:8080/","height":2465}},"source":["### ALS ###\n","\n","# hyperparameters\n","\n","PCT = [0.2,0.3]\n","factors = [32,64,128]\n","regularization = [0.01,0.05,0.1,0.2]\n","iterations = [10,20,50]\n","\n","# PCT = [0.2]\n","# factors = [32]\n","# regularization = [0.01]\n","# iterations = [10]\n","\n","scores = pd.DataFrame(columns = ['PCT','factors','regularization','iterations','score'])\n","\n","# Grid-search hyperparameter optimization\n","for i in PCT:\n","  for j in factors:\n","    for k in regularization: \n","      for index,l in enumerate(iterations):\n","        # creating train, test and altered sets\n","        train, test, altered = make_train(sparsed, pct_test = i)\n","\n","        # calculate the confidence by multiplying it by our alpha value\n","        alpha_val = 15\n","        train = (train * alpha_val).astype('double')\n","\n","        # defining the model\n","        model = implicit.als.AlternatingLeastSquares(factors=j, regularization = k, iterations = l)\n","\n","        # training the model\n","        model.fit(train.T)\n","\n","        # AUC for our recommender system\n","        score = calc_mean_auc(train, altered, [sparse.csr_matrix(model.user_factors), sparse.csr_matrix(model.item_factors.T)], test)\n","        print(model.user_factors.shape)\n","        # saving in a dataframe\n","        scores.loc[index,'PCT'] = i\n","        scores.loc[index,'factors'] = j\n","        scores.loc[index,'regularization'] = k\n","        scores.loc[index,'iterations'] = l\n","        scores.loc[index,'score'] = score\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 10.0/10 [00:00<00:00, 161.82it/s]\n","100%|██████████| 20.0/20 [00:00<00:00, 160.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 16.5/50 [00:00<00:00, 157.61it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 200.78it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 341.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 156.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 16.5/50 [00:00<00:00, 158.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 183.69it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 357.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 158.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 46%|████▌     | 23.0/50 [00:00<00:00, 229.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 238.59it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 352.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 157.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 35%|███▌      | 17.5/50 [00:00<00:00, 167.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 201.91it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 252.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 52%|█████▎    | 10.5/20 [00:00<00:00, 100.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 102.39it/s]\n"," 31%|███       | 15.5/50 [00:00<00:00, 150.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 186.48it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 261.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 52%|█████▎    | 10.5/20 [00:00<00:00, 100.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 106.17it/s]\n"," 27%|██▋       | 13.5/50 [00:00<00:00, 130.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 181.33it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 266.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 112.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 18.5/50 [00:00<00:00, 180.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 188.52it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 263.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 48%|████▊     | 9.5/20 [00:00<00:00, 92.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 98.17it/s]\n"," 33%|███▎      | 16.5/50 [00:00<00:00, 158.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 198.53it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 204.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 8.0/20 [00:00<00:00, 79.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 88.00it/s]\n"," 17%|█▋        | 8.5/50 [00:00<00:00, 78.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 107.57it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 79.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 42%|████▎     | 8.5/20 [00:00<00:00, 77.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 88.35it/s]\n"," 17%|█▋        | 8.5/50 [00:00<00:00, 77.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 127.51it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 79.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 8.0/20 [00:00<00:00, 79.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 80.47it/s]\n"," 16%|█▌        | 8.0/50 [00:00<00:00, 79.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 117.81it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 80.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 8.0/20 [00:00<00:00, 79.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 78.98it/s]\n"," 16%|█▌        | 8.0/50 [00:00<00:00, 79.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 126.63it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 175.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 181.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 23.5/50 [00:00<00:00, 226.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 219.90it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 352.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 183.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 41%|████      | 20.5/50 [00:00<00:00, 202.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 197.39it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 408.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 180.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 18.5/50 [00:00<00:00, 179.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 213.73it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 218.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 182.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 18.5/50 [00:00<00:00, 181.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 212.07it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 117.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 116.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 11.5/50 [00:00<00:00, 114.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 148.05it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 116.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 125.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 11.5/50 [00:00<00:00, 114.20it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 145.78it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 117.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 117.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 11.5/50 [00:00<00:00, 113.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 150.54it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 117.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 20.0/20 [00:00<00:00, 116.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 11.5/50 [00:00<00:00, 113.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 160.51it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 87.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 64)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 45%|████▌     | 9.0/20 [00:00<00:00, 89.20it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 102.85it/s]\n"," 18%|█▊        | 9.0/50 [00:00<00:00, 89.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 130.60it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 88.20it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 45%|████▌     | 9.0/20 [00:00<00:00, 89.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 90.27it/s]\n"," 18%|█▊        | 9.0/50 [00:00<00:00, 89.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 127.86it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 88.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 45%|████▌     | 9.0/20 [00:00<00:00, 89.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 94.19it/s]\n"," 18%|█▊        | 9.0/50 [00:00<00:00, 89.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 129.15it/s]\n","100%|██████████| 10.0/10 [00:00<00:00, 88.40it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 45%|████▌     | 9.0/20 [00:00<00:00, 88.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20.0/20 [00:00<00:00, 101.38it/s]\n"," 18%|█▊        | 9.0/50 [00:00<00:00, 89.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 131.35it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["(1252, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sAVu1MxoNV0D","outputId":"6e7aa946-fea7-47ea-d738-0c265c8bf1eb","colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["pd.DataFrame(scores.score.tolist(), index=scores[['PCT','factors','regularization','iterations']], columns=['ALS','Popularity']).sort_values(by='ALS', ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ALS</th>\n","      <th>Popularity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(0.3, 128, 0.2, 10)</th>\n","      <td>0.520</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>(0.3, 128, 0.2, 20)</th>\n","      <td>0.520</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>(0.3, 128, 0.2, 50)</th>\n","      <td>0.519</td>\n","      <td>0.602</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       ALS  Popularity\n","(0.3, 128, 0.2, 10)  0.520       0.602\n","(0.3, 128, 0.2, 20)  0.520       0.602\n","(0.3, 128, 0.2, 50)  0.519       0.602"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"id":"Zlt-ZLVRPrPz","outputId":"a5e0d693-719e-47b4-8e89-2d27e1ec6871","colab":{"base_uri":"https://localhost:8080/","height":1547}},"source":["### BPR ###\n","\n","# hyperparameters\n","\n","PCT = [0.2, 0.3]\n","factors = [31,63,127]\n","regularization = [0.01, 0.03, 0.05, 0.1, 0.2]\n","# learning_rate = [0.01, 0.05, 0.1]\n","iterations = [10,20,50]\n","\n","scores = pd.DataFrame(columns = ['PCT','factors','regularization','iterations','score'])\n","\n","# Grid-search hyperparameter optimization\n","for i in PCT:\n","  for j in factors:\n","    for k in regularization: \n","      for index,l in enumerate(iterations):\n","        # creating train, test and altered sets\n","        train, test, altered = make_train(sparsed, pct_test = i)\n","\n","        # calculate the confidence by multiplying it by our alpha value\n","        alpha_val = 15\n","        train = (train * alpha_val).astype('double')\n","\n","        # defining the model\n","        model = BayesianPersonalizedRanking(factors=j, regularization = k, iterations = l)\n","\n","        # training the model\n","        model.fit(train.T)\n","\n","        # AUC for our recommender system\n","        score = calc_mean_auc(train, altered, [sparse.csr_matrix(model.user_factors), sparse.csr_matrix(model.item_factors.T)], test)\n","        \n","        # saving in a dataframe\n","        scores.loc[index,'PCT'] = i\n","        scores.loc[index,'factors'] = j\n","        scores.loc[index,'regularization'] = k\n","        scores.loc[index,'iterations'] = l\n","        scores.loc[index,'score'] = score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 148.72it/s, correct=53.86%, skipped=27.36%]\n","100%|██████████| 20/20 [00:00<00:00, 124.86it/s, correct=54.75%, skipped=27.40%]\n","100%|██████████| 50/50 [00:00<00:00, 141.36it/s, correct=55.18%, skipped=27.36%]\n","100%|██████████| 10/10 [00:00<00:00, 179.50it/s, correct=53.87%, skipped=27.27%]\n","100%|██████████| 20/20 [00:00<00:00, 145.93it/s, correct=53.54%, skipped=27.76%]\n","100%|██████████| 50/50 [00:00<00:00, 157.31it/s, correct=55.41%, skipped=28.05%]\n","100%|██████████| 10/10 [00:00<00:00, 193.12it/s, correct=53.65%, skipped=27.72%]\n","100%|██████████| 20/20 [00:00<00:00, 139.21it/s, correct=54.41%, skipped=27.09%]\n","100%|██████████| 50/50 [00:00<00:00, 164.14it/s, correct=55.21%, skipped=27.41%]\n","100%|██████████| 10/10 [00:00<00:00, 159.37it/s, correct=53.42%, skipped=27.46%]\n","100%|██████████| 20/20 [00:00<00:00, 136.66it/s, correct=53.07%, skipped=27.23%]\n","100%|██████████| 50/50 [00:00<00:00, 168.69it/s, correct=54.50%, skipped=28.13%]\n","100%|██████████| 10/10 [00:00<00:00, 184.08it/s, correct=53.10%, skipped=27.02%]\n","100%|██████████| 20/20 [00:00<00:00, 138.54it/s, correct=53.48%, skipped=27.23%]\n","100%|██████████| 50/50 [00:00<00:00, 170.83it/s, correct=57.67%, skipped=27.29%]\n","100%|██████████| 10/10 [00:00<00:00, 191.59it/s, correct=54.01%, skipped=26.96%]\n","100%|██████████| 20/20 [00:00<00:00, 135.95it/s, correct=53.91%, skipped=27.01%]\n","100%|██████████| 50/50 [00:00<00:00, 146.26it/s, correct=54.73%, skipped=27.47%]\n","100%|██████████| 10/10 [00:00<00:00, 189.99it/s, correct=53.11%, skipped=27.29%]\n","100%|██████████| 20/20 [00:00<00:00, 137.36it/s, correct=54.58%, skipped=27.65%]\n","100%|██████████| 50/50 [00:00<00:00, 136.56it/s, correct=54.84%, skipped=27.93%]\n","100%|██████████| 10/10 [00:00<00:00, 190.24it/s, correct=53.14%, skipped=26.81%]\n","100%|██████████| 20/20 [00:00<00:00, 143.07it/s, correct=53.89%, skipped=27.64%]\n","100%|██████████| 50/50 [00:00<00:00, 154.41it/s, correct=54.22%, skipped=27.64%]\n","100%|██████████| 10/10 [00:00<00:00, 195.09it/s, correct=53.10%, skipped=27.44%]\n","100%|██████████| 20/20 [00:00<00:00, 140.14it/s, correct=53.29%, skipped=27.63%]\n","100%|██████████| 50/50 [00:00<00:00, 165.42it/s, correct=52.92%, skipped=27.88%]\n","100%|██████████| 10/10 [00:00<00:00, 189.79it/s, correct=52.85%, skipped=26.94%]\n","100%|██████████| 20/20 [00:00<00:00, 138.76it/s, correct=52.56%, skipped=27.43%]\n","100%|██████████| 50/50 [00:00<00:00, 144.33it/s, correct=59.11%, skipped=27.21%]\n","100%|██████████| 10/10 [00:00<00:00, 156.83it/s, correct=54.26%, skipped=27.26%]\n","100%|██████████| 20/20 [00:00<00:00, 139.86it/s, correct=53.83%, skipped=27.88%]\n","100%|██████████| 50/50 [00:00<00:00, 149.96it/s, correct=54.25%, skipped=27.33%]\n","100%|██████████| 10/10 [00:00<00:00, 100.74it/s, correct=54.85%, skipped=27.27%]\n","100%|██████████| 20/20 [00:00<00:00, 132.91it/s, correct=54.19%, skipped=27.86%]\n","100%|██████████| 50/50 [00:00<00:00, 139.92it/s, correct=55.09%, skipped=27.58%]\n","100%|██████████| 10/10 [00:00<00:00, 136.90it/s, correct=53.71%, skipped=27.29%]\n","100%|██████████| 20/20 [00:00<00:00, 134.78it/s, correct=53.65%, skipped=27.68%]\n","100%|██████████| 50/50 [00:00<00:00, 149.01it/s, correct=54.60%, skipped=27.37%]\n","100%|██████████| 10/10 [00:00<00:00, 135.31it/s, correct=54.13%, skipped=27.24%]\n","100%|██████████| 20/20 [00:00<00:00, 140.68it/s, correct=53.22%, skipped=27.69%]\n","100%|██████████| 50/50 [00:00<00:00, 153.71it/s, correct=53.05%, skipped=27.41%]\n","100%|██████████| 10/10 [00:00<00:00, 143.67it/s, correct=54.02%, skipped=27.56%]\n","100%|██████████| 20/20 [00:00<00:00, 133.77it/s, correct=51.42%, skipped=27.68%]\n","100%|██████████| 50/50 [00:00<00:00, 152.86it/s, correct=66.37%, skipped=27.71%]\n","100%|██████████| 10/10 [00:00<00:00, 133.45it/s, correct=52.82%, skipped=24.82%]\n","100%|██████████| 20/20 [00:00<00:00, 133.77it/s, correct=53.81%, skipped=24.99%]\n","100%|██████████| 50/50 [00:00<00:00, 153.62it/s, correct=54.59%, skipped=25.06%]\n","100%|██████████| 10/10 [00:00<00:00, 136.61it/s, correct=52.94%, skipped=25.00%]\n","100%|██████████| 20/20 [00:00<00:00, 130.78it/s, correct=54.17%, skipped=25.09%]\n","100%|██████████| 50/50 [00:00<00:00, 136.68it/s, correct=53.89%, skipped=24.66%]\n","100%|██████████| 10/10 [00:00<00:00, 130.18it/s, correct=52.23%, skipped=24.73%]\n","100%|██████████| 20/20 [00:00<00:00, 140.54it/s, correct=53.36%, skipped=24.34%]\n","100%|██████████| 50/50 [00:00<00:00, 143.46it/s, correct=53.59%, skipped=24.48%]\n","100%|██████████| 10/10 [00:00<00:00, 122.88it/s, correct=52.77%, skipped=25.22%]\n","100%|██████████| 20/20 [00:00<00:00, 138.65it/s, correct=52.77%, skipped=24.19%]\n","100%|██████████| 50/50 [00:00<00:00, 160.36it/s, correct=53.74%, skipped=25.04%]\n","100%|██████████| 10/10 [00:00<00:00, 153.01it/s, correct=53.36%, skipped=24.98%]\n","100%|██████████| 20/20 [00:00<00:00, 129.92it/s, correct=52.85%, skipped=24.58%]\n","100%|██████████| 50/50 [00:00<00:00, 142.81it/s, correct=58.85%, skipped=24.30%]\n","100%|██████████| 10/10 [00:00<00:00, 138.06it/s, correct=53.20%, skipped=24.94%]\n","100%|██████████| 20/20 [00:00<00:00, 139.66it/s, correct=53.68%, skipped=24.78%]\n","100%|██████████| 50/50 [00:00<00:00, 135.04it/s, correct=53.72%, skipped=24.39%]\n","100%|██████████| 10/10 [00:00<00:00, 137.35it/s, correct=52.24%, skipped=24.86%]\n","100%|██████████| 20/20 [00:00<00:00, 132.61it/s, correct=53.63%, skipped=24.15%]\n","100%|██████████| 50/50 [00:00<00:00, 141.46it/s, correct=54.30%, skipped=24.68%]\n","100%|██████████| 10/10 [00:00<00:00, 121.06it/s, correct=54.05%, skipped=24.93%]\n","100%|██████████| 20/20 [00:00<00:00, 120.97it/s, correct=53.53%, skipped=25.40%]\n","100%|██████████| 50/50 [00:00<00:00, 155.15it/s, correct=54.21%, skipped=24.62%]\n","100%|██████████| 10/10 [00:00<00:00, 132.96it/s, correct=53.20%, skipped=24.15%]\n","100%|██████████| 20/20 [00:00<00:00, 131.29it/s, correct=52.10%, skipped=24.60%]\n","100%|██████████| 50/50 [00:00<00:00, 139.29it/s, correct=52.76%, skipped=24.88%]\n","100%|██████████| 10/10 [00:00<00:00, 129.75it/s, correct=53.15%, skipped=24.28%]\n","100%|██████████| 20/20 [00:00<00:00, 122.74it/s, correct=52.80%, skipped=24.00%]\n","100%|██████████| 50/50 [00:00<00:00, 145.70it/s, correct=51.14%, skipped=24.57%]\n","100%|██████████| 10/10 [00:00<00:00, 131.42it/s, correct=53.50%, skipped=24.54%]\n","100%|██████████| 20/20 [00:00<00:00, 132.51it/s, correct=53.41%, skipped=24.72%]\n","100%|██████████| 50/50 [00:00<00:00, 154.48it/s, correct=55.21%, skipped=23.91%]\n","100%|██████████| 10/10 [00:00<00:00, 105.99it/s, correct=52.53%, skipped=24.48%]\n","100%|██████████| 20/20 [00:00<00:00, 136.50it/s, correct=53.21%, skipped=24.93%]\n","100%|██████████| 50/50 [00:00<00:00, 133.18it/s, correct=54.43%, skipped=24.28%]\n","100%|██████████| 10/10 [00:00<00:00, 119.62it/s, correct=53.11%, skipped=24.99%]\n","100%|██████████| 20/20 [00:00<00:00, 135.82it/s, correct=53.29%, skipped=25.13%]\n","100%|██████████| 50/50 [00:00<00:00, 147.54it/s, correct=54.29%, skipped=25.27%]\n","100%|██████████| 10/10 [00:00<00:00, 114.81it/s, correct=52.42%, skipped=24.37%]\n","100%|██████████| 20/20 [00:00<00:00, 133.19it/s, correct=52.97%, skipped=24.87%]\n","100%|██████████| 50/50 [00:00<00:00, 152.95it/s, correct=52.74%, skipped=24.88%]\n","100%|██████████| 10/10 [00:00<00:00, 133.68it/s, correct=53.01%, skipped=24.72%]\n","100%|██████████| 20/20 [00:00<00:00, 143.85it/s, correct=51.87%, skipped=24.65%]\n","100%|██████████| 50/50 [00:00<00:00, 143.25it/s, correct=64.64%, skipped=24.66%]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HaC4SPQhRBXh","outputId":"74b7476b-b233-40cf-bc92-749d9e3c57b9","colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["pd.DataFrame(scores.score.tolist(), index=scores[['PCT','factors','regularization','iterations']], columns=['ALS','Popularity']).sort_values(by='ALS', ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ALS</th>\n","      <th>Popularity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(0.3, 127, 0.2, 10)</th>\n","      <td>0.394</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>(0.3, 127, 0.2, 20)</th>\n","      <td>0.300</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>(0.3, 127, 0.2, 50)</th>\n","      <td>0.232</td>\n","      <td>0.602</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       ALS  Popularity\n","(0.3, 127, 0.2, 10)  0.394       0.602\n","(0.3, 127, 0.2, 20)  0.300       0.602\n","(0.3, 127, 0.2, 50)  0.232       0.602"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"id":"UY-3a4BgPrDw","outputId":"4f0ba189-4311-4aa3-8b2c-6b44247186db","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# ALS best parameters - (0.2, 128, 0.05, 20)\t\n","# BPR best parameters - (0.2, 127, 0.05, 20)\t\n","\n","df_n = pd.DataFrame()\n","df_n = calculate_recommendations(df_n, model_name='als', factors=128, regularization=0.05, iterations=20)\n","df_n = calculate_recommendations(df_n, model_name='bpr', factors=127, regularization=0.05, iterations=20)\n","df_n.to_csv('recommendations.csv')\n","df_n.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50.0/50 [00:00<00:00, 153.78it/s]\n","100%|██████████| 20/20 [00:00<00:00, 121.75it/s, correct=55.94%, skipped=34.42%]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id als</th>\n","      <th>recommendation als</th>\n","      <th>score als</th>\n","      <th>customer_id bpr</th>\n","      <th>recommendation bpr</th>\n","      <th>score bpr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000000000000</td>\n","      <td>90596</td>\n","      <td>0.008612</td>\n","      <td>1000000000000</td>\n","      <td>64293</td>\n","      <td>0.098874</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000000000000</td>\n","      <td>64274</td>\n","      <td>0.008383</td>\n","      <td>1000000000000</td>\n","      <td>57616</td>\n","      <td>0.091008</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000000000000</td>\n","      <td>90387</td>\n","      <td>0.008383</td>\n","      <td>1000000000000</td>\n","      <td>89962</td>\n","      <td>0.089681</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000000000000</td>\n","      <td>51754</td>\n","      <td>0.008383</td>\n","      <td>1000000000000</td>\n","      <td>55467</td>\n","      <td>0.085606</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000000000000</td>\n","      <td>51694</td>\n","      <td>0.008383</td>\n","      <td>1000000000000</td>\n","      <td>51053</td>\n","      <td>0.076858</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id als  recommendation als  score als  customer_id bpr  \\\n","0    1000000000000               90596   0.008612    1000000000000   \n","1    1000000000000               64274   0.008383    1000000000000   \n","2    1000000000000               90387   0.008383    1000000000000   \n","3    1000000000000               51754   0.008383    1000000000000   \n","4    1000000000000               51694   0.008383    1000000000000   \n","\n","   recommendation bpr  score bpr  \n","0               64293   0.098874  \n","1               57616   0.091008  \n","2               89962   0.089681  \n","3               55467   0.085606  \n","4               51053   0.076858  "]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"markdown","metadata":{"id":"23_0lqemJ7te"},"source":["### References\n","1.\thttps://www.benfrederickson.com/distance-metrics/\n","2.\thttps://github.com/benfred/bens-blog-code/blob/master/distance-metrics/calculate_similar.py\n","3.\thttps://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/\n","4.\thttps://www.benfrederickson.com/fast-implicit-matrix-factorization/\n","5.\thttps://www.ethanrosenthal.com/2016/10/19/implicit-mf-part-1/\n","6.\thttps://jessesw.com/Rec-System/\n","7.\thttps://github.com/benfred/implicit/blob/master/examples/lastfm.py\n","8.\thttps://github.com/benfred/implicit\n","9.\thttps://towardsdatascience.com/large-scale-jobs-recommendation-engine-using-implicit-data-in-pyspark-ccf8df5d910e\n","10.\thttp://activisiongamescience.github.io/2016/01/11/Implicit-Recommender-Systems-Biased-Matrix-Factorization/\n","11.\thttps://arxiv.org/pdf/1705.00105.pdf\n","12.\thttps://www.ijcai.org/Proceedings/15/Papers/255.pdf\n","13.\thttps://www.kaggle.com/c/msdchallenge/\n","14.\thttps://stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf\n","15.\thttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.5120&rep=rep1&type=pdf \n","16.\thttp://adrem.uantwerpen.be/bibrem/pubs/verstrepen15PhDthesis.pdf \n","17.\thttps://pdfs.semanticscholar.org/eb95/7789f53814a290bc0f8bb01dd01cbd0746cc.pdf \n","18.\thttps://implicit.readthedocs.io/en/latest/ \n","19.\thttps://github.com/akhilesh-reddy/Implicit-data-based-recommendation-system/blob/master/Implicit%20data%20based%20recommendation%20system%20using%20ALS.ipynb \n"]}]}