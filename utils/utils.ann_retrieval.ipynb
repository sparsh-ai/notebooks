{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils.ann_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Retrieval\n",
    "> Implementation of ANN (Approximate Nearest Neighbor) based retrieving algorithms.\n",
    "\n",
    "A typical recommender system has two phases: preference learning and recommendation retrieval. While the former can be done offline, the latter needs to be fast. However, the cost of linearly scanning through the whole set of billions of items are prohibitive or sometimes even impossible.\n",
    "\n",
    "To compute the nearest neighbors in the embedding space, the system can exhaustively score every potential candidate. Exhaustive scoring can be expensive for very large corpora, but you can use either of the following strategies to make it more efficient:\n",
    "- If the query embedding is known statically, the system can perform exhaustive scoring offline, precomputing and storing a list of the top candidates for each query. This is a common practice for related-item recommendation.\n",
    "- Use approximate nearest neighbors.\n",
    "\n",
    "Here, we are using the 2nd option - The ANN.\n",
    "\n",
    "<img src='https://github.com/recohut/reco-static/raw/master/media/diagrams/ann_retrieval.svg'>\n",
    "\n",
    "As shown in the above diagram, there are two main steps in the embedding-based retrieval system:\n",
    "1. Indexing: documents/items are first converted to vectors using deep learning models (aka embedding models). They are then stored in RAM and exportable to disk.\n",
    "2. Retrieving: a user query is first converted to its vector representation. Retrieving modules then uses this query vector to evaluate similarity against indexed documents and returns top-scored ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss\n",
    "!pip install nmslib\n",
    "!apt-get install libomp-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import faiss\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-28 05:20:34--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  29.6MB/s    in 0.2s    \n",
      "\n",
      "2022-01-28 05:20:35 (29.6 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
      "\n",
      "Archive:  ml-1m.zip\n",
      "   creating: ml-1m/\n",
      "  inflating: ml-1m/movies.dat        \n",
      "  inflating: ml-1m/ratings.dat       \n",
      "  inflating: ml-1m/README            \n",
      "  inflating: ml-1m/users.dat         \n"
     ]
    }
   ],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-870e4189-5e6a-4204-9350-daa63712929c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870e4189-5e6a-4204-9350-daa63712929c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-870e4189-5e6a-4204-9350-daa63712929c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-870e4189-5e6a-4204-9350-daa63712929c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   movieId                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', header=None).drop_duplicates()\n",
    "data.columns = ['movieId', 'title', 'genres']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use USE (Universal Sentence Encoder) model which has been trained to learn representation of a sentence semantic meaning from large public corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = data['title'].to_list()[:2000]\n",
    "# # OOM for large document size\n",
    "embeddings = embed(documents).numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally-Sensitive Hashing (LSH)\n",
    "LSH is a very classical binary hash. Its core is to create multiple hash functions to map vectors into binary codes. Vectors closely related are expected to hashed into the same codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexLSH():\n",
    "  def __init__(self, dimension, documents, embeddings):\n",
    "    self.dimension = dimension\n",
    "    self.documents = documents\n",
    "    self.embeddings = embeddings\n",
    "\n",
    "  def build(self, num_bits=8):\n",
    "    self.index = faiss.IndexLSH(self.dimension, num_bits)\n",
    "    self.index.add(self.embeddings)\n",
    "\n",
    "  def query(self, input_embedding, k=5):\n",
    "    distances, indices = self.index.search(input_embedding, k)\n",
    "\n",
    "    return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_lsh = IndexLSH(512, documents, embeddings)\n",
    "index_lsh.build(num_bits=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Quantization with Inverted File (IVFPQ)\n",
    "Product Quantization adopts k-means as its core quantizer and drastically increases the number of centroids by dividing each vector into many subvectors and run the quantizer on all of these subvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexIVFPQ():\n",
    "  def __init__(self, dimension, documents, embeddings):\n",
    "    self.dimension = dimension\n",
    "    self.documents = documents\n",
    "    self.embeddings = embeddings\n",
    "\n",
    "  def build(self,\n",
    "            number_of_partition=2,\n",
    "            number_of_subquantizers=2,\n",
    "            subvector_bits=4):\n",
    "    quantizer = faiss.IndexFlatL2(self.dimension)\n",
    "    self.index = faiss.IndexIVFPQ(quantizer, \n",
    "                                  self.dimension,\n",
    "                                  number_of_partition,\n",
    "                                  number_of_subquantizers,\n",
    "                                  subvector_bits)\n",
    "    self.index.train(self.embeddings)\n",
    "    self.index.add(self.embeddings)\n",
    "\n",
    "  def query(self, input_embedding, k=5):\n",
    "    distances, indices = self.index.search(input_embedding, k)\n",
    "\n",
    "    return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "index_pq = IndexIVFPQ(512, documents, embeddings)\n",
    "index_pq.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Navigable Small World Graphs (HNSW)\n",
    "This method relies on exploring the graph based on closeness relation between a node and its neighbors and neighbor's neighbor and so on. HNSW stores the full length vectors and the full graph structure in memory (RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HNSW():\n",
    "  def __init__(self, dimension, documents, embeddings):\n",
    "    self.dimension = dimension\n",
    "    self.documents = documents\n",
    "    self.embeddings = embeddings\n",
    "\n",
    "  def build(self, num_bits=8):\n",
    "    self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "    self.index.addDataPointBatch(self.embeddings)\n",
    "    self.index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "  def query(self, input_embedding, k=5):\n",
    "    indices, distances = self.index.knnQuery(input_embedding, k)\n",
    "\n",
    "    return [(distance, self.documents[index]) for distance, index in zip(distances, indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_hnsw = HNSW(512, documents, embeddings)\n",
    "index_hnsw.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexFlatL2():\n",
    "  def __init__(self, dimension, documents, embeddings):\n",
    "    self.dimension = dimension\n",
    "    self.documents = documents\n",
    "    self.embeddings = embeddings\n",
    "\n",
    "  def build(self, num_bits=8):\n",
    "    self.index = faiss.IndexFlatL2(self.dimension)\n",
    "    self.index.add(self.embeddings)\n",
    "\n",
    "  def query(self, input_embedding, k=5):\n",
    "    distances, indices = self.index.search(input_embedding, k)\n",
    "\n",
    "    return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flat = IndexFlatL2(512, documents, embeddings)\n",
    "index_flat.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ann_top_items(embedding_model, ann_index, query, k=10):\n",
    "    from timeit import default_timer as timer\n",
    "    query_vector = embedding_model([query]).numpy()\n",
    "    search_start = timer()\n",
    "    top_docs = ann_index.query(query_vector, k)\n",
    "    search_time = timer() - search_start\n",
    "    print(\"search time: {:.2f} ms\".format(search_time * 1000))\n",
    "    return top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time: 0.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9557337, 'True Romance (1993)'),\n",
       " (1.2160164, 'Love Serenade (1996)'),\n",
       " (1.2626684, 'Love Affair (1994)'),\n",
       " (1.3447756, 'Kissed (1996)'),\n",
       " (1.3752131, 'In Love and War (1996)'),\n",
       " (1.380403, 'Casablanca (1942)'),\n",
       " (1.3832322, 'Flirt (1995)'),\n",
       " (1.3862598, 'Moonlight and Valentino (1995)'),\n",
       " (1.3862815, 'Hotel de Love (1996)'),\n",
       " (1.3907105, 'Intimate Relations (1996)')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ann_top_items(embed, index_flat, \"romance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time: 0.48 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.0, 'Visitors, The (Les Visiteurs) (1993)'),\n",
       " (2.0, 'City Hall (1996)'),\n",
       " (2.0, 'Paradise Road (1997)'),\n",
       " (3.0, 'When a Man Loves a Woman (1994)'),\n",
       " (3.0, 'Cosi (1996)'),\n",
       " (3.0, 'Haunted World of Edward D. Wood Jr., The (1995)'),\n",
       " (3.0, 'Eddie (1996)'),\n",
       " (3.0, 'Ransom (1996)'),\n",
       " (3.0, 'Time to Kill, A (1996)'),\n",
       " (3.0, 'Mirage (1995)')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ann_top_items(embed, index_lsh, \"romance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time: 0.45 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0426195, 'Falling in Love Again (1980)'),\n",
       " (1.0426195, 'Prom Night III: The Last Kiss (1989)'),\n",
       " (1.063688, 'Love in Bloom (1935)'),\n",
       " (1.063688, 'So Dear to My Heart (1949)'),\n",
       " (1.0789009, \"Romy and Michele's High School Reunion (1997)\"),\n",
       " (1.0789009, 'Farewell My Concubine (1993)'),\n",
       " (1.0789009, 'When Harry Met Sally... (1989)'),\n",
       " (1.0789009, 'Sex, Lies, and Videotape (1989)'),\n",
       " (1.0952816, 'Gaslight (1944)'),\n",
       " (1.0952816, 'Philadelphia Story, The (1940)')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ann_top_items(embed, index_pq, \"romance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time: 0.47 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.47786677, 'True Romance (1993)'),\n",
       " (0.60800815, 'Love Serenade (1996)'),\n",
       " (0.6313339, 'Love Affair (1994)'),\n",
       " (0.67238766, 'Kissed (1996)'),\n",
       " (0.68760645, 'In Love and War (1996)'),\n",
       " (0.6916159, 'Flirt (1995)'),\n",
       " (0.6931299, 'Moonlight and Valentino (1995)'),\n",
       " (0.6931407, 'Hotel de Love (1996)'),\n",
       " (0.6953552, 'Intimate Relations (1996)'),\n",
       " (0.69853836, 'Love in Bloom (1935)')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ann_top_items(embed, index_hnsw, \"romance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2022-01-28 05:39:47\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.144+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "nmslib        : 2.1.1\n",
      "IPython       : 5.5.0\n",
      "tensorflow_hub: 0.12.0\n",
      "pandas        : 1.1.5\n",
      "faiss         : 1.5.3\n",
      "json          : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
