{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-21-rl-tictactoe.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T124730%20%7C%20Solving%20Tic-Tac-Toe%20with%20RL.ipynb","timestamp":1644659225723}],"collapsed_sections":[],"authorship_tag":"ABX9TyPjNrf7Gq07TXjHiCYqm0Eq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UJjPVHRyGvJv"},"source":["# Solving Tic-Tac-Toe with RL"]},{"cell_type":"markdown","metadata":{"id":"lJtdE5VrGvHn"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"XRPPgudTGvCJ"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"rmzCLbs5GtRj"},"source":["from abc import ABC, abstractmethod\n","import os\n","import pickle\n","import collections\n","import numpy as np\n","import random\n","import logging\n","import sys\n","import matplotlib.pylab as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPZkARJYHn4f"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"-vMQQ4PpHn2E"},"source":["class Args:\n","\n","    agent_type = \"q\" # 'q' for Q-learning, 's' for SARSA, Specify the computer agent learning algorithm.\n","    path = None # Specify the path for the agent pickle file. Defaults to q_agent.pkl for AGENT_TYPE='q' and \"sarsa_agent.pkl for AGENT_TYPE='s'.\n","    load = False # whether to load trained agent\n","    teacher_episodes = 0 # employ teacher agent who knows the optimal strategy and will play for TEACHER_EPISODES games"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNzYSmACI6AE"},"source":["def get_args():\n","    args = Args()\n","    # set default path\n","    if args.path is None:\n","        args.path = 'q_agent.pkl' if args.agent_type == 'q' else 'sarsa_agent.pkl'\n","    return args"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"88HpB1D5Iqv9"},"source":["### Logger"]},{"cell_type":"code","metadata":{"id":"aFv-S9b8IqsA"},"source":["logging.basicConfig(stream=sys.stdout,\n","                    level = logging.DEBUG,\n","                    format='%(asctime)s [%(levelname)s] : %(message)s',\n","                    datefmt='%d-%b-%y %H:%M:%S')\n","\n","logger = logging.getLogger('Tic-Tac-Toe Logger')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srWZbZKMGxgB"},"source":["## Utilities"]},{"cell_type":"markdown","metadata":{"id":"YVy692NSHKRp"},"source":["### Environment"]},{"cell_type":"code","metadata":{"id":"ZmlgPQY9HNrM"},"source":["class Game:\n","    \"\"\" The game class. New instance created for each new game. \"\"\"\n","    def __init__(self, agent, teacher=None):\n","        self.agent = agent\n","        self.teacher = teacher\n","        # initialize the game board\n","        self.board = [['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]\n","\n","    def playerMove(self):\n","        \"\"\"\n","        Querry player for a move and update the board accordingly.\n","        \"\"\"\n","        if self.teacher is not None:\n","            action = self.teacher.makeMove(self.board)\n","            self.board[action[0]][action[1]] = 'X'\n","        else:\n","            printBoard(self.board)\n","            while True:\n","                move = input(\"Your move! Please select a row and column from 0-2 \"\n","                             \"in the format row,col: \")\n","                print('\\n')\n","                try:\n","                    row, col = int(move[0]), int(move[2])\n","                except ValueError:\n","                    print(\"INVALID INPUT! Please use the correct format.\")\n","                    continue\n","                if row not in range(3) or col not in range(3) or not self.board[row][col] == '-':\n","                    print(\"INVALID MOVE! Choose again.\")\n","                    continue\n","                self.board[row][col] = 'X'\n","                break\n","\n","    def agentMove(self, action):\n","        \"\"\"\n","        Update board according to agent's move.\n","        \"\"\"\n","        self.board[action[0]][action[1]] = 'O'\n","\n","    def checkForWin(self, key):\n","        \"\"\"\n","        Check to see whether the player/agent with token 'key' has won.\n","        Returns a boolean holding truth value.\n","        Parameters\n","        ----------\n","        key : string\n","            token of most recent player. Either 'O' or 'X'\n","        \"\"\"\n","        # check for player win on diagonals\n","        a = [self.board[0][0], self.board[1][1], self.board[2][2]]\n","        b = [self.board[0][2], self.board[1][1], self.board[2][0]]\n","        if a.count(key) == 3 or b.count(key) == 3:\n","            return True\n","        # check for player win on rows/columns\n","        for i in range(3):\n","            col = [self.board[0][i], self.board[1][i], self.board[2][i]]\n","            row = [self.board[i][0], self.board[i][1], self.board[i][2]]\n","            if col.count(key) == 3 or row.count(key) == 3:\n","                return True\n","        return False\n","\n","    def checkForDraw(self):\n","        \"\"\"\n","        Check to see whether the game has ended in a draw. Returns a\n","        boolean holding truth value.\n","        \"\"\"\n","        draw = True\n","        for row in self.board:\n","            for elt in row:\n","                if elt == '-':\n","                    draw = False\n","        return draw\n","\n","    def checkForEnd(self, key):\n","        \"\"\"\n","        Checks if player/agent with token 'key' has ended the game. Returns -1\n","        if the game is still going, 0 if it is a draw, and 1 if the player/agent\n","        has won.\n","        Parameters\n","        ----------\n","        key : string\n","            token of most recent player. Either 'O' or 'X'\n","        \"\"\"\n","        if self.checkForWin(key):\n","            if self.teacher is None:\n","                printBoard(self.board)\n","                if key == 'X':\n","                    logger.info(\"Player wins!\")\n","                else:\n","                    logger.info(\"RL agent wins!\")\n","            return 1\n","        elif self.checkForDraw():\n","            if self.teacher is None:\n","                printBoard(self.board)\n","                logger.info(\"It's a draw!\")\n","            return 0\n","        return -1\n","\n","    def playGame(self, player_first):\n","        \"\"\" \n","        Begin the tic-tac-toe game loop. \n","        Parameters\n","        ----------\n","        player_first : boolean\n","            Whether or not the player will move first. If False, the\n","            agent goes first.\n","        \"\"\"\n","        # Initialize the agent's state and action\n","        if player_first:\n","            self.playerMove()\n","        prev_state = getStateKey(self.board)\n","        prev_action = self.agent.get_action(prev_state)\n","\n","        # iterate until game is over\n","        while True:\n","            # execute oldAction, observe reward and state\n","            self.agentMove(prev_action)\n","            check = self.checkForEnd('O')\n","            if not check == -1:\n","                # game is over. +1 reward if win, 0 if draw\n","                reward = check\n","                break\n","            self.playerMove()\n","            check = self.checkForEnd('X')\n","            if not check == -1:\n","                # game is over. -1 reward if lose, 0 if draw\n","                reward = -1*check\n","                break\n","            else:\n","                # game continues. 0 reward\n","                reward = 0\n","            new_state = getStateKey(self.board)\n","\n","            # determine new action (epsilon-greedy)\n","            new_action = self.agent.get_action(new_state)\n","            # update Q-values\n","            self.agent.update(prev_state, new_state, prev_action, new_action, reward)\n","            # reset \"previous\" values\n","            prev_state = new_state\n","            prev_action = new_action\n","            # append reward\n","\n","        # Game over. Perform final update\n","        self.agent.update(prev_state, None, prev_action, None, reward)\n","\n","    def start(self):\n","        \"\"\"\n","        Function to determine who moves first, and subsequently, start the game.\n","        If a teacher is employed, first mover is selected at random.\n","        If a human is playing, the human is asked whether he/she would\n","        like to move fist. \n","        \"\"\"\n","        if self.teacher is not None:\n","            # During teaching, chose who goes first randomly with equal probability\n","            if random.random() < 0.5:\n","                self.playGame(player_first=False)\n","            else:\n","                self.playGame(player_first=True)\n","        else:\n","            while True:\n","                response = input(\"Would you like to go first? [y/n]: \")\n","                print('')\n","                if response == 'n' or response == 'no':\n","                    self.playGame(player_first=False)\n","                    break\n","                elif response == 'y' or response == 'yes':\n","                    self.playGame(player_first=True)\n","                    break\n","                else:\n","                    logger.info(\"Invalid input. Please enter 'y' or 'n'.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsTSglgTHPqj"},"source":["def printBoard(board):\n","    \"\"\"\n","    Prints the game board as text output to the terminal.\n","    Parameters\n","    ----------\n","    board : list of lists\n","        the current game board\n","    \"\"\"\n","    print('    0   1   2\\n')\n","    for i, row in enumerate(board):\n","        print('%i   ' % i, end='')\n","        for elt in row:\n","            print('%s   ' % elt, end='')\n","        print('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5IzHwSPHRbW"},"source":["def getStateKey(board):\n","    \"\"\"\n","    Converts 2D list representing the board state into a string key\n","    for that state. Keys are used for Q-value hashing.\n","    Parameters\n","    ----------\n","    board : list of lists\n","        the current game board\n","    \"\"\"\n","    key = ''\n","    for row in board:\n","        for elt in row:\n","            key += elt\n","    return key"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWpDJ8h0HVwb"},"source":["class Teacher:\n","    \"\"\" \n","    A class to implement a teacher that knows the optimal playing strategy.\n","    Teacher returns the best move at any time given the current state of the game.\n","    Note: things are a bit more hard-coded here, as this was not the main focus of\n","    the exercise so I did not spend as much time on design/style. Everything works\n","    properly when tested.\n","    Parameters\n","    ----------\n","    level : float \n","        teacher ability level. This is a value between 0-1 that indicates the\n","        probability of making the optimal move at any given time.\n","    \"\"\"\n","\n","    def __init__(self, level=0.9):\n","        \"\"\"\n","        Ability level determines the probability that the teacher will follow\n","        the optimal strategy as opposed to choosing a random available move.\n","        \"\"\"\n","        self.ability_level = level\n","\n","    def win(self, board, key='X'):\n","        \"\"\" If we have two in a row and the 3rd is available, take it. \"\"\"\n","        # Check for diagonal wins\n","        a = [board[0][0], board[1][1], board[2][2]]\n","        b = [board[0][2], board[1][1], board[2][0]]\n","        if a.count('-') == 1 and a.count(key) == 2:\n","            ind = a.index('-')\n","            return ind, ind\n","        elif b.count('-') == 1 and b.count(key) == 2:\n","            ind = b.index('-')\n","            if ind == 0:\n","                return 0, 2\n","            elif ind == 1:\n","                return 1, 1\n","            else:\n","                return 2, 0\n","        # Now check for 2 in a row/column + empty 3rd\n","        for i in range(3):\n","            c = [board[0][i], board[1][i], board[2][i]]\n","            d = [board[i][0], board[i][1], board[i][2]]\n","            if c.count('-') == 1 and c.count(key) == 2:\n","                ind = c.index('-')\n","                return ind, i\n","            elif d.count('-') == 1 and d.count(key) == 2:\n","                ind = d.index('-')\n","                return i, ind\n","        return None\n","\n","    def blockWin(self, board):\n","        \"\"\" Block the opponent if she has a win available. \"\"\"\n","        return self.win(board, key='O')\n","\n","    def fork(self, board):\n","        \"\"\" Create a fork opportunity such that we have 2 threats to win. \"\"\"\n","        # Check all adjacent side middles\n","        if board[1][0] == 'X' and board[0][1] == 'X':\n","            if board[0][0] == '-' and board[2][0] == '-' and board[0][2] == '-':\n","                return 0, 0\n","            elif board[1][1] == '-' and board[2][1] == '-' and board[1][2] == '-':\n","                return 1, 1\n","        elif board[1][0] == 'X' and board[2][1] == 'X':\n","            if board[2][0] == '-' and board[0][0] == '-' and board[2][2] == '-':\n","                return 2, 0\n","            elif board[1][1] == '-' and board[0][1] == '-' and board[1][2] == '-':\n","                return 1, 1\n","        elif board[2][1] == 'X' and board[1][2] == 'X':\n","            if board[2][2] == '-' and board[2][0] == '-' and board[0][2] == '-':\n","                return 2, 2\n","            elif board[1][1] == '-' and board[1][0] == '-' and board[0][1] == '-':\n","                return 1, 1\n","        elif board[1][2] == 'X' and board[0][1] == 'X':\n","            if board[0][2] == '-' and board[0][0] == '-' and board[2][2] == '-':\n","                return 0, 2\n","            elif board[1][1] == '-' and board[1][0] == '-' and board[2][1] == '-':\n","                return 1, 1\n","        # Check all cross corners\n","        elif board[0][0] == 'X' and board[2][2] == 'X':\n","            if board[1][0] == '-' and board[2][1] == '-' and board[2][0] == '-':\n","                return 2, 0\n","            elif board[0][1] == '-' and board[1][2] == '-' and board[0][2] == '-':\n","                return 0, 2\n","        elif board[2][0] == 'X' and board[0][2] == 'X':\n","            if board[2][1] == '-' and board[1][2] == '-' and board[2][2] == '-':\n","                return 2, 2\n","            elif board[1][0] == '-' and board[0][1] == '-' and board[0][0] == '-':\n","                return 0, 0\n","        return None\n","\n","    def blockFork(self, board):\n","        \"\"\" Block the opponents fork if she has one available. \"\"\"\n","        corners = [board[0][0], board[2][0], board[0][2], board[2][2]]\n","        # Check all adjacent side middles\n","        if board[1][0] == 'O' and board[0][1] == 'O':\n","            if board[0][0] == '-' and board[2][0] == '-' and board[0][2] == '-':\n","                return 0, 0\n","            elif board[1][1] == '-' and board[2][1] == '-' and board[1][2] == '-':\n","                return 1, 1\n","        elif board[1][0] == 'O' and board[2][1] == 'O':\n","            if board[2][0] == '-' and board[0][0] == '-' and board[2][2] == '-':\n","                return 2, 0\n","            elif board[1][1] == '-' and board[0][1] == '-' and board[1][2] == '-':\n","                return 1, 1\n","        elif board[2][1] == 'O' and board[1][2] == 'O':\n","            if board[2][2] == '-' and board[2][0] == '-' and board[0][2] == '-':\n","                return 2, 2\n","            elif board[1][1] == '-' and board[1][0] == '-' and board[0][1] == '-':\n","                return 1, 1\n","        elif board[1][2] == 'O' and board[0][1] == 'O':\n","            if board[0][2] == '-' and board[0][0] == '-' and board[2][2] == '-':\n","                return 0, 2\n","            elif board[1][1] == '-' and board[1][0] == '-' and board[2][1] == '-':\n","                return 1, 1\n","        # Check all cross corners (first check for double fork opp using the corners array)\n","        elif corners.count('-') == 1 and corners.count('O') == 2:\n","            return 1, 2\n","        elif board[0][0] == 'O' and board[2][2] == 'O':\n","            if board[1][0] == '-' and board[2][1] == '-' and board[2][0] == '-':\n","                return 2, 0\n","            elif board[0][1] == '-' and board[1][2] == '-' and board[0][2] == '-':\n","                return 0, 2\n","        elif board[2][0] == 'O' and board[0][2] == 'O':\n","            if board[2][1] == '-' and board[1][2] == '-' and board[2][2] == '-':\n","                return 2, 2\n","            elif board[1][0] == '-' and board[0][1] == '-' and board[0][0] == '-':\n","                return 0, 0\n","        return None\n","\n","    def center(self, board):\n","        \"\"\" Pick the center if it is available. \"\"\"\n","        if board[1][1] == '-':\n","            return 1, 1\n","        return None\n","\n","    def corner(self, board):\n","        \"\"\" Pick a corner move. \"\"\"\n","        # Pick opposite corner of opponent if available\n","        if board[0][0] == 'O' and board[2][2] == '-':\n","            return 2, 2\n","        elif board[2][0] == 'O' and board[0][2] == '-':\n","            return 0, 2\n","        elif board[0][2] == 'O' and board[2][0] == '-':\n","            return 2, 0\n","        elif board[2][2] == 'O' and board[0][0] == '-':\n","            return 0, 0\n","        # Pick any corner if no opposites are available\n","        elif board[0][0] == '-':\n","            return 0, 0\n","        elif board[2][0] == '-':\n","            return 2, 0\n","        elif board[0][2] == '-':\n","            return 0, 2\n","        elif board[2][2] == '-':\n","            return 2, 2\n","        return None\n","\n","    def sideEmpty(self, board):\n","        \"\"\" Pick an empty side. \"\"\"\n","        if board[1][0] == '-':\n","            return 1, 0\n","        elif board[2][1] == '-':\n","            return 2, 1\n","        elif board[1][2] == '-':\n","            return 1, 2\n","        elif board[0][1] == '-':\n","            return 0, 1\n","        return None\n","\n","    def randomMove(self, board):\n","        \"\"\" Chose a random move from the available options. \"\"\"\n","        possibles = []\n","        for i in range(3):\n","            for j in range(3):\n","                if board[i][j] == '-':\n","                    possibles += [(i, j)]\n","        return possibles[random.randint(0, len(possibles)-1)]\n","\n","    def makeMove(self, board):\n","        \"\"\"\n","        Trainer goes through a hierarchy of moves, making the best move that\n","        is currently available each time. A touple is returned that represents\n","        (row, col).\n","        \"\"\"\n","        # Chose randomly with some probability so that the teacher does not always win\n","        if random.random() > self.ability_level:\n","            return self.randomMove(board)\n","        # Follow optimal strategy\n","        a = self.win(board)\n","        if a is not None:\n","            return a\n","        a = self.blockWin(board)\n","        if a is not None:\n","            return a\n","        a = self.fork(board)\n","        if a is not None:\n","            return a\n","        a = self.blockFork(board)\n","        if a is not None:\n","            return a\n","        a = self.center(board)\n","        if a is not None:\n","            return a\n","        a = self.corner(board)\n","        if a is not None:\n","            return a\n","        a = self.sideEmpty(board)\n","        if a is not None:\n","            return a\n","        return self.randomMove(board)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qH9W2XIYG0dx"},"source":["### Agents"]},{"cell_type":"code","metadata":{"id":"j7pws19vG1Ro"},"source":["class Learner(ABC):\n","    \"\"\"\n","    Parent class for Q-learning and SARSA agents.\n","    Parameters\n","    ----------\n","    alpha : float \n","        learning rate\n","    gamma : float\n","        temporal discounting rate\n","    eps : float \n","        probability of random action vs. greedy action\n","    eps_decay : float\n","        epsilon decay rate. Larger value = more decay\n","    \"\"\"\n","    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n","        # Agent parameters\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.eps = eps\n","        self.eps_decay = eps_decay\n","        # Possible actions correspond to the set of all x,y coordinate pairs\n","        self.actions = []\n","        for i in range(3):\n","            for j in range(3):\n","                self.actions.append((i,j))\n","        # Initialize Q values to 0 for all state-action pairs.\n","        # Access value for action a, state s via Q[a][s]\n","        self.Q = {}\n","        for action in self.actions:\n","            self.Q[action] = collections.defaultdict(int)\n","        # Keep a list of reward received at each episode\n","        self.rewards = []\n","\n","    def get_action(self, s):\n","        \"\"\"\n","        Select an action given the current game state.\n","        Parameters\n","        ----------\n","        s : string\n","            state\n","        \"\"\"\n","        # Only consider the allowed actions (empty board spaces)\n","        possible_actions = [a for a in self.actions if s[a[0]*3 + a[1]] == '-']\n","        if random.random() < self.eps:\n","            # Random choose.\n","            action = possible_actions[random.randint(0,len(possible_actions)-1)]\n","        else:\n","            # Greedy choose.\n","            values = np.array([self.Q[a][s] for a in possible_actions])\n","            # Find location of max\n","            ix_max = np.where(values == np.max(values))[0]\n","            if len(ix_max) > 1:\n","                # If multiple actions were max, then sample from them\n","                ix_select = np.random.choice(ix_max, 1)[0]\n","            else:\n","                # If unique max action, select that one\n","                ix_select = ix_max[0]\n","            action = possible_actions[ix_select]\n","\n","        # update epsilon; geometric decay\n","        self.eps *= (1.-self.eps_decay)\n","\n","        return action\n","\n","    def save(self, path):\n","        \"\"\" Pickle the agent object instance to save the agent's state. \"\"\"\n","        if os.path.isfile(path):\n","            os.remove(path)\n","        f = open(path, 'wb')\n","        pickle.dump(self, f)\n","        logger.info('model saved at {}'.format(path))\n","        f.close()\n","\n","    @abstractmethod\n","    def update(self, s, s_, a, a_, r):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8bLpKyrG88e"},"source":["class Qlearner(Learner):\n","    \"\"\"\n","    A class to implement the Q-learning agent.\n","    \"\"\"\n","    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n","        super().__init__(alpha, gamma, eps, eps_decay)\n","\n","    def update(self, s, s_, a, a_, r):\n","        \"\"\"\n","        Perform the Q-Learning update of Q values.\n","        Parameters\n","        ----------\n","        s : string\n","            previous state\n","        s_ : string\n","            new state\n","        a : (i,j) tuple\n","            previous action\n","        a_ : (i,j) tuple\n","            new action. NOT used by Q-learner!\n","        r : int\n","            reward received after executing action \"a\" in state \"s\"\n","        \"\"\"\n","        # Update Q(s,a)\n","        if s_ is not None:\n","            # hold list of Q values for all a_,s_ pairs. We will access the max later\n","            possible_actions = [action for action in self.actions if s_[action[0]*3 + action[1]] == '-']\n","            Q_options = [self.Q[action][s_] for action in possible_actions]\n","            # update\n","            self.Q[a][s] += self.alpha*(r + self.gamma*max(Q_options) - self.Q[a][s])\n","        else:\n","            # terminal state update\n","            self.Q[a][s] += self.alpha*(r - self.Q[a][s])\n","\n","        # add r to rewards list\n","        self.rewards.append(r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZJtaD-IHCcu"},"source":["class SARSAlearner(Learner):\n","    \"\"\"\n","    A class to implement the SARSA agent.\n","    \"\"\"\n","    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n","        super().__init__(alpha, gamma, eps, eps_decay)\n","\n","    def update(self, s, s_, a, a_, r):\n","        \"\"\"\n","        Perform the SARSA update of Q values.\n","        Parameters\n","        ----------\n","        s : string\n","            previous state\n","        s_ : string\n","            new state\n","        a : (i,j) tuple\n","            previous action\n","        a_ : (i,j) tuple\n","            new action\n","        r : int\n","            reward received after executing action \"a\" in state \"s\"\n","        \"\"\"\n","        # Update Q(s,a)\n","        if s_ is not None:\n","            self.Q[a][s] += self.alpha*(r + self.gamma*self.Q[a_][s_] - self.Q[a][s])\n","        else:\n","            # terminal state update\n","            self.Q[a][s] += self.alpha*(r - self.Q[a][s])\n","\n","        # add r to rewards list\n","        self.rewards.append(r)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQ8SxunXHEmm"},"source":["### Simulation"]},{"cell_type":"code","metadata":{"id":"5pEDMNBzHaLu"},"source":["class GameLearning(object):\n","    \"\"\"\n","    A class that holds the state of the learning process. Learning\n","    agents are created/loaded here, and a count is kept of the\n","    games that have been played.\n","    \"\"\"\n","    def __init__(self, args, alpha=0.5, gamma=0.9, epsilon=0.1):\n","\n","        if args.load:\n","            # load an existing agent and continue training\n","            if not os.path.isfile(args.path):\n","                raise ValueError(\"Cannot load agent: file does not exist.\")\n","            with open(args.path, 'rb') as f:\n","                agent = pickle.load(f)\n","        else:\n","            # check if agent state file already exists, and ask\n","            # user whether to overwrite if so\n","            if os.path.isfile(args.path):\n","                print('An agent is already saved at {}.'.format(args.path))\n","                while True:\n","                    response = input(\"Are you sure you want to overwrite? [y/n]: \")\n","                    if response.lower() in ['y', 'yes']:\n","                        break\n","                    elif response.lower() in ['n', 'no']:\n","                        print(\"OK. Quitting.\")\n","                        sys.exit(0)\n","                    else:\n","                        print(\"Invalid input. Please choose 'y' or 'n'.\")\n","            if args.agent_type == \"q\":\n","                agent = Qlearner(alpha,gamma,epsilon)\n","            else:\n","                agent = SARSAlearner(alpha,gamma,epsilon)\n","\n","        self.games_played = 0\n","        self.path = args.path\n","        self.agent = agent\n","\n","    def beginPlaying(self):\n","        \"\"\" Loop through game iterations with a human player. \"\"\"\n","        print(\"Welcome to Tic-Tac-Toe. You are 'X' and the computer is 'O'.\")\n","\n","        def play_again():\n","            logger.info(\"Games played: %i\" % self.games_played)\n","            while True:\n","                play = input(\"Do you want to play again? [y/n]: \")\n","                if play == 'y' or play == 'yes':\n","                    return True\n","                elif play == 'n' or play == 'no':\n","                    return False\n","                else:\n","                    print(\"Invalid input. Please choose 'y' or 'n'.\")\n","\n","        while True:\n","            game = Game(self.agent)\n","            game.start()\n","            self.games_played += 1\n","            self.agent.save(self.path)\n","            if not play_again():\n","                print(\"OK. Quitting.\")\n","                break\n","\n","    def beginTeaching(self, episodes):\n","        \"\"\" Loop through game iterations with a teaching agent. \"\"\"\n","        teacher = Teacher()\n","        # Train for alotted number of episodes\n","        while self.games_played < episodes:\n","            game = Game(self.agent, teacher=teacher)\n","            game.start()\n","            self.games_played += 1\n","            # Monitor progress\n","            if self.games_played % 1000 == 0:\n","                logger.info(\"Games played: %i\" % self.games_played)\n","        # save final agent\n","        self.agent.save(self.path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvyXNaD8NZxh"},"source":["def plot_agent_reward(rewards):\n","    \"\"\" Function to plot agent's accumulated reward vs. iteration \"\"\"\n","    plt.plot(np.cumsum(rewards))\n","    plt.title('Agent Cumulative Reward vs. Iteration')\n","    plt.ylabel('Reward')\n","    plt.xlabel('Episode')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubJKwtnfHk4Z"},"source":["## Jobs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2O_yKZIJCBq","executionInfo":{"status":"ok","timestamp":1636368743926,"user_tz":-330,"elapsed":3453,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"026f9131-3781-4e9f-8c2d-8949d78e72ad"},"source":["logger.info('JOB START: employing expert to play game with q-learning')\n","# get default args\n","args = get_args()\n","# set args\n","args.teacher_episodes = 1000\n","# initialize game instance\n","gl = GameLearning(args)\n","# letting teacher/expert play\n","gl.beginTeaching(args.teacher_episodes)\n","logger.info('JOB END: employing expert to play game with q-learning')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08-Nov-21 10:52:21 [INFO] : JOB START: employing expert to play game with q-learning\n","An agent is already saved at q_agent.pkl.\n","Are you sure you want to overwrite? [y/n]: y\n","08-Nov-21 10:52:23 [INFO] : Games played: 1000\n","08-Nov-21 10:52:23 [INFO] : JOB END: employing expert to play game with q-learning\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iy8PXK-jKCb3","executionInfo":{"status":"ok","timestamp":1636369010929,"user_tz":-330,"elapsed":210964,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"aee17fb2-baa2-4ba2-8418-3f2a90376e68"},"source":["logger.info('JOB START: playing game with on q-learning')\n","# get default args\n","args = get_args()\n","# initialize game instance\n","gl = GameLearning(args)\n","# start playing\n","gl.beginPlaying()\n","logger.info('JOB END: playing game with on q-learning')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08-Nov-21 10:53:20 [INFO] : JOB START: playing game with on q-learning\n","An agent is already saved at q_agent.pkl.\n","Are you sure you want to overwrite? [y/n]: y\n","Welcome to Tic-Tac-Toe. You are 'X' and the computer is 'O'.\n","Would you like to go first? [y/n]: y\n","\n","    0   1   2\n","\n","0   -   -   -   \n","\n","1   -   -   -   \n","\n","2   -   -   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 2,0\n","\n","\n","    0   1   2\n","\n","0   -   -   -   \n","\n","1   -   O   -   \n","\n","2   X   -   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 0,0\n","\n","\n","    0   1   2\n","\n","0   X   -   -   \n","\n","1   O   O   -   \n","\n","2   X   -   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 1,2\n","\n","\n","    0   1   2\n","\n","0   X   -   -   \n","\n","1   O   O   X   \n","\n","2   X   O   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 0,1\n","\n","\n","    0   1   2\n","\n","0   X   X   O   \n","\n","1   O   O   X   \n","\n","2   X   O   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 2,2\n","\n","\n","    0   1   2\n","\n","0   X   X   O   \n","\n","1   O   O   X   \n","\n","2   X   O   X   \n","\n","It's a draw!\n","08-Nov-21 10:56:46 [INFO] : Games played: 1\n","Do you want to play again? [y/n]: n\n","OK. Quitting.\n","08-Nov-21 10:56:51 [INFO] : JOB END: playing game with on q-learning\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3zBiNu9K-Iw","executionInfo":{"status":"ok","timestamp":1636369066774,"user_tz":-330,"elapsed":14044,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0fedd5ee-cbd0-4a0f-c103-18cc843309bc"},"source":["logger.info('JOB START: employing expert to play game with sarsa')\n","# get default args\n","args = get_args()\n","# set args\n","args.agent_type = 's'\n","args.teacher_episodes = 1000\n","# initialize game instance\n","gl = GameLearning(args)\n","# letting teacher/expert play\n","gl.beginTeaching(args.teacher_episodes)\n","logger.info('JOB END: employing expert to play game with sarsa')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08-Nov-21 10:57:33 [INFO] : JOB START: employing expert to play game with sarsa\n","An agent is already saved at q_agent.pkl.\n","Are you sure you want to overwrite? [y/n]: y\n","08-Nov-21 10:57:46 [INFO] : Games played: 1000\n","08-Nov-21 10:57:46 [INFO] : JOB END: employing expert to play game with sarsa\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMfUhft3MjB4","executionInfo":{"status":"ok","timestamp":1636369163872,"user_tz":-330,"elapsed":56277,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a6b201ea-3942-4c9c-eed5-b10a963f1e0f"},"source":["logger.info('JOB START: playing game with on sarsa')\n","# get default args\n","args = get_args()\n","# set args\n","args.agent_type = 's'\n","# initialize game instance\n","gl = GameLearning(args)\n","# start playing\n","gl.beginPlaying()\n","logger.info('JOB END: playing game with on sarsa')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08-Nov-21 10:58:27 [INFO] : JOB START: playing game with on sarsa\n","An agent is already saved at q_agent.pkl.\n","Are you sure you want to overwrite? [y/n]: y\n","Welcome to Tic-Tac-Toe. You are 'X' and the computer is 'O'.\n","Would you like to go first? [y/n]: y\n","\n","    0   1   2\n","\n","0   -   -   -   \n","\n","1   -   -   -   \n","\n","2   -   -   -   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 0,0\n","\n","\n","    0   1   2\n","\n","0   X   -   -   \n","\n","1   -   -   -   \n","\n","2   -   -   O   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 2,0\n","\n","\n","    0   1   2\n","\n","0   X   -   -   \n","\n","1   -   -   O   \n","\n","2   X   -   O   \n","\n","Your move! Please select a row and column from 0-2 in the format row,col: 1,0\n","\n","\n","    0   1   2\n","\n","0   X   -   -   \n","\n","1   X   -   O   \n","\n","2   X   -   O   \n","\n","Player wins!\n","08-Nov-21 10:59:19 [INFO] : Games played: 1\n","Do you want to play again? [y/n]: n\n","OK. Quitting.\n","08-Nov-21 10:59:24 [INFO] : JOB END: playing game with on sarsa\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"FMYcc1OvNjBi","executionInfo":{"status":"ok","timestamp":1636369561996,"user_tz":-330,"elapsed":543,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d5a7e619-e292-4484-933c-16418517ab50"},"source":["logging.getLogger('matplotlib').setLevel(logging.WARNING)\n","logger.info('JOB START: plotting agent rewards')\n","# get default args\n","args = get_args()\n","# loading agent\n","with open(args.path, 'rb') as f:\n","    agent = pickle.load(f)\n","# plot rewards\n","plot_agent_reward(agent.rewards)\n","logger.info('JOB END: plotting agent rewards')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08-Nov-21 11:06:02 [INFO] : JOB START: plotting agent rewards\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["08-Nov-21 11:06:02 [INFO] : JOB END: plotting agent rewards\n"]}]}]}