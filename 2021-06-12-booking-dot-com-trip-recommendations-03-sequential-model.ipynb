{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021-06-12-booking-dot-com-trip-recommendations-03-sequential-model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNPqI5qoI6sRSROP45qwF8W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bd5f013f0d8f4a5dbbed3bee35fb026c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d1f5a71f917042f69cc0fedfbd9237cd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba87625893c8417ea8074e98c10a489a","IPY_MODEL_edc7772376e647868fab2f0e7f559c54"]}},"d1f5a71f917042f69cc0fedfbd9237cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba87625893c8417ea8074e98c10a489a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_671e6bb54604409a9b0ae6607774633a","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":282628,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":282628,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87a936870f8843478321bcd96cb98c9c"}},"edc7772376e647868fab2f0e7f559c54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f90575f1e594a34bff0fbf3a1804744","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 282628/282628 [05:50&lt;00:00, 806.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae0ed2e9ff9e4948817592b33e3f2f59"}},"671e6bb54604409a9b0ae6607774633a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"87a936870f8843478321bcd96cb98c9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f90575f1e594a34bff0fbf3a1804744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ae0ed2e9ff9e4948817592b33e3f2f59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5860510ce0e4017841643bcf020b067":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7dc72bba45cc4619a1e94618daa02532","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e88f652d702467a94e4b12161502132","IPY_MODEL_96cd15f06a6a41058eaa342d0897f308"]}},"7dc72bba45cc4619a1e94618daa02532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e88f652d702467a94e4b12161502132":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96a4849c9bb045ada32905baa47d32c9","_dom_classes":[],"description":" 38%","_model_name":"FloatProgressModel","bar_style":"","max":24,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f246ae8f24474a5d83d8345e02aae694"}},"96cd15f06a6a41058eaa342d0897f308":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8a79b86bab794a2182ce37afe7b8eb94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9/24 [2:41:15&lt;4:44:39, 1138.61s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d10bc5b5c8cf4e4da776b912a4cb4260"}},"96a4849c9bb045ada32905baa47d32c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f246ae8f24474a5d83d8345e02aae694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a79b86bab794a2182ce37afe7b8eb94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d10bc5b5c8cf4e4da776b912a4cb4260":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b54dee9d9aaf48f8ba4307c27fdf3157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f1ce3196d41448d8bf46271e04fba7d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ba9ed5697f449af810ae01c43b7a3b8","IPY_MODEL_d4ef1ea86a6c4600969a5510631f4772"]}},"f1ce3196d41448d8bf46271e04fba7d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ba9ed5697f449af810ae01c43b7a3b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3004880b49f74960ba633a01ab1b4c35","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0021ba7201d347e09b6568862c64c7bd"}},"d4ef1ea86a6c4600969a5510631f4772":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bf6b552ce7645c6b69ee0a9a61b10bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [19:57&lt;00:00, 23.96s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcb8702518fa4aedb86aea8f5139dec7"}},"3004880b49f74960ba633a01ab1b4c35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0021ba7201d347e09b6568862c64c7bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bf6b552ce7645c6b69ee0a9a61b10bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bcb8702518fa4aedb86aea8f5139dec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff6e8aa7364a4f299bd860efce6bd214":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a4f36728ab74059aee9d1ebc263fc2d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_90ff547c175e4a8f936da7651cd21194","IPY_MODEL_a27e914a2314471f82370252b49b58da"]}},"0a4f36728ab74059aee9d1ebc263fc2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90ff547c175e4a8f936da7651cd21194":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c3ead754cd5a49f69ecbed8cbed22402","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ab1bce6c705443f9ce64860a2d3ecf3"}},"a27e914a2314471f82370252b49b58da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2487c7282782404898c10e8f12a2abb6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:16&lt;00:00, 24.33s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4e5ae82c1a34936ace03349423eac99"}},"c3ead754cd5a49f69ecbed8cbed22402":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3ab1bce6c705443f9ce64860a2d3ecf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2487c7282782404898c10e8f12a2abb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4e5ae82c1a34936ace03349423eac99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a88d58b2c41407f93a48de60671182a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ad668fe52544cb0a1f493df5aa498d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a1e47d717054381878a93d2cbac9453","IPY_MODEL_0410eccb4b3c4898a96cfe58e8ff9b0a"]}},"6ad668fe52544cb0a1f493df5aa498d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a1e47d717054381878a93d2cbac9453":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bff8902ef03f41b9a49409ef2bef1bd3","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb2e50a511d545b68231466f365ea5dc"}},"0410eccb4b3c4898a96cfe58e8ff9b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_256e808ecae84e089b76ea4005d87a04","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:20&lt;00:00, 24.41s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b946e6e47f244c98e506ed6320995b6"}},"bff8902ef03f41b9a49409ef2bef1bd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb2e50a511d545b68231466f365ea5dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"256e808ecae84e089b76ea4005d87a04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b946e6e47f244c98e506ed6320995b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"116a22d986b94666b9d63c7c0da270da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f0e01e76ad34b48af4c0c9d4050a786","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_849644cb6a4341cd9c4c42d05123a59b","IPY_MODEL_5a4a65a2328e4502911c863043ebbb06"]}},"5f0e01e76ad34b48af4c0c9d4050a786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"849644cb6a4341cd9c4c42d05123a59b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9e9d836a9e2d480189aeecd6d52fdfd3","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8d3feef68af423da22e5bf2ed4e1523"}},"5a4a65a2328e4502911c863043ebbb06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bbc79301f77048ff87dd9e6504d5f4d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:08&lt;00:00, 24.17s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d9890702aba4fc59d22b5cc4413d93b"}},"9e9d836a9e2d480189aeecd6d52fdfd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8d3feef68af423da22e5bf2ed4e1523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bbc79301f77048ff87dd9e6504d5f4d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0d9890702aba4fc59d22b5cc4413d93b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9cbf6bbd87d492a8783cac7c2b3a148":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ca6e58df9434c3b84d7c1d8afa7022d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ed6b7955cef43efbfdd594a98b1779f","IPY_MODEL_81d9f8351afd4f7491e8317296ba9322"]}},"8ca6e58df9434c3b84d7c1d8afa7022d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ed6b7955cef43efbfdd594a98b1779f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20da5c74e5e44c5fb0eba216e6c1fd8d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c257170ad69240f9a2ce3b717391c7d1"}},"81d9f8351afd4f7491e8317296ba9322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e8f9963b1324f838bcbf09db65357a0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:01&lt;00:00, 24.03s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83d70daba9f3408bbcffc44ca8c7bbbb"}},"20da5c74e5e44c5fb0eba216e6c1fd8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c257170ad69240f9a2ce3b717391c7d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e8f9963b1324f838bcbf09db65357a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"83d70daba9f3408bbcffc44ca8c7bbbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e98c404de6542ad85ab784d17765373":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_992409e46fa94aff8058740c6a64a810","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bedc3a91b8c144e4bdcb0fbef877d2d2","IPY_MODEL_cf5971b21caa4b6baec201dcf6216eed"]}},"992409e46fa94aff8058740c6a64a810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bedc3a91b8c144e4bdcb0fbef877d2d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3df24f839ac34db386dcc968883fab71","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c44cceb3cb944207b334877b8872f371"}},"cf5971b21caa4b6baec201dcf6216eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd3b371138d94d6996740b5b66117065","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:13&lt;00:00, 24.27s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bf19ecfe32643e1859fa38d0a081710"}},"3df24f839ac34db386dcc968883fab71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c44cceb3cb944207b334877b8872f371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd3b371138d94d6996740b5b66117065":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3bf19ecfe32643e1859fa38d0a081710":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2393264f83d480fb7f2bd09bdcbca68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a93d06da02974b2a9f84594f6bf325f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_567200e2fa3f4ffbb5cad40e545916f6","IPY_MODEL_4852e657ad014e22be2ed6549655bbb8"]}},"a93d06da02974b2a9f84594f6bf325f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"567200e2fa3f4ffbb5cad40e545916f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a130abc6fd3d433daa5e314db8449f82","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94163d6093424d7d96a96f431d948260"}},"4852e657ad014e22be2ed6549655bbb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df5de35a223849a5a531c186e2601131","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:12&lt;00:00, 24.25s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_baa0e25b78e543a697616d5edc2a7e26"}},"a130abc6fd3d433daa5e314db8449f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"94163d6093424d7d96a96f431d948260":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df5de35a223849a5a531c186e2601131":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"baa0e25b78e543a697616d5edc2a7e26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ff6b9482d7b47c6af44ec46efce6321":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7730b68e77d49c69bd8476b7b9984e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd45ba78e06d4376ae0d18b7daf413b5","IPY_MODEL_af538c4e37924720b89e5952f9983974"]}},"a7730b68e77d49c69bd8476b7b9984e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd45ba78e06d4376ae0d18b7daf413b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59583a662df04788a830c5ef32d5ea84","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bf4194da3eb4da394ae076582852510"}},"af538c4e37924720b89e5952f9983974":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0b9659a8eda4a35811dcf5d8b879252","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [20:01&lt;00:00, 24.03s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_156917a8062447dd86680c69a388d042"}},"59583a662df04788a830c5ef32d5ea84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3bf4194da3eb4da394ae076582852510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0b9659a8eda4a35811dcf5d8b879252":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"156917a8062447dd86680c69a388d042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b38a8d854b124e18aee92f21d670ac4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5fd6e4526d3f4af0b7bbae2ea4735bdd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dcf30c10b4ba44d896a7251269893021","IPY_MODEL_f7b676044ba14fc0944cc3b882d654c0"]}},"5fd6e4526d3f4af0b7bbae2ea4735bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dcf30c10b4ba44d896a7251269893021":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d6f57d40881542d395376d95a8dc96a7","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_874ec2b445a94c8d95d4c7a6225714e7"}},"f7b676044ba14fc0944cc3b882d654c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ea88188316b451fbe3074e4c9cd1dcb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/50 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3105c1304bef4c3b9c4f66f431a7d611"}},"d6f57d40881542d395376d95a8dc96a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"874ec2b445a94c8d95d4c7a6225714e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ea88188316b451fbe3074e4c9cd1dcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3105c1304bef4c3b9c4f66f431a7d611":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeilBegM_LnC","executionInfo":{"status":"ok","timestamp":1623516294419,"user_tz":-330,"elapsed":4904,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"36f9a71c-1bbe-4995-be86-6c74ae5d2188"},"source":["!pip install GPUtil"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting GPUtil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=fb9f8104299a2c29e29e9398408b42349d276bfb341ae33ee6c50292421ef1ae\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YrHhkJNbghNP","executionInfo":{"status":"ok","timestamp":1623516771264,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import numpy as np\n","import pandas as pd\n","import sys\n","from collections import defaultdict\n","from typing import List, Tuple, Dict, Generator\n","from tqdm.notebook import tqdm\n","import seaborn as sns\n","\n","import functools\n","import hashlib\n","import inspect\n","import json\n","import logging\n","from enum import Enum\n","from typing import List, Dict, Tuple, Iterator\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","\n","import os\n","import time\n","from datetime import timedelta\n","import itertools\n","\n","import gc\n","import subprocess\n","from datetime import datetime\n","from os import listdir\n","from os.path import isfile\n","\n","import GPUtil as GPU\n","import humanize\n","import psutil\n","\n","%matplotlib inline\n","sns.set_theme(style=\"whitegrid\")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LR03pKu4hTyH","executionInfo":{"status":"ok","timestamp":1623516303103,"user_tz":-330,"elapsed":2604,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"562b6642-dc1c-43a9-a751-057c8dfcb732"},"source":["!wget https://github.com/sparsh-ai/reco-data/raw/master/BookingChallenge.zip\n","!unzip BookingChallenge.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-06-12 16:45:04--  https://github.com/sparsh-ai/reco-data/raw/master/BookingChallenge.zip\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/sparsh-ai/reco-data/master/BookingChallenge.zip [following]\n","--2021-06-12 16:45:04--  https://raw.githubusercontent.com/sparsh-ai/reco-data/master/BookingChallenge.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 18779182 (18M) [application/zip]\n","Saving to: ‘BookingChallenge.zip’\n","\n","BookingChallenge.zi 100%[===================>]  17.91M  67.1MB/s    in 0.3s    \n","\n","2021-06-12 16:45:05 (67.1 MB/s) - ‘BookingChallenge.zip’ saved [18779182/18779182]\n","\n","Archive:  BookingChallenge.zip\n","  inflating: evaluation_demo.ipynb   \n","  inflating: ground_truth.csv        \n","  inflating: __MACOSX/._ground_truth.csv  \n","  inflating: Readme.md               \n","  inflating: __MACOSX/._Readme.md    \n","  inflating: submission.csv          \n","  inflating: __MACOSX/._submission.csv  \n","  inflating: test_set.csv            \n","  inflating: train_set.csv           \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rjOWZsSq0ufD","executionInfo":{"status":"ok","timestamp":1623516303105,"user_tz":-330,"elapsed":37,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","N_SPLITS = 10\n","EPOCHS = 50\n","BATCH_SIZE = 256\n","EMBEDDING_SIZES = {\n","    'affiliate_id': (3611, 25),\n","    'booker_country': (5, 25),\n","    'checkin_day': (31, 5),\n","    'checkin_month': (12, 5),\n","    'checkin_year': (3, 5),\n","    'city_id': (39901, 128),\n","    'days_stay': (30, 5),\n","    'device_class': (3, 5),\n","    'hotel_country': (195, 25),\n","    'transition_days': (32, 5)\n","}\n","FEATURES_TO_ENCODE = ['city_id', 'device_class', 'affiliate_id',\n","                      'booker_country', 'hotel_country', 'checkin_year',\n","                      'days_stay', 'checkin_day', 'checkin_month',\n","                      'transition_days']\n","FEATURES_EMBEDDING = FEATURES_TO_ENCODE + ['next_' + column for column in\n","                                           ['affiliate_id', 'booker_country', 'days_stay', 'checkin_day']]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieAPVx3P1Hfv","executionInfo":{"status":"ok","timestamp":1623516303107,"user_tz":-330,"elapsed":38,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class ModelType(str, Enum):\n","    MANY_TO_ONE = 1\n","    MANY_TO_MANY = 2\n","\n","\n","class WeightType(str, Enum):\n","    UNWEIGHTED = 1\n","    UNIFORM = 2\n","    CUMSUM_CORRECTED = 3\n","\n","\n","class RecurrentType(str, Enum):\n","    GRU = 1\n","    LSTM = 2\n","\n","\n","class FeatureProjectionType(str, Enum):\n","    CONCATENATION = 1\n","    MULTIPLICATION = 2\n","\n","\n","class OptimizerType(str, Enum):\n","    ADAM = 1\n","    ADAMW = 2\n","\n","\n","BatchType = Dict[str, torch.Tensor]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_M8vXhJp_wlF","executionInfo":{"status":"ok","timestamp":1623516303108,"user_tz":-330,"elapsed":37,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["RESOURCES_PATH = './content'\n","\n","\n","def get_resources_path(file_path: str) -> str:\n","    \"\"\"\n","    Get resources path from file path.\n","    \"\"\"\n","    path = os.path.join(RESOURCES_PATH, file_path)\n","    dirs = '/'.join(path.split('/')[:-1])\n","\n","    if not os.path.exists(dirs):\n","        os.makedirs(dirs)\n","\n","    return path\n","\n","\n","def get_path(*args, dirs=None, format=None, filename=None, **kwargs) -> str:\n","    \"\"\"\n","    Get path from args and kwargs.\n","    \"\"\"\n","    path = []\n","    for arg in args:\n","        path.append(str(arg))\n","    for k, v in kwargs.items():\n","        if isinstance(v, bool):\n","            if v:\n","                path.append(k)\n","        else:\n","            path.append('{}_{}'.format(k, v))\n","\n","    dirs_str = ''\n","    if dirs is not None:\n","        if type(dirs) is not list:\n","            dirs = [dirs]\n","        dirs_str = '/'.join(dirs) + '/'\n","\n","    path = get_resources_path(dirs_str + '_'.join(path))\n","    if filename is not None:\n","        path += filename\n","    if format is not None:\n","        path += \".\" + format\n","\n","    return path\n","\n","\n","def get_model_ckpt_paths(model_hash: str, checkpoint_type='accuracy_at_k') -> List:\n","    \"\"\"\n","    Get model checkpoints paths from `model_hash` by `checkpoint_type`.\n","    \"\"\"\n","    base_path = get_path(f\"models/{model_hash}\")\n","    ckpt_paths = [f\"{base_path}/{f}\" for f in listdir(base_path) if isfile(f\"{base_path}/{f}\")]\n","    return sorted(list(filter(lambda s: checkpoint_type in s, ckpt_paths)))\n","\n","\n","def get_model_arch_path(model_hash) -> str:\n","    \"\"\"\n","    Get model architecture paths from `model_hash`.\n","    \"\"\"\n","    return get_path(dirs=\"architectures\",\n","                    hash=model_hash,\n","                    filename=None,\n","                    format='json')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgaMnKMs-eD9","executionInfo":{"status":"ok","timestamp":1623518878795,"user_tz":-330,"elapsed":476,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class LabelEncoder:\n","    \"\"\"\n","    LabelEncoder similar to `sklearn.preprocessing.LabelEncoder`\n","    with the exception it ignores `NaN` values.\n","    .. todo:: Enhance this encoder with the option to set a `min_frequency`.\n","    \"\"\"\n","\n","    def fit_transform(self, col: pd.Series) -> pd.Series:\n","        self.rev_classes_ = dict(enumerate(sorted(col.dropna().unique())))\n","        self.classes_ = {v: k for k, v in self.rev_classes_.items()}\n","        return col.apply(lambda k: self.classes_.get(k, np.nan))\n","\n","    def inverse_transform(self, col: pd.Series) -> pd.Series:\n","        return col.apply(lambda k: self.rev_classes_.get(k, np.nan))\n","\n","\n","class DatasetEncoder:\n","    \"\"\"\n","    DatasetEncoder looks to encapsulate multiple LabelEncoder objects\n","    to fully transform a dataset.\n","    \"\"\"\n","\n","    def __init__(self, features_embedding: List[str]):\n","        self.label_encoders = {c: LabelEncoder() for c in features_embedding}\n","\n","    def fit_transform(self, df: pd.DataFrame) -> None:\n","        \"\"\"\n","        Transform columns in all columns given by feature_embedding.\n","         df:\n","        :return:\n","        \"\"\"\n","        logging.info(\"Running LabelEncoder on columns\")\n","        for column, encoder in self.label_encoders.items():\n","            # reserve zero index for OOV elements\n","            df[column] = encoder.fit_transform(df[column]) + 1\n","            logging.info(f\"{column}: {len(encoder.classes_)}\")\n","\n","\n","def get_embedding_complexity_proxy(dataset_encoder: DatasetEncoder) -> Dict:\n","    \"\"\"\n","    Get embedding complexity proxy\n","    The idea is to find out how many bits (dimension) we need to naively encode each element in the encoder.\n","    It's a proxy since we have no idea which is the dimension of the underlying manifold for every feature.\n","    \"\"\"\n","    return {k: (len(v.classes_), np.ceil(np.log2(len(v.classes_))))\n","            for k, v in dataset_encoder.label_encoders.items()}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0THktfNx2Zl","executionInfo":{"status":"ok","timestamp":1623518881208,"user_tz":-330,"elapsed":999,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["_NEXT_CITY_COLUMNS = ['city_id', 'affiliate_id',\n","                      'booker_country', 'days_stay',\n","                      'checkin_day']\n","\n","\n","def build_dataset(reserved_obs: int = 10000) -> pd.DataFrame:\n","    \"\"\"\n","    Builds dataset by unifying training and test set.\n","    :return: pd.DataFrame with unified dataset.\n","    \"\"\"\n","    train_set = pd.read_csv('train_set.csv', index_col=0,\n","                            dtype={'user_id': 'int32', 'city_id': 'int32'},\n","                            parse_dates=['checkin', 'checkout']).sort_values(by=['utrip_id', 'checkin'])\n","    test_set = pd.read_csv('test_set.csv',\n","                           dtype={'user_id': 'int32', 'city_id': 'int32'},\n","                           parse_dates=['checkin', 'checkout']).sort_values(by=['utrip_id', 'checkin'])\n","\n","    # create dataset identifiers and homogenize dataframes\n","    train_set['train'] = 1\n","    test_set['train'] = 0\n","    # test_set.drop(columns=['row_num', 'total_rows'], inplace=True)\n","    test_set['city_id'] = test_set['city_id'].replace({0: np.nan})\n","\n","    # reserve observations for sanity check\n","    train_set['reserved'] = np.arange(len(train_set)) <= reserved_obs\n","\n","    # unify datasets\n","    dataset = pd.concat([train_set, test_set])\n","\n","    # create some time features\n","    dataset['days_stay'] = (dataset['checkout'] - dataset['checkin']).dt.days - 1\n","    dataset['checkin_day'] = dataset['checkin'].dt.dayofweek\n","    dataset['checkin_month'] = dataset['checkin'].dt.month\n","    dataset['checkin_year'] = dataset['checkin'].dt.year\n","\n","    # create transition time feature\n","    dataset['prev_checkout'] = dataset.groupby('utrip_id')['checkout'].shift(periods=1)\n","    dataset['transition_days'] = (dataset['checkout'] - dataset['prev_checkout']).dt.days - 1\n","    dataset['transition_days'].fillna(0, inplace=True)\n","    dataset.drop(columns=\"prev_checkout\", inplace=True)\n","    return dataset\n","\n","\n","def set_future_features(df: pd.DataFrame) -> None:\n","    \"\"\"\n","    Add features about the next city to the dataframe.\n","    \"\"\"\n","    for column in _NEXT_CITY_COLUMNS:\n","        df['next_' + column] = df.groupby('utrip_id')[column].shift(periods=-1)\n","\n","\n","def get_training_set_from_dataset(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Get training set by ignoring reserved test set observations.\n","    \"\"\"\n","    return df[df.reserved != True]\n","\n","\n","def get_test_set_from_dataset(df: pd.DataFrame,\n","                              sequence_length: int = 3) -> pd.DataFrame:\n","    \"\"\"\n","    Get test set from unified dataframe and constrain the minimum\n","    sequence length to avoid a test/submissions set distribution mismatch.\n","    \"\"\"\n","    test_set = df[df.reserved == True]\n","    return min_sequence_length_transformer(test_set, sequence_length)\n","\n","\n","def get_submission_set_from_dataset(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Get submission set from dataset, filtering `NaN` cities that appeared\n","    when merging the training and test set.\n","    .. warning::\n","        You should create the submission set before filtering `NaN`.\n","    \"\"\"\n","    submission_set = df[(df.train == 0) & (~df.city_id.isna())]\n","    assert len(submission_set) == 308005\n","    return submission_set\n","\n","\n","def min_sequence_length_transformer(df: pd.DataFrame,\n","                                    sequence_length: int = 3) -> pd.DataFrame:\n","    \"\"\"\n","    Constrains the minimum trip length to `sequence_length`.\n","    \"\"\"\n","    return df.groupby('utrip_id').filter(lambda x: len(x) >= sequence_length)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"me4XIJ9Zx2WS","executionInfo":{"status":"ok","timestamp":1623518881211,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class BookingDataset(Dataset):\n","\n","    def __init__(self,\n","                 df: pd.DataFrame,\n","                 features: List[str],\n","                 group_var='utrip_id'):\n","        sorted_groups = sorted(df.groupby(group_var), key=lambda g: len(g[1]), reverse=True)\n","        self.trips = [BookingDataset.pre_process(group, features) for _, group in tqdm(sorted_groups)]\n","        self.utrip_ids = [utrip_id for utrip_id, _ in sorted_groups]\n","        self.group_lengths = [len(g[1]) for g in sorted_groups]\n","\n","    def __len__(self):\n","        return len(self.trips)\n","\n","    def __getitem__(self, idx):\n","        return self.trips[idx]\n","\n","    def get_ids(self):\n","        return pd.DataFrame({'utrip_id': self.utrip_ids,\n","                             'group_length': self.group_lengths})\n","\n","    @staticmethod\n","    def pre_process(group: pd.DataFrame, features: List[str]):\n","        g = group[features].to_dict(orient='list')\n","        return {k: torch.LongTensor(np.array(v)) for k, v in g.items()}\n","\n","\n","def pad_collate(batch: List[BatchType]):\n","    \"\"\"\n","    Unify observations in a padded batch dictionary.\n","    \"\"\"\n","    batch_dict = defaultdict(list)\n","    lengths = []\n","    for d in batch:\n","        for k, v in d.items():\n","            batch_dict[k].append(v)\n","        # add the next city id if we are training\n","        if 'next_city_id' in d:\n","            batch_dict['last_city'].append(d['next_city_id'][-1])\n","        lengths.append(v.size())\n","\n","    res = {k: pad_sequence(v, batch_first=True, padding_value=0)\n","           for k, v in batch_dict.items() if k != 'last_city'}\n","\n","    # add last city id if we are training\n","    if 'next_city_id' in d:\n","        res['last_city'] = torch.tensor(batch_dict['last_city'])\n","\n","    lengths = torch.tensor(lengths, dtype=torch.int64).squeeze()\n","    return res, lengths\n","\n","\n","def get_dataset_and_dataloader(df: pd.DataFrame,\n","                               features: List[str],\n","                               batch_size: int = 256) -> Tuple[BookingDataset, DataLoader]:\n","    \"\"\"\n","    Get dataset and dataloader.\n","    \"\"\"\n","    dataset = BookingDataset(df, features)\n","    data_loader = DataLoader(dataset,\n","                             batch_size=batch_size,\n","                             shuffle=False,\n","                             collate_fn=pad_collate)\n","    return dataset, data_loader\n","\n","\n","def batches_to_device(data_loader: DataLoader) -> np.array:\n","    \"\"\"\n","    Batches to device.\n","    By pre-loading all batches in GPU for training, we avoid transferring data\n","    from memory to GPU on every fold. The risk of doing this is biasing the gradients,\n","    reason why we are then careful with the distribution of batches on each fold,\n","    also shuffling the batches every time we train a model.\n","    \"\"\"\n","    if DEVICE == 'cpu':\n","        batches = np.array([({k: v for k, v in d.items()}, seq_len)\n","                            for (d, seq_len) in data_loader])\n","    else:\n","        batches = np.array([({k: v.cuda(non_blocking=True)\n","                              for k, v in d.items()}, seq_len) for (d, seq_len) in data_loader])\n","\n","    return batches\n","\n","\n","def filter_batches_by_length(batches: List[BatchType], min_length: int = 3):\n","    \"\"\"\n","    Filter batches to have a minimum length of `min_length`.\n","    \"\"\"\n","    return list(filter(lambda b: b[1].min().item() > min_length, batches))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ZCjx-m20OxL","executionInfo":{"status":"ok","timestamp":1623518881213,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class BookingNet(nn.Module):\n","    \"\"\"\n","    BookingNet Sequence Aware Recommender System Network\n","    \"\"\"\n","\n","    def __init__(self,\n","                 features_embedding: List[str],\n","                 hidden_size: int,\n","                 output_size: int,\n","                 embedding_sizes: Dict[str, Tuple[int, int]],\n","                 n_layers: int = 2,\n","                 dropout: float = 0.3,\n","                 rnn_dropout: float = 0.1,\n","                 tie_embedding_and_projection: bool = True,\n","                 model_type: ModelType = ModelType.MANY_TO_MANY,\n","                 recurrent_type: RecurrentType = RecurrentType.GRU,\n","                 weight_type: WeightType = WeightType.UNWEIGHTED,\n","                 feature_projection_type: FeatureProjectionType = FeatureProjectionType.CONCATENATION,\n","                 **kwargs: List):\n","        \"\"\"\n","        Args:\n","             features_embedding: Features to embed at each time step.\n","             hidden_size: Hidden size of the recurrent encoder (`LSTM` or `GRU`).\n","             output_size: Quantity of cities to predict.\n","             embedding_sizes: Sizes of each feature embedding.\n","             n_layers: Number of recurrent layers.\n","             dropout: Dropout used in our input layer.\n","             rnn_dropout: Dropout used in recurrent layer.\n","             recurrent_type: Select between `RecurrentType.GRU` or `RecurrentType.LSTM`\n","             tie_embedding_and_projection: If `true`, parameterize last linear layer with embedding matrix.\n","             feature_projection_type: Select between `FeatureCombinationType.CONCATENATION`\n","                or `FeatureCombinationType.MULTIPLICATION`\n","             model_type: The model can either only predict the last city (`ModelType.MANY_TO_ONE`) or\n","                predict every city in the sequence (`ModelType.MANY_TO_MANY`)\n","             weight_type:\n","                1. `WeightType.UNWEIGHTED`: Unweighted cross entropy.\n","                2. `WeightType.UNIFORM`: Uniform cross entropy.\n","                3. `WeightType.CUMSUM_CORRECTED`: Cross entropy corrected to reflect original\n","                    one to many weighting.\n","        \"\"\"\n","        super().__init__()\n","        # save model arguments to re-initialize later\n","        model_params = inspect.getargvalues(inspect.currentframe()).locals\n","        if 'kwargs' in model_params:\n","            model_params.update(model_params['kwargs'])\n","            model_params.pop('kwargs')\n","        model_params.pop('__class__')\n","        model_params.pop('self')\n","        self.model_params = model_params\n","\n","        self.features_embedding = features_embedding\n","        self.hidden_size = hidden_size\n","        self.target_variable = \"next_city_id\"\n","        self.embedding_layers = nn.ModuleDict(\n","            {key: nn.Embedding(num_embeddings=int(qty_embeddings) + 1,  # reserve 0 index for padding/OOV.\n","                               embedding_dim=int(size_embeddings),\n","                               max_norm=None,  # Failed experiment, enforcing spherical embeddings degraded performance.\n","                               norm_type=2,\n","                               padding_idx=0)\n","             for key, (qty_embeddings, size_embeddings) in embedding_sizes.items()})\n","\n","        # encode every variable with the prefix `next_` to the embedding matrix of the suffix.\n","        self.features_dim = int(np.sum([embedding_sizes[k.replace(\"next_\", \"\")][1]\n","                                        for k in self.features_embedding]))\n","        self.city_embedding_size = embedding_sizes['city_id'][1]\n","\n","        self.feature_combination_type = feature_projection_type\n","        self.tie_embedding_and_projection = tie_embedding_and_projection\n","        self.recurrent_encoder = self.get_recurrent_encoder(recurrent_type, n_layers, rnn_dropout)\n","\n","        if feature_projection_type == FeatureProjectionType.MULTIPLICATION:\n","            self.attn_weights = nn.ParameterDict(\n","                {key: nn.Parameter(torch.rand(1)) for key in self.features_embedding}\n","            )\n","\n","        if self.city_embedding_size != self.hidden_size:\n","            logging.info(\n","                f\"Warning: Using linear layer to reconcile output of size \"\n","                f\"{self.hidden_size} with city embedding of size {self.city_embedding_size}.\")\n","            self.linear_to_city = nn.Linear(self.hidden_size,\n","                                            self.city_embedding_size,\n","                                            bias=False)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.dense = nn.Linear(self.city_embedding_size, output_size, bias=False)\n","\n","        if self.tie_embedding_and_projection:\n","            # ignore first embedding, since it corresponds to padding/OOV\n","            self.dense.weight = nn.Parameter(self.embedding_layers['city_id'].weight[1:])\n","\n","        # self.initialize_parameters()\n","\n","        # other parameters\n","        self.loss = nn.CrossEntropyLoss(ignore_index=-1, reduction='none')\n","        self.model_type = model_type\n","        self.weight_type = weight_type\n","        self.optimizer = None\n","        self.cross_entropy_weights = None\n","\n","    def forward(self, batch: BatchType, seq_length: torch.Tensor):\n","        seq_length = seq_length.squeeze()\n","\n","        # build feature map\n","        feature_input = self.get_feature_input(batch)\n","        feature_input = self.dropout(feature_input)\n","\n","        # sequence encoder\n","        feature_input = nn.utils.rnn.pack_padded_sequence(feature_input,\n","                                                          seq_length,\n","                                                          batch_first=True,\n","                                                          enforce_sorted=False)\n","        seq_out, _ = self.recurrent_encoder(feature_input)\n","        seq_out, _ = nn.utils.rnn.pad_packed_sequence(seq_out,\n","                                                      batch_first=True)\n","\n","        # reconcile encoder output size with city embedding size\n","        if self.city_embedding_size != self.hidden_size:\n","            seq_out = self.linear_to_city(seq_out)\n","\n","        # create final predictions (no softmax)\n","        city_encoding = self.dropout(seq_out)\n","        dense_out = self.dense(city_encoding)\n","        return dense_out\n","\n","    def get_feature_input(self, batch: BatchType):\n","        if self.feature_combination_type == FeatureProjectionType.CONCATENATION:\n","            return self.feature_concatenation(batch)\n","        else:\n","            return self.feature_multiplication(batch)\n","\n","    def feature_concatenation(self, batch: BatchType):\n","        \"\"\"\n","        Enables feature concatenation for every sequential step.\n","        \"\"\"\n","        feature_list = [self.embedding_layers[k.replace(\"next_\", \"\")](batch[k]) for k in self.features_embedding]\n","        return torch.cat(feature_list, axis=2)\n","\n","    def feature_multiplication(self, batch: BatchType):\n","        \"\"\"\n","        Enables feature multiplication for every sequential step.\n","        \"\"\"\n","        attention_embs = [self.attn_weights[k] * self.embedding_layers[k.replace(\"next_\", \"\")](batch[k])\n","                          for k in self.features_embedding if k != 'city_id']\n","        attention = functools.reduce(lambda a, b: a + b, attention_embs)\n","        return self.embedding_layers['city_id'](batch['city_id']) * attention\n","\n","    def get_loss(self,\n","                 city_scores: torch.Tensor,\n","                 batch: BatchType,\n","                 seq_len: torch.Tensor,\n","                 device=DEVICE) -> torch.Tensor:\n","        \"\"\"\n","        Loss function computation for the network, depending on model type:\n","        Args:\n","            1. `ModelType.MANY_TO_ONE`: Train many to one sequential model.\n","            2. `ModelType.MANY_TO_MANY`: Train many to many sequential model.\n","        \"\"\"\n","        bs, ts = batch['city_id'].shape\n","        loss = self.loss(city_scores, batch['next_city_id'].view(-1) - 1)\n","        loss = loss.view(-1, ts)\n","        if self.model_type == ModelType.MANY_TO_ONE:\n","            return torch.sum(loss * torch.nn.functional.one_hot(seq_len - 1).to(device)) / torch.sum(seq_len)\n","        elif self.model_type == ModelType.MANY_TO_MANY:\n","            if isinstance(self.cross_entropy_weights, int):\n","                return torch.sum(loss) / torch.sum(seq_len)\n","            else:\n","                # TODO: Find a way to control for variance. Batches with less\n","                #  subsequences should have a lower weight.\n","                return torch.sum(self.cross_entropy_weights[:ts] * loss) / torch.sum(seq_len)\n","        else:\n","            logging.error('Invalid model type in get_loss().')\n","\n","    def get_recurrent_encoder(self,\n","                              recurrent_type: RecurrentType,\n","                              n_layers: int,\n","                              dropout: float):\n","        if recurrent_type == RecurrentType.LSTM:\n","            return nn.LSTM(self.features_dim,\n","                           self.hidden_size,\n","                           num_layers=n_layers,\n","                           dropout=dropout,\n","                           batch_first=True)\n","        elif recurrent_type == RecurrentType.GRU:\n","            return nn.GRU(self.features_dim,\n","                          self.hidden_size,\n","                          num_layers=n_layers,\n","                          dropout=dropout,\n","                          batch_first=True)\n","        else:\n","            logging.error('Invalid recurrent encoder type in get_recurrent_encoder().')\n","\n","    def set_optimizer(self, optimizer_type: OptimizerType) -> None:\n","        if optimizer_type == OptimizerType.ADAMW:\n","            self.optimizer = torch.optim.AdamW(\n","                self.parameters(),\n","                lr=0.001,\n","                betas=(0.9, 0.999),\n","                eps=1e-08,\n","                weight_decay=0.01,\n","                amsgrad=False)\n","        elif optimizer_type == OptimizerType.ADAM:\n","            self.optimizer = torch.optim.Adam(\n","                self.parameters(),\n","                lr=0.001,\n","                betas=(0.9, 0.999),\n","                eps=1e-08,\n","                weight_decay=0,\n","                amsgrad=False)\n","        else:\n","            logging.error('Invalid optimizer type in set_optimizer().')\n","\n","    def set_entropy_weights(self,\n","                            train_set: pd.DataFrame):\n","        \"\"\"\n","        Set entropy weights for `ModelType.MANY_TO_MANY`. These weights\n","        depend on the `WeightType` passed in the constructor.\n","        \"\"\"\n","        if self.weight_type is WeightType.UNWEIGHTED:\n","            self.cross_entropy_weights = 1\n","        elif self.weight_type in (WeightType.UNIFORM, WeightType.CUMSUM_CORRECTED):\n","            weights_train = dict(train_set.groupby('utrip_id').size().value_counts().items())\n","            weights_train = np.array([weights_train.get(k, 0) for k in range(1, 50)])\n","            numerator = 1 if self.weight_type == WeightType.UNIFORM else weights_train\n","            reweighting = numerator / np.cumsum(weights_train[::-1])[::-1]\n","\n","            if np.any(np.isnan(reweighting)):\n","                logging.warning('Warning: NaN found in weights.')\n","\n","            reweighting[np.isnan(reweighting)] = 0\n","            reweighting[np.isinf(reweighting)] = 0\n","            self.cross_entropy_weights = torch.tensor(reweighting, device=DEVICE)\n","        else:\n","            logging.error(f\"Unknown weight type {self.weight_type} in set_entropy_weights()\")\n","\n","        logging.info(f'Weights: {self.cross_entropy_weights}')\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Network parameter initialization. Ended up using the default one.\n","        \"\"\"\n","        # https://pytorch.org/docs/stable/nn.init.html\n","        for name, param in self.named_parameters():\n","            if len(param.shape) > 1:\n","                logging.info(f\"Initializing {name}\")\n","                nn.init.xavier_uniform_(param)\n","\n","    def __str__(self):\n","        return json.dumps(self.model_params, indent=4, sort_keys=True)\n","\n","    @property\n","    def hash(self):\n","        \"\"\"\n","        Unique model hash for checkpoint/metrics identification.\n","        \"\"\"\n","        return hashlib.md5(self.__str__().encode('utf-8')).hexdigest()[:8]\n","\n","\n","def get_model_predictions(model: BookingNet,\n","                          data_loader: DataLoader,\n","                          model_ckpt_path: str) -> Iterator[torch.FloatTensor]:\n","    \"\"\"\n","    Get model predictions model checkpoint and batches data loader.\n","    \"\"\"\n","    model.load_state_dict(\n","        torch.load(model_ckpt_path,\n","                   map_location=torch.device(DEVICE))\n","    )\n","    model.eval()\n","    with torch.no_grad():\n","        for batch, seq_len in data_loader:\n","            if DEVICE == 'cuda':\n","                batch = {k: v.cuda(non_blocking=True) for k, v in batch.items()}\n","\n","            city_scores = model(batch, seq_len)\n","            city_scores = torch.bmm(\n","                torch.nn.functional.one_hot(seq_len - 1).unsqueeze(dim=1).type(torch.FloatTensor).to(DEVICE),\n","                city_scores).squeeze()\n","            city_scores = nn.Softmax(dim=1)(city_scores)\n","            yield city_scores.cpu()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"etbEi2bU1QPl","executionInfo":{"status":"ok","timestamp":1623518881215,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def round_robin_kfold(batches: List[BatchType],\n","                      n_splits: int = 10) -> Generator:\n","    \"\"\"\n","    Round robin k-fold cross validation.\n","    Useful when batches are sorted by sequence length, to keep the training\n","    set and validation set as balanced as possible in sequence length.\n","    Train indices are shuffled to try to reduce the bias in the gradient updates.\n","    \"\"\"\n","    np.random.seed(42)\n","    n = len(batches)\n","    groups = defaultdict(list)\n","\n","    group_id = 0\n","    for i in range(n):\n","        groups[group_id % n_splits].append(i)\n","        group_id += 1\n","\n","    for i in range(n_splits):\n","        train_index = np.concatenate([group for group_id, group in groups.items()\n","                                      if group_id != i])\n","        valid_index = np.array(groups[i])\n","        np.random.shuffle(train_index)\n","        yield train_index, valid_index"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RVKfKzW1sLJ","executionInfo":{"status":"ok","timestamp":1623518881929,"user_tz":-330,"elapsed":729,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def get_model_metrics(batch: BatchType,\n","                      seq_len: torch.Tensor,\n","                      city_scores: torch.Tensor) -> Tuple:\n","    \"\"\"\n","    Get model metrics, e.g. accuracy@1, accuracy@4.\n","    \"\"\"\n","    bs, ts = batch['city_id'].shape\n","    predicted_cities = (city_scores\n","                        .argmax(1)\n","                        .view(-1, ts)\n","                        .gather(1, (seq_len.unsqueeze(1) - 1).to(DEVICE))\n","                        .squeeze(1) + 1)\n","    predicted_cities_top_k = (torch.topk(city_scores, 4, dim=1).indices.view(bs, -1, 4)\n","                              .gather(1, (torch.cat([seq_len.unsqueeze(1)] * 4, axis=1).view(-1, 1, 4) - 1)\n","                                      .to(DEVICE))).squeeze(1) + 1\n","    hits_at_1 = (predicted_cities == batch['last_city']).float().sum()\n","    hits_at_k = torch.sum(predicted_cities_top_k.eq(batch['last_city'].unsqueeze(1)), dim=1).float().sum()\n","    return hits_at_1, hits_at_k\n","\n","\n","def train_step(model: BookingNet,\n","               batch: List[BatchType]) -> Dict:\n","    \"\"\"\n","    Training step, including loss evaluation and backprop.\n","    \"\"\"\n","    batch, seq_len = batch\n","    model.optimizer.zero_grad(set_to_none=True)\n","    city_scores = model(batch, seq_len)\n","    city_scores = city_scores.view(-1, 39901)\n","    loss = model.get_loss(city_scores,\n","                          batch,\n","                          seq_len,\n","                          device=DEVICE)\n","    loss.backward()\n","    model.optimizer.step()\n","    return {\n","        'train_loss': loss.item()\n","    }\n","\n","\n","def validation_step(model: BookingNet,\n","                    batch: BatchType) -> Dict:\n","    \"\"\"\n","    Validation step, including metric computation for batch.\n","    \"\"\"\n","    batch, seq_len = batch\n","    city_scores = model(batch, seq_len)\n","    city_scores = city_scores.view(-1, 39901)\n","    loss = model.get_loss(city_scores,\n","                          batch,\n","                          seq_len)\n","    hits_at_1, hits_at_k = get_model_metrics(batch, seq_len, city_scores)\n","    obs = len(batch['city_id'])\n","    return {\n","        'valid_loss': loss.item(),\n","        'hits_at_1': hits_at_1.item(),\n","        'hits_at_k': hits_at_k.item(),\n","        'obs': obs\n","    }\n","\n","\n","def train_for_all_batches(model: BookingNet,\n","                          train_batches: List[BatchType]) -> Dict:\n","    \"\"\"\n","    Train model on all given batches.\n","    \"\"\"\n","    current_time = time.time()\n","    train_loss = 0\n","    model.train()\n","    for batch in train_batches:\n","        train_step_result = train_step(model, batch)\n","        train_loss += train_step_result['train_loss']\n","    train_loss /= len(train_batches)  # loss per batch\n","    ellapsed_time = timedelta(seconds=int(time.time() - current_time))\n","    return {\n","        'train_loss': train_loss,\n","        'ellapsed_time': ellapsed_time,\n","    }\n","\n","\n","def valid_for_all_batches(model: BookingNet,\n","                          valid_batches: List[BatchType]) -> Dict:\n","    \"\"\"\n","    Run validation set metrics for all batches.\n","    \"\"\"\n","    current_time = time.time()\n","    valid_result = {\n","        'valid_loss': 0,\n","        'hits_at_1': 0,\n","        'hits_at_k': 0,\n","        'obs': 0\n","    }\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in valid_batches:\n","            batch_result = validation_step(model, batch)\n","            for key in valid_result.keys():\n","                valid_result[key] += batch_result[key]\n","    ellapsed_time = timedelta(seconds=int(time.time() - current_time))\n","    return {\n","        'valid_loss': valid_result['valid_loss'] / len(valid_batches),  # loss per batch\n","        'accuracy@1': valid_result['hits_at_1'] / valid_result['obs'],\n","        'accuracy@4': valid_result['hits_at_k'] / valid_result['obs'],\n","        'ellapsed_time_valid': ellapsed_time\n","    }\n","\n","\n","def model_checkpoint_exists(model_hash: str,\n","                            fold: int) -> bool:\n","    \"\"\"\n","    Returns `true` if the model checkpoint given by the path exists, `false` otherwise.\n","    \"\"\"\n","    ckpt_path = get_path(dirs=[\"models\", model_hash],\n","                         filename=f\"fold_{fold}_best_accuracy_at_k\",\n","                         format=\"pt\")\n","    # ckpt_path = f\"./models/{models.hash}/fold_{fold}_best_accuracy_at_k.pt\"\n","    return os.path.exists(ckpt_path)\n","\n","\n","def train_model(model: BookingNet,\n","                train_batches: List[BatchType],\n","                valid_batches: List[BatchType],\n","                epochs: int = 50,\n","                fold: int = 0,\n","                min_epochs_to_save: int = 20,\n","                verbose: bool = True) -> pd.DataFrame:\n","    \"\"\"\n","    Train model from batches and save checkpoints of best models by accuracy.\n","    \"\"\"\n","    epoch_report = {}\n","    best_accuracy_at_k = 0\n","    for epoch in tqdm(range(epochs)):\n","        train_report = train_for_all_batches(model, train_batches)\n","        valid_report = valid_for_all_batches(model, valid_batches)\n","\n","        if epoch >= min_epochs_to_save and valid_report['accuracy@4'] > best_accuracy_at_k:\n","            best_accuracy_at_k = valid_report['accuracy@4']\n","            torch.save(model.state_dict(), get_path(dirs=[\"models\", model.hash],\n","                                                    filename=f\"fold_{fold}_best_accuracy_at_k\",\n","                                                    format=\"pt\"))\n","            # torch.save(model.state_dict(),  f\"./models/{models.hash}/fold_{fold}_best_accuracy_at_k.pt\")\n","\n","        r = dict(train_report)\n","        r.update(valid_report)\n","        epoch_report[epoch] = r\n","\n","        if verbose:\n","            epoch_str = [f\"Epoch: {epoch}\",\n","                         f\"train loss: {r['train_loss']:.4f}\",\n","                         f\"valid loss: {r['valid_loss']:.4f}\",\n","                         f\"accuracy@1: {r['accuracy@1']:.4f}\",\n","                         f\"accuracy@4: {r['accuracy@4']:.4f}\",\n","                         f\"time: {r['ellapsed_time']}\"]\n","            epoch_str = ', '.join(epoch_str)\n","            logging.info(epoch_str)\n","\n","    # save report\n","    pd.DataFrame(epoch_report).T.to_csv(get_path(dirs=[\"reports\", model.hash],\n","                                                 hash=model.hash,\n","                                                 fold=fold,\n","                                                 format='csv'))\n","    # pd.DataFrame(epoch_report).T.to_csv(f\"./reports/{models.hash}/fold_{fold}.csv\")\n","\n","    # with open(f\"architectures/{model.hash}\", \"w\") as fhandle:\n","    with open(get_model_arch_path(model.hash), \"w\") as fhandle:\n","        fhandle.write(str(model))\n","\n","    return pd.DataFrame(epoch_report).T\n","\n","\n","def train_model_for_folds(dataset_batches: List[BatchType],\n","                          train_set: pd.DataFrame,\n","                          model_configuration: Dict,\n","                          n_models: int = N_SPLITS,\n","                          min_epochs_to_save: int = 25,\n","                          skip_checkpoint=False) -> str:\n","    \"\"\"\n","    Train `n_models` given a model configuration, returning the model hash.\n","    \"\"\"\n","    for fold, (train_index, valid_index) in enumerate(round_robin_kfold(dataset_batches,\n","                                                                        n_splits=N_SPLITS)):\n","        if fold >= n_models:\n","            break\n","\n","        model = BookingNet(**model_configuration).to(DEVICE)\n","        model.set_optimizer(optimizer_type=OptimizerType.ADAMW)\n","        model.set_entropy_weights(train_set)\n","\n","        model_hash = model.hash\n","\n","        if not skip_checkpoint and model_checkpoint_exists(model.hash, fold):\n","            continue\n","\n","        train_batches = dataset_batches[train_index]\n","        valid_batches = dataset_batches[valid_index]\n","        # valid_batches = filter_batches_by_length(valid_batches)\n","\n","        logging.info(f\"Training model {model.hash} for fold {fold}\")\n","        train_model(model,\n","                    train_batches,\n","                    valid_batches,\n","                    epochs=EPOCHS,\n","                    min_epochs_to_save=min_epochs_to_save,\n","                    fold=fold)\n","\n","        # Empty CUDA memory\n","        del model\n","        torch.cuda.empty_cache()\n","\n","    return model_hash"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8Yv3qtS-tvA","executionInfo":{"status":"ok","timestamp":1623518881931,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def print_gpu_usage(gpu_id: int = 0):\n","    \"\"\"\n","    Display GPU usage.\n","    \"\"\"\n","    gpu_list = GPU.getGPUs()\n","    gpu = gpu_list[gpu_id]\n","    process = psutil.Process(os.getpid())\n","    logging.info(f\"Gen RAM Free: {humanize.naturalsize(psutil.virtual_memory().available)}\"\n","                 f\" | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n","    logging.info(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree,\n","                                                                                                       gpu.memoryUsed,\n","                                                                                                       gpu.memoryUtil * 100,\n","                                                                                                       gpu.memoryTotal))\n","\n","\n","def accuracy_at_k(submission: pd.DataFrame,\n","                  ground_truth: pd.DataFrame) -> Dict:\n","    \"\"\"\n","    Calculates accuracy@k for k in {1, 4, 10} by group length and overall.\n","    \"\"\"\n","    data_to_eval = submission.join(ground_truth, on='utrip_id')\n","\n","    for k in [1, 4, 10]:\n","        data_to_eval[f'hits_at_{k}'] = data_to_eval.apply(\n","            lambda row: row['city_id'] in row[[f'city_id_{i}' for i in range(1, k + 1)]].values, axis=1)\n","    return {\n","        'accuracy@1': data_to_eval['hits_at_1'].mean(),\n","        'accuracy@4': data_to_eval['hits_at_4'].mean(),\n","        'accuracy@10': data_to_eval['hits_at_10'].mean(),\n","        'accuracy@4_by_pos': data_to_eval.groupby('group_length')['hits_at_4'].mean().to_dict()\n","    }\n","\n","\n","def get_submission(dataset: BookingDataset,\n","                   data_loader: DataLoader,\n","                   model: BookingNet,\n","                   checkpoint_path_list: List[str],\n","                   dataset_encoder: DatasetEncoder) -> pd.DataFrame:\n","    \"\"\"\n","    Get submission from dataset.\n","    \"\"\"\n","    assert len(checkpoint_path_list) > 0\n","\n","    ensemble_batch_probs = None\n","    for checkpoint_path in tqdm(checkpoint_path_list):\n","        batch_probs_generator = get_model_predictions(model,\n","                                                      data_loader,\n","                                                      checkpoint_path)\n","        if ensemble_batch_probs is None:\n","            ensemble_batch_probs = list(batch_probs_generator)\n","        else:\n","            for i, batch_probs in enumerate(batch_probs_generator):\n","                ensemble_batch_probs[i] += batch_probs\n","\n","    top_cities = torch.cat(\n","        [torch.topk(batch_submission, 10, dim=1).indices + 1\n","         for batch_submission in ensemble_batch_probs],\n","        axis=0\n","    )\n","    del ensemble_batch_probs\n","    cities_prediction = pd.DataFrame(top_cities.numpy(),\n","                                     columns=[f'city_id_{i}' for i in range(1, 11)])\n","    del top_cities\n","    gc.collect()\n","\n","    for city_id in range(1, 11):\n","        cities_prediction[f'city_id_{city_id}'] = dataset_encoder.label_encoders['city_id'].inverse_transform(\n","            cities_prediction[f'city_id_{city_id}'] - 1).astype(int)\n","\n","    submission = pd.concat([dataset.get_ids(), cities_prediction], axis=1)\n","    return submission\n","\n","\n","def get_ground_truth_from_dataset(df: pd.DataFrame,\n","                                  booking_dataset: BookingDataset,\n","                                  dataset_encoder: DatasetEncoder) -> pd.DataFrame:\n","    \"\"\"\n","    Get ground truth from dataset. Assumes the df is sorted by checkin ASC.\n","    \"\"\"\n","    ground_truth = df.groupby('utrip_id').tail(1)[['utrip_id', 'next_city_id']].set_index('utrip_id')\n","    ground_truth['city_id'] = (dataset_encoder\n","                               .label_encoders['city_id']\n","                               .inverse_transform(ground_truth['next_city_id'] - 1))\n","    if not ground_truth['city_id'].isnull().values.any():\n","        ground_truth['city_id'] = ground_truth['city_id'].astype(int)\n","    else:\n","        logging.warning(\"Warning: next_city_id has nulls\")\n","\n","    ground_truth = ground_truth.loc[booking_dataset.utrip_ids]  # reorder obs like batches\n","    ground_truth.drop(columns=\"next_city_id\", inplace=True)\n","    return ground_truth\n","\n","\n","def get_count_distribution(df: pd.DataFrame,\n","                           by: str = 'utrip_id') -> pd.DataFrame:\n","    \"\"\"\n","    Get count distribution from dataset.\n","    \"\"\"\n","    df_dist = df.groupby(by)[by].count().value_counts(sort=True)\n","    df_dist /= df_dist.sum()\n","    return df_dist\n","\n","\n","def get_distribution_by_pos(**kwargs) -> pd.DataFrame:\n","    \"\"\"\n","    Get distribution by pos from a list of key: dataframe pairs.\n","    \"\"\"\n","    return functools.reduce(lambda a, b: a.join(b),\n","                            [get_count_distribution(df).to_frame(name)\n","                             for name, df in kwargs.items()]).sort_index()\n","\n","\n","def check_device() -> None:\n","    \"\"\"\n","    Check if we are using GPU acceleration and warn the user.\n","    \"\"\"\n","    if DEVICE != 'cuda':\n","        logging.warning('You are not using a GPU. If you are using colab, go to Runtime -> Change runtime type')\n","    else:\n","        current_gpu = subprocess.check_output(['nvidia-smi', '-L']).strip().decode('ascii')\n","        logging.info(f\"Using {current_gpu}\")\n","\n","\n","def get_trained_models() -> Dict:\n","    \"\"\"\n","    Get dictionary of all models trained\n","    \"\"\"\n","    base_path = get_path(\"architectures\")\n","    model_paths = [f\"{base_path}/{f}\" for f in listdir(base_path) if isfile(f\"{base_path}/{f}\")]\n","\n","    d = {}\n","\n","    for path in model_paths:\n","        with open(path) as f:\n","            model_hash = path[-13:-5]\n","            d[model_hash] = json.load(f)\n","    return d\n","\n","\n","def get_final_submission(submission_set: pd.DataFrame,\n","                         model_hash: str,\n","                         dataset_encoder: DatasetEncoder) -> None:\n","    \"\"\"\n","    Get final submission from model hash.\n","    \"\"\"\n","    # create final submission\n","    dataset_submission, data_loader_submission = get_dataset_and_dataloader(\n","        df=submission_set,\n","        features=FEATURES_EMBEDDING\n","    )\n","\n","    # get model parameters from hash\n","    with open(get_model_arch_path(model_hash)) as fhandle:\n","        model_parameters = json.load(fhandle)\n","    ckpt_list = get_model_ckpt_paths(model_hash=model_hash,\n","                                     checkpoint_type='accuracy_at_k')\n","\n","    # load model and get predictions\n","    model = BookingNet(**model_parameters).to(DEVICE)\n","    predictions = get_submission(dataset_submission,\n","                                 data_loader_submission,\n","                                 model,\n","                                 ckpt_list,\n","                                 dataset_encoder)\n","\n","    # build final csv and run sanity checks\n","    timestamp = datetime.now().strftime(\"%d_%m_%Y_%Hh_%Mm_%Ss\")\n","    cols = [\"utrip_id\", \"city_id_1\", \"city_id_2\", \"city_id_3\", \"city_id_4\"]\n","    filename = f'submission_{model_hash}_{timestamp}'\n","    final_submission = predictions[cols]\n","    final_submission.to_csv(get_path(dirs=\"submissions\",\n","                                     filename=filename,\n","                                     format='csv'),\n","                            index=False)\n","    submission_sanity_checks(final_submission)\n","\n","\n","def submission_sanity_checks(submission: pd.DataFrame) -> None:\n","    \"\"\"\n","    Run submission sanity checks to make sure our dataframe is healthy.\n","    \"\"\"\n","    _TOTAL_SUBMISSION_ROWS = 70662\n","    df = pd.read_csv(get_resources_path('booking_test_set.csv'),\n","                     dtype={'user_id': 'int32', 'city_id': 'int32'},\n","                     parse_dates=['checkin', 'checkout'])\n","\n","    utrip_ids = set(df.utrip_id.unique())\n","    assert len(set(submission.utrip_id.unique()).intersection(utrip_ids)) == _TOTAL_SUBMISSION_ROWS\n","    assert submission.shape == (_TOTAL_SUBMISSION_ROWS, 5)\n","    assert submission.notna().values.all()\n","\n","    df = pd.read_csv(get_resources_path('booking_train_set.csv'),\n","                     dtype={'user_id': 'int32', 'city_id': 'int32'},\n","                     parse_dates=['checkin', 'checkout'])\n","\n","    # verify city ids\n","    city_ids = set(df.city_id.unique().astype(int))\n","    assert len(set(submission.city_id_1.unique()).difference(city_ids)) == 0\n","    assert len(set(submission.city_id_2.unique()).difference(city_ids)) == 0\n","    assert len(set(submission.city_id_3.unique()).difference(city_ids)) == 0\n","    assert len(set(submission.city_id_4.unique()).difference(city_ids)) == 0\n","    logging.info(\"Passed all sanity checks!\")"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":644,"referenced_widgets":["bd5f013f0d8f4a5dbbed3bee35fb026c","d1f5a71f917042f69cc0fedfbd9237cd","ba87625893c8417ea8074e98c10a489a","edc7772376e647868fab2f0e7f559c54","671e6bb54604409a9b0ae6607774633a","87a936870f8843478321bcd96cb98c9c","3f90575f1e594a34bff0fbf3a1804744","ae0ed2e9ff9e4948817592b33e3f2f59","b5860510ce0e4017841643bcf020b067","7dc72bba45cc4619a1e94618daa02532","0e88f652d702467a94e4b12161502132","96cd15f06a6a41058eaa342d0897f308","96a4849c9bb045ada32905baa47d32c9","f246ae8f24474a5d83d8345e02aae694","8a79b86bab794a2182ce37afe7b8eb94","d10bc5b5c8cf4e4da776b912a4cb4260","b54dee9d9aaf48f8ba4307c27fdf3157","f1ce3196d41448d8bf46271e04fba7d1","2ba9ed5697f449af810ae01c43b7a3b8","d4ef1ea86a6c4600969a5510631f4772","3004880b49f74960ba633a01ab1b4c35","0021ba7201d347e09b6568862c64c7bd","3bf6b552ce7645c6b69ee0a9a61b10bf","bcb8702518fa4aedb86aea8f5139dec7","ff6e8aa7364a4f299bd860efce6bd214","0a4f36728ab74059aee9d1ebc263fc2d","90ff547c175e4a8f936da7651cd21194","a27e914a2314471f82370252b49b58da","c3ead754cd5a49f69ecbed8cbed22402","3ab1bce6c705443f9ce64860a2d3ecf3","2487c7282782404898c10e8f12a2abb6","d4e5ae82c1a34936ace03349423eac99","4a88d58b2c41407f93a48de60671182a","6ad668fe52544cb0a1f493df5aa498d9","4a1e47d717054381878a93d2cbac9453","0410eccb4b3c4898a96cfe58e8ff9b0a","bff8902ef03f41b9a49409ef2bef1bd3","bb2e50a511d545b68231466f365ea5dc","256e808ecae84e089b76ea4005d87a04","4b946e6e47f244c98e506ed6320995b6","116a22d986b94666b9d63c7c0da270da","5f0e01e76ad34b48af4c0c9d4050a786","849644cb6a4341cd9c4c42d05123a59b","5a4a65a2328e4502911c863043ebbb06","9e9d836a9e2d480189aeecd6d52fdfd3","c8d3feef68af423da22e5bf2ed4e1523","bbc79301f77048ff87dd9e6504d5f4d3","0d9890702aba4fc59d22b5cc4413d93b","e9cbf6bbd87d492a8783cac7c2b3a148","8ca6e58df9434c3b84d7c1d8afa7022d","2ed6b7955cef43efbfdd594a98b1779f","81d9f8351afd4f7491e8317296ba9322","20da5c74e5e44c5fb0eba216e6c1fd8d","c257170ad69240f9a2ce3b717391c7d1","5e8f9963b1324f838bcbf09db65357a0","83d70daba9f3408bbcffc44ca8c7bbbb","1e98c404de6542ad85ab784d17765373","992409e46fa94aff8058740c6a64a810","bedc3a91b8c144e4bdcb0fbef877d2d2","cf5971b21caa4b6baec201dcf6216eed","3df24f839ac34db386dcc968883fab71","c44cceb3cb944207b334877b8872f371","cd3b371138d94d6996740b5b66117065","3bf19ecfe32643e1859fa38d0a081710","b2393264f83d480fb7f2bd09bdcbca68","a93d06da02974b2a9f84594f6bf325f4","567200e2fa3f4ffbb5cad40e545916f6","4852e657ad014e22be2ed6549655bbb8","a130abc6fd3d433daa5e314db8449f82","94163d6093424d7d96a96f431d948260","df5de35a223849a5a531c186e2601131","baa0e25b78e543a697616d5edc2a7e26","5ff6b9482d7b47c6af44ec46efce6321","a7730b68e77d49c69bd8476b7b9984e3","bd45ba78e06d4376ae0d18b7daf413b5","af538c4e37924720b89e5952f9983974","59583a662df04788a830c5ef32d5ea84","3bf4194da3eb4da394ae076582852510","f0b9659a8eda4a35811dcf5d8b879252","156917a8062447dd86680c69a388d042","b38a8d854b124e18aee92f21d670ac4c","5fd6e4526d3f4af0b7bbae2ea4735bdd","dcf30c10b4ba44d896a7251269893021","f7b676044ba14fc0944cc3b882d654c0","d6f57d40881542d395376d95a8dc96a7","874ec2b445a94c8d95d4c7a6225714e7","2ea88188316b451fbe3074e4c9cd1dcb","3105c1304bef4c3b9c4f66f431a7d611"]},"id":"IBSm4NNn4rP0","outputId":"a74977fc-aca5-4927-8a84-0bcd8f83d904"},"source":["def run_experiments(base_configuration: Dict,\n","                    experiments: List[Dict],\n","                    n_models: int,\n","                    dataset_batches: List[BatchType],\n","                    train_set: pd.DataFrame,\n","                    skip_checkpoint=False) -> None:\n","    \"\"\"\n","    Given a base configuration in a dictionary, run experiments\n","    by overriding parameters of this base configuration with\n","    a list of overrides in `experiments`.\n","    \"\"\"\n","    for model_overrides in tqdm(experiments):\n","        logging.info(model_overrides)\n","        model_configuration = dict(base_configuration, **model_overrides)\n","        train_model_for_folds(dataset_batches,\n","                              train_set,\n","                              model_configuration,\n","                              n_models=n_models,\n","                              skip_checkpoint=skip_checkpoint)\n","\n","\n","def get_base_configuration():\n","    \"\"\"\n","    The base configuration describes our best model. Experiments\n","    change elements of this configuration to try to find an even\n","    better one.\n","    \"\"\"\n","    return {\n","        'features_embedding': FEATURES_EMBEDDING,\n","        'hidden_size': int(EMBEDDING_SIZES['city_id'][1]),\n","        'output_size': int(EMBEDDING_SIZES['city_id'][0]),\n","        'embedding_sizes': EMBEDDING_SIZES,\n","        'n_layers': 2,\n","        'dropout': 0.3,\n","        'rnn_dropout': 0.1,\n","        'tie_embedding_and_projection': True,\n","        'model_type': ModelType.MANY_TO_MANY,\n","        'recurrent_type': RecurrentType.GRU,\n","        'weight_type': WeightType.UNWEIGHTED,\n","        'feature_projection_type': FeatureProjectionType.CONCATENATION,\n","        'num_folds': N_SPLITS,\n","        'batch_size': BATCH_SIZE\n","    }\n","\n","\n","def get_experiments() -> List:\n","    \"\"\"\n","    An experiment is a dict that describes the parameters\n","    that will be overridden in the base configuration\n","    during an experiment.\n","    \"\"\"\n","    params = ['model_type', 'weight_type', 'recurrent_type', 'tie_embedding_and_projection']\n","    return [\n","        dict(zip(params, p))\n","        for p in itertools.product(\n","            *map(list, [ModelType, WeightType, RecurrentType, [True, False]])\n","        )\n","    ]\n","\n","\n","def get_model_performance_data(test_set: pd.DataFrame,\n","                               dataset_encoder: DatasetEncoder,\n","                               model_hashes: List[str] = None) -> Tuple[pd.DataFrame, Dict]:\n","    \"\"\"\n","    Get model performance data from all trained models.\n","    \"\"\"\n","    booking_dataset_test, dataset_loader_test = get_dataset_and_dataloader(\n","        df=test_set,\n","        features=FEATURES_EMBEDDING\n","    )\n","    ground_truth_test = get_ground_truth_from_dataset(\n","        df=test_set,\n","        booking_dataset=booking_dataset_test,\n","        dataset_encoder=dataset_encoder\n","    )\n","\n","    trained_models = get_trained_models()\n","\n","    if model_hashes:\n","        trained_models = {h: trained_models[h] for h in model_hashes}\n","\n","    df_rows = []\n","    accuracy_at_4_by_length = {}\n","    for model_hash, model_parameters in trained_models.items():\n","        try:\n","            ckpt_list = get_model_ckpt_paths(model_hash=model_hash,\n","                                             checkpoint_type='accuracy_at_k')\n","        except FileNotFoundError:\n","            continue\n","\n","        d = {\n","            'single': ckpt_list[:1],\n","            'ensemble': ckpt_list\n","        }\n","\n","        for model_type, ckpt_list in d.items():\n","            if model_type == 'ensemble' and len(ckpt_list) == 1:\n","                continue\n","\n","            model = BookingNet(**model_parameters).to(DEVICE)\n","            predictions = get_submission(booking_dataset_test,\n","                                         dataset_loader_test,\n","                                         model,\n","                                         ckpt_list,\n","                                         dataset_encoder)\n","            accuracy = accuracy_at_k(predictions, ground_truth_test)\n","            model_parameters['num_models'] = len(ckpt_list)\n","            model_parameters['accuracy@1'] = accuracy['accuracy@1']\n","            model_parameters['accuracy@4'] = accuracy['accuracy@4']\n","            model_parameters['accuracy@10'] = accuracy['accuracy@10']\n","            model_parameters['hash'] = model_hash\n","            df = pd.DataFrame.from_dict(model_parameters, orient='index').T\n","            df_rows.append(pd.concat(\n","                [df, pd.DataFrame.from_dict(accuracy['accuracy@4_by_pos'], orient='index').T]\n","                , axis=1))\n","            accuracy_at_4_by_length[(model_hash, model_type)] = accuracy['accuracy@4_by_pos']\n","    return pd.concat(df_rows), accuracy_at_4_by_length\n","\n","\n","def filter_results_table(results: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Filter results table to get only attributes that change between models.\n","    \"\"\"\n","    columns = ['model_type', 'recurrent_type', 'tie_embedding_and_projection',\n","               'weight_type', 'accuracy@1', 'accuracy@4', 'accuracy@10', 'hash']\n","    selected_columns = [col for col in results.columns.values\n","                        if results[col].apply(str).nunique() > 1\n","                        or col in columns]\n","    filtered_results = (results[selected_columns]\n","                        .sort_values(\"accuracy@4\", ascending=False))\n","\n","    decode = {\n","        'model_type': ModelType,\n","        'weight_type': WeightType,\n","        'recurrent_type': RecurrentType\n","    }\n","\n","    for key, enum_type in decode.items():\n","        filtered_results[key] = (filtered_results[key]\n","                                 .apply(enum_type)\n","                                 .apply(lambda s: str(s).split('.')[1]))\n","\n","    df_table = filtered_results[columns].sort_values(\n","        [\"model_type\", \"recurrent_type\", \"tie_embedding_and_projection\", \"accuracy@4\"],\n","        ascending=[True, True, False, False])\n","    return df_table\n","\n","\n","# build and encode dataset\n","dataset = build_dataset(reserved_obs=30000)\n","de = DatasetEncoder(FEATURES_TO_ENCODE)\n","de.fit_transform(dataset)\n","set_future_features(dataset)\n","\n","submission_set = get_submission_set_from_dataset(dataset)\n","\n","# keep only observations before the last visit\n","dataset = dataset[~dataset.next_city_id.isna()]\n","\n","# split training and test set from dataset\n","train_set = get_training_set_from_dataset(dataset)\n","test_set = get_test_set_from_dataset(dataset)\n","\n","logging.info(f\"Training set: {train_set.shape}\")\n","logging.info(f\"Test set: {test_set.shape}\")\n","logging.info(f\"Dataset: {dataset.shape}\")\n","\n","logging.info(get_distribution_by_pos(dataset=dataset,\n","                                      train_set=train_set[train_set.train == 1],\n","                                      test_set=test_set,\n","                                      submission=submission_set).head(10))\n","\n","# pre-load all batches to GPU\n","_, dataset_loader = get_dataset_and_dataloader(\n","    train_set,\n","    features=FEATURES_EMBEDDING + ['next_city_id'],\n","    batch_size=BATCH_SIZE\n",")\n","dataset_batches_cuda = batches_to_device(dataset_loader)\n","\n","print_gpu_usage(0)\n","\n","# run experiments from base configuration\n","base_configuration = get_base_configuration()\n","experiments = get_experiments()\n","run_experiments(base_configuration=base_configuration,\n","                experiments=experiments,\n","                n_models=1,\n","                dataset_batches=dataset_batches_cuda,\n","                train_set=train_set)\n","\n","# get and save results table\n","results, _ = get_model_performance_data(test_set, de)\n","\n","filter_results_table(results).to_csv(\n","    get_path(\n","        filename='experiments',\n","        format='csv'),\n","    index=False\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd5f013f0d8f4a5dbbed3bee35fb026c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=282628.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5860510ce0e4017841643bcf020b067","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b54dee9d9aaf48f8ba4307c27fdf3157","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff6e8aa7364a4f299bd860efce6bd214","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a88d58b2c41407f93a48de60671182a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:224: RuntimeWarning: divide by zero encountered in true_divide\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"116a22d986b94666b9d63c7c0da270da","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9cbf6bbd87d492a8783cac7c2b3a148","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e98c404de6542ad85ab784d17765373","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2393264f83d480fb7f2bd09bdcbca68","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:224: RuntimeWarning: invalid value encountered in true_divide\n","WARNING:root:Warning: NaN found in weights.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ff6b9482d7b47c6af44ec46efce6321","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Warning: NaN found in weights.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b38a8d854b124e18aee92f21d670ac4c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"YWro3lXzFnCX","executionInfo":{"status":"aborted","timestamp":1623518887595,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def get_plot_from_accuracy(**kwargs) -> None:\n","    \"\"\"\n","    Accuracy plot by position.\n","    \"\"\"\n","    df_list = []\n","    for key, accuracy_dict in kwargs.items():\n","        df = pd.DataFrame.from_dict(accuracy_dict, orient='index', columns=['accuracy']).head(8)\n","        df['type'] = key\n","        df_list.append(df)\n","    g = sns.catplot(\n","        data=pd.concat(df_list).reset_index(), kind=\"bar\",\n","        x=\"index\", y=\"accuracy\", hue=\"type\",\n","        palette=\"bone\", height=6, legend_out=False\n","    )\n","    g.set(ylim=(0.4, 0.7))\n","    g.set_axis_labels(\"Sequence length\", \"accuracy@4\")\n","    g.savefig(\"accuracy_by_position.pdf\")\n","\n","\n","def get_plot_from_distribution_by_pos(df: pd.DataFrame):\n","    \"\"\"\n","    Plot distribution by position from dataframe.\n","    \"\"\"\n","    df_melt = pd.melt(df,\n","                      value_vars=['train_set', 'submission'],\n","                      var_name='dataset_type',\n","                      value_name='sequence_length',\n","                      ignore_index=False)\n","\n","    sns.set_style('white')\n","    sns.set_context('paper', font_scale=2)\n","    sns.set_palette(['#000000', '#ABABAB'])\n","    sns.set_style('ticks', {'axes.edgecolor': '0',\n","                            'xtick.color': '0',\n","                            'ytick.color': '0'})\n","\n","    g = sns.catplot(\n","        data=df_melt.reset_index(), kind=\"bar\",\n","        x=\"index\", y=\"sequence_length\", hue=\"dataset_type\",\n","        ci=\"sd\", height=6, legend_out=False,\n","    )\n","    g.set_axis_labels(\"Sequence length\", \"Proportion\")\n","    new_labels = ['Training set', 'Submission set']\n","    for t, l in zip(g._legend.texts, new_labels):\n","        t.set_text(l)\n","\n","    g._legend.set_title('')\n","    g.savefig(\"sequence_length_distribution.pdf\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUgGokMXCFyv","executionInfo":{"status":"aborted","timestamp":1623518887598,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["get_plot_from_accuracy(single=acc_dict[(model_hash, 'single')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgY1umOHFrlI","executionInfo":{"status":"aborted","timestamp":1623516710168,"user_tz":-330,"elapsed":34,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["# build submission from single model\n","get_final_submission(submission_set, model_hash, de)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_K4sAgoFrgB","executionInfo":{"status":"aborted","timestamp":1623516710171,"user_tz":-330,"elapsed":37,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":[""],"execution_count":null,"outputs":[]}]}