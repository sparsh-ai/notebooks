{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T847725 | Attribute to Feature Mappings for Cold-Start Recommendations","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6IKOvVNsD9eoek5lldeP1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8-aWDAVNdOAd"},"source":["# Attribute to Feature Mappings for Cold-Start Recommendations"]},{"cell_type":"markdown","metadata":{"id":"FK65Ha4JdMRr"},"source":["## Datasets"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqKHrO5gMvYN","executionInfo":{"status":"ok","timestamp":1635664489529,"user_tz":-330,"elapsed":476,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"4bb480cf-3e42-4a67-a237-e44f2f37ea98"},"source":["%%writefile attribute.txt\n","0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n","0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n","0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n","0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n","0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0\n","0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n","0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n","0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n","0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n","0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n","0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n","0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing attribute.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqvcTHM_M2NG","executionInfo":{"status":"ok","timestamp":1635664508883,"user_tz":-330,"elapsed":492,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"fd83669d-c9e4-4c2c-d106-c79407e501ec"},"source":["%%writefile feedback.txt\n","1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n","1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n","1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0\n","0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n","0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0\n","0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1\n","0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n","1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n","1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1\n","0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing feedback.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"PqZgnqfbNrWW"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"JUWFMgwFM7Jx"},"source":["import numpy as np\n","from math import exp, log\n","from copy import deepcopy\n","import random\n","import scipy.sparse as sp\n","import sys\n","from math import sqrt, exp\n","import scipy.sparse as sp\n","from copy import copy\n","import functools"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rMst_GnmNs5k"},"source":["## BPR"]},{"cell_type":"code","metadata":{"id":"qKEWHiZzNAXI"},"source":["class BPRArgs(object):\n","\n","    def __init__(self,learning_rate=0.05,\n","                 bias_regularization=1.0,\n","                 user_regularization=0.0025,\n","                 positive_item_regularization=0.0025,\n","                 negative_item_regularization=0.00025,\n","                 update_negative_item_factors=True):\n","        self.learning_rate = learning_rate\n","        self.bias_regularization = bias_regularization\n","        self.user_regularization = user_regularization\n","        self.positive_item_regularization = positive_item_regularization\n","        self.negative_item_regularization = negative_item_regularization\n","        self.update_negative_item_factors = update_negative_item_factors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF2us0JNNDiR"},"source":["class BPR(object):\n","\n","    def __init__(self,D,args):\n","        \"\"\"initialise BPR matrix factorization model\n","        D: number of factors\n","        \"\"\"\n","        self.D = D\n","        self.learning_rate = args.learning_rate\n","        self.bias_regularization = args.bias_regularization\n","        self.user_regularization = args.user_regularization\n","        self.positive_item_regularization = args.positive_item_regularization\n","        self.negative_item_regularization = args.negative_item_regularization\n","        self.update_negative_item_factors = args.update_negative_item_factors\n","\n","    def train(self,dataidx,num_items,sampler,num_iters):\n","        \"\"\"train model\n","        data: user-item matrix as a scipy sparse matrix\n","              users and items are zero-indexed\n","        \"\"\"\n","        self.init(dataidx,num_items)\n","\n","        #print 'initial loss = {0}'.format(self.loss())\n","        for it in range(num_iters):\n","            #print 'starting iteration {0}'.format(it)\n","            for u,i,j in sampler.generate_samples(self.dataidx, self.num_items):\n","                self.update_factors(u,i,j)\n","            print('iteration {0}: loss = {1}'.format(it,self.loss()))\n","\n","    def init(self,dataidx,num_items):\n","        self.dataidx = dataidx\n","        self.num_users = len(dataidx)\n","        self.num_items = num_items\n","\n","        self.item_bias = np.zeros(self.num_items)\n","        self.user_factors = np.random.random_sample((self.num_users,self.D))\n","        self.item_factors = np.random.random_sample((self.num_items,self.D))\n","\n","        self.create_loss_samples()\n","\n","    def create_loss_samples(self):\n","        # apply rule of thumb to decide num samples over which to compute loss\n","        num_loss_samples = int(100*self.num_users**0.5)\n","\n","        sampler = UniformUserUniformItem()\n","        self.loss_samples = [t for t in sampler.generate_samples(self.dataidx,self.num_items,num_loss_samples)]\n","\n","    def update_factors(self,u,i,j,update_u=True,update_i=True):\n","        \"\"\"apply SGD update\"\"\"\n","        update_j = self.update_negative_item_factors\n","\n","        x = self.item_bias[i] - self.item_bias[j] \\\n","            + np.dot(self.user_factors[u,:],self.item_factors[i,:]-self.item_factors[j,:])\n","\n","        #XXX: maybe it should be exp(-x)/(1.0+exp(-x))\n","        #z = 1.0/(1.0+exp(x))\n","        z = 1.0 - 1.0/(1.0+exp(-x))\n","\n","        # update bias terms\n","        if update_i:\n","            d = z - self.bias_regularization * self.item_bias[i]\n","            self.item_bias[i] += self.learning_rate * d\n","        if update_j:\n","            d = -z - self.bias_regularization * self.item_bias[j]\n","            self.item_bias[j] += self.learning_rate * d\n","\n","        if update_u:\n","            d = (self.item_factors[i,:]-self.item_factors[j,:])*z - self.user_regularization*self.user_factors[u,:]\n","            self.user_factors[u,:] += self.learning_rate*d\n","        if update_i:\n","            d = self.user_factors[u,:]*z - self.positive_item_regularization*self.item_factors[i,:]\n","            self.item_factors[i,:] += self.learning_rate*d\n","        if update_j:\n","            d = -self.user_factors[u,:]*z - self.negative_item_regularization*self.item_factors[j,:]\n","            self.item_factors[j,:] += self.learning_rate*d\n","\n","    def loss(self):\n","        ranking_loss = 0;\n","        for u,i,j in self.loss_samples:\n","            x = self.predict(u,i) - self.predict(u,j)\n","            #it should be ln(1.0/(1.0+exp(-x)) according to thesis)\n","            #ranking_loss += 1.0/(1.0+exp(x))\n","            ranking_loss += log(1.0/(1.0+exp(-x)))\n","\n","        complexity = 0;\n","        for u,i,j in self.loss_samples:\n","            complexity += self.user_regularization * np.dot(self.user_factors[u],self.user_factors[u])\n","            complexity += self.positive_item_regularization * np.dot(self.item_factors[i],self.item_factors[i])\n","            complexity += self.negative_item_regularization * np.dot(self.item_factors[j],self.item_factors[j])\n","            complexity += self.bias_regularization * self.item_bias[i]**2\n","            complexity += self.bias_regularization * self.item_bias[j]**2\n","\n","        #XXX: where does 0.5 come from? returns negative BPR-OPT so that it looks we are minimizing it\n","        #return ranking_loss + 0.5*complexity\n","        return -ranking_loss + complexity\n","\n","    def predict(self,u,i):\n","        return self.item_bias[i] + np.dot(self.user_factors[u],self.item_factors[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJwogO6VNueC"},"source":["## Sampling"]},{"cell_type":"code","metadata":{"id":"RFrUnJzrNFZY"},"source":["class Sampler(object):\n","\n","    def __init__(self):\n","        pass\n","\n","    def init(self,dataidx,num_items,max_samples=None):\n","        self.dataidx = dataidx\n","        self.num_users = len(dataidx)\n","        self.num_items = num_items\n","        self.max_samples = max_samples\n","        self.datannz = 0\n","        for u in range(self.num_users):\n","            self.datannz += len(dataidx[u])\n","\n","    def sample_user(self):\n","        u = self.uniform_user()\n","        num_pos = len(self.dataidx[u])\n","        assert(num_pos > 0 and num_pos != self.num_items)\n","        return u\n","\n","    def sample_negative_item(self,user_items):\n","        j = random.randint(0,self.num_items-1)\n","        while j in user_items:\n","            j = random.randint(0,self.num_items-1)\n","        return j\n","\n","    def uniform_user(self):\n","        return random.randint(0,self.num_users-1)\n","\n","    def num_samples(self,n):\n","        if self.max_samples is None:\n","            return n\n","        return min(n,self.max_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOtjZlvzNO8G"},"source":["class UniformUserUniformItem(Sampler):\n","\n","    def generate_samples(self,dataidx,num_items,max_samples=None):\n","        self.init(dataidx,num_items,max_samples)\n","        for _ in range(self.num_samples(self.datannz)):\n","            u = self.uniform_user()\n","            indices = self.dataidx[u]\n","            # sample positive item\n","            num_pos = len(indices)\n","            if (num_pos<=0 or num_pos==self.num_items):\n","                #throw bad user samples out\n","                continue\n","            i = random.choice(indices)\n","            j = self.sample_negative_item(indices)\n","            yield u,i,j"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7IzDuepNTFk"},"source":["class UniformUserUniformItemWithoutReplacement(Sampler):\n","\n","    def generate_samples(self,dataidx,num_items,max_samples=None):\n","        self.init(dataidx,num_items,max_samples)\n","        # make a local copy of data as we're going to \"forget\" some entries\n","        self.local_dataidx = deepcopy(self.dataidx)\n","        for _ in range(self.num_samples(self.datannz)):\n","            u = self.uniform_user()\n","            # sample positive item without replacement if we can\n","            user_items = self.local_dataidx[u]\n","            if user_items.size == 0:\n","                if self.dataidx[u].size == 0:\n","                    continue\n","                # reset user data if it's all been sampled\n","                self.local_dataidx[u] = self.dataidx[u].copy()\n","                user_items = self.local_dataidx[u]\n","            i = random.randint(0,user_items.size-1)\n","            # forget this item so we don't sample it again for the same user\n","            self.local_dataidx[u] = np.delete(user_items,i)\n","            j = self.sample_negative_item(user_items)\n","            yield u,i,j"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MfpIS0rNRyT"},"source":["class ExternalSchedule(Sampler):\n","\n","    def __init__(self,filepath,index_offset=0):\n","        self.filepath = filepath\n","        self.index_offset = index_offset\n","\n","    def generate_samples(self,dataidx,num_items,max_samples=None):\n","        self.init(dataidx,num_items,max_samples)\n","        f = open(self.filepath)\n","        samples = [map(int,line.strip().split()) for line in f]\n","        random.shuffle(samples)  # important!\n","        num_samples = self.num_samples(len(samples))\n","        for u,i,j in samples[:num_samples]:\n","            yield u-self.index_offset,i-self.index_offset,j-self.index_offset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0vbXSv2wNUGP"},"source":["## Splitting"]},{"cell_type":"code","metadata":{"id":"GvCmyDkPN2ZQ"},"source":["class DataSplitter(object):\n","\n","    def __init__(self, datamat, attrmat, k):\n","        assert sp.isspmatrix_csc(datamat)\n","        self.datamat = datamat\n","        self.attrmat = attrmat\n","        self.k = k\n","        _, self.num_items = datamat.shape\n","        assert self.k<=self.num_items\n","        self.index = [i for i in range(self.num_items)]\n","        #random.shuffle(self.index)\n","\n","    def split_data(self):\n","        base = 0\n","        result = []\n","        for i in range(self.k):\n","            tmp = []\n","            for j in range(int(min(self.num_items-base, self.num_items/self.k))):\n","                tmp.append(self.datamat.getcol(self.index[base+j]))\n","            base = base + int(self.num_items/self.k)\n","            result.append(sp.hstack(tmp,\"csc\"))\n","        return result\n","\n","    def split_attr(self):\n","        base = 0\n","        result = []\n","        for i in range(self.k):\n","            tmp = []\n","            for j in range(int(min(self.num_items-base, self.num_items/self.k))):\n","                tmp.append(self.attrmat[self.index[base+j]])\n","            base = base + int(self.num_items/self.k)\n","            result.append(np.vstack(tmp))\n","        return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzmbWdO1N-JB"},"source":["## Parsing"]},{"cell_type":"code","metadata":{"id":"rFd4dK5uN3GN"},"source":["import sys\n","\n","class DataParser(object):\n","\n","    def __init__(self):\n","        pass\n","\n","    def init(self, filename, k):\n","        self.filename = filename\n","        self.attrfile = attrfile\n","        self.k = k\n","\n","class Ml_100_Parser(DataParser):\n","    \n","    def parse(self, filename, k):\n","        pass\n","                \n","    def split(self, data):\n","        pass\n","\n","class Ml_1M_Parser(DataParser):\n","\n","    def parse(self, filename, k):\n","        pass\n","\n","    def split(self, data):\n","        pass\n","\n","if __name__ == '__main__':\n","    pass\n","    # example of training and testing with mapping functions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTX-lVdPON2T"},"source":["## Mapping"]},{"cell_type":"code","metadata":{"id":"srDPFqpEVbey"},"source":["import operator as op\n","\n","def cmp(a, b):\n","    # return (a > b) - (a < b) \n","    x = int(op.gt(a,b))#.astype(np.float32)\n","    y = int(op.lt(a,b))#.astype(np.float32)\n","    return x - y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnrSp7IEOOut"},"source":["class Mapper(object):\n","\n","    def __init__(self):\n","        pass\n","\n","    def init(self, data, attr, bpr_k=None, bpr_args=None, bpr_model=None):\n","        assert sp.isspmatrix_csc(data)\n","        self.data = data\n","        self.num_users, self.num_items = data.shape\n","        self.attr = attr\n","        assert attr.shape[0] >= self.num_items\n","        _, self.num_attrs = attr.shape\n","        if bpr_model==None:\n","            self.bpr_k = [self.num_users/5,bpr_k][bpr_k!=None]\n","            if bpr_args==None:\n","                self.bpr_args = BPRArgs(0.01, 1.0, 0.02125, 0.00355, 0.00355)\n","            else:\n","                self.bpr_args = bpr_args\n","            self.bpr_model = BPR(self.bpr_k, self.bpr_args)\n","        else:\n","            self.bpr_model = bpr_model\n","            self.bpr_k = bpr_model.D\n","            self.bpr_args = BPRArgs(bpr_model.learning_rate, \\\n","                bpr_model.bias_regularization, \\\n","                bpr_model.user_regularization, \\\n","                bpr_model.positive_item_regularization, \\\n","                bpr_model.negative_item_regularization, \\\n","                bpr_model.update_negative_item_factors)\n","        self.sampler = UniformUserUniformItem()\n","    \n","    def train_init(self):\n","        tmp = self.data.tocsr()\n","        self.dataidx = []\n","        for u in range(self.num_users):\n","            self.dataidx.append(tmp[u].indices)\n","\n","    def test_init(self, test_data, test_attr):\n","        assert sp.isspmatrix_csc(test_data)\n","        self.num_test_items, _ = test_attr.shape\n","        tmp = test_data.tocsr()\n","        self.test_attr = test_attr\n","        self.test_dataidx = []\n","        for u in range(self.num_users):\n","            self.test_dataidx.append(tmp[u].indices)\n","\n","    def cos_similarity(self, i):\n","        try:\n","            assert len(self.attr_sqr_cache) == len(self.attr)\n","            assert len(self.tattr_sqr_cache) == len(self.test_attr)\n","        except:\n","            self.attr_sqr_cache = []\n","            self.tattr_sqr_cache = []\n","            for j in range(self.num_items):\n","                self.attr_sqr_cache.append(sqrt(np.dot(self.attr[j], self.attr[j])))\n","            for j in range(self.num_test_items):\n","                self.tattr_sqr_cache.append(sqrt(np.dot(self.test_attr[j], self.test_attr[j])))\n","\n","        similarity = []\n","        for j in range(self.num_items):\n","            similarity.append(np.dot(self.test_attr[i], self.attr[j]) / (self.tattr_sqr_cache[i] * self.attr_sqr_cache[j]))\n","        return similarity\n","\n","    def accuracy(self, threshold=0.5):\n","    #XXX: bpr models have no range bound, while its focus are pair-wise relationships, so it's hard to set a threshold and test accuracy\n","        result = 0.0\n","        for i in range(self.num_test_items):\n","            pred_i = self.test_predict(i)\n","            for u in range(self.num_users):\n","                posidx = self.test_dataidx[u]\n","                if (pred_i[u]>=threshold and (i in posidx)) or (pred_i[u]<threshold and (not i in posidx)):\n","                    result += 1\n","        result /= (self.num_items * self.num_users)\n","        return result\n","\n","    def prec_at_n(self, prec_n):\n","        #precision of top-n recommended results, average across users\n","        assert prec_n <= self.num_test_items\n","        result = 0\n","        \n","        cand = [[] for i in range(self.num_users)]\n","        for i in range(self.num_test_items):\n","            pred_i = self.test_predict(i)\n","            for u in range(self.num_users):\n","                cand[u].append((pred_i[u], i))\n","        for u in range(self.num_users):\n","            keyfunc = functools.cmp_to_key(lambda x,y : cmp(x[0],y[0]))\n","            cand[u].sort(key=keyfunc, reverse=True)\n","            tmp = 0.0\n","            row_u = self.test_dataidx[u]\n","            for i in range(prec_n):\n","                if cand[u][i][1] in row_u:\n","                    tmp += 1\n","            result += tmp/prec_n\n","        result /= self.num_users\n","        return result\n","\n","    def auc(self):\n","        #area under ROC curve, compute , average across users\n","        result = 0\n","        pred = [[] for i in range(self.num_users)]\n","        for i in range(self.num_test_items):\n","            pred_i = self.test_predict(i)\n","            for u in range(self.num_users):\n","                pred[u].append(pred_i[u])\n","        for u in range(self.num_users):\n","            tmp = 0.0\n","            posidx = self.test_dataidx[u]\n","            for j in range(self.num_test_items):\n","                if j in posidx:\n","                    continue\n","                for i in posidx:\n","                    if pred[u][i]-pred[u][j]>=0:\n","                        tmp += 1\n","            real_pos = len(posidx)\n","            result += tmp/max(real_pos, 1)/max(self.num_test_items-real_pos, 1)\n","        result /= self.num_users\n","        return result \n","\n","    def cross_validation(self, cv_num_iters, cv_set, cv_folds):\n","        origin_data = self.data\n","        origin_attr = self.attr\n","        origin_model = self.bpr_model\n","        splitter = DataSplitter(origin_data, origin_attr, cv_folds)\n","        datamats = splitter.split_data()\n","        attrmats = splitter.split_attr()\n","        bestscore = 0.0\n","        bestpara = None\n","        for para in cv_set:\n","            self.set_parameter(para)\n","            avg_score = 0.0\n","            print(\"Cross-validating parameter\",para,\".........\")\n","            for i in range(cv_folds):\n","                tmp_data = copy(datamats)\n","                tmp_data.pop(i)\n","                tmp_attr = copy(attrmats)\n","                tmp_attr.pop(i)\n","                self.init(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), self.bpr_k, self.bpr_args)\n","                self.train(cv_num_iters)\n","                self.test_init(datamats[i], attrmats[i])\n","                #avg_score += self.accuracy()\n","                cur_score = self.prec_at_n(5)\n","                print(\"prec@5 of cross-validation fold\",i,\":\",cur_score)\n","                avg_score += cur_score\n","            avg_score /= cv_folds\n","            print(\"Average score for parameter after cross-validation\",para,\":\",avg_score)\n","            if (avg_score > bestscore):\n","                bestpara = para\n","                bestscore = avg_score\n","        #print(\"best parameter in cross-validation :\", bestpara, \"with accuracy\", bestscore)\n","        print(\"best parameter in cross-validation :\", bestpara, \"with prec@n\", bestscore)\n","        self.init(origin_data, origin_attr, None, None, origin_model)\n","        return para\n","\n","class Map_KNN(Mapper):\n","\n","    def __init__(self, data, attr, bpr_k=None, bpr_args=None, k=1):\n","        self.init(data, attr, bpr_k, bpr_args)\n","        self.k = k\n","\n","    def set_parameter(self, k):\n","        self.k = k\n","\n","    def train(self, num_iters):\n","        self.train_init()\n","        self.bpr_model.train(self.dataidx, self.num_items, self.sampler, num_iters)\n","        \n","    def test(self, test_data, test_attr, prec_n=5):\n","        self.test_init(test_data, test_attr)\n","        return [self.prec_at_n(prec_n), self.auc()]   \n","\n","    def test_predict(self, i):\n","        result = []\n","        cos_sim = self.cos_similarity(i)\n","        cand = [(cos_sim[i], i) for i in range(self.num_items)]\n","        keyfunc = functools.cmp_to_key(lambda x,y: cmp(x[0],y[0]))\n","        cand.sort(key=keyfunc, reverse=True)\n","        #average new h from top-k h vectors, and predict with bpr\n","        i_factors = np.zeros(self.bpr_k)\n","        i_bias = 0\n","        for j in range(self.k):\n","            i_factors += cand[j][0] * self.bpr_model.item_factors[cand[j][1],:]\n","            i_bias += cand[j][0] * self.bpr_model.item_bias[cand[j][1]]\n","        sim_sum = sum(cand[j][0] for j in range(self.k))\n","        i_factors /= sim_sum\n","        i_bias /= sim_sum\n","        for u in range(self.num_users):\n","            result.append(i_bias + np.dot(self.bpr_model.user_factors[u], i_factors))\n","        return result\n","\n","class Map_Linear(Mapper):\n","\n","    def __init__(self, data, attr, bpr_k=None, bpr_args=None, learning_rate=None, penalty_factor=None):\n","        self.init(data, attr, bpr_k, bpr_args)\n","        self.learning_rate = learning_rate\n","        self.penalty_factor = penalty_factor\n","\n","    def train(self, num_iters):\n","        self.train_init()\n","        self.bpr_model.train(self.dataidx, self.num_items, self.sampler, num_iters)\n","        #train linear models for bpr_k column across attributes(X=attrs, Y=H[u])\n","        self.mapper_factors = np.random.random_sample((self.bpr_k, self.num_attrs))\n","        self.mapper_bias = np.zeros(self.bpr_k)\n","        self.mapper_factors_b = np.random.random_sample(self.num_attrs)\n","        self.mapper_bias_b = 0\n","        for it in range(num_iters):\n","            print(\"Mapper Map_Linear trainning for iteration\",it,\"...\")\n","            diff = np.dot(self.attr, self.mapper_factors.transpose()) + np.dot(np.ones((self.num_items,1)), self.mapper_bias.reshape((1,self.bpr_k))) \\\n","                - self.bpr_model.item_factors \n","            self.mapper_factors -= self.learning_rate/self.num_items*(np.dot(diff.transpose(), self.attr)+self.penalty_factor*self.mapper_factors)\n","            self.mapper_bias -= self.learning_rate/self.num_items*(np.dot(diff.transpose(), np.ones(self.num_items)))\n","            diff_b = np.dot(self.attr, self.mapper_factors_b) + self.mapper_bias_b*np.ones(self.num_items)-self.bpr_model.item_bias\n","            self.mapper_factors_b -= self.learning_rate/self.num_items*(np.dot(diff_b, self.attr) + self.penalty_factor*self.mapper_factors_b)\n","            self.mapper_bias_b -= self.learning_rate/self.num_items*(np.dot(diff_b, np.ones(self.num_items)))\n","\n","    def test(self, test_data, test_attr, prec_n=5):\n","        self.test_init(test_data, test_attr) \n","        return [self.prec_at_n(prec_n), self.auc()]   \n","\n","    def test_predict(self, i):\n","        result = []\n","        i_factors = self.mapper_bias + np.dot(self.mapper_factors, self.test_attr[i])\n","        i_bias = self.mapper_bias_b + np.dot(self.mapper_factors_b, self.test_attr[i])\n","        for u in range(self.num_users):\n","            result.append(i_bias + np.dot(self.bpr_model.user_factors[u], i_factors))\n","        return result\n","\n","    def set_parameter(self, para_set):\n","        self.learning_rate = para_set[0]\n","        self.penalty_factor = para_set[1]\n","\n","class Map_BPR(Mapper):\n","\n","    def __init__(self, data, attr, bpr_k=None, bpr_args=None, learning_rate=None, penalty_factor=None):\n","        self.init(data, attr, bpr_k, bpr_args)\n","        self.learning_rate = learning_rate\n","        self.penalty_factor = penalty_factor\n","\n","    def train(self, num_iters):\n","        self.train_init()\n","        self.bpr_model.train(self.dataidx, self.num_items, self.sampler, num_iters)\n","        #train linear models for bpr_k column across attributes(X=attrs, Y=H[u])\n","        self.mapper_factors = np.random.random_sample((self.bpr_k, self.num_attrs))\n","        #self.mapper_bias = np.zeros((self.bpr_k, 1))\n","        #self.mapper_factors_b = np.random.random_sample(self.num_attrs)\n","        #self.mapper_bias_b = np.zeros(1)\n","        for it in range(num_iters):\n","            print(\"Mapper Map_BPR trainning for iteration\",it,\"...\")\n","            for u,i,j in self.sampler.generate_samples(self.dataidx, self.num_items):\n","                x_uij = self.predict(u,i) - self.predict(u,j)\n","                #XXX: maybe it should be exp(-x)/(1.0+exp(-x))\n","                #z = 1.0/(1.0+exp(x_uij))\n","                z = 1.0 - 1.0/(1.0+exp(-x_uij))\n","                u_factor = (self.bpr_model.user_factors[u,:]).reshape((self.bpr_k, 1))\n","                ij_diff = (self.attr[i]-self.attr[j]).reshape((1, self.num_attrs))\n","\n","                gradient = z * np.dot(u_factor, ij_diff) \n","                self.mapper_factors = self.learning_rate * ( \\\n","                    gradient - self.penalty_factor * self.mapper_factors )\n","                #self.mapper_bias = self.learning_rate * ( \\\n","                #    z * u_factor \\\n","                #    - self.penalty_factor * self.mapper_bias )\n","\n","    def predict(self, u, i):\n","        return np.dot( self.bpr_model.user_factors[u,:] \\\n","            , np.dot(self.mapper_factors, self.attr[i]) )\n","            #\\+self.mapper_bias )\n","\n","    def test(self, test_data, test_attr, prec_n=5):\n","        self.test_init(test_data, test_attr) \n","        return [self.prec_at_n(prec_n), self.auc()]   \n","\n","    def test_predict(self, i):\n","        result = []\n","        i_factors = np.dot(self.mapper_factors, self.test_attr[i])\n","            #\\+self.mapper_bias\n","        #no i_bias here because we didn't use actual h_i in trainning\n","        for u in range(self.num_users):\n","            result.append(np.dot(self.bpr_model.user_factors[u], i_factors))\n","        return result\n","\n","    def set_parameter(self, para_set):\n","        self.learning_rate = para_set[0]\n","        self.penalty_factor = para_set[1]\n","\n","class CBF_KNN(Mapper):\n","\n","    def __init__(self, data, attr, bpr_k=None, bpr_args=None, k=None):\n","        self.init(data, attr, bpr_k, bpr_args)\n","        self.k = k\n","\n","    def set_parameter(self, k):\n","        self.k = k\n","\n","    def train(self, num_iters):\n","        # underlying bpr model is useless, so no need to train\n","        self.train_init()\n","        pass \n","\n","    def test(self, test_data, test_attr, prec_n=5):\n","        self.test_init(test_data, test_attr)\n","        return [self.prec_at_n(prec_n), self.auc()]   \n","\n","    def test_predict(self, i):\n","        result = []\n","        cos_sim = self.cos_similarity(i)\n","        if self.k==None:\n","            # k is infinity by default\n","            for u in range(self.num_users):\n","                pred_j = 0\n","                for j in self.dataidx[u]:\n","                    pred_j += cos_sim[j]\n","                result.append(pred_j)\n","        else:\n","            for u in range(self.num_users):\n","                cand = []\n","                for j in self.dataidx[u]:\n","                    cand.append(cos_sim[j])\n","                cand.sort()\n","                pred_j = 0\n","                for j in range(self.k):\n","                    pred_j += cand[j]\n","                result.append(pred_j)\n","        return result\n","\n","class Map_Random(Mapper):\n","\n","    def __init__(self, data, attr, bpr_k=None, bpr_args=None):\n","        self.init(data, attr, bpr_k, bpr_args)\n","\n","    def train(self, num_iters):\n","        #no need to train\n","        pass\n","\n","    def test(self, test_data, test_attr, prec_n=5):\n","        self.test_init(test_data, test_attr)\n","        return [self.prec_at_n(prec_n), self.auc()]   \n","\n","    def test_predict(self, i, max_score=1.0):\n","        return [(random.random() * max_score) for i in range(self.num_users)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"18rynne1Q35g"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"FwCVHDGGby56"},"source":["def main(model_id):\n","    #all parameters needed setting are here\n","    num_folds = 3\n","    bpr_args = BPRArgs(0.01, 1.0, 0.02125, 0.00355, 0.00355)\n","    bpr_k = 24\n","    cv_iters = 10\n","    cv_folds = 3\n","    num_iters = 20\n","\n","    data = sp.csc_matrix(np.loadtxt('feedback.txt'))\n","    attr = np.loadtxt('attribute.txt')\n","    splitter = DataSplitter(data, attr, num_folds)\n","    datamats = splitter.split_data()\n","    attrmats = splitter.split_attr()\n","\n","    assert num_folds>1\n","    assert cv_folds>1\n","    avg_prec = 0\n","    avg_auc = 0\n","\n","    #training & testing\n","    for i in range(num_folds):\n","        tmp_data = copy(datamats)\n","        tmp_data.pop(i)\n","        tmp_attr = copy(attrmats)\n","        tmp_attr.pop(i)\n","\n","        if (model_id == 0):\n","            cv_parameter_set = [(0.03,0.03), (0.03,0.1), (0.1,0.03), (0.1,0.1)]\n","            model = Map_BPR(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), bpr_k, bpr_args)\n","        elif (model_id == 1):\n","            cv_parameter_set = [(0.03,0.03), (0.03,0.1), (0.1,0.03), (0.1,0.1)]\n","            model = Map_Linear(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), bpr_k, bpr_args)\n","        elif (model_id == 2):\n","            cv_parameter_set = [1, 2, 3]\n","            model = Map_KNN(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), bpr_k, bpr_args)\n","        elif (model_id == 3):\n","            model = CBF_KNN(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), bpr_k, bpr_args)\n","        elif (model_id == 4):\n","            model = Map_Random(sp.hstack(tmp_data,\"csc\"), np.vstack(tmp_attr), bpr_k, bpr_args)\n","\n","        if (model_id<3):\n","            para = model.cross_validation(cv_iters, cv_parameter_set, cv_folds)\n","            model.set_parameter(para)\n","        model.train(num_iters)\n","\n","        prec, auc = model.test(datamats[i], attrmats[i])\n","        print(\"Test for fold\",i,\": Prec@n =\",prec,\"auc =\",auc)\n","        print(\"------------------------------------------------\")\n","        avg_prec += prec\n","        avg_auc += auc\n","    print(\"avg_prec = \", avg_prec/num_folds, \", avg_auc = \", avg_auc/num_folds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DATZJ_XbcIau"},"source":["## Runs"]},{"cell_type":"markdown","metadata":{"id":"2uCSTKw9OiYr"},"source":["0=Map_BPR 1=Map_Linear 2=Map_KNN 3=CBF_KNN 4=Random"]},{"cell_type":"markdown","metadata":{"id":"nceJJCR5cKyj"},"source":["### Random"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLLzDBTPVj-V","executionInfo":{"status":"ok","timestamp":1635668537125,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"7fdcbe36-6942-4777-b76a-1fb7c30b9f54"},"source":["main(model_id=4)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test for fold 0 : Prec@n = 0.34 auc = 0.40187818662818664\n","------------------------------------------------\n","Test for fold 1 : Prec@n = 0.23000000000000004 auc = 0.36780595330595334\n","------------------------------------------------\n","Test for fold 2 : Prec@n = 0.19 auc = 0.30416527916527913\n","------------------------------------------------\n","avg_prec =  0.25333333333333335 , avg_auc =  0.35794980636647306\n"]}]},{"cell_type":"markdown","metadata":{"id":"iYum03z-QVfY"},"source":["### CBF-KNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GddVLNjWTm2P","executionInfo":{"status":"ok","timestamp":1635668581409,"user_tz":-330,"elapsed":586,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"222097f6-6a59-4813-f67b-c75d3dcabd26"},"source":["main(model_id=3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test for fold 0 : Prec@n = 0.35000000000000003 auc = 0.6394615477115477\n","------------------------------------------------\n","Test for fold 1 : Prec@n = 0.31 auc = 0.488562382062382\n","------------------------------------------------\n","Test for fold 2 : Prec@n = 0.09 auc = 0.21145521145521146\n","------------------------------------------------\n","avg_prec =  0.25 , avg_auc =  0.4464930470763804\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQJcklOCcdcl","executionInfo":{"status":"ok","timestamp":1635668689047,"user_tz":-330,"elapsed":3898,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d7bd7ad5-4851-43e4-8bd3-66140106256c"},"source":["### Map-KNN\n","main(model_id=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validating parameter 1 .........\n","iteration 0: loss = 43.40243399091855\n","iteration 1: loss = 40.65759467250106\n","iteration 2: loss = 37.850404923721015\n","iteration 3: loss = 36.12252169933082\n","iteration 4: loss = 33.60884418137949\n","iteration 5: loss = 32.73648687535113\n","iteration 6: loss = 31.443470041655193\n","iteration 7: loss = 30.511488100610023\n","iteration 8: loss = 30.054597528818107\n","iteration 9: loss = 29.903831916431155\n","prec@5 of cross-validation fold 0 : 0.25000000000000006\n","iteration 0: loss = 64.4090728002564\n","iteration 1: loss = 58.06587235120557\n","iteration 2: loss = 52.93512649079631\n","iteration 3: loss = 49.65735295762282\n","iteration 4: loss = 47.145812876094396\n","iteration 5: loss = 45.80213683270445\n","iteration 6: loss = 44.4974831686896\n","iteration 7: loss = 42.77294614129626\n","iteration 8: loss = 41.60951943560116\n","iteration 9: loss = 41.17911214468912\n","prec@5 of cross-validation fold 1 : 0.25\n","iteration 0: loss = 61.32393802142997\n","iteration 1: loss = 56.61785171648897\n","iteration 2: loss = 52.01337289263955\n","iteration 3: loss = 50.149989595324946\n","iteration 4: loss = 48.1626596598943\n","iteration 5: loss = 46.175831599348356\n","iteration 6: loss = 45.35313989794629\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:179: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:180: RuntimeWarning: invalid value encountered in double_scalars\n"]},{"output_type":"stream","name":"stdout","text":["iteration 7: loss = 44.19893913590752\n","iteration 8: loss = 42.53815374221108\n","iteration 9: loss = 41.39456742078118\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation 1 : 0.21\n","Cross-validating parameter 2 .........\n","iteration 0: loss = 44.831161945616216\n","iteration 1: loss = 40.76142681723129\n","iteration 2: loss = 39.0730877640284\n","iteration 3: loss = 36.48856464903984\n","iteration 4: loss = 34.468941470569455\n","iteration 5: loss = 32.61980395526727\n","iteration 6: loss = 31.606291029008787\n","iteration 7: loss = 30.470414216872534\n","iteration 8: loss = 29.487360945399644\n","iteration 9: loss = 27.85419391874221\n","prec@5 of cross-validation fold 0 : 0.26000000000000006\n","iteration 0: loss = 52.79399853538475\n","iteration 1: loss = 50.58614178324535\n","iteration 2: loss = 47.15013968108587\n","iteration 3: loss = 45.11858772907325\n","iteration 4: loss = 43.69562158794619\n","iteration 5: loss = 41.78073842155967\n","iteration 6: loss = 41.17133662772308\n","iteration 7: loss = 40.22444138018134\n","iteration 8: loss = 39.39257220458339\n","iteration 9: loss = 38.74770298171789\n","prec@5 of cross-validation fold 1 : 0.24000000000000005\n","iteration 0: loss = 56.346433575937795\n","iteration 1: loss = 52.28143558983291\n","iteration 2: loss = 48.63636639594341\n","iteration 3: loss = 46.78291956078614\n","iteration 4: loss = 44.292107183634776\n","iteration 5: loss = 41.78893820037616\n","iteration 6: loss = 40.152258484880655\n","iteration 7: loss = 38.9296484057496\n","iteration 8: loss = 37.80315576828086\n","iteration 9: loss = 36.992514456492174\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation 2 : 0.21000000000000005\n","Cross-validating parameter 3 .........\n","iteration 0: loss = 35.08606491871245\n","iteration 1: loss = 33.53375153264883\n","iteration 2: loss = 32.13683535520916\n","iteration 3: loss = 31.238961397099658\n","iteration 4: loss = 30.5093403418766\n","iteration 5: loss = 29.784285929856797\n","iteration 6: loss = 29.511655007155007\n","iteration 7: loss = 28.94868001394659\n","iteration 8: loss = 28.4832194915134\n","iteration 9: loss = 27.943911475551985\n","prec@5 of cross-validation fold 0 : 0.26000000000000006\n","iteration 0: loss = 63.00610293308826\n","iteration 1: loss = 58.57886968697898\n","iteration 2: loss = 54.78304878688647\n","iteration 3: loss = 50.03941576682113\n","iteration 4: loss = 47.67348587289633\n","iteration 5: loss = 46.66131226105141\n","iteration 6: loss = 45.19878393819917\n","iteration 7: loss = 44.1126159468976\n","iteration 8: loss = 43.54142545797538\n","iteration 9: loss = 42.58062603592771\n","prec@5 of cross-validation fold 1 : 0.19000000000000003\n","iteration 0: loss = 65.06556784808845\n","iteration 1: loss = 56.37143403985609\n","iteration 2: loss = 53.08521079797845\n","iteration 3: loss = 50.27713249694848\n","iteration 4: loss = 48.40616553901774\n","iteration 5: loss = 46.9170325324579\n","iteration 6: loss = 45.22266961454842\n","iteration 7: loss = 43.392937023791205\n","iteration 8: loss = 42.51358269499687\n","iteration 9: loss = 41.88145551535415\n","prec@5 of cross-validation fold 2 : 0.15000000000000002\n","Average score for parameter after cross-validation 3 : 0.20000000000000004\n","best parameter in cross-validation : 2 with prec@n 0.21000000000000005\n","iteration 0: loss = 76.28673050930851\n","iteration 1: loss = 71.79427009403891\n","iteration 2: loss = 68.1584280968783\n","iteration 3: loss = 64.71021126203388\n","iteration 4: loss = 63.11561027200814\n","iteration 5: loss = 61.25679438117817\n","iteration 6: loss = 60.28227779319883\n","iteration 7: loss = 59.294960576796\n","iteration 8: loss = 58.51690654092427\n","iteration 9: loss = 57.93410776026923\n","iteration 10: loss = 57.1846746345047\n","iteration 11: loss = 55.91769486204663\n","iteration 12: loss = 55.42639933530113\n","iteration 13: loss = 54.6548447807004\n","iteration 14: loss = 54.724936065364254\n","iteration 15: loss = 53.9947598276371\n","iteration 16: loss = 53.51816000869425\n","iteration 17: loss = 52.75552264148136\n","iteration 18: loss = 52.395071495498904\n","iteration 19: loss = 51.827473093100636\n","Test for fold 0 : Prec@n = 0.3400000000000001 auc = 0.5143437673437674\n","------------------------------------------------\n","Cross-validating parameter 1 .........\n","iteration 0: loss = 53.1869316873635\n","iteration 1: loss = 49.23851190761488\n","iteration 2: loss = 46.31372372104262\n","iteration 3: loss = 44.25543412927418\n","iteration 4: loss = 43.06133728470088\n","iteration 5: loss = 41.93277870665634\n","iteration 6: loss = 40.92955472378242\n","iteration 7: loss = 40.39492651343292\n","iteration 8: loss = 39.492956853698345\n","iteration 9: loss = 38.57219163628457\n","prec@5 of cross-validation fold 0 : 0.3\n","iteration 0: loss = 81.76170922411431\n","iteration 1: loss = 74.29579759203912\n","iteration 2: loss = 68.46000854141361\n","iteration 3: loss = 64.80868277697506\n","iteration 4: loss = 62.649285879263374\n","iteration 5: loss = 59.72468065230031\n","iteration 6: loss = 58.18754161499027\n","iteration 7: loss = 56.96415596743242\n","iteration 8: loss = 55.081459740080774\n","iteration 9: loss = 53.808238834856205\n","prec@5 of cross-validation fold 1 : 0.2\n","iteration 0: loss = 115.93679071972426\n","iteration 1: loss = 103.7633962497899\n","iteration 2: loss = 95.47639622604781\n","iteration 3: loss = 86.53758702826957\n","iteration 4: loss = 81.92741075977989\n","iteration 5: loss = 78.94810330502568\n","iteration 6: loss = 76.43250546423978\n","iteration 7: loss = 74.8212550578003\n","iteration 8: loss = 72.59446220407688\n","iteration 9: loss = 71.16897361285532\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation 1 : 0.21\n","Cross-validating parameter 2 .........\n","iteration 0: loss = 68.72292464512692\n","iteration 1: loss = 60.525547356162114\n","iteration 2: loss = 56.53771982996667\n","iteration 3: loss = 53.90520938631746\n","iteration 4: loss = 50.880296712870376\n","iteration 5: loss = 48.720816949949906\n","iteration 6: loss = 47.44042138848758\n","iteration 7: loss = 46.49834108976505\n","iteration 8: loss = 45.59541357051351\n","iteration 9: loss = 44.53717768389533\n","prec@5 of cross-validation fold 0 : 0.22000000000000003\n","iteration 0: loss = 76.93440737663748\n","iteration 1: loss = 68.02306956181035\n","iteration 2: loss = 61.41435511488804\n","iteration 3: loss = 57.33100427726546\n","iteration 4: loss = 54.88796220312288\n","iteration 5: loss = 52.68597860870178\n","iteration 6: loss = 51.31875930932274\n","iteration 7: loss = 49.96392689149043\n","iteration 8: loss = 48.75891385607049\n","iteration 9: loss = 47.24327727570021\n","prec@5 of cross-validation fold 1 : 0.25000000000000006\n","iteration 0: loss = 107.64578192473252\n","iteration 1: loss = 96.81972020955993\n","iteration 2: loss = 91.36887435332743\n","iteration 3: loss = 86.94697501271173\n","iteration 4: loss = 82.29293556517806\n","iteration 5: loss = 78.2824425576034\n","iteration 6: loss = 75.06456566319066\n","iteration 7: loss = 73.44841768183309\n","iteration 8: loss = 72.68415334091212\n","iteration 9: loss = 71.79855617178683\n","prec@5 of cross-validation fold 2 : 0.17\n","Average score for parameter after cross-validation 2 : 0.21333333333333337\n","Cross-validating parameter 3 .........\n","iteration 0: loss = 81.45870717349669\n","iteration 1: loss = 74.89283417369069\n","iteration 2: loss = 70.39084559612736\n","iteration 3: loss = 67.46362511561139\n","iteration 4: loss = 64.78326377613058\n","iteration 5: loss = 62.635625127621765\n","iteration 6: loss = 60.98400973356874\n","iteration 7: loss = 59.39501004573002\n","iteration 8: loss = 59.07542760046221\n","iteration 9: loss = 57.68533326754971\n","prec@5 of cross-validation fold 0 : 0.36999999999999994\n","iteration 0: loss = 83.05586548370444\n","iteration 1: loss = 72.09296277226142\n","iteration 2: loss = 66.09362613566503\n","iteration 3: loss = 62.290011169160834\n","iteration 4: loss = 59.313460893973314\n","iteration 5: loss = 57.09611005512291\n","iteration 6: loss = 55.65619669267673\n","iteration 7: loss = 54.870444910538936\n","iteration 8: loss = 53.370890247854376\n","iteration 9: loss = 52.1412714588534\n","prec@5 of cross-validation fold 1 : 0.28\n","iteration 0: loss = 110.95755245029903\n","iteration 1: loss = 99.3417491920096\n","iteration 2: loss = 91.26108824122758\n","iteration 3: loss = 85.8369997424384\n","iteration 4: loss = 81.80931363444697\n","iteration 5: loss = 77.71378591089723\n","iteration 6: loss = 76.06446429359609\n","iteration 7: loss = 74.91227934398228\n","iteration 8: loss = 73.07811889483177\n","iteration 9: loss = 71.16155571135889\n","prec@5 of cross-validation fold 2 : 0.15000000000000002\n","Average score for parameter after cross-validation 3 : 0.26666666666666666\n","best parameter in cross-validation : 3 with prec@n 0.26666666666666666\n","iteration 0: loss = 138.77809051226328\n","iteration 1: loss = 125.35669025089234\n","iteration 2: loss = 115.57909982801235\n","iteration 3: loss = 108.0344590801985\n","iteration 4: loss = 103.07675352893446\n","iteration 5: loss = 99.10910350678938\n","iteration 6: loss = 95.48334171516208\n","iteration 7: loss = 92.5740461420919\n","iteration 8: loss = 90.2979477648368\n","iteration 9: loss = 88.74560689712484\n","iteration 10: loss = 87.25517291442704\n","iteration 11: loss = 85.80724141588591\n","iteration 12: loss = 83.45082114893013\n","iteration 13: loss = 81.7330257133095\n","iteration 14: loss = 80.66432666162476\n","iteration 15: loss = 79.46130977578039\n","iteration 16: loss = 78.39700747068824\n","iteration 17: loss = 77.26577135237758\n","iteration 18: loss = 76.59235752832262\n","iteration 19: loss = 75.8085169423163\n","Test for fold 1 : Prec@n = 0.2 auc = 0.29203337403337404\n","------------------------------------------------\n","Cross-validating parameter 1 .........\n","iteration 0: loss = 90.20856764265909\n","iteration 1: loss = 81.67880037744551\n","iteration 2: loss = 76.51544384793665\n","iteration 3: loss = 72.66795025893701\n","iteration 4: loss = 69.9552351856739\n","iteration 5: loss = 68.74826463463579\n","iteration 6: loss = 66.72227331064357\n","iteration 7: loss = 64.45941960342373\n","iteration 8: loss = 63.368305863491464\n","iteration 9: loss = 63.109509704499224\n","prec@5 of cross-validation fold 0 : 0.28\n","iteration 0: loss = 112.72906093959065\n","iteration 1: loss = 99.37396952951198\n","iteration 2: loss = 92.94382012908636\n","iteration 3: loss = 88.06580882374006\n","iteration 4: loss = 83.98596082914884\n","iteration 5: loss = 80.41885598900058\n","iteration 6: loss = 78.66904968916904\n","iteration 7: loss = 75.99111968003011\n","iteration 8: loss = 74.64702385796856\n","iteration 9: loss = 72.09565490285922\n","prec@5 of cross-validation fold 1 : 0.37\n","iteration 0: loss = 105.96570925834638\n","iteration 1: loss = 96.59259614124058\n","iteration 2: loss = 88.29821603922298\n","iteration 3: loss = 83.05141643387675\n","iteration 4: loss = 80.50207043943675\n","iteration 5: loss = 79.14850783201992\n","iteration 6: loss = 76.36661234893717\n","iteration 7: loss = 74.28220239233181\n","iteration 8: loss = 72.74345360570766\n","iteration 9: loss = 71.39849995496321\n","prec@5 of cross-validation fold 2 : 0.32\n","Average score for parameter after cross-validation 1 : 0.3233333333333333\n","Cross-validating parameter 2 .........\n","iteration 0: loss = 105.34181908138254\n","iteration 1: loss = 92.42763262364716\n","iteration 2: loss = 83.8010763826438\n","iteration 3: loss = 78.7058238889885\n","iteration 4: loss = 73.2766838034653\n","iteration 5: loss = 69.38747424939623\n","iteration 6: loss = 66.19064411037434\n","iteration 7: loss = 63.56895929879138\n","iteration 8: loss = 62.477313698758515\n","iteration 9: loss = 61.765935377059236\n","prec@5 of cross-validation fold 0 : 0.26000000000000006\n","iteration 0: loss = 88.00582062319651\n","iteration 1: loss = 82.0114419355074\n","iteration 2: loss = 75.67875856816329\n","iteration 3: loss = 71.75985089440768\n","iteration 4: loss = 70.08130693646346\n","iteration 5: loss = 68.62867741707264\n","iteration 6: loss = 67.22791572139812\n","iteration 7: loss = 66.47133275001391\n","iteration 8: loss = 65.87442590701434\n","iteration 9: loss = 64.54610968898835\n","prec@5 of cross-validation fold 1 : 0.32\n","iteration 0: loss = 98.99405146612001\n","iteration 1: loss = 90.5827707900088\n","iteration 2: loss = 85.72184292530181\n","iteration 3: loss = 83.68908848717058\n","iteration 4: loss = 78.43651218663008\n","iteration 5: loss = 74.92447264826828\n","iteration 6: loss = 71.6064611442016\n","iteration 7: loss = 69.12427068466948\n","iteration 8: loss = 67.81967123422392\n","iteration 9: loss = 66.75509761113452\n","prec@5 of cross-validation fold 2 : 0.31\n","Average score for parameter after cross-validation 2 : 0.2966666666666667\n","Cross-validating parameter 3 .........\n","iteration 0: loss = 88.64842146181579\n","iteration 1: loss = 78.78838995152881\n","iteration 2: loss = 74.42113047194815\n","iteration 3: loss = 71.56282744550751\n","iteration 4: loss = 68.90470851684023\n","iteration 5: loss = 65.96255822028886\n","iteration 6: loss = 64.37810155239987\n","iteration 7: loss = 62.60544142686069\n","iteration 8: loss = 61.64523085096974\n","iteration 9: loss = 60.29229702274347\n","prec@5 of cross-validation fold 0 : 0.24000000000000007\n","iteration 0: loss = 116.31531039795414\n","iteration 1: loss = 99.70385966223014\n","iteration 2: loss = 90.75414256016089\n","iteration 3: loss = 85.31945746703403\n","iteration 4: loss = 81.12280731643224\n","iteration 5: loss = 78.52984715398168\n","iteration 6: loss = 76.83015563263936\n","iteration 7: loss = 75.71972317649926\n","iteration 8: loss = 75.29933499851016\n","iteration 9: loss = 73.03432836259424\n","prec@5 of cross-validation fold 1 : 0.3\n","iteration 0: loss = 109.91181895013813\n","iteration 1: loss = 102.03774030464812\n","iteration 2: loss = 98.41953623798821\n","iteration 3: loss = 93.5266811950956\n","iteration 4: loss = 91.15261313188493\n","iteration 5: loss = 89.31741898785431\n","iteration 6: loss = 86.6664531243207\n","iteration 7: loss = 86.10276421150806\n","iteration 8: loss = 83.27373563116922\n","iteration 9: loss = 81.7329905401836\n","prec@5 of cross-validation fold 2 : 0.24000000000000005\n","Average score for parameter after cross-validation 3 : 0.26\n","best parameter in cross-validation : 1 with prec@n 0.3233333333333333\n","iteration 0: loss = 155.75605511569893\n","iteration 1: loss = 143.82460279272107\n","iteration 2: loss = 132.88492774991477\n","iteration 3: loss = 124.90310473477817\n","iteration 4: loss = 120.45914214283623\n","iteration 5: loss = 118.78708726295352\n","iteration 6: loss = 114.28244333120517\n","iteration 7: loss = 112.72518274232357\n","iteration 8: loss = 110.78474359228113\n","iteration 9: loss = 106.81732173412004\n","iteration 10: loss = 104.17304361031096\n","iteration 11: loss = 102.47071052657381\n","iteration 12: loss = 99.73135540929007\n","iteration 13: loss = 98.58665323471672\n","iteration 14: loss = 97.775835251675\n","iteration 15: loss = 95.74445276370975\n","iteration 16: loss = 93.9317302257866\n","iteration 17: loss = 94.36916192307723\n","iteration 18: loss = 91.94268848566844\n","iteration 19: loss = 90.66369526349945\n","Test for fold 2 : Prec@n = 0.13999999999999999 auc = 0.16775863025863025\n","------------------------------------------------\n","avg_prec =  0.22666666666666668 , avg_auc =  0.32471192387859055\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcML2MnUciyz","executionInfo":{"status":"ok","timestamp":1635668710033,"user_tz":-330,"elapsed":5428,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"dc54929b-feca-481f-eeb5-271b4a58479b"},"source":["### Map-Linear\n","main(model_id=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 38.72110191953468\n","iteration 1: loss = 37.33848327162904\n","iteration 2: loss = 35.852620509390334\n","iteration 3: loss = 34.36757973583349\n","iteration 4: loss = 32.75507774618757\n","iteration 5: loss = 31.803825179188497\n","iteration 6: loss = 31.30625507899908\n","iteration 7: loss = 30.522994369260182\n","iteration 8: loss = 30.055099726478865\n","iteration 9: loss = 29.145269779842653\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.24000000000000005\n","iteration 0: loss = 63.75652757049426\n","iteration 1: loss = 59.71755507985954\n","iteration 2: loss = 54.57610556646238\n","iteration 3: loss = 52.19316147481439\n","iteration 4: loss = 50.550792544725056\n","iteration 5: loss = 48.46283508764442\n","iteration 6: loss = 47.18710443195921\n","iteration 7: loss = 45.63929716811934\n","iteration 8: loss = 44.70338869295071\n","iteration 9: loss = 43.70523819724141\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.21000000000000002\n","iteration 0: loss = 50.44807258184729\n","iteration 1: loss = 47.03861752127486\n","iteration 2: loss = 45.831738932562125\n","iteration 3: loss = 44.44770320376346\n","iteration 4: loss = 43.47216498160616\n","iteration 5: loss = 42.11015258504228\n","iteration 6: loss = 41.7422444910796\n","iteration 7: loss = 40.86066882699268\n","iteration 8: loss = 40.66017935827529\n","iteration 9: loss = 40.330093107992106\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.14000000000000004\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.19666666666666668\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 44.51203969251187\n","iteration 1: loss = 42.35983720180233\n","iteration 2: loss = 41.24991151374239\n","iteration 3: loss = 39.87535180437539\n","iteration 4: loss = 38.4123794989418\n","iteration 5: loss = 36.937801579142295\n","iteration 6: loss = 35.34631999637787\n","iteration 7: loss = 34.850258560777185\n","iteration 8: loss = 34.387713088803935\n","iteration 9: loss = 33.866926700041375\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.24000000000000005\n","iteration 0: loss = 52.35650538406176\n","iteration 1: loss = 49.08081134489775\n","iteration 2: loss = 47.22220182664272\n","iteration 3: loss = 45.89629892166444\n","iteration 4: loss = 44.368985950261774\n","iteration 5: loss = 43.56503230063383\n","iteration 6: loss = 42.85996122828686\n","iteration 7: loss = 41.84549297182073\n","iteration 8: loss = 41.24527274350195\n","iteration 9: loss = 40.84569275443251\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.21000000000000002\n","iteration 0: loss = 58.022518493619664\n","iteration 1: loss = 56.07603633081405\n","iteration 2: loss = 53.01054502673558\n","iteration 3: loss = 51.041153599388366\n","iteration 4: loss = 50.055067526299496\n","iteration 5: loss = 48.726283997252224\n","iteration 6: loss = 48.42671340967409\n","iteration 7: loss = 47.47039188539853\n","iteration 8: loss = 46.03137923895811\n","iteration 9: loss = 45.114571734376426\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.14000000000000004\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.19666666666666668\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 35.38839472709905\n","iteration 1: loss = 33.44711625579536\n","iteration 2: loss = 31.42770217291145\n","iteration 3: loss = 30.44107633196943\n","iteration 4: loss = 29.343255355031754\n","iteration 5: loss = 27.722410703240723\n","iteration 6: loss = 26.519678105585577\n","iteration 7: loss = 25.62289652243623\n","iteration 8: loss = 24.84586262168021\n","iteration 9: loss = 23.8575693454898\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.24000000000000005\n","iteration 0: loss = 58.50199265867212\n","iteration 1: loss = 53.83356663667264\n","iteration 2: loss = 51.0642565124257\n","iteration 3: loss = 48.736185000902836\n","iteration 4: loss = 47.392721909214636\n","iteration 5: loss = 45.87478964631016\n","iteration 6: loss = 44.64390651148578\n","iteration 7: loss = 44.115585739623114\n","iteration 8: loss = 43.671152453708245\n","iteration 9: loss = 43.25171667129495\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.21000000000000002\n","iteration 0: loss = 74.04799308483484\n","iteration 1: loss = 68.92629327472721\n","iteration 2: loss = 65.04668115071402\n","iteration 3: loss = 61.77180553124112\n","iteration 4: loss = 59.11730614161611\n","iteration 5: loss = 56.10266654823612\n","iteration 6: loss = 53.69817344332952\n","iteration 7: loss = 52.68986299445123\n","iteration 8: loss = 50.72871387749008\n","iteration 9: loss = 49.159301463890316\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.19333333333333336\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 38.226564678770174\n","iteration 1: loss = 35.88599717985704\n","iteration 2: loss = 32.67278659099904\n","iteration 3: loss = 30.63455667228466\n","iteration 4: loss = 29.56763771833808\n","iteration 5: loss = 28.251761015607983\n","iteration 6: loss = 26.818618987622532\n","iteration 7: loss = 26.06090631668346\n","iteration 8: loss = 25.125574927622345\n","iteration 9: loss = 24.68277483569384\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.24000000000000005\n","iteration 0: loss = 50.33263946057157\n","iteration 1: loss = 47.976382388010784\n","iteration 2: loss = 45.51497587592171\n","iteration 3: loss = 45.777318046615314\n","iteration 4: loss = 44.10622602961264\n","iteration 5: loss = 42.95162922950871\n","iteration 6: loss = 42.72338423114154\n","iteration 7: loss = 42.1556385088286\n","iteration 8: loss = 41.581172832826994\n","iteration 9: loss = 41.211010304137204\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.21000000000000002\n","iteration 0: loss = 60.05377272926742\n","iteration 1: loss = 56.4428499267014\n","iteration 2: loss = 51.23189501057954\n","iteration 3: loss = 48.44568610847839\n","iteration 4: loss = 47.59736122313833\n","iteration 5: loss = 46.17529873689218\n","iteration 6: loss = 44.77404987085256\n","iteration 7: loss = 43.966564038897474\n","iteration 8: loss = 43.7310603579124\n","iteration 9: loss = 42.76591429016679\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.19333333333333336\n","best parameter in cross-validation : (0.03, 0.03) with prec@n 0.19666666666666668\n","iteration 0: loss = 78.71908367324262\n","iteration 1: loss = 73.80289816209095\n","iteration 2: loss = 70.16309293308794\n","iteration 3: loss = 66.0784267448405\n","iteration 4: loss = 63.56276664841539\n","iteration 5: loss = 62.30246287636227\n","iteration 6: loss = 60.949353186099984\n","iteration 7: loss = 58.98521273308824\n","iteration 8: loss = 57.83051938468452\n","iteration 9: loss = 56.42111018002737\n","iteration 10: loss = 55.919820170927494\n","iteration 11: loss = 54.45270769440145\n","iteration 12: loss = 52.9084908266318\n","iteration 13: loss = 51.833315234265186\n","iteration 14: loss = 51.58881112746023\n","iteration 15: loss = 50.552064712711854\n","iteration 16: loss = 49.56145798819622\n","iteration 17: loss = 49.62983425687048\n","iteration 18: loss = 48.62940586541692\n","iteration 19: loss = 48.17589839128594\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","Mapper Map_Linear trainning for iteration 10 ...\n","Mapper Map_Linear trainning for iteration 11 ...\n","Mapper Map_Linear trainning for iteration 12 ...\n","Mapper Map_Linear trainning for iteration 13 ...\n","Mapper Map_Linear trainning for iteration 14 ...\n","Mapper Map_Linear trainning for iteration 15 ...\n","Mapper Map_Linear trainning for iteration 16 ...\n","Mapper Map_Linear trainning for iteration 17 ...\n","Mapper Map_Linear trainning for iteration 18 ...\n","Mapper Map_Linear trainning for iteration 19 ...\n","Test for fold 0 : Prec@n = 0.38 auc = 0.5291151163651163\n","------------------------------------------------\n","Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 75.85577432372551\n","iteration 1: loss = 70.53425915121724\n","iteration 2: loss = 65.6175367899295\n","iteration 3: loss = 62.94848718526701\n","iteration 4: loss = 60.54025371784861\n","iteration 5: loss = 58.92922062751449\n","iteration 6: loss = 57.63486469513007\n","iteration 7: loss = 56.54646352175845\n","iteration 8: loss = 55.66639048409365\n","iteration 9: loss = 54.80039701558939\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 71.5953991719417\n","iteration 1: loss = 66.20778540244862\n","iteration 2: loss = 61.521543313095066\n","iteration 3: loss = 59.84308851048047\n","iteration 4: loss = 56.62964299068872\n","iteration 5: loss = 54.20637780054307\n","iteration 6: loss = 53.46722179686061\n","iteration 7: loss = 50.961694186313274\n","iteration 8: loss = 49.3893453250318\n","iteration 9: loss = 48.52183614136226\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.22000000000000003\n","iteration 0: loss = 106.12330352434272\n","iteration 1: loss = 93.96527064923454\n","iteration 2: loss = 85.60393247568958\n","iteration 3: loss = 81.63847539709238\n","iteration 4: loss = 77.85311124407627\n","iteration 5: loss = 75.94269420459804\n","iteration 6: loss = 73.78128058443149\n","iteration 7: loss = 71.60434595311051\n","iteration 8: loss = 70.62708064128518\n","iteration 9: loss = 69.09422669521165\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.14\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.22666666666666668\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 61.56966895344209\n","iteration 1: loss = 55.420406712037156\n","iteration 2: loss = 51.58858521345395\n","iteration 3: loss = 49.817370580590634\n","iteration 4: loss = 47.170903317212755\n","iteration 5: loss = 45.15905241507549\n","iteration 6: loss = 44.380434484851214\n","iteration 7: loss = 43.33365901135963\n","iteration 8: loss = 42.78718572527674\n","iteration 9: loss = 41.98920434894307\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 51.80164975226287\n","iteration 1: loss = 50.37112128380707\n","iteration 2: loss = 49.42128921346582\n","iteration 3: loss = 48.08370459117578\n","iteration 4: loss = 46.624485436696176\n","iteration 5: loss = 46.08796712598863\n","iteration 6: loss = 45.19669589078613\n","iteration 7: loss = 44.63931585883654\n","iteration 8: loss = 43.728088741146124\n","iteration 9: loss = 43.557207550250965\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.17\n","iteration 0: loss = 110.12192849239005\n","iteration 1: loss = 100.75608815967121\n","iteration 2: loss = 94.50049377074673\n","iteration 3: loss = 89.23566480123391\n","iteration 4: loss = 85.60274596276054\n","iteration 5: loss = 81.57123868357002\n","iteration 6: loss = 79.08016404817818\n","iteration 7: loss = 77.07868094426391\n","iteration 8: loss = 75.02330896430117\n","iteration 9: loss = 73.16075075927311\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.14\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.21\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 67.34267083761549\n","iteration 1: loss = 61.09113180221871\n","iteration 2: loss = 57.36250784380786\n","iteration 3: loss = 54.233973049026076\n","iteration 4: loss = 52.61631025843409\n","iteration 5: loss = 50.385304710047194\n","iteration 6: loss = 49.25325462504185\n","iteration 7: loss = 48.10534278855641\n","iteration 8: loss = 46.66963416644785\n","iteration 9: loss = 45.64129170436033\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 89.3893670509352\n","iteration 1: loss = 78.39871450776607\n","iteration 2: loss = 71.74684598265837\n","iteration 3: loss = 66.85218792167939\n","iteration 4: loss = 62.325573443710255\n","iteration 5: loss = 59.675333287440516\n","iteration 6: loss = 57.92130702894602\n","iteration 7: loss = 55.95546468034375\n","iteration 8: loss = 54.97575145784492\n","iteration 9: loss = 54.13562026166726\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.26\n","iteration 0: loss = 96.94851233046954\n","iteration 1: loss = 86.79389243215282\n","iteration 2: loss = 80.26606742641434\n","iteration 3: loss = 76.27940400973092\n","iteration 4: loss = 72.95981572047938\n","iteration 5: loss = 69.8899050525978\n","iteration 6: loss = 67.82523585517136\n","iteration 7: loss = 65.83519891472497\n","iteration 8: loss = 64.18761430175375\n","iteration 9: loss = 62.82341657812361\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.14000000000000004\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.24000000000000002\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 76.87293798953588\n","iteration 1: loss = 71.46300337331505\n","iteration 2: loss = 66.97374030529856\n","iteration 3: loss = 63.54310864928047\n","iteration 4: loss = 58.90326149109913\n","iteration 5: loss = 56.626285350087336\n","iteration 6: loss = 54.44027540735155\n","iteration 7: loss = 52.6555113228943\n","iteration 8: loss = 51.32767623349268\n","iteration 9: loss = 50.029286071708015\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 84.86049932192518\n","iteration 1: loss = 70.83708270625695\n","iteration 2: loss = 62.02053099287983\n","iteration 3: loss = 56.533578558907344\n","iteration 4: loss = 53.5846849346443\n","iteration 5: loss = 50.81302190480561\n","iteration 6: loss = 49.17038138698103\n","iteration 7: loss = 46.51317148039881\n","iteration 8: loss = 45.68479826634973\n","iteration 9: loss = 44.64725029652452\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.18\n","iteration 0: loss = 114.85121471018834\n","iteration 1: loss = 102.96901378542532\n","iteration 2: loss = 96.17080201859324\n","iteration 3: loss = 91.08695075787969\n","iteration 4: loss = 86.61886129263384\n","iteration 5: loss = 82.51275008669731\n","iteration 6: loss = 79.54434714053663\n","iteration 7: loss = 77.7289413983446\n","iteration 8: loss = 76.27798830345117\n","iteration 9: loss = 75.3185637906642\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.15000000000000002\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.21666666666666667\n","best parameter in cross-validation : (0.1, 0.03) with prec@n 0.24000000000000002\n","iteration 0: loss = 124.46006628607819\n","iteration 1: loss = 112.36033012184456\n","iteration 2: loss = 107.38807287902765\n","iteration 3: loss = 103.27960696659312\n","iteration 4: loss = 98.86547295951968\n","iteration 5: loss = 96.76355982144976\n","iteration 6: loss = 94.94849916580031\n","iteration 7: loss = 92.54673235236027\n","iteration 8: loss = 90.06550044959505\n","iteration 9: loss = 88.32668486762023\n","iteration 10: loss = 88.66233493841327\n","iteration 11: loss = 88.43834118231393\n","iteration 12: loss = 87.08089352447443\n","iteration 13: loss = 86.6343984233306\n","iteration 14: loss = 85.45103083853346\n","iteration 15: loss = 84.56132057182904\n","iteration 16: loss = 83.79341944177965\n","iteration 17: loss = 83.03166695501167\n","iteration 18: loss = 81.24723740599796\n","iteration 19: loss = 80.11479767990198\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","Mapper Map_Linear trainning for iteration 10 ...\n","Mapper Map_Linear trainning for iteration 11 ...\n","Mapper Map_Linear trainning for iteration 12 ...\n","Mapper Map_Linear trainning for iteration 13 ...\n","Mapper Map_Linear trainning for iteration 14 ...\n","Mapper Map_Linear trainning for iteration 15 ...\n","Mapper Map_Linear trainning for iteration 16 ...\n","Mapper Map_Linear trainning for iteration 17 ...\n","Mapper Map_Linear trainning for iteration 18 ...\n","Mapper Map_Linear trainning for iteration 19 ...\n","Test for fold 1 : Prec@n = 0.2700000000000001 auc = 0.4208597698597698\n","------------------------------------------------\n","Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 95.34204233411499\n","iteration 1: loss = 87.25362311158572\n","iteration 2: loss = 79.86558109838077\n","iteration 3: loss = 76.56375360582524\n","iteration 4: loss = 74.37286565679707\n","iteration 5: loss = 72.73522351858287\n","iteration 6: loss = 71.07676538623056\n","iteration 7: loss = 69.63816927384937\n","iteration 8: loss = 69.04064127944392\n","iteration 9: loss = 67.55186709844355\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 101.49658886372552\n","iteration 1: loss = 92.29456620243754\n","iteration 2: loss = 86.19342668032513\n","iteration 3: loss = 81.20117229494916\n","iteration 4: loss = 77.3471826414692\n","iteration 5: loss = 74.56633860858292\n","iteration 6: loss = 73.18638222696231\n","iteration 7: loss = 70.25710807841352\n","iteration 8: loss = 69.07630175347363\n","iteration 9: loss = 68.94704819831247\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.26000000000000006\n","iteration 0: loss = 101.83879418832473\n","iteration 1: loss = 94.57437199776861\n","iteration 2: loss = 87.50326290443226\n","iteration 3: loss = 83.36251561228214\n","iteration 4: loss = 81.70253197221848\n","iteration 5: loss = 79.13341890876865\n","iteration 6: loss = 77.30777697260399\n","iteration 7: loss = 75.46961298426702\n","iteration 8: loss = 74.62493573502663\n","iteration 9: loss = 72.7745518752809\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.3200000000000001\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.30000000000000004\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 100.96297257438103\n","iteration 1: loss = 93.50955403874838\n","iteration 2: loss = 85.87860777547444\n","iteration 3: loss = 79.1017167477718\n","iteration 4: loss = 75.61447085083407\n","iteration 5: loss = 72.78051724482998\n","iteration 6: loss = 70.89973701773035\n","iteration 7: loss = 69.61236969390718\n","iteration 8: loss = 67.63375044538509\n","iteration 9: loss = 66.5265372847443\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 99.36169910689968\n","iteration 1: loss = 93.9240540449201\n","iteration 2: loss = 86.45749199528045\n","iteration 3: loss = 81.93041776058466\n","iteration 4: loss = 77.87274604507624\n","iteration 5: loss = 75.39207444067705\n","iteration 6: loss = 73.59235182561844\n","iteration 7: loss = 72.16618707243057\n","iteration 8: loss = 70.95295397970035\n","iteration 9: loss = 69.87080505195053\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.23000000000000004\n","iteration 0: loss = 103.13612121726243\n","iteration 1: loss = 94.36486876319391\n","iteration 2: loss = 87.8909129253078\n","iteration 3: loss = 83.99277477706907\n","iteration 4: loss = 80.97948169458431\n","iteration 5: loss = 78.50708338346094\n","iteration 6: loss = 76.61789257301174\n","iteration 7: loss = 75.64240440779338\n","iteration 8: loss = 73.85526681444277\n","iteration 9: loss = 72.69186544616582\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.3200000000000001\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.29000000000000004\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 94.08119232891474\n","iteration 1: loss = 85.84226377416495\n","iteration 2: loss = 77.13570413856304\n","iteration 3: loss = 73.53034379845093\n","iteration 4: loss = 70.65253550644454\n","iteration 5: loss = 67.4571580133078\n","iteration 6: loss = 66.43142980058005\n","iteration 7: loss = 64.17251777978879\n","iteration 8: loss = 63.42628189334437\n","iteration 9: loss = 62.21524908141399\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.33\n","iteration 0: loss = 106.18650206946616\n","iteration 1: loss = 98.9380644853544\n","iteration 2: loss = 91.38940046338669\n","iteration 3: loss = 86.19887636806399\n","iteration 4: loss = 81.36374968320874\n","iteration 5: loss = 78.52743901550392\n","iteration 6: loss = 75.83783940116957\n","iteration 7: loss = 73.0848124251452\n","iteration 8: loss = 71.22656588394358\n","iteration 9: loss = 69.34866441843226\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.2700000000000001\n","iteration 0: loss = 89.19192174443849\n","iteration 1: loss = 82.25161729736494\n","iteration 2: loss = 79.53980462112716\n","iteration 3: loss = 75.7859445229158\n","iteration 4: loss = 73.09621558933762\n","iteration 5: loss = 70.62608642255864\n","iteration 6: loss = 68.82008650129762\n","iteration 7: loss = 66.5167431236496\n","iteration 8: loss = 65.06869572226736\n","iteration 9: loss = 63.53376673541463\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.3200000000000001\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.3066666666666667\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 103.77810488017015\n","iteration 1: loss = 92.21332507051272\n","iteration 2: loss = 84.45588017260394\n","iteration 3: loss = 79.3637195216271\n","iteration 4: loss = 75.86235553095273\n","iteration 5: loss = 72.68646988310891\n","iteration 6: loss = 71.22059255042284\n","iteration 7: loss = 68.58036897253992\n","iteration 8: loss = 66.83775046600202\n","iteration 9: loss = 65.42670797270429\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.32\n","iteration 0: loss = 92.73810851430943\n","iteration 1: loss = 82.3396750726133\n","iteration 2: loss = 77.37436740213772\n","iteration 3: loss = 73.99576304579358\n","iteration 4: loss = 69.09108316394895\n","iteration 5: loss = 66.43836118417222\n","iteration 6: loss = 64.133735679214\n","iteration 7: loss = 61.805945651765924\n","iteration 8: loss = 60.070955753114205\n","iteration 9: loss = 58.08845186324167\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.23000000000000004\n","iteration 0: loss = 111.28785238955332\n","iteration 1: loss = 100.94018881801168\n","iteration 2: loss = 92.42932889155774\n","iteration 3: loss = 87.10087940234253\n","iteration 4: loss = 83.84903087935322\n","iteration 5: loss = 82.01921727514019\n","iteration 6: loss = 79.69171411894177\n","iteration 7: loss = 77.81022059671957\n","iteration 8: loss = 75.58763427874123\n","iteration 9: loss = 74.27966224065084\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.3200000000000001\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.29000000000000004\n","best parameter in cross-validation : (0.1, 0.03) with prec@n 0.3066666666666667\n","iteration 0: loss = 171.11205397190705\n","iteration 1: loss = 149.99138263358213\n","iteration 2: loss = 136.85139418484243\n","iteration 3: loss = 127.50416778318433\n","iteration 4: loss = 120.38799013936473\n","iteration 5: loss = 113.81416094454435\n","iteration 6: loss = 109.9310828721341\n","iteration 7: loss = 106.22498070862731\n","iteration 8: loss = 103.45511543336255\n","iteration 9: loss = 100.85828495797978\n","iteration 10: loss = 97.51173073194963\n","iteration 11: loss = 94.81880027810881\n","iteration 12: loss = 92.85864620305833\n","iteration 13: loss = 90.57206310586213\n","iteration 14: loss = 88.91203936762143\n","iteration 15: loss = 87.65031086737943\n","iteration 16: loss = 85.7929225379281\n","iteration 17: loss = 84.59973723898746\n","iteration 18: loss = 83.15500726797657\n","iteration 19: loss = 82.78261495983034\n","Mapper Map_Linear trainning for iteration 0 ...\n","Mapper Map_Linear trainning for iteration 1 ...\n","Mapper Map_Linear trainning for iteration 2 ...\n","Mapper Map_Linear trainning for iteration 3 ...\n","Mapper Map_Linear trainning for iteration 4 ...\n","Mapper Map_Linear trainning for iteration 5 ...\n","Mapper Map_Linear trainning for iteration 6 ...\n","Mapper Map_Linear trainning for iteration 7 ...\n","Mapper Map_Linear trainning for iteration 8 ...\n","Mapper Map_Linear trainning for iteration 9 ...\n","Mapper Map_Linear trainning for iteration 10 ...\n","Mapper Map_Linear trainning for iteration 11 ...\n","Mapper Map_Linear trainning for iteration 12 ...\n","Mapper Map_Linear trainning for iteration 13 ...\n","Mapper Map_Linear trainning for iteration 14 ...\n","Mapper Map_Linear trainning for iteration 15 ...\n","Mapper Map_Linear trainning for iteration 16 ...\n","Mapper Map_Linear trainning for iteration 17 ...\n","Mapper Map_Linear trainning for iteration 18 ...\n","Mapper Map_Linear trainning for iteration 19 ...\n","Test for fold 2 : Prec@n = 0.15 auc = 0.2594079531579532\n","------------------------------------------------\n","avg_prec =  0.2666666666666667 , avg_auc =  0.40312761312761314\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hqnw3Wo2cjQq","executionInfo":{"status":"ok","timestamp":1635668721170,"user_tz":-330,"elapsed":7501,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"6105e36b-f928-4d21-b888-e0b59242c3ac"},"source":["### Map-BPR\n","main(model_id=0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 29.977828699989207\n","iteration 1: loss = 29.34276911568471\n","iteration 2: loss = 28.46009811702563\n","iteration 3: loss = 27.861713108035186\n","iteration 4: loss = 27.145908463397376\n","iteration 5: loss = 26.111656378970473\n","iteration 6: loss = 25.81385972458753\n","iteration 7: loss = 25.030018575284664\n","iteration 8: loss = 24.56115325004894\n","iteration 9: loss = 24.50204897123986\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.22000000000000006\n","iteration 0: loss = 61.509460706919356\n","iteration 1: loss = 56.915374288454586\n","iteration 2: loss = 51.4337747816551\n","iteration 3: loss = 48.45501331624014\n","iteration 4: loss = 47.490596610295924\n","iteration 5: loss = 45.877182279668816\n","iteration 6: loss = 43.68084482673598\n","iteration 7: loss = 41.91725148187348\n","iteration 8: loss = 40.73373767190496\n","iteration 9: loss = 40.1416990005772\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.14\n","iteration 0: loss = 65.40703794998775\n","iteration 1: loss = 62.735088464148745\n","iteration 2: loss = 57.3689706870058\n","iteration 3: loss = 52.94686365335909\n","iteration 4: loss = 50.69818182525377\n","iteration 5: loss = 48.003042977951175\n","iteration 6: loss = 46.51843588206096\n","iteration 7: loss = 45.98412955919399\n","iteration 8: loss = 44.36576856618166\n","iteration 9: loss = 43.17019349097438\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.16333333333333336\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 40.086073241475454\n","iteration 1: loss = 37.95153743034384\n","iteration 2: loss = 36.94721565893394\n","iteration 3: loss = 35.687513838090865\n","iteration 4: loss = 34.415498524897\n","iteration 5: loss = 33.730906237606206\n","iteration 6: loss = 33.54396391566418\n","iteration 7: loss = 32.51745535304978\n","iteration 8: loss = 31.659978474627362\n","iteration 9: loss = 30.73604259781784\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.30000000000000004\n","iteration 0: loss = 60.6652611709918\n","iteration 1: loss = 56.36742257623443\n","iteration 2: loss = 53.83268925868299\n","iteration 3: loss = 50.424245617685614\n","iteration 4: loss = 47.74112090742891\n","iteration 5: loss = 45.941029512045915\n","iteration 6: loss = 44.77726076449809\n","iteration 7: loss = 43.433642171398915\n","iteration 8: loss = 43.18354663186356\n","iteration 9: loss = 42.29566534273625\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.21000000000000005\n","iteration 0: loss = 64.48853694471995\n","iteration 1: loss = 59.21720897563975\n","iteration 2: loss = 55.97129342348772\n","iteration 3: loss = 54.01978939346952\n","iteration 4: loss = 52.07998884668258\n","iteration 5: loss = 51.09337878907781\n","iteration 6: loss = 50.2425742949512\n","iteration 7: loss = 49.512188691622455\n","iteration 8: loss = 48.100194755056485\n","iteration 9: loss = 47.56016706637163\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.19000000000000003\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.2333333333333334\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 35.191383984304565\n","iteration 1: loss = 33.74530498333268\n","iteration 2: loss = 32.163308628076564\n","iteration 3: loss = 30.456497876747157\n","iteration 4: loss = 29.769366988786413\n","iteration 5: loss = 28.966158099237436\n","iteration 6: loss = 28.548899758905392\n","iteration 7: loss = 27.510649646458987\n","iteration 8: loss = 27.155669686775457\n","iteration 9: loss = 26.384102292447537\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.2700000000000001\n","iteration 0: loss = 64.45830451375328\n","iteration 1: loss = 57.596641376542074\n","iteration 2: loss = 52.48995725490479\n","iteration 3: loss = 49.41590345446434\n","iteration 4: loss = 46.32944634626301\n","iteration 5: loss = 43.731889504334774\n","iteration 6: loss = 42.62479960871868\n","iteration 7: loss = 40.74894460829719\n","iteration 8: loss = 39.47935697816516\n","iteration 9: loss = 38.408570144684234\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.22000000000000003\n","iteration 0: loss = 66.60807036394876\n","iteration 1: loss = 60.44360094114895\n","iteration 2: loss = 56.298128329635674\n","iteration 3: loss = 52.99477922049538\n","iteration 4: loss = 50.67080030078757\n","iteration 5: loss = 48.87896745811647\n","iteration 6: loss = 46.499258147769794\n","iteration 7: loss = 45.68182819929654\n","iteration 8: loss = 45.02491580651321\n","iteration 9: loss = 44.2406190531355\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.07999999999999999\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.19000000000000003\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 49.50232070789762\n","iteration 1: loss = 46.64124555743094\n","iteration 2: loss = 43.54571662754808\n","iteration 3: loss = 39.79557958026745\n","iteration 4: loss = 38.33458797639979\n","iteration 5: loss = 36.38587557285952\n","iteration 6: loss = 35.23970827220485\n","iteration 7: loss = 33.79654809809035\n","iteration 8: loss = 32.24562977608936\n","iteration 9: loss = 30.877356864043843\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.30000000000000004\n","iteration 0: loss = 34.26557095053759\n","iteration 1: loss = 33.238287506594475\n","iteration 2: loss = 32.45542715966752\n","iteration 3: loss = 31.761312839729126\n","iteration 4: loss = 31.09584831797708\n","iteration 5: loss = 30.42309411647719\n","iteration 6: loss = 29.794170952988793\n","iteration 7: loss = 29.60748186278383\n","iteration 8: loss = 29.253953032908896\n","iteration 9: loss = 29.115276340243994\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.25\n","iteration 0: loss = 56.05096739519354\n","iteration 1: loss = 51.780888069270766\n","iteration 2: loss = 48.536815202202696\n","iteration 3: loss = 45.806521480357844\n","iteration 4: loss = 44.55378146249163\n","iteration 5: loss = 43.16817947409752\n","iteration 6: loss = 41.89461447767185\n","iteration 7: loss = 41.13713950622773\n","iteration 8: loss = 40.66797056252193\n","iteration 9: loss = 40.0955722643599\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.13\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.22666666666666668\n","best parameter in cross-validation : (0.03, 0.1) with prec@n 0.2333333333333334\n","iteration 0: loss = 99.6919598878761\n","iteration 1: loss = 91.1093044849722\n","iteration 2: loss = 84.24359688753194\n","iteration 3: loss = 80.82750636084987\n","iteration 4: loss = 78.53894012781251\n","iteration 5: loss = 76.52748772090771\n","iteration 6: loss = 74.11553612952504\n","iteration 7: loss = 71.98936308181023\n","iteration 8: loss = 70.42397310991454\n","iteration 9: loss = 69.46960960568629\n","iteration 10: loss = 68.9956321070601\n","iteration 11: loss = 66.66601183854385\n","iteration 12: loss = 66.09219908558549\n","iteration 13: loss = 65.7109633174326\n","iteration 14: loss = 64.32498166609561\n","iteration 15: loss = 63.8802129563811\n","iteration 16: loss = 63.23908758815965\n","iteration 17: loss = 62.19339784272758\n","iteration 18: loss = 61.848605953670614\n","iteration 19: loss = 61.39592329968908\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","Mapper Map_BPR trainning for iteration 10 ...\n","Mapper Map_BPR trainning for iteration 11 ...\n","Mapper Map_BPR trainning for iteration 12 ...\n","Mapper Map_BPR trainning for iteration 13 ...\n","Mapper Map_BPR trainning for iteration 14 ...\n","Mapper Map_BPR trainning for iteration 15 ...\n","Mapper Map_BPR trainning for iteration 16 ...\n","Mapper Map_BPR trainning for iteration 17 ...\n","Mapper Map_BPR trainning for iteration 18 ...\n","Mapper Map_BPR trainning for iteration 19 ...\n","Test for fold 0 : Prec@n = 0.38 auc = 0.5001042753542754\n","------------------------------------------------\n","Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 76.02032723683715\n","iteration 1: loss = 69.79198127087436\n","iteration 2: loss = 64.00661033040846\n","iteration 3: loss = 61.4111758697577\n","iteration 4: loss = 59.132526043625795\n","iteration 5: loss = 57.52146669549399\n","iteration 6: loss = 56.23855961592831\n","iteration 7: loss = 54.81353074824324\n","iteration 8: loss = 53.960922215524505\n","iteration 9: loss = 53.00359937459818\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.20000000000000004\n","iteration 0: loss = 77.15118515902054\n","iteration 1: loss = 71.07370636263673\n","iteration 2: loss = 64.95093296750602\n","iteration 3: loss = 59.74190184552493\n","iteration 4: loss = 56.93888942924824\n","iteration 5: loss = 53.80065096453046\n","iteration 6: loss = 51.78972064180289\n","iteration 7: loss = 49.77629246387353\n","iteration 8: loss = 48.13929066199729\n","iteration 9: loss = 46.67315620145511\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.22000000000000003\n","iteration 0: loss = 114.32446497478954\n","iteration 1: loss = 101.39826846650008\n","iteration 2: loss = 94.25682448832741\n","iteration 3: loss = 90.06730888744903\n","iteration 4: loss = 86.56652072242028\n","iteration 5: loss = 84.12828514895186\n","iteration 6: loss = 82.39940267380629\n","iteration 7: loss = 80.4785560596325\n","iteration 8: loss = 78.80278776050969\n","iteration 9: loss = 77.669915040804\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.15000000000000002\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.19000000000000003\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 81.99556460200438\n","iteration 1: loss = 73.219466122013\n","iteration 2: loss = 65.74687172272183\n","iteration 3: loss = 61.62886306064817\n","iteration 4: loss = 59.19995640666398\n","iteration 5: loss = 56.955500639690044\n","iteration 6: loss = 55.596570137334695\n","iteration 7: loss = 54.59891966472628\n","iteration 8: loss = 54.086208903023234\n","iteration 9: loss = 53.38443401747381\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.41000000000000003\n","iteration 0: loss = 90.3694834294592\n","iteration 1: loss = 76.84762067743118\n","iteration 2: loss = 70.3667917202881\n","iteration 3: loss = 63.47469769407084\n","iteration 4: loss = 59.214564678413446\n","iteration 5: loss = 56.298832561566826\n","iteration 6: loss = 54.71979739136732\n","iteration 7: loss = 52.9314952509562\n","iteration 8: loss = 51.5601006138991\n","iteration 9: loss = 50.33253187838316\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.30000000000000004\n","iteration 0: loss = 99.82593790608439\n","iteration 1: loss = 90.21313204297124\n","iteration 2: loss = 84.6094755565313\n","iteration 3: loss = 79.08733194379067\n","iteration 4: loss = 75.99723754979505\n","iteration 5: loss = 73.42793340135465\n","iteration 6: loss = 71.50146115171759\n","iteration 7: loss = 70.54446362298918\n","iteration 8: loss = 69.34826937460618\n","iteration 9: loss = 68.53421741381902\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.16\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.29000000000000004\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 77.58007094936823\n","iteration 1: loss = 69.39955440683866\n","iteration 2: loss = 64.73569322772872\n","iteration 3: loss = 61.96565720524838\n","iteration 4: loss = 59.07407272964056\n","iteration 5: loss = 55.69174298705883\n","iteration 6: loss = 54.2935038236665\n","iteration 7: loss = 53.28615248652414\n","iteration 8: loss = 51.90457168233401\n","iteration 9: loss = 51.11603565823965\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.20000000000000004\n","iteration 0: loss = 77.29427263209021\n","iteration 1: loss = 69.6020909527413\n","iteration 2: loss = 64.81164812574912\n","iteration 3: loss = 60.26333364319137\n","iteration 4: loss = 57.535999114215315\n","iteration 5: loss = 55.35383541171872\n","iteration 6: loss = 53.19406569124696\n","iteration 7: loss = 52.035915459567775\n","iteration 8: loss = 50.25189652345028\n","iteration 9: loss = 48.74947882595022\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.36\n","iteration 0: loss = 89.87219220581949\n","iteration 1: loss = 80.73411641001486\n","iteration 2: loss = 75.5796444420368\n","iteration 3: loss = 72.97656612004035\n","iteration 4: loss = 70.58927392285436\n","iteration 5: loss = 67.47296831307632\n","iteration 6: loss = 66.10426373423637\n","iteration 7: loss = 64.51699442725162\n","iteration 8: loss = 62.28202383461942\n","iteration 9: loss = 61.36464915595061\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.15\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.2366666666666667\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 105.5035804230589\n","iteration 1: loss = 91.51577024138058\n","iteration 2: loss = 82.62447964152904\n","iteration 3: loss = 76.64739230849881\n","iteration 4: loss = 72.0004610899436\n","iteration 5: loss = 67.1953323340974\n","iteration 6: loss = 64.39123597432804\n","iteration 7: loss = 61.111901407964275\n","iteration 8: loss = 59.788823104375\n","iteration 9: loss = 58.02120008941881\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.25000000000000006\n","iteration 0: loss = 65.55878889598526\n","iteration 1: loss = 62.02511203865143\n","iteration 2: loss = 59.23934701034878\n","iteration 3: loss = 56.995328095104014\n","iteration 4: loss = 55.04254284500972\n","iteration 5: loss = 53.36009933194594\n","iteration 6: loss = 52.010152784148595\n","iteration 7: loss = 51.40954770420967\n","iteration 8: loss = 50.51444790843264\n","iteration 9: loss = 49.40101528217535\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.29\n","iteration 0: loss = 115.5906682030821\n","iteration 1: loss = 105.61073415406517\n","iteration 2: loss = 96.79070602580185\n","iteration 3: loss = 91.99177819263103\n","iteration 4: loss = 86.23917039514328\n","iteration 5: loss = 84.65836471288017\n","iteration 6: loss = 81.94294140677187\n","iteration 7: loss = 79.92526370814832\n","iteration 8: loss = 75.85369202171483\n","iteration 9: loss = 73.46186008860894\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.11000000000000001\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.21666666666666667\n","best parameter in cross-validation : (0.03, 0.1) with prec@n 0.29000000000000004\n","iteration 0: loss = 132.60906088048927\n","iteration 1: loss = 118.41867608235681\n","iteration 2: loss = 109.74322328947986\n","iteration 3: loss = 104.44191406002189\n","iteration 4: loss = 101.2161175736957\n","iteration 5: loss = 97.82027022187825\n","iteration 6: loss = 94.55068250778305\n","iteration 7: loss = 91.90844672739965\n","iteration 8: loss = 89.92906691914598\n","iteration 9: loss = 87.37864252308918\n","iteration 10: loss = 85.73541377686435\n","iteration 11: loss = 83.85818296198624\n","iteration 12: loss = 82.82541925005367\n","iteration 13: loss = 81.93139554908169\n","iteration 14: loss = 80.29205286794956\n","iteration 15: loss = 79.01123398385234\n","iteration 16: loss = 78.15795560313552\n","iteration 17: loss = 77.26416194479083\n","iteration 18: loss = 75.83638538131521\n","iteration 19: loss = 74.59343184159812\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","Mapper Map_BPR trainning for iteration 10 ...\n","Mapper Map_BPR trainning for iteration 11 ...\n","Mapper Map_BPR trainning for iteration 12 ...\n","Mapper Map_BPR trainning for iteration 13 ...\n","Mapper Map_BPR trainning for iteration 14 ...\n","Mapper Map_BPR trainning for iteration 15 ...\n","Mapper Map_BPR trainning for iteration 16 ...\n","Mapper Map_BPR trainning for iteration 17 ...\n","Mapper Map_BPR trainning for iteration 18 ...\n","Mapper Map_BPR trainning for iteration 19 ...\n","Test for fold 1 : Prec@n = 0.13999999999999999 auc = 0.3214172494172494\n","------------------------------------------------\n","Cross-validating parameter (0.03, 0.03) .........\n","iteration 0: loss = 74.19579076339939\n","iteration 1: loss = 67.63719037285351\n","iteration 2: loss = 63.77604205963122\n","iteration 3: loss = 61.87245878771538\n","iteration 4: loss = 59.678313047349846\n","iteration 5: loss = 57.977882030961744\n","iteration 6: loss = 56.895436923381496\n","iteration 7: loss = 55.94001818577986\n","iteration 8: loss = 55.07690806976321\n","iteration 9: loss = 54.16867157357475\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.2500000000000001\n","iteration 0: loss = 82.50836437766333\n","iteration 1: loss = 77.39748985282064\n","iteration 2: loss = 73.43256657301637\n","iteration 3: loss = 70.99599672684057\n","iteration 4: loss = 68.36963831072165\n","iteration 5: loss = 66.23524160883451\n","iteration 6: loss = 65.23012261814148\n","iteration 7: loss = 63.772209708046795\n","iteration 8: loss = 62.604272994132515\n","iteration 9: loss = 61.414818251687535\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.33000000000000007\n","iteration 0: loss = 95.28108006338633\n","iteration 1: loss = 87.14555763365331\n","iteration 2: loss = 81.94541118988928\n","iteration 3: loss = 78.61775979465081\n","iteration 4: loss = 75.56810147793645\n","iteration 5: loss = 73.78447795662748\n","iteration 6: loss = 71.8605188009369\n","iteration 7: loss = 70.8696734799316\n","iteration 8: loss = 69.27374611022304\n","iteration 9: loss = 67.77336817102133\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.25000000000000006\n","Average score for parameter after cross-validation (0.03, 0.03) : 0.2766666666666668\n","Cross-validating parameter (0.03, 0.1) .........\n","iteration 0: loss = 78.91006899489945\n","iteration 1: loss = 72.78784748923573\n","iteration 2: loss = 68.80431202482244\n","iteration 3: loss = 66.77846247850378\n","iteration 4: loss = 63.910750538417375\n","iteration 5: loss = 61.50988755530945\n","iteration 6: loss = 60.10858429456228\n","iteration 7: loss = 58.52261948954573\n","iteration 8: loss = 57.454351225766715\n","iteration 9: loss = 56.68080421315588\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.22000000000000006\n","iteration 0: loss = 105.25797692471674\n","iteration 1: loss = 97.80741672218296\n","iteration 2: loss = 88.74084131187938\n","iteration 3: loss = 82.67889901614966\n","iteration 4: loss = 80.59703802401435\n","iteration 5: loss = 76.24100334833047\n","iteration 6: loss = 73.57964593267414\n","iteration 7: loss = 71.17008355168647\n","iteration 8: loss = 69.43167598104881\n","iteration 9: loss = 68.53047169194633\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.28\n","iteration 0: loss = 113.28576656662948\n","iteration 1: loss = 100.35605529201194\n","iteration 2: loss = 92.75150015757046\n","iteration 3: loss = 87.97743977712969\n","iteration 4: loss = 84.49554842640063\n","iteration 5: loss = 81.76491914107613\n","iteration 6: loss = 79.48233445053832\n","iteration 7: loss = 76.66632154938478\n","iteration 8: loss = 74.2619153878411\n","iteration 9: loss = 73.17153585465405\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.33\n","Average score for parameter after cross-validation (0.03, 0.1) : 0.27666666666666667\n","Cross-validating parameter (0.1, 0.03) .........\n","iteration 0: loss = 79.77818896192603\n","iteration 1: loss = 76.57931688732829\n","iteration 2: loss = 72.20636899808687\n","iteration 3: loss = 69.99637417836918\n","iteration 4: loss = 68.32840532045343\n","iteration 5: loss = 66.45880736174175\n","iteration 6: loss = 65.3336225342891\n","iteration 7: loss = 64.56477944848005\n","iteration 8: loss = 63.2577017081858\n","iteration 9: loss = 62.31566130551285\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.12\n","iteration 0: loss = 92.2441407317897\n","iteration 1: loss = 85.06704805585038\n","iteration 2: loss = 80.4425431975042\n","iteration 3: loss = 76.7068584829817\n","iteration 4: loss = 73.90473903164394\n","iteration 5: loss = 72.46252618069184\n","iteration 6: loss = 70.83192885921109\n","iteration 7: loss = 68.66836055428635\n","iteration 8: loss = 67.56862141214872\n","iteration 9: loss = 65.82042860390791\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.33000000000000007\n","iteration 0: loss = 131.7653189849784\n","iteration 1: loss = 112.64335171227188\n","iteration 2: loss = 99.50429603510469\n","iteration 3: loss = 94.32693519134804\n","iteration 4: loss = 88.65777434046794\n","iteration 5: loss = 84.9354842339392\n","iteration 6: loss = 81.15412264999186\n","iteration 7: loss = 79.44815504947525\n","iteration 8: loss = 76.68485640441388\n","iteration 9: loss = 74.58855600710056\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.32\n","Average score for parameter after cross-validation (0.1, 0.03) : 0.25666666666666665\n","Cross-validating parameter (0.1, 0.1) .........\n","iteration 0: loss = 105.00270783729476\n","iteration 1: loss = 95.78539711925606\n","iteration 2: loss = 87.88917912492178\n","iteration 3: loss = 82.1959801022884\n","iteration 4: loss = 78.40661012155824\n","iteration 5: loss = 74.84650928476944\n","iteration 6: loss = 72.03689569380005\n","iteration 7: loss = 70.32607783948335\n","iteration 8: loss = 69.46196422521558\n","iteration 9: loss = 67.73092444355703\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 0 : 0.31\n","iteration 0: loss = 104.75328684239847\n","iteration 1: loss = 92.76361799120974\n","iteration 2: loss = 83.7514835412139\n","iteration 3: loss = 79.54458443425335\n","iteration 4: loss = 75.70049530476453\n","iteration 5: loss = 74.55342923995234\n","iteration 6: loss = 71.24261008571139\n","iteration 7: loss = 69.53205411998351\n","iteration 8: loss = 67.71529477448134\n","iteration 9: loss = 66.378914600994\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 1 : 0.28\n","iteration 0: loss = 96.78154580803877\n","iteration 1: loss = 87.0390388581543\n","iteration 2: loss = 81.94834136658476\n","iteration 3: loss = 77.01939147562315\n","iteration 4: loss = 75.77481304532236\n","iteration 5: loss = 72.71433939151322\n","iteration 6: loss = 70.97237053251857\n","iteration 7: loss = 69.00370803720631\n","iteration 8: loss = 67.14696506582621\n","iteration 9: loss = 66.14510695421757\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","prec@5 of cross-validation fold 2 : 0.2900000000000001\n","Average score for parameter after cross-validation (0.1, 0.1) : 0.2933333333333334\n","best parameter in cross-validation : (0.1, 0.1) with prec@n 0.2933333333333334\n","iteration 0: loss = 162.53107728410265\n","iteration 1: loss = 146.00199522595452\n","iteration 2: loss = 135.2137646678167\n","iteration 3: loss = 128.5108453845093\n","iteration 4: loss = 122.13667252738139\n","iteration 5: loss = 117.27340499473476\n","iteration 6: loss = 114.85333764557294\n","iteration 7: loss = 112.1953093693822\n","iteration 8: loss = 109.69915951079139\n","iteration 9: loss = 106.81008554792666\n","iteration 10: loss = 104.86541068265062\n","iteration 11: loss = 101.5011161721189\n","iteration 12: loss = 100.47343064330883\n","iteration 13: loss = 98.59792482656967\n","iteration 14: loss = 97.45644644760068\n","iteration 15: loss = 95.5182478344106\n","iteration 16: loss = 94.55338858008751\n","iteration 17: loss = 93.60006015457324\n","iteration 18: loss = 92.31262570964589\n","iteration 19: loss = 91.9928407247335\n","Mapper Map_BPR trainning for iteration 0 ...\n","Mapper Map_BPR trainning for iteration 1 ...\n","Mapper Map_BPR trainning for iteration 2 ...\n","Mapper Map_BPR trainning for iteration 3 ...\n","Mapper Map_BPR trainning for iteration 4 ...\n","Mapper Map_BPR trainning for iteration 5 ...\n","Mapper Map_BPR trainning for iteration 6 ...\n","Mapper Map_BPR trainning for iteration 7 ...\n","Mapper Map_BPR trainning for iteration 8 ...\n","Mapper Map_BPR trainning for iteration 9 ...\n","Mapper Map_BPR trainning for iteration 10 ...\n","Mapper Map_BPR trainning for iteration 11 ...\n","Mapper Map_BPR trainning for iteration 12 ...\n","Mapper Map_BPR trainning for iteration 13 ...\n","Mapper Map_BPR trainning for iteration 14 ...\n","Mapper Map_BPR trainning for iteration 15 ...\n","Mapper Map_BPR trainning for iteration 16 ...\n","Mapper Map_BPR trainning for iteration 17 ...\n","Mapper Map_BPR trainning for iteration 18 ...\n","Mapper Map_BPR trainning for iteration 19 ...\n","Test for fold 2 : Prec@n = 0.19 auc = 0.33380439005439005\n","------------------------------------------------\n","avg_prec =  0.23666666666666666 , avg_auc =  0.385108638275305\n"]}]},{"cell_type":"markdown","metadata":{"id":"_3HapHXLEvIR"},"source":["## Extra Notes"]},{"cell_type":"markdown","metadata":{"id":"zYRLWJ3bExZM"},"source":["### Example"]},{"cell_type":"markdown","metadata":{"id":"bgv8w1qEEyoG"},"source":["Training a hypothetical factorization model with k = 2 yields two matrices consisting of the user and item factor vectors, respectively:"]},{"cell_type":"markdown","metadata":{"id":"9pLxFvzAmZBC"},"source":["<p><center><img src='_images/T847725_1.png'></center></p>"]},{"cell_type":"markdown","metadata":{"id":"9-W2IlQqE3Kl"},"source":["### Loss function\n","\n","The general form of score estimation by mapping from item attributes to item factors is:\n","\n","$$\\hat{y}_{ui} := \\sum_{f=1}^k w_{uf}\\phi_f(a_i^I) = \\langle w_u,\\phi(a_i^I) \\rangle$$"]},{"cell_type":"markdown","metadata":{"id":"nVG0k-P-CuX8"},"source":["## Citations\n","\n","Learning Attribute to Feature Mappings for Cold-Start Recommendations. Lucas Drumond, Christoph Freudenthaler, Steffen Rendle, Lars Schmidt-Thieme. 2010. ICDM. [https://bit.ly/3Eh4NEK](https://bit.ly/3Eh4NEK)"]}]}