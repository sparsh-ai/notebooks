{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wikirecs-3.worker","provenance":[{"file_id":"1Gr4GCAcjI5y_Uo25c39zxnomGW01xxJH","timestamp":1625764548200},{"file_id":"1oar0IIoKvzlao9331q0pCluMvDwhaJh4","timestamp":1625764091799},{"file_id":"1KDUlGmiF0QDqDEriKYiAn9i5Xhxtpy10","timestamp":1625763528590}],"collapsed_sections":[],"mount_file_id":"1g_FBxVVcxXyAO8N4PpjmbJoxP1DYmucV","authorship_tag":"ABX9TyPqy9Z8YWwXMQy3DNRfW6OP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Jep4VQyz3ZzE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625764608126,"user_tz":-330,"elapsed":13697,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"4d324b0c-1a40-4dcc-84eb-6916f762b272"},"source":["project_name=\"reco-wikirecs\"; branch=\"master\"; account=\"sparsh-ai\"\n","\n","!cp /content/drive/MyDrive/mykeys.py /content\n","import mykeys\n","!rm /content/mykeys.py\n","path = \"/content/\" + project_name; \n","!mkdir \"{path}\"\n","%cd \"{path}\"\n","import sys; sys.path.append(path)\n","!git config --global user.email \"sparsh@recohut.com\"\n","!git config --global user.name  \"colab-sparsh\"\n","!git init\n","!git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n","!git pull origin \"{branch}\"\n","\n","# !git status\n","# !git add . && git commit -m 'commit' && git push origin \"{branch}\"\n","\n","!pip install -r requirements.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/reco-wikirecs\n","Initialized empty Git repository in /content/reco-wikirecs/.git/\n","remote: Enumerating objects: 42, done.\u001b[K\n","remote: Counting objects: 100% (42/42), done.\u001b[K\n","remote: Compressing objects: 100% (29/29), done.\u001b[K\n","remote: Total 42 (delta 13), reused 38 (delta 9), pack-reused 0\u001b[K\n","Unpacking objects: 100% (42/42), done.\n","From https://github.com/sparsh-ai/reco-wikirecs\n"," * branch            master     -> FETCH_HEAD\n"," * [new branch]      master     -> origin/master\n","Collecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Collecting umap\n","  Downloading https://files.pythonhosted.org/packages/4b/46/08ab68936625400fe690684428d4db4764f49b406782cc133df1d0299d06/umap-0.1.1.tar.gz\n","Collecting itables\n","  Downloading https://files.pythonhosted.org/packages/f4/29/501d21d839a2ea3bbd5821e0c7b228db2b281d06b577971dd97f8d340a41/itables-0.3.0-py3-none-any.whl\n","Collecting PyYAML>=5.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia->-r requirements.txt (line 1)) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia->-r requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from itables->-r requirements.txt (line 3)) (5.5.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from itables->-r requirements.txt (line 3)) (1.1.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 1)) (2021.5.30)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (5.0.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (57.0.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->itables->-r requirements.txt (line 3)) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->itables->-r requirements.txt (line 3)) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->itables->-r requirements.txt (line 3)) (2.8.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython->itables->-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->itables->-r requirements.txt (line 3)) (0.7.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->itables->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->itables->-r requirements.txt (line 3)) (0.2.5)\n","Building wheels for collected packages: wikipedia, umap\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp37-none-any.whl size=11697 sha256=203c0fafd53e3ba4c4cca1198295a70232b0c99b8c53059d3205b2d131563215\n","  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-cp37-none-any.whl size=3568 sha256=3af817abcd50f961baabcdff319e17db23807c4df6e17239e57551ef2b76a95f\n","  Stored in directory: /root/.cache/pip/wheels/7b/29/33/b4d917dc95f69c0a060e2ab012d95e15db9ed4cc0b94ccac26\n","Successfully built wikipedia umap\n","Installing collected packages: wikipedia, umap, itables, PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.4.1 itables-0.3.0 umap-0.1.1 wikipedia-1.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPv3P678HCYi","executionInfo":{"status":"ok","timestamp":1625764422021,"user_tz":-330,"elapsed":776,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"7c9cd3ea-a618-440f-de9c-50e127050317"},"source":["%cd /content/reco-wikirecs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/reco-wikirecs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c_uAz5OS4sm3","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1625764608128,"user_tz":-330,"elapsed":24,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"6806e19a-f086-48a0-f9d2-35e4b469cb20"},"source":["import yaml\n","import os\n","from itables.javascript import load_datatables\n","load_datatables()\n","\n","with open('config.yaml') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/javascript":["require.config({\n","    paths: {\n","        datatables: 'https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min',\n","    }\n","});\n","\n","$('head').append('<link rel=\"stylesheet\" type=\"text/css\" \\\n","                href = \"https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\" > ');\n","\n","$('head').append('<style> table td { text-overflow: ellipsis; overflow: hidden; } </style>');\n","\n","$('head').append(`<script>\n","function eval_functions(map_or_text) {\n","    if (typeof map_or_text === \"string\") {\n","        if (map_or_text.startsWith(\"function\")) {\n","            try {\n","                // Note: parenthesis are required around the whole expression for eval to return a value!\n","                // See https://stackoverflow.com/a/7399078/911298.\n","                //\n","                // eval(\"local_fun = \" + map_or_text) would fail because local_fun is not declared\n","                // (using var, let or const would work, but it would only be declared in the local scope\n","                // and therefore the value could not be retrieved).\n","                const func = eval(\"(\" + map_or_text + \")\");\n","                if (typeof func !== \"function\") {\n","                    // Note: backquotes are super convenient!\n","                    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\n","                    console.error(\"Evaluated expression \" + map_or_text + \" is not a function (type is \" + typeof func + \")\");\n","                    return map_or_text;\n","                }\n","                // Return the function\n","                return func;\n","            } catch (e) {\n","                // Make sure to print the error with a second argument to console.error().\n","                console.error(\"itables was not able to parse \" + map_or_text, e);\n","            }\n","        }\n","    } else if (typeof map_or_text === \"object\") {\n","        if (map_or_text instanceof Array) {\n","            // Note: \"var\" is now superseded by \"let\" and \"const\".\n","            // https://medium.com/javascript-scene/javascript-es6-var-let-or-const-ba58b8dcde75\n","            const result = [];\n","            // Note: \"for of\" is the best way to iterate through an iterable.\n","            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for...of\n","            for (const item of map_or_text) {\n","                result.push(eval_functions(item));\n","            }\n","            return result;\n","\n","            // Alternatively, more functional approach in one line:\n","            // return map_or_text.map(eval_functions);\n","        } else {\n","            const result = {};\n","            // Object.keys() is safer than \"for in\" because otherwise you might have keys\n","            // that aren't defined in the object itself.\n","            //\n","            // See https://stackoverflow.com/a/684692/911298.\n","            for (const item of Object.keys(map_or_text)) {\n","                result[item] = eval_functions(map_or_text[item]);\n","            }\n","            return result;\n","        }\n","    }\n","\n","    return map_or_text;\n","}\n","\n","</` + 'script>');"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"iRqIusXhEsUJ","cellView":"form","executionInfo":{"status":"ok","timestamp":1625764608719,"user_tz":-330,"elapsed":602,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["#@markdown\n","import pandas as pd\n","import numpy as np\n","import requests\n","import time\n","import os\n","from tqdm import tqdm\n","from pyarrow import feather\n","\n","\n","def get_recent_changes(N):\n","    S = requests.Session()\n","\n","    t = tqdm(total=N, position=0, leave=True)\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"format\": \"json\",\n","        \"rcprop\": \"title|ids|sizes|flags|user|userid|timestamp\",\n","        \"rcshow\": \"!bot|!anon|!minor\",\n","        \"rctype\": \"edit\",\n","        \"rcnamespace\": \"0\",\n","        \"list\": \"recentchanges\",\n","        \"action\": \"query\",\n","        \"rclimit\": \"500\",\n","    }\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","    all_rc = RECENTCHANGES\n","\n","    i = 500\n","    t.update(500)\n","    while i <= N:\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","        all_rc.extend(RECENTCHANGES)\n","        i = i + 500\n","        t.update(500)\n","\n","    if len(all_rc) > N:\n","        all_rc = all_rc[:N]\n","\n","    return all_rc\n","\n","\n","def get_sample_of_users(edit_lookback, outfile=None):\n","    \"\"\"Get a sample of recently active users by pulling the most recent N edits\n","    Note that this will be biased towards highly active users.\n","    Args:\n","        edit_lookback: The number of edits to go back.\n","        outfile: Pickle file path to write the user list to\n","    Returns:\n","        Dataframe with user and user id columns\n","    \"\"\"\n","    df = get_recent_changes(edit_lookback)\n","\n","    # Drop missing userid entries\n","    df = pd.DataFrame(df).dropna(subset=[\"userid\"])\n","\n","    print(\"Earliest timestamp: {}\".format(df.timestamp.min()))\n","    print(\"Latest timestamp: {}\".format(df.timestamp.max()))\n","    print(\"Number of distinct users: {}\".format(len(df.user.unique())))\n","    print(\n","        \"Mean number of edits per user in timeframe: %.2f\"\n","        % (len(df) / len(df.user.unique()))\n","    )\n","    print(\"Number of distinct pages edited: {}\".format(len(df.pageid.unique())))\n","    print(\n","        \"Mean number of edits per page in timeframe: %.2f\"\n","        % (len(df) / len(df.pageid.unique()))\n","    )\n","\n","    # Deduplicate to get\n","    sampled_users = df.loc[:, [\"user\", \"userid\"]].drop_duplicates()\n","\n","    # Remove RFD\n","    sampled_users = sampled_users[np.invert(sampled_users.user == \"RFD\")]\n","    sampled_users = sampled_users.reset_index(drop=True)\n","\n","    if outfile:\n","        sampled_users.to_csv(outfile, index=False)\n","\n","    return sampled_users\n","\n","\n","def get_edit_history(\n","    userid=None, user=None, latest_timestamp=None, earliest_timestamp=None, limit=None):\n","    \"\"\"For a particular user, pull their whole history of edits.\n","    Args:\n","        param1 (int): The first parameter.\n","        param2 (str): The second parameter.\n","    Returns:\n","        bool: The return value. True for success, False otherwise.\n","    \"\"\"\n","\n","    S = requests.Session()\n","    S.headers.update(\n","        {\"User-Agent\": \"WikiRecs (danielrsaunders@gmail.com) One-time pull\"}\n","    )\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"action\": \"query\",\n","        \"format\": \"json\",\n","        \"ucnamespace\": \"0\",\n","        \"list\": \"usercontribs\",\n","        \"ucuserids\": userid,\n","        \"ucprop\": \"title|ids|sizediff|flags|comment|timestamp\",\n","        \"ucshow=\": \"!minor|!new\",\n","    }\n","    if latest_timestamp is not None:\n","        PARAMS[\"ucstart\"] = latest_timestamp\n","    if earliest_timestamp is not None:\n","        PARAMS[\"ucend\"] = earliest_timestamp\n","    if user is not None:\n","        PARAMS[\"ucuser\"] = user\n","    if userid is not None:\n","        PARAMS[\"ucuserid\"] = userid\n","\n","    PARAMS[\"uclimit\"] = 500\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    if \"query\" not in DATA:\n","        print(DATA)\n","        raise ValueError\n","\n","    USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","    all_ucs = USERCONTRIBS\n","    i = 500\n","    while i < 100000:\n","        if \"continue\" not in DATA:\n","            break\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","        all_ucs.extend(USERCONTRIBS)\n","        i = i + 500\n","\n","    return all_ucs\n","\n","\n","def pull_edit_histories(\n","    sampled_users_file,\n","    edit_histories_file_pattern,\n","    users_per_chunk,\n","    earliest_timestamp,\n","    start=0):\n","    histories = []\n","    cols = [\"userid\", \"user\", \"pageid\", \"title\", \"timestamp\", \"sizediff\"]\n","    sampled_users = pd.read_csv(sampled_users_file)\n","    sampled_users.loc[:, \"userid\"].astype(int)\n","\n","    sampled_users = sampled_users.reset_index()\n","\n","    # Iterate through all the users in the list\n","    for i, (user, userid) in tqdm(\n","        iterable=enumerate(\n","            zip(sampled_users[\"user\"][start:], sampled_users[\"userid\"][start:]),\n","            start=start),\n","        total=len(sampled_users)): \n","\n","        # Get the history of edits for this userid\n","        thehistory = get_edit_history(\n","            userid=int(userid), earliest_timestamp=earliest_timestamp\n","        )\n","\n","        # If no edits, skip\n","        if len(thehistory) == 0:\n","            continue\n","\n","        thehistory = pd.DataFrame(thehistory)\n","\n","        # Remove edits using automated tools by looking for the word \"using\" in the comments\n","        try:\n","            thehistory = thehistory[\n","                np.invert(thehistory.comment.astype(str).str.contains(\"using\"))\n","            ]\n","        except AttributeError:\n","            continue\n","\n","        if len(thehistory) == 0:\n","            continue\n","\n","        histories.append(thehistory.loc[:, cols])\n","\n","        # if np.mod(i, 50) == 0:\n","        #     print(\n","        #         \"Most recent: {}/{} {} ({}) has {} edits\".format(\n","        #             i, len(sampled_users), user, int(userid), len(thehistory)\n","        #         )\n","        #     )\n","\n","        # Every x users save it out, for the sake of ram limitations\n","        if np.mod(i, users_per_chunk) == 0:\n","            feather.write_feather(\n","                pd.concat(histories), edit_histories_file_pattern.format(i)\n","            )\n","\n","            histories = []\n","      \n","    # Get the last few users that don't make up a full chunk\n","    feather.write_feather(pd.concat(histories), edit_histories_file_pattern.format(i))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vNLJxSLB2m8","outputId":"3be04f23-b54e-45cf-9a17-697bd5072985"},"source":["pull_edit_histories(\n","    config['outfile'],\n","    os.path.join(config['file_save_path'],config['edit_histories_file_pattern']),\n","    config['users_per_chunk'],\n","    config['earliest_timestamp'],\n","    start=20000,\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  9%|▉         | 5014/54339 [17:11<2:09:58,  6.32it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vji9aQdmH1PH"},"source":[""],"execution_count":null,"outputs":[]}]}