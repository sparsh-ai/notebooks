{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi Bandit Gym",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXSLdP1IFBKW+OTpPsz6uI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQQoRnCyKAh8"
      },
      "source": [
        "# Best Ads detection using bandit methods\n",
        "> Multi-armed Bandit for Banner Ad and 4 Exploration Strategies\n",
        "\n",
        "- toc: false\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [Bandit, RL, MAB]\n",
        "- image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM-r2TFApyhv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAvHyehnlqHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f5a606-f1b7-48a8-fbf8-96c0276ba28d"
      },
      "source": [
        "# First, let's clone the Gym bandits repository:\n",
        "! git clone https://github.com/JKCooper2/gym-bandits\n",
        "\n",
        "# Next, we can install it using pip:\n",
        "%cd gym-bandits\n",
        "! pip install -e .\n",
        "\n",
        "# After installation, we import gym_bandits and also the gym library:\n",
        "import gym_bandits\n",
        "import gym\n",
        "\n",
        "# gym_bandits provides several versions of the bandit environment. \n",
        "# We can examine the different bandit versions at https://github.com/JKCooper2/gym-bandits\n",
        "\n",
        "#Let's just create a simple 2-armed bandit whose environment ID is BanditTwoArmedHighLowFixed-v0:\n",
        "env = gym.make(\"BanditTwoArmedHighLowFixed-v0\")\n",
        "\n",
        "# Since we created a 2-armed bandit, our action space will be 2 (as there are two arms), as shown here:\n",
        "print(env.action_space.n)    # The preceding code will print: 2\n",
        "\n",
        "# We can also check the probability distribution of the arm with:\n",
        "print(env.p_dist)    # The preceding code will print: [0.8, 0.2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gym-bandits' already exists and is not an empty directory.\n",
            "/content/gym-bandits\n",
            "Obtaining file:///content/gym-bandits\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-bandits==0.0.2) (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bandits==0.0.2) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bandits==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bandits==0.0.2) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-bandits==0.0.2) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-bandits==0.0.2) (0.16.0)\n",
            "Installing collected packages: gym-bandits\n",
            "  Running setup.py develop for gym-bandits\n",
            "Successfully installed gym-bandits\n",
            "2\n",
            "[0.8, 0.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Qmkgvtmjby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590ce2bd-7d8a-4d89-a436-d42769f5be77"
      },
      "source": [
        "# First, let's initialize the variables.\n",
        "# Initialize the count for storing the number of times an arm is pulled:\n",
        "count = np.zeros(2)\n",
        "# Initialize sum_rewards for storing the sum of rewards of each arm:\n",
        "sum_rewards = np.zeros(2)\n",
        "# Initialize Q for storing the average reward of each arm:\n",
        "Q = np.zeros(2)\n",
        "# Set the number of rounds (iterations):\n",
        "num_rounds = 100\n",
        "\n",
        "# Now, let's define the epsilon_greedy function.\n",
        "def epsilon_greedy(epsilon):\n",
        "    \"\"\"First, we generate a random number from a uniform distribution. If the random \n",
        "    number is less than epsilon, then we pull the random arm; else, we pull \n",
        "    the best arm that has the maximum average reward\"\"\"\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return np.argmax(Q)\n",
        "\n",
        "# Now, let's play the game and try to find the best arm using the epsilon-greedy method.\n",
        "# For each round:\n",
        "for i in range(num_rounds):\n",
        "  # Select the arm based on the epsilon-greedy method:\n",
        "  arm = epsilon_greedy(epsilon=0.5)\n",
        "  # Pull the arm and store the reward and next state information:\n",
        "  next_state, reward, done, info = env.step(arm)\n",
        "  # Increment the count of the arm by 1:\n",
        "  count[arm] += 1\n",
        "  # Update the sum of rewards of the arm:\n",
        "  sum_rewards[arm]+=reward\n",
        "  # Update the average reward of the arm:\n",
        "  Q[arm] = sum_rewards[arm]/count[arm]\n",
        "  \n",
        "# After all the rounds, we look at the average reward obtained from each of the arms:\n",
        "print(Q)    # The preceding code will print something like this: [0.xx 0.yy]\n",
        "\n",
        "# Now, we can select the optimal arm as the one that has the maximum average reward:\n",
        "print('The optimal arm is arm {}'.format(np.argmax(Q)+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.81012658 0.0952381 ]\n",
            "The optimal arm is arm 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tChBKAL2rz1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126e7606-3321-4b4b-df3c-e45a34a54512"
      },
      "source": [
        "# First, let's initialize the variables.\n",
        "# Initialize the count for storing the number of times an arm is pulled:\n",
        "count = np.zeros(2)\n",
        "# Initialize sum_rewards for storing the sum of rewards of each arm:\n",
        "sum_rewards = np.zeros(2)\n",
        "# Initialize Q for storing the average reward of each arm:\n",
        "Q = np.zeros(2)\n",
        "# Set the number of rounds (iterations):\n",
        "num_rounds = 100\n",
        "\n",
        "# Now, we define the softmax function with the temperature T:\n",
        "def softmax(T):\n",
        "  # Compute the probability of each arm based on the temperature equation:\n",
        "  denom = sum([np.exp(i/T) for i in Q])\n",
        "  probs = [np.exp(i/T)/denom for i in Q]\n",
        "  # Select the arm based on the computed probability distribution of arms:\n",
        "  arm = np.random.choice(env.action_space.n, p=probs)  \n",
        "  return arm\n",
        "\n",
        "# Now, let's play the game and try to find the best arm using the softmax exploration method.\n",
        "# Let's begin by setting the temperature T to a high number, say, 50:\n",
        "T = 50\n",
        "# For each round:\n",
        "for i in range(num_rounds):\n",
        "  # Select the arm based on the softmax exploration method:\n",
        "  arm = softmax(T)\n",
        "  # Pull the arm and store the reward and next state information:\n",
        "  next_state, reward, done, info = env.step(arm)\n",
        "  # Increment the count of the arm by 1:\n",
        "  count[arm] += 1\n",
        "  # Update the sum of rewards of the arm:\n",
        "  sum_rewards[arm]+=reward\n",
        "  # Update the average reward of the arm:\n",
        "  Q[arm] = sum_rewards[arm]/count[arm]\n",
        "  # Reduce the temperature T:\n",
        "  T = T*0.99\n",
        "\n",
        "# After all the rounds, we check the Q value, that is, the average reward of all the arms:\n",
        "print(Q)    # The preceding code will print something like this: [0.xx 0.yy]\n",
        "\n",
        "# Now, we can select the optimal arm as the one that has the maximum average reward:\n",
        "print('The optimal arm is arm {}'.format(np.argmax(Q)+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.73214286 0.11363636]\n",
            "The optimal arm is arm 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICezyy2tvH0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de6dbf8-ae97-45b9-efa9-3e4eb5d0d6d3"
      },
      "source": [
        "# First, let's initialize the variables.\n",
        "# Initialize the count for storing the number of times an arm is pulled:\n",
        "count = np.zeros(2)\n",
        "# Initialize sum_rewards for storing the sum of rewards of each arm:\n",
        "sum_rewards = np.zeros(2)\n",
        "# Initialize Q for storing the average reward of each arm:\n",
        "Q = np.zeros(2)\n",
        "# Set the number of rounds (iterations):\n",
        "num_rounds = 100\n",
        "\n",
        "# Now, we define the UCB function, which returns the best arm as the \n",
        "# one that has the highest UCB:\n",
        "def UCB(i):\n",
        "  # Initialize the numpy array for storing the UCB of all the arms:\n",
        "  ucb = np.zeros(2)\n",
        "  # Before computing the UCB, we explore all the arms at least once, so for the \n",
        "  # first 2 rounds, we directly select the arm corresponding to the round number:\n",
        "  if i < 2:\n",
        "    return i\n",
        "  # If the round is greater than 2, then we compute the UCB of all the arms as \n",
        "  # specified in the UCB equation and return the arm that has the highest UCB:\n",
        "  else:\n",
        "    for arm in range(2):\n",
        "      ucb[arm] = Q[arm] + np.sqrt((2*np.log(sum(count))) / count[arm])\n",
        "  return (np.argmax(ucb))\n",
        "\n",
        "# Now, let's play the game and try to find the best arm using the UCB method.\n",
        "# For each round:\n",
        "for i in range(num_rounds):\n",
        "  # Select the arm based on the UCB method:\n",
        "  arm = UCB(i)\n",
        "  # Pull the arm and store the reward and next state information:\n",
        "  next_state, reward, done, info = env.step(arm)\n",
        "  # Increment the count of the arm by 1:\n",
        "  count[arm] += 1\n",
        "  # Update the sum of rewards of the arm:\n",
        "  sum_rewards[arm]+=reward\n",
        "  # Update the average reward of the arm:\n",
        "  Q[arm] = sum_rewards[arm]/count[arm]\n",
        "\n",
        "# Now, we can select the optimal arm as the one that has the maximum average reward:\n",
        "print('The optimal arm is arm {}'.format(np.argmax(Q)+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal arm is arm 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGvGGpl5zATM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d75d71b-ce77-480b-f767-d361579d4387"
      },
      "source": [
        "# First, let's initialize the variables.\n",
        "# Initialize the count for storing the number of times an arm is pulled:\n",
        "count = np.zeros(2)\n",
        "# Initialize sum_rewards for storing the sum of rewards of each arm:\n",
        "sum_rewards = np.zeros(2)\n",
        "# Initialize Q for storing the average reward of each arm:\n",
        "Q = np.zeros(2)\n",
        "# Initialize the alpha value as 1 for both arms:\n",
        "alpha = np.ones(2)\n",
        "# Initialize the beta value as 1 for both arms:\n",
        "beta = np.ones(2)\n",
        "# Set the number of rounds (iterations):\n",
        "num_rounds = 100\n",
        "\n",
        "# Now, let's define the thompson_sampling function\n",
        "def thompson_sampling(alpha,beta):\n",
        "  \"\"\"we randomly sample values from the beta distributions of both arms and \n",
        "  return the arm that has the maximum sampled value\"\"\"\n",
        "  samples = [np.random.beta(alpha[i]+1,beta[i]+1) for i in range(2)]\n",
        "  return np.argmax(samples)\n",
        "\n",
        "# Now, let's play the game and try to find the best arm using the Thompson sampling method.\n",
        "# For each round:\n",
        "for i in range(num_rounds):\n",
        "  # Select the arm based on the Thompson sampling method:\n",
        "  arm = thompson_sampling(alpha,beta)\n",
        "  # Pull the arm and store the reward and next state information:\n",
        "  next_state, reward, done, info = env.step(arm) \n",
        "  # Increment the count of the arm by 1:\n",
        "  count[arm] += 1\n",
        "  # Update the sum of rewards of the arm:\n",
        "  sum_rewards[arm]+=reward\n",
        "  # Update the average reward of the arm:\n",
        "  Q[arm] = sum_rewards[arm]/count[arm]\n",
        "  # If we win the game, that is, if the reward is equal to 1, then we update \n",
        "  # the value of alpha to alpha+1, else we update the value of beta to beta+1:\n",
        "  if reward==1:\n",
        "    alpha[arm] = alpha[arm] + 1\n",
        "  else:\n",
        "    beta[arm] = beta[arm] + 1\n",
        "\n",
        "# After all the rounds, we can select the optimal arm as the one that has the highest average reward:\n",
        "print('The optimal arm is arm {}'.format(np.argmax(Q)+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal arm is arm 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4USecQPc-SEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78f7115-f16f-4f24-9714-ed06c74c4756"
      },
      "source": [
        "# Creating a dataset\n",
        "# We generate a dataset with five columns denoting the five advertisement banners, \n",
        "# where the values in the rows will be either 0 or 1, indicating whether the \n",
        "# advertisement banner has been clicked (1) or not clicked (0) by the user:\n",
        "df = pd.DataFrame()\n",
        "for i in range(5):\n",
        "  df['Banner_type_'+str(i)] = np.random.randint(0,2,100000)\n",
        "\n",
        "# Now, let's initialize some of the important variables.\n",
        "# Set the number of iterations:\n",
        "num_iterations = 100000\n",
        "# Define the number of banners:\n",
        "num_banner = 5\n",
        "# Initialize count for storing the number of times the banner was clicked:\n",
        "count = np.zeros(num_banner)\n",
        "# Initialize sum_rewards for storing the sum of rewards obtained from each banner:\n",
        "sum_rewards = np.zeros(num_banner)\n",
        "# Initialize Q for storing the mean reward of each banner:\n",
        "Q = np.zeros(num_banner)\n",
        "# Define a list for storing the selected banners:\n",
        "banner_selected = []\n",
        "\n",
        "# Now, let's define the epsilon-greedy method:\n",
        "def epsilon_greedy_policy(epsilon):\n",
        "  if np.random.uniform(0,1) < epsilon:\n",
        "    return np.random.choice(num_banner)\n",
        "  else:\n",
        "    return np.argmax(Q)\n",
        "\n",
        "# Now, we run the epsilon-greedy policy to find out which advertisement banner is the best.\n",
        "# For each iteration:\n",
        "for i in range(num_iterations):\n",
        "  # Select the banner using the epsilon-greedy policy:\n",
        "  banner = epsilon_greedy_policy(0.5)\n",
        "  # Get the reward of the banner:\n",
        "  reward = df.values[i, banner]\n",
        "  # Increment the counter:\n",
        "  count[banner] += 1\n",
        "  # Store the sum of rewards:\n",
        "  sum_rewards[banner]+=reward\n",
        "  # Compute the average reward:\n",
        "  Q[banner] = sum_rewards[banner]/count[banner]\n",
        "  # Store the banner to the banner selected list:\n",
        "  banner_selected.append(banner)\n",
        "\n",
        "# After all the rounds, we can select the best banner as the one that has the maximum average reward:\n",
        "print( 'The best banner is banner {}'.format(np.argmax(Q)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best banner is banner 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGxceCn-8ths",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "48733be4-4638-4eb4-c892-6a1ede311dbc"
      },
      "source": [
        "# We can also plot and see which banner is selected the most often:\n",
        "ax = sns.countplot(banner_selected)\n",
        "ax.set(xlabel='Banner', ylabel='Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}