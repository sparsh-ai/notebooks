{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T445041 | IEEE BigData 2021 RecSys ComFOR RL Model","provenance":[],"collapsed_sections":[],"mount_file_id":"17Ooq4Y9qaDsvAL0QyGmWdU_GhffqRM2P","authorship_tag":"ABX9TyO0hPpNEqFzXx9QRf5a7Rx+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c869695ad6a145b28d6940503dbba252":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9cf661a2b1264855aca52f042fae12d3","IPY_MODEL_b56438dab4e442a9bb21fac14ee32e4e","IPY_MODEL_4810d1c20ec54a15aaacdeb8f56e2478"],"layout":"IPY_MODEL_ee3ff1c5c1e848f39657742b0f5e0a18"}},"9cf661a2b1264855aca52f042fae12d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04e53ec292c94fe0b7e35ce5a8838b01","placeholder":"​","style":"IPY_MODEL_5bd3f62468854d29b2a6c0c01c6e9edb","value":" 32%"}},"b56438dab4e442a9bb21fac14ee32e4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_32b52cab9c0149bf927e9f54794164cc","max":260087,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45a71bf5bda641aeaca69f252401e758","value":83697}},"4810d1c20ec54a15aaacdeb8f56e2478":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccbed971f11a45ed8020060b2412b5ed","placeholder":"​","style":"IPY_MODEL_5fb96f9cd5ba4fdd9a187743460e50d7","value":" 83695/260087 [1:46:35&lt;4:11:53, 11.67it/s]"}},"ee3ff1c5c1e848f39657742b0f5e0a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e53ec292c94fe0b7e35ce5a8838b01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd3f62468854d29b2a6c0c01c6e9edb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32b52cab9c0149bf927e9f54794164cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45a71bf5bda641aeaca69f252401e758":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccbed971f11a45ed8020060b2412b5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb96f9cd5ba4fdd9a187743460e50d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"3GofkbEjwQCI"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaXpEKLdXNPa","executionInfo":{"elapsed":663,"status":"ok","timestamp":1636271220486,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"2aacf9ae-cc79-43f0-f3f9-41ae04c75e16"},"source":["import os\n","project_name = \"ieee21cup-recsys\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', branch)\n","\n","if not os.path.exists(project_path):\n","    !cp -r /content/drive/MyDrive/git_credentials/. ~\n","    !mkdir \"{project_path}\"\n","    %cd \"{project_path}\"\n","    !git init\n","    !git remote add origin https://github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout -b \"{branch}\"\n","else:\n","    %cd \"{project_path}\""],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content/main\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZvPHRyMXdlS","executionInfo":{"elapsed":967,"status":"ok","timestamp":1636271225175,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"9ace871e-5585-4062-e21a-70e4d38d537e"},"source":["%cd /content"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"2eRcpGL6XfDs"},"source":["!cd /content/main && git add . && git commit -m 'commit' && git push origin main"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DctyNOSdx-7h"},"source":["!pip install -q wget"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrEmNkAAsQlM"},"source":["import io\n","import copy\n","import sys\n","import wget\n","import os\n","import logging\n","import pandas as pd\n","from os import path as osp\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from pathlib import Path\n","\n","import multiprocessing as mp\n","import functools\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import bz2\n","import pickle\n","import _pickle as cPickle\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4swQxyAsQnj"},"source":["class Args:\n","\n","    # Paths\n","    datapath_bronze = '/content/main/data/bronze'\n","    datapath_silver = '/content/main/data/silver/T445041'\n","    datapath_gold = '/content/main/data/gold/T445041'\n","\n","    filename_trainset = 'train.csv'\n","    filename_iteminfo = 'item_info.csv'\n","    filename_track1_testset = 'track1_testset.csv'\n","\n","    data_sep = ' '\n","\n","    N_ITEMS = 380\n","    N_USER_PORTRAITS = 10\n","    N_THREADS = mp.cpu_count() - 1\n","\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wIDRSKqOtEdb"},"source":["logging.basicConfig(stream=sys.stdout,\n","                    level = logging.INFO,\n","                    format='%(asctime)s [%(levelname)s] : %(message)s',\n","                    datefmt='%d-%b-%y %H:%M:%S')\n","\n","logger = logging.getLogger('IEEE21 Logger')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1bmqnvQv27E"},"source":["## Utilities"]},{"cell_type":"code","metadata":{"id":"tH7lmOJbAOIf"},"source":["def save_pickle(data, title):\n"," with bz2.BZ2File(title, 'w') as f: \n","    cPickle.dump(data, f)\n","\n","def load_pickle(path):\n","    data = bz2.BZ2File(path, 'rb')\n","    data = cPickle.load(data)\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AGTVUdmtwWgZ"},"source":["def download_dataset():\n","    # create bronze folder if not exist\n","    Path(args.datapath_bronze).mkdir(parents=True, exist_ok=True)\n","    # also creating silver and gold folder for later use\n","    Path(args.datapath_silver).mkdir(parents=True, exist_ok=True)\n","    Path(args.datapath_gold).mkdir(parents=True, exist_ok=True)\n","    # for each of the file, download if not exist\n","    datasets = ['train.parquet.snappy', 'item_info.parquet.snappy',\n","                'track1_testset.parquet.snappy', 'track2_testset.parquet.snappy']\n","    for filename in datasets:\n","        file_savepath = osp.join(args.datapath_bronze,filename)\n","        if not osp.exists(file_savepath):\n","            logger.info('Downloading {}'.format(filename))\n","            wget.download(url='https://github.com/sparsh-ai/ieee21cup-recsys/raw/main/data/bronze/{}'.format(filename),\n","                          out=file_savepath)\n","        else:\n","            logger.info('{} file already exists, skipping!'.format(filename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vk93jRMwtEWP"},"source":["def parquet_to_csv(path):\n","    savepath = osp.join(str(Path(path).parent),str(Path(path).name).split('.')[0]+'.csv')\n","    pd.read_parquet(path).to_csv(savepath, index=False, sep=args.data_sep)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_F4vRpFCzYsf"},"source":["def convert_dataset():\n","    # for each of the file, convert into csv, if csv not exist\n","    datasets = ['train.parquet.snappy', 'item_info.parquet.snappy',\n","                'track1_testset.parquet.snappy', 'track2_testset.parquet.snappy']\n","    datasets = {x:str(Path(x).name).split('.')[0]+'.csv' for x in datasets}\n","    for sfilename, tfilename in datasets.items():\n","        file_loadpath = osp.join(args.datapath_bronze,sfilename)\n","        file_savepath = osp.join(args.datapath_bronze,tfilename)\n","        if not osp.exists(file_savepath):\n","            logger.info('Converting {} to {}'.format(sfilename, tfilename))\n","            parquet_to_csv(file_loadpath)\n","        else:\n","            logger.info('{} file already exists, skipping!'.format(tfilename))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3usPrS7pKdo5"},"source":["```\n","Script to prepare data objects for training and testing\n","   Usage: from DataPrep import getUserFeaturesTrainSet, getPurchasedItemsTrainSet, getUserFeaturesTestSet\n","   1. getUserFeaturesTrainSet():\n","        return: DataFrame with N_ITEMS+N_USER_PORTRAITS columns\n","            first N_ITEMS cols: one hot encoding of clicked items\n","            last N_USER_PORTRAITS cols: normalized user portraits to [0,1] range\n","        DataFrame shape: (260087, 380+10)\n","   2. getPurchasedItemsTrainSet():\n","        return: a list, each element is a list of purchased itemIDs by a user\n","            each element i of the list corresponds to a user in row i of getUserFeaturesTrainSet()\n","        list length: 260087\n","   3. getUserFeaturesTestSet():\n","        return: DataFrame with N_ITEMS+N_USER_PORTRAITS columns\n","            first N_ITEMS cols: one hot encoding of clicked items\n","            last N_USER_PORTRAITS cols: normalized user portraits to [0,1] range\n","   4. getClusterLabels():\n","      return: (model, labels)\n","            model : model for testset prediction\n","            labels: numpy array of labels of clusters from the trainset\n","```"]},{"cell_type":"code","metadata":{"id":"I5iL4t4TM5C9"},"source":["def parseUserFeaturesOneLine(inputArray):\n","    \"\"\"\n","    Kernel function\n","    Return: list of length args.N_ITEMS + args.N_USER_PORTRAITS \n","    Input:\n","        inputArray: an array as a row of trainset or testset raw data\n","    ASSUMPTIONS:\n","        user_click_history is on column index  1 of inputArray\n","        user_portrait is on column index 2 of inputArray\n","    \"\"\"\n","    CLICKHIST_INDEX = 1\n","    PORTRAIT_INDEX = 2\n","    output = [0]*(args.N_ITEMS + args.N_USER_PORTRAITS)\n","    # parse click history, assuming \n","    clickSeries = inputArray[CLICKHIST_INDEX].split(',')\n","    clickedItems = [item.partition(':')[0] for item in clickSeries]\n","    # add clicked items to output\n","    for itemID in clickedItems:\n","        if int(itemID)<=0 or int(itemID)>=args.N_ITEMS:  # ignore if itemID invalid\n","            continue\n","        colIndex = int(itemID) - 1  # index of clicked item on an element of outputSharedList\n","        output[colIndex] = 1\n","    # parse user portraits\n","    portraits = inputArray[PORTRAIT_INDEX].split(',')\n","    if len(portraits)!=args.N_USER_PORTRAITS:\n","        raise Exception(\"row \"+rowIndex+\" of data set does not have the expected number of portrait features\")\n","    # add portrait features to output\n","    for i in range(args.N_USER_PORTRAITS):\n","        colIndex = args.N_ITEMS + i  # index of feature on an element of outputSharedList\n","        output[colIndex] = int(portraits[i])\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTygb9y5Kdmc"},"source":["def prepareUserFeaturesTrainSet():\n","    \"\"\"\n","    save to UserFeaturesTrainSet.pkl\n","        data frame with N_ITEMS+N_USER_PORTRAITS columns\n","        first N_ITEMS cols: one hot encoding of clicked items\n","        last N_USER_PORTRAITS cols: normalized user portraits\n","    Data source: trainset.csv\n","    \"\"\"\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_trainset)\n","    outfilepath = osp.join(args.datapath_silver,'UserFeaturesTrainSet.pkl')\n","\n","    if not osp.exists(outfilepath):\n","        # read data to pd dataframe\n","        logger.info('reading raw data file ...')\n","        rawTrainSet = pd.read_csv(readfilepath, sep=args.data_sep)\n","        # create output frame\n","        colNames = ['clickedItem'+str(i+1) for i in range(args.N_ITEMS)] + ['userPortrait'+str(i+1) for i in range(args.N_USER_PORTRAITS)]\n","        output = pd.DataFrame(data = np.zeros(shape = (rawTrainSet.shape[0], args.N_ITEMS+args.N_USER_PORTRAITS)), columns = colNames)\n","        # parse each line in parallel\n","        # first objects in shared memory for input and output\n","        logger.info('creating shared memory objects ...')\n","        inputList = rawTrainSet.values.tolist()  # for memory efficiency\n","        p = mp.Pool(args.N_THREADS)\n","        logger.info('multiprocessing ... ')\n","        outputList = p.map(parseUserFeaturesOneLine, inputList)\n","        # convert outputSharedList back to DataFrame\n","        logger.info('convert to DataFrame ...')\n","        output = pd.DataFrame(data = outputList, columns = colNames)\n","\n","        import gc; gc.collect()\n","\n","        # normalize the portraits columns\n","        for i in range(args.N_USER_PORTRAITS):\n","            colName = 'userPortrait' + str(i+1)\n","            scaler = MinMaxScaler()\n","            output[colName] = scaler.fit_transform(output[colName].values.reshape(-1,1))\n","        # save to pickle file\n","        output.to_pickle(outfilepath)\n","        logger.info('Saved processed file at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} Processed data already exists, skipping!'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAu5MxaOU8Ze","executionInfo":{"elapsed":86158,"status":"ok","timestamp":1636271401213,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"5472f3fe-fbdc-4bec-f5db-22a88c94631e"},"source":["prepareUserFeaturesTrainSet()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["07-Nov-21 07:48:35 [INFO] : reading raw data file ...\n","07-Nov-21 07:48:41 [INFO] : creating shared memory objects ...\n","07-Nov-21 07:48:42 [INFO] : multiprocessing ... \n","07-Nov-21 07:49:03 [INFO] : convert to DataFrame ...\n","07-Nov-21 07:49:52 [INFO] : Saved processed file at /content/main/data/silver/T445041/UserFeaturesTrainSet.pkl\n"]}]},{"cell_type":"code","metadata":{"id":"56YPgpz4KdkL"},"source":["def preparePurchasedItemsTrainSet():\n","    \"\"\"\n","    save to PurchasedItemsTrainSet.pkl\n","    Data source: trainset.csv\n","    \"\"\"\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_trainset)\n","    outfilepath = osp.join(args.datapath_silver,'PurchasedItemsTrainSet.pkl')\n","\n","    if not osp.exists(outfilepath):\n","        # read data to pd dataframe\n","        logger.info('reading raw data file ...')\n","        rawTrainSet = pd.read_csv(readfilepath, sep=args.data_sep)\n","        output = []\n","        logger.info('processing ...')\n","        for i in tqdm(range(rawTrainSet.shape[0])):\n","            # parse each line\n","            exposedItems = rawTrainSet.exposed_items[i]\n","            labels = rawTrainSet.labels[i]\n","            exposedItems = exposedItems.split(',')\n","            labels = labels.split(',')\n","            purchasedItems = []\n","            for j in range(len(labels)):\n","                if int(labels[j])==1:\n","                    # item is purchased, append it to the purchasedItems list\n","                    purchasedItems.append(int(exposedItems[j]))\n","\n","            import gc; gc.collect()\n","\n","            # append the list of this row to output\n","            output.append(purchasedItems)\n","        # save to pickle file\n","        save_pickle(output, outfilepath)\n","        logger.info('Saved processed file at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} Processed data already exists, skipping!'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["c869695ad6a145b28d6940503dbba252","9cf661a2b1264855aca52f042fae12d3","b56438dab4e442a9bb21fac14ee32e4e","4810d1c20ec54a15aaacdeb8f56e2478","ee3ff1c5c1e848f39657742b0f5e0a18","04e53ec292c94fe0b7e35ce5a8838b01","5bd3f62468854d29b2a6c0c01c6e9edb","32b52cab9c0149bf927e9f54794164cc","45a71bf5bda641aeaca69f252401e758","ccbed971f11a45ed8020060b2412b5ed","5fb96f9cd5ba4fdd9a187743460e50d7"]},"id":"VcuA07bJWzap","outputId":"1bb4ca57-16e2-46c3-dc01-3f0569643141"},"source":["preparePurchasedItemsTrainSet()"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["07-Nov-21 07:56:47 [INFO] : reading raw data file ...\n","07-Nov-21 07:56:51 [INFO] : processing ...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c869695ad6a145b28d6940503dbba252","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/260087 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"id":"nQ5kzkryOonD"},"source":["def prepareUserFeaturesTestSet():\n","    \"\"\"\n","    save to PurchasedItemsTestSet.pkl\n","    write content: userIDs, UserFeaturesTestSet\n","        userIDs: array of user ids\n","        UserFeaturesTestSet: data frame with N_ITEMS+N_USER_PORTRAITS columns\n","    Data source: track1_testset.csv\n","    \"\"\"\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_track1_testset)\n","    outfilepath = osp.join(args.datapath_silver,'PurchasedItemsTestSet.pkl')\n","\n","    if not osp.exists(outfilepath):\n","        # read data to pd dataframe\n","        logger.info('reading raw data file ...')\n","        rawTestSet = pd.read_csv(readfilepath)\n","        # create output frame\n","        colNames = ['clickedItem'+str(i+1) for i in range(args.N_ITEMS)] + ['userPortrait'+str(i+1) for i in range(args.N_USER_PORTRAITS)]\n","        output = pd.DataFrame(data = np.zeros(shape = (rawTestSet.shape[0], args.N_ITEMS+args.N_USER_PORTRAITS)), columns = colNames)\n","        # parse each line in parallel\n","        # first objects in shared memory for input and output\n","        print('creating shared memory objects ... ')\n","        inputList = rawTestSet.values.tolist()  # for memory efficiency\n","        p = mp.Pool(args.N_THREADS)\n","        print('multiprocessing ... ')\n","        outputList = p.map(parseUserFeaturesOneLine, inputList)\n","        # convert outputSharedList back to DataFrame\n","        print('convert to DataFrame ...')\n","        output = pd.DataFrame(data = outputList, columns = colNames)\n","        # normalize the portraits columns\n","        for i in range(args.N_USER_PORTRAITS):\n","            colName = 'userPortrait' + str(i+1)\n","            scaler = MinMaxScaler()\n","            output[colName] = scaler.fit_transform(output[colName].values.reshape(-1,1))\n","        # create userIDs array\n","        userIDs = rawTestSet['user_id'].tolist()\n","        # save to pickle file\n","        save_pickle((userIDs,output), outfilepath)\n","        logger.info('Saved processed file at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} Processed data already exists, skipping!'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0desQ4yISXDX"},"source":["def getUserFeaturesTrainSet():\n","    savefilepath = osp.join(args.datapath_silver,'UserFeaturesTrainSet.pkl')\n","    return load_pickle(savefilepath)\n","\n","\n","def getPurchasedItemsTrainSet():\n","    savefilepath = osp.join(args.datapath_silver,'PurchasedItemsTrainSet.pkl')\n","    return load_pickle(savefilepath)\n","\n","\n","def getUserFeaturesTestSet():\n","    savefilepath = osp.join(args.datapath_silver,'UserFeaturesTestSet.pkl')\n","    return load_pickle(savefilepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQMyFaoQUSiv"},"source":["def getExposedItemsTrainSet():\n","    \"\"\"return list of exposed items in trainset and whether they are purchased\n","    (exposedItems, purchaseLabels)\n","    both are list of list\n","    \"\"\"\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_trainset)\n","    rawTrainSet = pd.read_csv(readfilepath)\n","    exposedItems = rawTrainSet.exposed_items\n","    purchaseLabels = rawTrainSet.labels\n","    exposedItems_out = []\n","    purchaseLabels_out = []\n","    for i in range(len(exposedItems)):\n","        items = exposedItems[i]\n","        labels = purchaseLabels[i]\n","        items = [int(x) for x in items.split(',')]\n","        labels = [int(x) for x in labels.split(',')]\n","        exposedItems_out.append(items)\n","        purchaseLabels_out.append(labels)\n","    return (exposedItems_out, purchaseLabels_out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewFHPoEmUsGG"},"source":["def getItemPrice():\n","    \"\"\"return: array of item prices\"\"\"\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_iteminfo)\n","    itemInfo = pd.read_csv(readfilepath)\n","    itemInfo = itemInfo.sort_values(by = 'item_id')\n","    itemPrice = itemInfo.price\n","    return itemPrice"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePwzVpKuSXBC"},"source":["def splitTrainSet(percentageTrain = 0.8):\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_trainset)\n","    outfilepath = osp.join(args.datapath_silver,'splitTrainSet.pkl')\n","\n","    if not osp.exists(outfilepath):\n","        # read raw data\n","        userFeatures = getUserFeaturesTrainSet()\n","        rawTrainSet = pd.read_csv(readfilepath)\n","        purchaseLabels1 = rawTrainSet.labels\n","        recItems1 = rawTrainSet.exposed_items\n","        N = len(purchaseLabels1)\n","        # create permutation index\n","        permutedIndex = np.random.permutation(N)\n","        trainIndex = permutedIndex[:int(N*percentageTrain)]\n","        testIndex = permutedIndex[int(N*percentageTrain):]\n","        # split user features\n","        userFeaturesTrain = userFeatures.iloc[trainIndex]\n","        userFeaturesTest = userFeatures.iloc[testIndex]\n","        # convert recItems to integer\n","        recItems = []\n","        for i, s in enumerate(recItems1):\n","        # loop thru samples\n","            recItems.append([int(x) for x in s.split(',')])\n","        recItems = np.array(recItems)\n","        # convert purchaseLabels to integer\n","        purchaseLabels = []\n","        for i, s in enumerate(purchaseLabels1):\n","        # loop thru samples\n","            purchaseLabels.append([int(x) for x in s.split(',')])\n","        purchaseLabels = np.array(purchaseLabels)\n","        # split recItems\n","        recItemsTrain = recItems[trainIndex]\n","        recItemsTest = recItems[testIndex]\n","        # split purchaseLabels\n","        purchaseLabelTrain = purchaseLabels[trainIndex]\n","        purchaseLabelTest = purchaseLabels[testIndex]\n","        # saving pickle\n","        save_pickle((userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesTest, recItemsTest, purchaseLabelTest), outfilepath)\n","        logger.info('Saved processed file at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} Processed data already exists, skipping!'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaYdx9KRSW-y"},"source":["class Metrics:\n","    def __init__(self, recommended_testset, purchaseLabels_testset, itemPrice):\n","        \"\"\" recommended_testset: list\n","            purchaseLabels_testset: list\n","            itemPrice: list\n","        \"\"\"\n","        self.rec = recommended_testset\n","        self.labels = purchaseLabels_testset\n","        self.price = itemPrice\n","        \n","    def calculate_metrics1(self, recommendedItems):\n","        \"\"\"\n","        recommendedItems: list of length equal to recommended_testset\n","        metrics calculated by summing total rewards of purchased items, no punishment\n","        \"\"\"\n","        score = 0\n","        for i in range(len(recommendedItems)):\n","        # loop each sample in data\n","            predItems = recommendedItems[i]\n","            givenItems = self.rec[i]\n","            labels = self.labels[i]\n","            purchaseAND = [givenItems[i] for i in range(9) if labels[i]==1]\n","            for item in predItems:\n","            # loop each items in the sample\n","                if item in purchaseAND:\n","                    score = score + self.price[item-1]\n","        return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BM2s0auSacpX"},"source":["################################################################\n","# Exploring Collaborative Filtering based on KNN\n","################################################################\n","# 1. Use User data with clicked items and user_portraits\n","# 2. train KNN algorithm\n","# 3. for a test observaion, find K nearest neighbors\n","# 4. find the most common items from the neighbors to recommend\n","# 4. Use cross-validation to calibrate K\n","\n","from sklearn.neighbors import NearestNeighbors\n","\n","class KNNModel:\n","    def __init__(self, TrainData, purchaseData, K_neighbors):\n","        \"\"\"\n","        train KNN model on TrainData\n","        purchaseData: list of length len(TrainData), each element is a list of purchased itemID\n","        K_neighbors: KNN parameter\n","        \"\"\"\n","        self.model = NearestNeighbors(n_neighbors = K_neighbors)\n","        self.model.fit(TrainData)\n","        self.purchaseData = purchaseData\n","        self.K_neighbors = K_neighbors\n","    def predict(self, newPoint):\n","        \"\"\"\n","        newPoint should have the same columns as TrainData, any number of row\n","        first find the nearest neighbors\n","        then count the frequency of their purchased items\n","        return: list with length = nrow of newPoint\n","            each element of list is a list of length 9\n","        \"\"\"\n","        neighborDist, neighborIDs = self.model.kneighbors(newPoint)\n","        output = []\n","        # calculate score of purchased items with dictionary\n","        itemScore = {}\n","        for rowID in range(len(neighborIDs)):\n","            for i in range(self.K_neighbors):\n","                uID = neighborIDs[rowID][i]\n","                dist = neighborDist[rowID][i]\n","                if dist==0:\n","                    dist = 1e-7\n","                itemList = self.purchaseData[uID]\n","                for itemID in itemList:\n","                    if itemID not in itemScore.keys():\n","                        itemScore[itemID] = 1/dist\n","                    else:\n","                        itemScore[itemID] = itemScore[itemID] + 1/dist\n","            # find 9 items with highest frequency\n","            # first sort the dict by decreasing value\n","            sortedDict = {k: v for k, v in sorted(itemScore.items(), key=lambda item: item[1], reverse = True)}\n","            finalItems = list(sortedDict.keys())[:9]\n","            output.append(finalItems)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NL4KP4XrasQn"},"source":["def knn_training_and_prediction():\n","    # load processed datasets\n","    TrainSet = getUserFeaturesTrainSet()\n","    PurchasedItems = getPurchasedItemsTrainSet()\n","    # initiate knn model object\n","    model = KNNModel(TrainSet, PurchasedItems, 50)\n","    # get test set\n","    userIDs, TestSet = getUserFeaturesTestSet()\n","    # make prediction\n","    recommendedItems = model.predict(TestSet)\n","    # format data according to submission format and write to file\n","    outFile = '/tf/shared/track2_output.csv'\n","    f = open(outFile, \"w\")\n","    f.write('id,itemids')\n","    for i in range(len(userIDs)):\n","        f.write('\\n')\n","        itemList = recommendedItems[i]\n","        itemString = ' '.join([str(j) for j in itemList])\n","        outString = str(userIDs[i]) + ',' + itemString\n","        f.write(outString)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"igLLZV6gGu-v"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"koFQxtgos6gE"},"source":["## Jobs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2y8mdDjds6dr","executionInfo":{"elapsed":5,"status":"ok","timestamp":1636267384268,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"c4db2615-7617-4509-ae6a-3bbb88430e98"},"source":["logger.info('JOB START: DOWNLOAD_RAW_DATASET')\n","download_dataset()\n","logger.info('JOB END: DOWNLOAD_RAW_DATASET')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["07-Nov-21 06:43:04 [INFO] : JOB START: DOWNLOAD_RAW_DATASET\n","07-Nov-21 06:43:04 [INFO] : train.parquet.snappy file already exists, skipping!\n","07-Nov-21 06:43:04 [INFO] : item_info.parquet.snappy file already exists, skipping!\n","07-Nov-21 06:43:04 [INFO] : track1_testset.parquet.snappy file already exists, skipping!\n","07-Nov-21 06:43:04 [INFO] : track2_testset.parquet.snappy file already exists, skipping!\n","07-Nov-21 06:43:04 [INFO] : JOB END: DOWNLOAD_RAW_DATASET\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ig3tPpB2Fx-","executionInfo":{"elapsed":14250,"status":"ok","timestamp":1636267418097,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"outputId":"bbc27a15-6f9c-4e5a-f227-e6cfd9363c6f"},"source":["logger.info('JOB START: DATASET_CONVERSION_PARQUET_TO_CSV')\n","convert_dataset()\n","logger.info('JOB END: DATASET_CONVERSION_PARQUET_TO_CSV')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["07-Nov-21 06:43:24 [INFO] : JOB START: DATASET_CONVERSION_PARQUET_TO_CSV\n","07-Nov-21 06:43:24 [INFO] : Converting train.parquet.snappy to train.csv\n","07-Nov-21 06:43:29 [INFO] : Converting item_info.parquet.snappy to item_info.csv\n","07-Nov-21 06:43:29 [INFO] : Converting track1_testset.parquet.snappy to track1_testset.csv\n","07-Nov-21 06:43:34 [INFO] : Converting track2_testset.parquet.snappy to track2_testset.csv\n","07-Nov-21 06:43:37 [INFO] : JOB END: DATASET_CONVERSION_PARQUET_TO_CSV\n"]}]},{"cell_type":"code","metadata":{"id":"toXUL9pVItp_"},"source":[""],"execution_count":null,"outputs":[]}]}