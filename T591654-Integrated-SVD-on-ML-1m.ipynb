{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T591654 | Integrated SVD on ML-1m","provenance":[],"collapsed_sections":[],"mount_file_id":"16z8K9gL8SxhneDP4Mi3L4Opbck-aYxO8","authorship_tag":"ABX9TyOEQreF75jTgMq3is9ZSwpl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"RuiURj-F17mq","executionInfo":{"status":"ok","timestamp":1638116889957,"user_tz":-330,"elapsed":694,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["import numpy as np\n","import pandas as pd\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"aB3rWtCGOm0U"},"source":["!wget -q --show-progress https://github.com/sparsh-ai/stanza/raw/S629908/rec/CDL/data/ml_100k_train.npy\n","!wget -q --show-progress https://github.com/sparsh-ai/stanza/raw/S629908/rec/CDL/data/ml_100k_test.npy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGgWfwh7T8oe","executionInfo":{"status":"ok","timestamp":1638116892206,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["train = np.load('ml_100k_train.npy')\n","test = np.load('ml_100k_test.npy')\n","\n","train_imp = (train > 0).astype(float)\n","test_imp = (test > 0).astype(float)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N3cj-gQQB-ce","executionInfo":{"status":"ok","timestamp":1638116892209,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class Config:\n","    learning_rate = 0.01\n","    weight_decay = 0.1\n","    early_stopping_round = 0\n","    epochs = 100\n","    seed = 1995\n","    dim_f = 15\n","    K = 30\n","    \n","config = Config()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WhLB-jSCgLa","executionInfo":{"status":"ok","timestamp":1638119631829,"user_tz":-330,"elapsed":2706533,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"f3e1da4b-328e-4124-f77c-3cca9b162589"},"source":["def get_neighbor(train_e, train_i, lambda_=100):\n","    neighbor = []\n","    for data in [train_e, train_i]:\n","        RHO = np.corrcoef(data.T)\n","        RHO = np.nan_to_num(RHO, nan=-1)\n","        n_ij = np.dot(train_i.T, train_i)\n","\n","        S = n_ij / (n_ij + lambda_) * RHO\n","        np.fill_diagonal(S, -1)    \n","\n","        R_u = {u: data[u, :].nonzero()[0] for u in range(len(data))}\n","        S_k = {i: np.argsort(S[i, :])[-config.K:] for i in range(len(S))}\n","        neighbor.append((R_u, S_k))\n","    \n","    return neighbor\n","\n","(R_u, S_k_r), (N_u, S_k_n) = get_neighbor(train, train_imp)\n","\n","dd = []\n","for u in range(train.shape[0]):\n","    for i in range(train.shape[1]):\n","        if train[u, i] != 0:\n","            dd.append(len(np.intersect1d(R_u[u], S_k_r[i])))\n","\n","class SVD_integrated():    \n","    def __init__(self, train_exp, train_imp, test_exp, test_imp, dim_f, seed):\n","        self.R_tr = train_exp\n","        self.N_tr = train_imp\n","        self.R_tst = test_exp\n","        self.N_tst = test_imp\n","        \n","        self.dim_f = dim_f\n","        self.user_num = train_exp.shape[0]\n","        self.item_num = train_exp.shape[1]\n","\n","        np.random.seed(seed)\n","        self.P = np.random.standard_normal((self.user_num, dim_f))\n","        self.Q = np.random.standard_normal((self.item_num, dim_f))\n","        self.Y = np.random.standard_normal((self.item_num, dim_f))\n","        self.W = np.random.standard_normal((self.item_num, self.item_num))\n","        self.C = np.random.standard_normal((self.item_num, self.item_num))\n","\n","        self.B_u = np.random.standard_normal(self.user_num)\n","        self.B_i = np.random.standard_normal(self.item_num)\n","        self.mu = np.mean(train_exp[train_exp != 0])\n","        \n","        (self.R_u, self.S_k_r), (self.N_u, self.S_k_n) = get_neighbor(train_exp, train_imp)\n","\n","        self.loss_tr = defaultdict(float)\n","        self.loss_tst = defaultdict(float)\n","\n","    def fit(self):\n","        start = datetime.now() \n","        for epoch in range(config.epochs):\n","            # stochastic \n","            n = 0\n","            for u in range(self.user_num):\n","                N_u = np.where(self.N_tr[u, :] != 0)[0]\n","\n","                for i in range(self.item_num):\n","                    # rating 있는 애들만\n","                    if self.R_tr[u, i] != 0:                 \n","                        # p, q, bu, bi, y update\n","                        R_k_iu = np.intersect1d(self.R_u[u], self.S_k_r[i])\n","                        N_k_iu = np.intersect1d(self.N_u[u], self.S_k_n[i])\n","                        self.loss_tr[epoch] += self.gradient_descent(u, i, N_u, R_k_iu, N_k_iu)\n","                        n += 1\n","\n","            self.loss_tr[epoch] = np.sqrt(self.loss_tr[epoch]/n )\n","            self.loss_tst[epoch] = self.evaluate()\n","            if epoch % 10 == 0 or epoch == config.epochs-1:\n","                print(f'EPOCH {epoch+1} : TRAINING RMSE {self.loss_tr[epoch]:.5f}, VALID RMSE {self.loss_tst[epoch]:.5f}')\n","        end = datetime.now()\n","        print(f'Training takes time {end-start}')\n","        \n","    def scoring(self, u, i, N_u, R_k_iu, N_k_iu):\n","        p = self.P[u] + np.sum(self.Y[N_u], axis=0)/np.sqrt(len(N_u))\n","        MF_part = np.dot(p, self.Q[i].T)\n","        if len(R_k_iu) > 0:\n","            bias_loss = self.R_tr[u, R_k_iu] - (self.mu + self.B_u[u] + self.B_i[R_k_iu])\n","            NB_part_exp = np.dot(bias_loss, self.W[i, R_k_iu]) / np.sqrt(len(R_k_iu))\n","        else:\n","            bias_loss = 0\n","            NB_part_exp = 0\n","        if len(N_k_iu) > 0:\n","            NB_part_imp = np.sum(self.C[i, N_k_iu]) / np.sqrt(len(N_k_iu))\n","        else: \n","            NB_part_imp = 0\n","\n","        return self.mu + self.B_u[u] + self.B_i[i] + MF_part + NB_part_exp + NB_part_imp, bias_loss\n","    \n","    def gradient(self, u, i, N_u, R_k_iu, N_k_iu):\n","        score, bias_loss = self.scoring(u, i, N_u, R_k_iu, N_k_iu)\n","        loss =  self.R_tr[u, i] - score\n","        added = np.sum(self.Y[N_u], axis=0)/np.sqrt(len(N_u))\n","\n","        dp = loss*self.Q[i] - config.weight_decay*self.P[u]\n","        dq = loss*(self.P[u] + added) - config.weight_decay*self.Q[i]\n","        dbu = loss - config.weight_decay*self.B_u[u]\n","        dbi = loss - config.weight_decay*self.B_i[i]\n","        dyj = (loss*self.Q[i]/np.sqrt(len(N_u))).reshape(1, -1) - config.weight_decay*self.Y[N_u]\n","        dw = loss*(bias_loss)/np.sqrt(len(R_k_iu)) - config.weight_decay*self.W[i, R_k_iu]\n","        dc = loss/np.sqrt(len(N_k_iu)) - config.weight_decay*self.C[i, N_k_iu]\n","        return dp, dq, dbu, dbi, dyj, dw, dc, loss**2\n","\n","    def gradient_descent(self, u, i, N_u, R_k_iu, N_k_iu):\n","        dp, dq, dbu, dbi, dyj, dw, dc, loss = self.gradient(u, i, N_u, R_k_iu, N_k_iu)\n","        \n","        self.P[u] = self.P[u] + config.learning_rate * dp\n","        self.Q[i] = self.Q[i] + config.learning_rate * dq\n","        self.B_u[u] = self.B_u[u] + config.learning_rate * dbu\n","        self.B_i[i] = self.B_i[i] + config.learning_rate * dbi\n","        self.Y[N_u] = self.Y[N_u] + config.learning_rate * dyj\n","        if len(R_k_iu) > 0:\n","            self.W[i, R_k_iu] = self.W[i, R_k_iu] + config.learning_rate * dw\n","        if len(N_k_iu) > 0:\n","            self.C[i, N_k_iu] = self.C[i, N_k_iu] + config.learning_rate * dc\n","        return loss\n","\n","    def predict(self):\n","        pred = np.zeros((self.user_num, self.item_num))\n","        for u in range(self.user_num):\n","            N_u = np.where(self.N_tr[u, :] != 0)[0]\n","            for i in range(self.item_num):\n","                # rating 있는 애들만\n","                if self.R_tst[u, i] != 0:                 \n","                    # p, q, bu, bi, y update\n","                    R_k_iu = np.intersect1d(self.R_u[u], self.S_k_r[i])\n","                    N_k_iu = np.intersect1d(self.N_u[u], self.S_k_n[i])\n","                    pred[u, i], _ = self.scoring(u, i, N_u, R_k_iu, N_k_iu)\n","        return pred\n","\n","    def evaluate(self):\n","        pred = self.predict()\n","        rating_idx = self.R_tst != 0\n","        \n","        loss_pred = np.sqrt(np.mean(np.power((self.R_tst - pred)[rating_idx], 2)))\n","\n","        return loss_pred\n","\n","    def plot_loss(self):\n","        fig, ax = plt.subplots(1,1, figsize=(10, 5))\n","        \n","        ax.plot(list(self.loss_tr.keys()), list(self.loss_tr.values()), color='orange', label='train')\n","        ax.plot(list(self.loss_tst.keys()), list(self.loss_tst.values()), color='green', label='valid')\n","        plt.legend()\n","        plt.show()\n","\n","mf = SVD_integrated(train, train_imp, test, test_imp, config.dim_f, config.seed)\n","\n","mf.fit()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH 1 : TRAINING RMSE 2.63512, VALID RMSE 2.19120\n","EPOCH 11 : TRAINING RMSE 0.87367, VALID RMSE 1.22922\n","EPOCH 21 : TRAINING RMSE 0.76840, VALID RMSE 1.10704\n","EPOCH 31 : TRAINING RMSE 0.73078, VALID RMSE 1.05564\n","EPOCH 41 : TRAINING RMSE 0.71187, VALID RMSE 1.02779\n","EPOCH 51 : TRAINING RMSE 0.69984, VALID RMSE 1.01032\n","EPOCH 61 : TRAINING RMSE 0.69095, VALID RMSE 0.99826\n","EPOCH 71 : TRAINING RMSE 0.68390, VALID RMSE 0.98944\n","EPOCH 81 : TRAINING RMSE 0.67817, VALID RMSE 0.98274\n","EPOCH 91 : TRAINING RMSE 0.67348, VALID RMSE 0.97752\n","EPOCH 100 : TRAINING RMSE 0.66995, VALID RMSE 0.97374\n","Training takes time 0:45:33.598752\n"]}]},{"cell_type":"markdown","metadata":{"id":"vhB5APuTQNQI"},"source":["---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpKEP2FGQSKE","executionInfo":{"status":"ok","timestamp":1638116703733,"user_tz":-330,"elapsed":4043,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"063116a7-3c20-4668-b019-e7055a1b84c7"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-11-28 16:25:03\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","IPython   : 5.5.0\n","numpy     : 1.19.5\n","matplotlib: 3.2.2\n","pandas    : 1.1.5\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"-k-HLCIjQNQR"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Mxkw17lSQNQS"},"source":["**END**"]}]}