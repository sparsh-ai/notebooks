{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T799147 | Preprocessing of RetailRocket Dataset","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNtziKCc35U4qkAE7mGvd56"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylELIzcYizTO","executionInfo":{"status":"ok","timestamp":1637952090595,"user_tz":-330,"elapsed":53483,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ee9eabe9-0a27-4047-a750-6453870902df"},"source":["!wget -q --show-progress https://paddlerec.bj.bcebos.com/datasets/Retailrocket/Retailrocket.zip\n","!mkdir raw && mv Retailrocket.zip raw\n","!cd raw && unzip Retailrocket.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Retailrocket.zip    100%[===================>] 290.60M  12.2MB/s    in 41s     \n","Archive:  Retailrocket.zip\n","  inflating: category_tree.csv       \n","  inflating: events.csv              \n","  inflating: item_properties_part1.csv  \n","  inflating: item_properties_part2.csv  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_yN6ki9jbB9","executionInfo":{"status":"ok","timestamp":1637952169840,"user_tz":-330,"elapsed":54562,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5f5fd955-9348-42a5-a9b3-c05effce8db4"},"source":["!cd raw && sort -k1 -n -t, events.csv > sorted_events.csv\n","!cd raw && sort -k1 -n -t, item_properties_part1.csv > sorted_item_properties_part1.csv\n","!cd raw && sort -k1 -n -t, item_properties_part2.csv > sorted_item_properties_part2.csv"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tcmalloc: large alloc 6125469696 bytes == 0x564ad807c000 @  0x7f5e448541e7 0x564ad5ebc718 0x564ad5ebb5a1 0x7f5e44232bf7 0x564ad5ebc02a\n","tcmalloc: large alloc 8370978816 bytes == 0x5573fce8e000 @  0x7f77bb23e1e7 0x5573fb707718 0x5573fb7065a1 0x7f77bac1cbf7 0x5573fb70702a\n","tcmalloc: large alloc 7296679936 bytes == 0x55a73cafc000 @  0x7fd808f6c1e7 0x55a73b0be718 0x55a73b0bd5a1 0x7fd80894abf7 0x55a73b0be02a\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgoRi9KrokHz","executionInfo":{"status":"ok","timestamp":1637953477021,"user_tz":-330,"elapsed":656,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ce602878-1658-4927-e5e6-ebd1ee140c66"},"source":["!head raw/sorted_events.csv"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["timestamp,visitorid,event,itemid,transactionid\n","1431581976753,7,view,139394,\n","1431582162817,7,view,164941,\n","1431750039214,7,view,226353,\n","1433030513812,8,view,434230,\n","1436377007285,9,view,222422,\n","1437097556439,5,view,61396,\n","1438413035296,3,view,385090,\n","1438969904567,2,view,325215,\n","1438970013790,2,view,325215,\n"]}]},{"cell_type":"code","metadata":{"id":"c1A7yWSAosqK","executionInfo":{"status":"ok","timestamp":1637953494263,"user_tz":-330,"elapsed":432,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a2d6769f-daf6-41b9-eb6d-9544ccd80e38","colab":{"base_uri":"https://localhost:8080/"}},"source":["!head raw/sorted_item_properties_part1.csv"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["timestamp,itemid,property,value\n","1431226800000,1,available,1\n","1431226800000,1,categoryid,1114\n","1431226800000,2,categoryid,1305\n","1431226800000,3,available,0\n","1431226800000,6,available,1\n","1431226800000,6,categoryid,1091\n","1431831600000,0,available,0\n","1431831600000,1,available,0\n","1431831600000,4,available,0\n"]}]},{"cell_type":"code","metadata":{"id":"VXlmef5Xjq_A","executionInfo":{"status":"ok","timestamp":1637952606489,"user_tz":-330,"elapsed":443,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["import csv\n","import os\n","import json\n","import gzip\n","import math\n","from collections import deque\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-fVXR5akEuk","executionInfo":{"status":"ok","timestamp":1637952608590,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["# event fields\n","TIMESTAMP = 'timestamp'\n","PRESENTED_ITEMS = 'presentedItems'\n","EVENT_ITEM = 'clickedItem'\n","EVENT_TYPE = 'eventType'\n","EVENT_CONTEXT = 'context'\n","EVENT_USER_HASH = 'userHash'\n","EVENT_USER_ID = 'userId'\n","EVENT_SESSION_ID = 'sessionId'\n","\n","# item fields\n","ITEM_ID = 'id'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4u-6K6BlVKB","executionInfo":{"status":"ok","timestamp":1637953105485,"user_tz":-330,"elapsed":698,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["directory = '.'\n","directory_input = 'raw/'\n","input_path_events = directory_input + 'sorted_events.csv'\n","input_path_items = [\n","    directory_input + 'sorted_item_properties_part1.csv', directory_input + 'sorted_item_properties_part2.csv'\n","]\n","input_category_tree = directory_input + 'category_tree.csv'\n","\n","delimiter = ','\n","\n","datasets = 5\n","datasets_dir_prefix = './processed/data'\n","datasets_dirs = []\n","timestamp_first_event = 1430622004384\n","timestamp_last_event = 1442545187788\n","\n","\n","class RetailRocket:\n","    def __init__(self):\n","        self.items = dict()\n","        self.category_tree = dict()\n","        self.users_sessions = dict()\n","        self.next_session_id = 0\n","        self.items_in_datasets = dict()\n","        self.items_all_properties = set()\n","        self.items_mutable_properties = set()\n","        for i in range(datasets):\n","            self.items_in_datasets[i] = set()\n","\n","    def prepare_items(self):\n","        self._read_category_tree()\n","        for input_path in input_path_items:\n","            self._add_items_properties(input_path)\n","        self._find_immutable_properties()\n","\n","    def generate_events_file(self):\n","        rows = self._prepare_events()\n","        data = self._filter_events(rows)\n","        self._save_events_to_file(data)\n","\n","    def save_items_to_file(self):\n","        print('Saving all items...')\n","        with gzip.open(f'{datasets_dir_prefix}/items.jsonl.gz', 'wt') as f:\n","            for item in self.items.values():\n","                f.write(item.transform_into_jsonl_format())\n","                f.write('\\n')\n","\n","        print('Saving splited items...')\n","        for i in range(datasets):\n","            items_set = self.items_in_datasets[i]\n","            with gzip.open(f'{datasets_dir_prefix}-{i+1}/items.jsonl.gz', 'wt') as f:\n","                for item_id in items_set:\n","                    item_jsonl = self.items[item_id].transform_into_jsonl_format()\n","                    f.write(item_jsonl)\n","                    f.write('\\n')\n","\n","    def _prepare_events(self):\n","        rows = []\n","        with open(input_path_events) as input_file:\n","            csv_reader = csv.reader(input_file, delimiter=delimiter)\n","            next(csv_reader, None)\n","\n","            for line in csv_reader:\n","                event_jsonl = self._prepare_event_in_jsonl(line)\n","                if event_jsonl is not None:\n","                    ev_dict = json.loads(event_jsonl)\n","                    file_no = self.calculate_file_no(ev_dict['timestamp'])\n","                    row = [ev_dict['sessionId'], ev_dict['clickedItem'], ev_dict['timestamp'], event_jsonl, file_no]\n","                    rows.append(row)\n","        return rows\n","\n","    def _filter_events(self, rows):\n","        columns = ['session_id', 'item_id', 'timestamp', 'event_jsonl', 'file_no']\n","        return self._filter_data(pd.DataFrame(rows, columns=columns))\n","\n","    def _save_events_to_file(self, data):\n","        for i in range(datasets):\n","            d = f'{datasets_dir_prefix}-{i+1}'\n","            os.makedirs(d, exist_ok=True)\n","            datasets_dirs.append(d)\n","\n","        os.makedirs(datasets_dir_prefix, exist_ok=True)\n","        datasets_dirs.append(datasets_dir_prefix)\n","\n","        print('Saving all events dataset...')\n","        with gzip.open(f'{datasets_dir_prefix}/sessions.jsonl.gz', 'wt') as f:\n","            for _, row in data.iterrows():\n","                f.write(row['event_jsonl'] + '\\n')\n","\n","        print('Saving splited events datasets...')\n","        outputs = [gzip.open(f'{datasets_dir_prefix}-{i+1}/sessions.jsonl.gz', 'wt') for i in range(datasets)]\n","        for _, row in data.iterrows():\n","            if row['file_no'] < datasets:\n","                if row['item_id'] in self.items:\n","                    outputs[row['file_no']].write(row['event_jsonl'] + '\\n')\n","                    self.items_in_datasets[row['file_no']].add(row['item_id'])\n","                else:\n","                    print(f'Item id: {row.item_id} is clicked but not in items dataset')\n","        map(lambda f: f.close(), outputs)\n","\n","    def _add_items_properties(self, path):\n","        with open(path) as input_file:\n","            csv_reader = csv.reader(input_file, delimiter=delimiter)\n","            next(csv_reader, None)\n","            for line in csv_reader:\n","                self._add_item_property(line)\n","\n","    def _add_item_property(self, line):\n","        assert len(line) == 4\n","        timestamp = int(line[0])\n","        item_id = line[1]\n","        property_name = line[2]\n","        value = line[3].strip().split(' ')\n","        if len(value) == 1:  # single value, no array is neccessary\n","            value = value[0]\n","\n","        if item_id not in self.items.keys():\n","            self.items[item_id] = Item(item_id)\n","\n","        self.items[item_id].add_property(property_name, timestamp, value)\n","\n","        if property_name == \"categoryid\" and value in self.category_tree:\n","            category_path_ids = self._read_path_to_root(value)\n","            self.items[item_id].add_property(\"category_path_ids\", timestamp, category_path_ids)\n","\n","    def _read_path_to_root(self, leaf):\n","        current_node = leaf\n","        result = deque([current_node])\n","\n","        while self.category_tree[current_node] != current_node:\n","            current_node = self.category_tree[current_node]\n","            result.appendleft(current_node)\n","\n","        return result\n","\n","    def _read_category_tree(self):\n","        with open(input_category_tree) as input_file:\n","            csv_reader = csv.reader(input_file, delimiter=delimiter)\n","            next(csv_reader, None)\n","\n","            for line in csv_reader:\n","                if line[1] != \"\":\n","                    self.category_tree[int(line[0])] = int(line[1])\n","                else:  # when line describes root category\n","                    self.category_tree[int(line[0])] = int(line[0])\n","\n","    def _find_immutable_properties(self):\n","        for item_id, item in self.items.items():\n","            for k, v in item.properties.items():  # k = property name, v = list of tuples (timestamp, value)\n","                self.items_all_properties.add(k)\n","                if len(v) > 1:  # if for all timestamps there is the same value => not muttable\n","                    for el in v:\n","                        if el[1] != v[0][1]:\n","                            self.items_mutable_properties.add(k)\n","                            break\n","\n","        print(\n","            f'All items properties number: {len(self.items_all_properties)}, mutable: {len(self.items_mutable_properties)}'\n","        )\n","        for item_id, item in self.items.items():\n","            for k, v in item.properties.items():\n","                if k in self.items_mutable_properties:\n","                    item.mutable_properties[k] = v\n","                else:\n","                    item.immutable_properties[k] = v[0][1]  # take first value\n","\n","    @staticmethod\n","    def normalize_context(r):\n","        d = dict()\n","        attribs = []\n","        for k, values in r.items():\n","            if not isinstance(values, list):\n","                values = [values]\n","            for v in values:\n","                if v.startswith('n'):  # number\n","                    f = float(v[1:])\n","                    if math.isinf(f):\n","                        print(f'Infinity! Bad value for {k} : {v}. Skipping...')\n","                        continue\n","                    d[k] = f\n","                else:\n","                    attribs.append(f'{k}|{v}')\n","        d['properties'] = attribs\n","        return d\n","\n","    def _prepare_event_in_jsonl(self, line):\n","        def converter(o):\n","            if isinstance(o, datetime):\n","                return o.__str__()\n","\n","        timestamp = int(line[0])\n","        user_id = int(line[1])\n","        item_id = line[3]\n","\n","        if user_id not in self.users_sessions:\n","            self.users_sessions[user_id] = [timestamp, self.next_session_id]\n","            self.next_session_id += 1\n","        else:\n","            if timestamp - self.users_sessions[user_id][0] > 30 * 60 * 1000:  # 30 min * 60s * 1000ms\n","                self.users_sessions[user_id] = [timestamp, self.next_session_id]\n","                self.next_session_id += 1\n","            else:\n","                self.users_sessions[user_id][0] = timestamp  # update last activity in session\n","\n","        if item_id in self.items:\n","            data = {\n","               TIMESTAMP: timestamp,\n","               EVENT_USER_ID: user_id,\n","               EVENT_TYPE: line[2],\n","               EVENT_ITEM: item_id,\n","               EVENT_SESSION_ID: self.users_sessions[user_id][1]\n","            }\n","            context = self._prepare_context(item_id, timestamp)\n","            if len(context) > 0:\n","                data[EVENT_CONTEXT] = RetailRocket.normalize_context(context)\n","            return json.dumps(data, default=converter, separators=(',', ':'))\n","\n","    def _prepare_context(self, item_id, timestamp):\n","        context = {}\n","        for property, values in self.items[item_id].mutable_properties.items():\n","            ts, val = 0, 0\n","            for time, value in values:\n","                if timestamp >= time > ts:\n","                    ts = time\n","                    val = value\n","            if ts > 0:\n","                context[property] = val\n","        return context\n","\n","    @staticmethod\n","    def _filter_data(data):  # based on 130L session-rec/preprocessing/preprocess_retailrocket.py\n","\n","        session_lengths = data.groupby('session_id').size()\n","        data = data[np.in1d(data.session_id, session_lengths[session_lengths > 1].index)]\n","\n","        item_supports = data.groupby('item_id').size()\n","        data = data[np.in1d(data.item_id, item_supports[item_supports >= 5].index)]\n","\n","        session_lengths = data.groupby('session_id').size()\n","        data = data[np.in1d(data.session_id, session_lengths[session_lengths >= 2].index)]\n","\n","        return data\n","\n","    @staticmethod\n","    def calculate_file_no(ts):\n","        return int((ts - timestamp_first_event) / (1000 * 60 * 60 * 24 * 27))  # 1000ms * 60s * 60min * 24h * 27d\n","\n","\n","class Item:\n","    def __init__(self, id):\n","        self.id = str(id)\n","        self.properties = dict()  # all properties\n","        self.immutable_properties = dict()  # add to items.jsonl\n","        self.mutable_properties = dict()  # add to sessions.jsonl in context field\n","\n","    def add_property(self, property, timestamp, value):\n","        if property not in self.properties.keys():\n","            self.properties[property] = list()\n","        self.properties[property].append((timestamp, value))\n","\n","    def transform_into_jsonl_format(self):\n","        dt = {ITEM_ID: self.id}\n","        dt.update(RetailRocket.normalize_context(self.immutable_properties))\n","        return json.dumps(dt, separators=(',', ':'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFJnWWnplWVw","outputId":"97d166e0-5eb4-434c-884e-c52808f06adc"},"source":["items = RetailRocket()\n","items.prepare_items()\n","items.generate_events_file()\n","items.save_items_to_file()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 202 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 888 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 202 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 888 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 202 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 888 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 283 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n","Infinity! Bad value for 917 : nInfinity. Skipping...\n"]}]},{"cell_type":"code","metadata":{"id":"5tQ_wgIinOiz"},"source":[""],"execution_count":null,"outputs":[]}]}