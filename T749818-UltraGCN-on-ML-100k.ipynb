{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T749818 | UltraGCN on ML-100k","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNnOvxluQN4CDluW40rdzSK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2TRsPnfVTuGF"},"source":["# UltraGCN on ML-100k"]},{"cell_type":"markdown","metadata":{"id":"kDyGauIBgOO4"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"J6YVYq5ggptl"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"X49IEpJHiOSX","executionInfo":{"status":"ok","timestamp":1635783462857,"user_tz":-330,"elapsed":24781,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["from IPython import embed\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pickle\n","import numpy as np\n","import torch.utils.data as data\n","import scipy.sparse as sp\n","import os\n","import gc\n","import configparser\n","import time\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfBBansIXdbt","executionInfo":{"status":"ok","timestamp":1635784729121,"user_tz":-330,"elapsed":4376,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"1675cc6b-ac3a-4015-e26c-b8b1dd7bfb63"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -m -iv -u -t -d"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Last updated: 2021-11-01 16:38:45\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","IPython: 5.5.0\n","numpy  : 1.19.5\n","scipy  : 1.4.1\n","csv    : 1.0\n","torch  : 1.9.0+cu111\n","pandas : 1.1.5\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"LHdL4aitgrfK"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"zLp8oVaZgsEu","executionInfo":{"status":"ok","timestamp":1635783536872,"user_tz":-330,"elapsed":508,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class Args:\n","    embedding_dim = 64\n","    ii_neighbor_num = 10\n","    model_save_path = './ultragcn_movielens.pt'\n","    max_epoch = 50\n","    enable_tensorboard = True\n","    initial_weight = 1e-4\n","    dataset = 'movielens'\n","    train_file_path = './train_ml.txt'\n","    gpu = '0' #need to specify the avaliable gpu index. If gpu is not avaliable, we will use cpu.\n","    lr = 1e-3\n","    batch_size = 128\n","    early_stop_epoch = 15\n","    w1 = 1e-4\n","    w2 = 1\n","    w3 = 1\n","    w4 = 1e-4\n","    negative_num = 50\n","    negative_weight = 50\n","    gamma = 1e-4 #weight of l2 normalization\n","    lambda_ = 2.75 #weight of L_I\n","    sampling_sift_pos = False #whether to sift the pos item when doing negative sampling\n","    test_batch_size = 128 #can be customized to your gpu size\n","    topk = 20\n","    test_file_path = './test_ml.txt'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFPE3_IQi7wb","executionInfo":{"status":"ok","timestamp":1635783539114,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["args = Args()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzf5uleni67z","executionInfo":{"status":"ok","timestamp":1635783539118,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["args.device = torch.device('cuda:'+ args.gpu if torch.cuda.is_available() else \"cpu\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCtXwV2lguvx"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"JgiLkumHEZM-"},"source":["Amazon-books"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0h_a7Onwgx4d","executionInfo":{"status":"ok","timestamp":1635783469430,"user_tz":-330,"elapsed":6603,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0a2aae3e-29e0-43fa-bf58-3270dc90adbd"},"source":["!rm -r *.txt\n","\n","!wget -q --show-progress https://github.com/xue-pai/UltraGCN/raw/main/data/amazon/train.txt\n","!wget -q --show-progress https://github.com/xue-pai/UltraGCN/raw/main/data/amazon/test.txt\n","!wget -q --show-progress https://github.com/xue-pai/UltraGCN/raw/main/data/amazon/user_list.txt\n","!wget -q --show-progress https://github.com/xue-pai/UltraGCN/raw/main/data/amazon/item_list.txt\n","\n","!wc -l train.txt\n","!wc -l test.txt\n","!wc -l user_list.txt\n","!wc -l item_list.txt\n","\n","!head user_list.txt"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '*.txt': No such file or directory\n","train.txt           100%[===================>]  13.47M  --.-KB/s    in 0.08s   \n","test.txt            100%[===================>]   3.67M  --.-KB/s    in 0.04s   \n","user_list.txt       100%[===================>]   1.03M  --.-KB/s    in 0.02s   \n","item_list.txt       100%[===================>]   1.47M  --.-KB/s    in 0.03s   \n","52643 train.txt\n","52643 test.txt\n","52644 user_list.txt\n","91600 item_list.txt\n","org_id remap_id\n","A3GT2VY34AXBOJ 0\n","AX54G5AL870Q8 1\n","AWEOR1WZSMBEZ 2\n","A2UYWE97KME0M 3\n","A2KKXV0HG92CJ8 4\n","AYKYFFCC49HVT 5\n","AA3YR5Q1K4KLC 6\n","A3GJZT8C84V1NP 7\n","A15NS9ERV7LT7A 8\n"]}]},{"cell_type":"markdown","metadata":{"id":"EYZMnfFTJmeR"},"source":["Movielens"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0G_cc6AMPAIZ","executionInfo":{"status":"ok","timestamp":1635783495152,"user_tz":-330,"elapsed":22491,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"baa9381a-d855-4cfa-b147-50648abf5783"},"source":["!pip install -q git+https://github.com/sparsh-ai/recochef\n","!wget -q --show-progress http://files.grouplens.org/datasets/movielens/ml-100k.zip\n","!unzip -qq ml-100k.zip\n","\n","import os\n","import csv \n","import pandas as pd\n","from pathlib import Path\n","from recochef.preprocessing.split import chrono_split\n","\n","df = pd.read_csv('ml-100k/u.data', sep='\\t', header=None, names=['USERID','ITEMID','RATING','TIMESTAMP'])\n","df_train, df_test = chrono_split(df, ratio=0.8)\n","\n","def preprocess(data):\n","  data = data.copy()\n","  data = data.sort_values(by=['USERID','TIMESTAMP'])\n","  data['USERID'] = data['USERID'] - 1\n","  data['ITEMID'] = data['ITEMID'] - 1\n","  data.drop(['TIMESTAMP','RATING'], axis=1, inplace=True)\n","  data = data.groupby('USERID')['ITEMID'].apply(list).reset_index(name='ITEMID')\n","  return data\n","\n","def store(data, target_file='./data/movielens/train.txt'):\n","  Path(target_file).parent.mkdir(parents=True, exist_ok=True)\n","  with open(target_file, 'w+') as f:\n","    writer = csv.writer(f, delimiter=' ')\n","    for USERID, row in zip(data.USERID.values,data.ITEMID.values):\n","      row = [USERID] + row\n","      writer.writerow(row)\n","\n","store(preprocess(df_train), 'train_ml.txt')\n","store(preprocess(df_test), 'test_ml.txt')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 4.3 MB 12.6 MB/s \n","\u001b[?25h  Building wheel for recochef (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","ml-100k.zip         100%[===================>]   4.70M  2.64MB/s    in 1.8s    \n"]}]},{"cell_type":"code","metadata":{"id":"RaMBQdzmncNA","executionInfo":{"status":"ok","timestamp":1635783540658,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def load_data(train_file, test_file):\n","    trainUniqueUsers, trainItem, trainUser = [], [], []\n","    testUniqueUsers, testItem, testUser = [], [], []\n","    n_user, m_item = 0, 0\n","    trainDataSize, testDataSize = 0, 0\n","    with open(train_file, 'r') as f:\n","        for l in f.readlines():\n","            if len(l) > 0:\n","                l = l.strip('\\n').split(' ')\n","                items = [int(i) for i in l[1:]]\n","                uid = int(l[0])\n","                trainUniqueUsers.append(uid)\n","                trainUser.extend([uid] * len(items))\n","                trainItem.extend(items)\n","                m_item = max(m_item, max(items))\n","                n_user = max(n_user, uid)\n","                trainDataSize += len(items)\n","    trainUniqueUsers = np.array(trainUniqueUsers)\n","    trainUser = np.array(trainUser)\n","    trainItem = np.array(trainItem)\n","\n","    with open(test_file) as f:\n","        for l in f.readlines():\n","            if len(l) > 0:\n","                l = l.strip('\\n').split(' ')\n","                try:\n","                    items = [int(i) for i in l[1:]]\n","                except:\n","                    items = []\n","                uid = int(l[0])\n","                testUniqueUsers.append(uid)\n","                testUser.extend([uid] * len(items))\n","                testItem.extend(items)\n","                try:\n","                    m_item = max(m_item, max(items))\n","                except:\n","                    m_item = m_item\n","                n_user = max(n_user, uid)\n","                testDataSize += len(items)\n","\n","\n","    train_data = []\n","    test_data = []\n","\n","    n_user += 1\n","    m_item += 1\n","\n","    for i in range(len(trainUser)):\n","        train_data.append([trainUser[i], trainItem[i]])\n","    for i in range(len(testUser)):\n","        test_data.append([testUser[i], testItem[i]])\n","    train_mat = sp.dok_matrix((n_user, m_item), dtype=np.float32)\n","\n","    for x in train_data:\n","        train_mat[x[0], x[1]] = 1.0\n","\n","\n","    # construct degree matrix for graphmf\n","\n","    items_D = np.sum(train_mat, axis = 0).reshape(-1)\n","    users_D = np.sum(train_mat, axis = 1).reshape(-1)\n","\n","    beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n","    beta_iD = (1 / np.sqrt(items_D + 1)).reshape(1, -1)\n","\n","    constraint_mat = torch.from_numpy(beta_uD.dot(beta_iD))  # n_user * m_item\n","    constraint_mat = constraint_mat.flatten()\n","\n","    return train_data, test_data, train_mat, n_user, m_item, constraint_mat"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-HbT9mZhsdN","executionInfo":{"status":"ok","timestamp":1635783543652,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def get_ii_constraint_mat(train_mat, num_neighbors, ii_diagonal_zero = False):\n","    \n","    print('Computing \\\\Omega for the item-item graph... ')\n","    A = train_mat.T.dot(train_mat)\t# I * I\n","    n_items = A.shape[0]\n","    res_mat = torch.zeros((n_items, num_neighbors))\n","    res_sim_mat = torch.zeros((n_items, num_neighbors))\n","    if ii_diagonal_zero:\n","        A[range(n_items), range(n_items)] = 0\n","    items_D = np.sum(A, axis = 0).reshape(-1)\n","    users_D = np.sum(A, axis = 1).reshape(-1)\n","\n","    beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n","    beta_iD = (1 / np.sqrt(items_D + 1)).reshape(1, -1)\n","    all_ii_constraint_mat = torch.from_numpy(beta_uD.dot(beta_iD))\n","    \n","    for i in range(n_items):\n","        row = all_ii_constraint_mat[i] * torch.from_numpy(A.getrow(i).toarray()[0])\n","        row_sims, row_idxs = torch.topk(row, num_neighbors)\n","        res_mat[i] = row_idxs\n","        res_sim_mat[i] = row_sims\n","        if i % 15000 == 0:\n","            print('i-i constraint matrix {} ok'.format(i))\n","\n","    print('Computation \\\\Omega OK!')\n","    return res_mat.long(), res_sim_mat.float()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXGAOOtunj4H","executionInfo":{"status":"ok","timestamp":1635783543653,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["'''\n","Useful functions\n","'''\n","\n","def pload(path):\n","\twith open(path, 'rb') as f:\n","\t\tres = pickle.load(f)\n","\tprint('load path = {} object'.format(path))\n","\treturn res\n","\n","def pstore(x, path):\n","\twith open(path, 'wb') as f:\n","\t\tpickle.dump(x, f)\n","\tprint('store object in path = {} ok'.format(path))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHhb4HZ3jqSw","executionInfo":{"status":"ok","timestamp":1635783543651,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def data_param_prepare(args):\n","\n","    # dataset processing\n","    train_data, test_data, train_mat, user_num, item_num, constraint_mat = load_data(args.train_file_path, args.test_file_path)\n","    train_loader = data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=2)\n","    test_loader = data.DataLoader(list(range(user_num)), batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n","\n","    args.user_num = user_num\n","    args.item_num = item_num\n","\n","    # mask matrix for testing to accelarate testing speed\n","    mask = torch.zeros(user_num, item_num)\n","    interacted_items = [[] for _ in range(user_num)]\n","    for (u, i) in train_data:\n","        mask[u][i] = -np.inf\n","        interacted_items[u].append(i)\n","\n","    # test user-item interaction, which is ground truth\n","    test_ground_truth_list = [[] for _ in range(user_num)]\n","    for (u, i) in test_data:\n","        test_ground_truth_list[u].append(i)\n","\n","    \n","    # Compute \\Omega to extend UltraGCN to the item-item occurrence graph\n","    ii_cons_mat_path = './' + args.dataset + '_ii_constraint_mat'\n","    ii_neigh_mat_path = './' + args.dataset + '_ii_neighbor_mat'\n","    \n","    if os.path.exists(ii_cons_mat_path):\n","        ii_constraint_mat = pload(ii_cons_mat_path)\n","        ii_neighbor_mat = pload(ii_neigh_mat_path)\n","    else:\n","        ii_neighbor_mat, ii_constraint_mat = get_ii_constraint_mat(train_mat, args.ii_neighbor_num)\n","        pstore(ii_neighbor_mat, ii_neigh_mat_path)\n","        pstore(ii_constraint_mat, ii_cons_mat_path)\n","\n","    return args, constraint_mat, ii_constraint_mat, ii_neighbor_mat, train_loader, test_loader, mask, test_ground_truth_list, interacted_items"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNnbegiCYEpU"},"source":["## Negative Sampling"]},{"cell_type":"code","metadata":{"id":"sp1hjePBnoC3","executionInfo":{"status":"ok","timestamp":1635783543654,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def Sampling(pos_train_data, item_num, neg_ratio, interacted_items, sampling_sift_pos):\n","\tneg_candidates = np.arange(item_num)\n","\n","\tif sampling_sift_pos:\n","\t\tneg_items = []\n","\t\tfor u in pos_train_data[0]:\n","\t\t\tprobs = np.ones(item_num)\n","\t\t\tprobs[interacted_items[u]] = 0\n","\t\t\tprobs /= np.sum(probs)\n","\n","\t\t\tu_neg_items = np.random.choice(neg_candidates, size = neg_ratio, p = probs, replace = True).reshape(1, -1)\n","\t\n","\t\t\tneg_items.append(u_neg_items)\n","\n","\t\tneg_items = np.concatenate(neg_items, axis = 0) \n","\telse:\n","\t\tneg_items = np.random.choice(neg_candidates, (len(pos_train_data[0]), neg_ratio), replace = True)\n","\t\n","\tneg_items = torch.from_numpy(neg_items)\n","\t\n","\treturn pos_train_data[0], pos_train_data[1], neg_items\t# users, pos_items, neg_items"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQgcbO1AoARX"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"ujj7eZoihU8x"},"source":["$ L = -(w1 + w2*\\beta) * log(sigmoid(e_u e_i)) - \\sum_{N^-} (w3 + w4*\\beta) * log(sigmoid(e_u e_i')) $"]},{"cell_type":"code","metadata":{"id":"tSuNY4EOns8r","executionInfo":{"status":"ok","timestamp":1635783544379,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class UltraGCN(nn.Module):\n","    def __init__(self, args, constraint_mat, ii_constraint_mat, ii_neighbor_mat):\n","        super(UltraGCN, self).__init__()\n","        self.user_num = args.user_num\n","        self.item_num = args.item_num\n","        self.embedding_dim = args.embedding_dim\n","        self.w1 = args.w1\n","        self.w2 = args.w2\n","        self.w3 = args.w3\n","        self.w4 = args.w4\n","\n","        self.negative_weight = args.negative_weight\n","        self.gamma = args.gamma\n","        self.lambda_ = args.lambda_\n","\n","        self.user_embeds = nn.Embedding(self.user_num, self.embedding_dim)\n","        self.item_embeds = nn.Embedding(self.item_num, self.embedding_dim)\n","\n","        self.constraint_mat = constraint_mat\n","        self.ii_constraint_mat = ii_constraint_mat\n","        self.ii_neighbor_mat = ii_neighbor_mat\n","\n","        self.initial_weight = args.initial_weight\n","\n","        self.initial_weights()\n","\n","    def initial_weights(self):\n","        nn.init.normal_(self.user_embeds.weight, std=self.initial_weight)\n","        nn.init.normal_(self.item_embeds.weight, std=self.initial_weight)\n","\n","\n","    def get_omegas(self, users, pos_items, neg_items):\n","        device = self.get_device()\n","        if self.w2 > 0:\n","            pos_weight = self.constraint_mat[users * self.item_num + pos_items].to(device)\n","            pow_weight = self.w1 + self.w2 * pos_weight\n","        else:\n","            pos_weight = self.w1 * torch.ones(len(pos_items)).to(device)\n","        \n","        users = (users * self.item_num).unsqueeze(0)\n","\n","        if self.w4 > 0:\n","            neg_weight = self.constraint_mat[torch.cat([users] * neg_items.size(1)).transpose(1, 0) + neg_items].flatten().to(device)\n","            neg_weight = self.w3 + self.w4 * neg_weight\n","        else:\n","            neg_weight = self.w3 * torch.ones(neg_items.size(0) * neg_items.size(1)).to(device)\n","\n","\n","        weight = torch.cat((pow_weight, neg_weight))\n","        return weight\n","\n","\n","    def cal_loss_L(self, users, pos_items, neg_items, omega_weight):\n","        device = self.get_device()\n","        user_embeds = self.user_embeds(users)\n","        pos_embeds = self.item_embeds(pos_items)\n","        neg_embeds = self.item_embeds(neg_items)\n","      \n","        pos_scores = (user_embeds * pos_embeds).sum(dim=-1) # batch_size\n","        user_embeds = user_embeds.unsqueeze(1)\n","        neg_scores = (user_embeds * neg_embeds).sum(dim=-1) # batch_size * negative_num\n","\n","        neg_labels = torch.zeros(neg_scores.size()).to(device)\n","        neg_loss = F.binary_cross_entropy_with_logits(neg_scores, neg_labels, weight = omega_weight[len(pos_scores):].view(neg_scores.size()), reduction='none').mean(dim = -1)\n","        \n","        pos_labels = torch.ones(pos_scores.size()).to(device)\n","        pos_loss = F.binary_cross_entropy_with_logits(pos_scores, pos_labels, weight = omega_weight[:len(pos_scores)], reduction='none')\n","\n","        loss = pos_loss + neg_loss * self.negative_weight\n","      \n","        return loss.sum()\n","\n","\n","    def cal_loss_I(self, users, pos_items):\n","        device = self.get_device()\n","        neighbor_embeds = self.item_embeds(self.ii_neighbor_mat[pos_items].to(device))    # len(pos_items) * num_neighbors * dim\n","        sim_scores = self.ii_constraint_mat[pos_items].to(device)     # len(pos_items) * num_neighbors\n","        user_embeds = self.user_embeds(users).unsqueeze(1)\n","        \n","        loss = -sim_scores * (user_embeds * neighbor_embeds).sum(dim=-1).sigmoid().log()\n","      \n","        # loss = loss.sum(-1)\n","        return loss.sum()\n","\n","    def norm_loss(self):\n","        loss = 0.0\n","        for parameter in self.parameters():\n","            loss += torch.sum(parameter ** 2)\n","        return loss / 2\n","\n","\n","    def forward(self, users, pos_items, neg_items):\n","        omega_weight = self.get_omegas(users, pos_items, neg_items)\n","        \n","        loss = self.cal_loss_L(users, pos_items, neg_items, omega_weight)\n","        loss += self.gamma * self.norm_loss()\n","        loss += self.lambda_ * self.cal_loss_I(users, pos_items)\n","        return loss\n","\n","\n","    def test_foward(self, users):\n","        items = torch.arange(self.item_num).to(users.device)\n","        user_embeds = self.user_embeds(users)\n","        item_embeds = self.item_embeds(items)\n","         \n","        return user_embeds.mm(item_embeds.t())\n","\n","\n","    def get_device(self):\n","        return self.user_embeds.weight.device"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JS_x_QQkoFnt"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"-xCwsQvXn-mf","executionInfo":{"status":"ok","timestamp":1635783545214,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def train(model, optimizer, train_loader, test_loader, mask, test_ground_truth_list, interacted_items, args):\n","    device = args.device\n","    best_epoch, best_recall, best_ndcg = 0, 0, 0\n","    early_stop_count = 0\n","    early_stop = False\n","\n","    batches = len(train_loader.dataset) // args.batch_size\n","    if len(train_loader.dataset) % args.batch_size != 0:\n","        batches += 1\n","    print('Total training batches = {}'.format(batches))\n","    \n","    if args.enable_tensorboard:\n","        writer = SummaryWriter()\n","    \n","\n","    for epoch in range(args.max_epoch):\n","        model.train() \n","        start_time = time.time()\n","\n","        for batch, x in enumerate(train_loader): # x: tensor:[users, pos_items]\n","            users, pos_items, neg_items = Sampling(x, args.item_num, args.negative_num, interacted_items, args.sampling_sift_pos)\n","            users = users.to(device)\n","            pos_items = pos_items.to(device)\n","            neg_items = neg_items.to(device)\n","\n","            model.zero_grad()\n","            loss = model(users, pos_items, neg_items)\n","            if args.enable_tensorboard:\n","                writer.add_scalar(\"Loss/train_batch\", loss, batches * epoch + batch)\n","            loss.backward()\n","            optimizer.step()\n","        \n","        train_time = time.strftime(\"%H: %M: %S\", time.gmtime(time.time() - start_time))\n","        if args.enable_tensorboard:\n","            writer.add_scalar(\"Loss/train_epoch\", loss, epoch)\n","\n","        need_test = True\n","        if epoch < 50 and epoch % 5 != 0:\n","            need_test = False\n","            \n","        if need_test:\n","            start_time = time.time()\n","            F1_score, Precision, Recall, NDCG = test(model, test_loader, test_ground_truth_list, mask, args.topk, args.user_num)\n","            if args.enable_tensorboard:\n","                writer.add_scalar('Results/recall@20', Recall, epoch)\n","                writer.add_scalar('Results/ndcg@20', NDCG, epoch)\n","            test_time = time.strftime(\"%H: %M: %S\", time.gmtime(time.time() - start_time))\n","            \n","            print('The time for epoch {} is: train time = {}, test time = {}'.format(epoch, train_time, test_time))\n","            print(\"Loss = {:.5f}, F1-score: {:5f} \\t Precision: {:.5f}\\t Recall: {:.5f}\\tNDCG: {:.5f}\".format(loss.item(), F1_score, Precision, Recall, NDCG))\n","\n","            if Recall > best_recall:\n","                best_recall, best_ndcg, best_epoch = Recall, NDCG, epoch\n","                early_stop_count = 0\n","                torch.save(model.state_dict(), args.model_save_path)\n","\n","            else:\n","                early_stop_count += 1\n","                if early_stop_count == args.early_stop_epoch:\n","                    early_stop = True\n","        \n","        if early_stop:\n","            print('##########################################')\n","            print('Early stop is triggered at {} epochs.'.format(epoch))\n","            print('Results:')\n","            print('best epoch = {}, best recall = {}, best ndcg = {}'.format(best_epoch, best_recall, best_ndcg))\n","            print('The best model is saved at {}'.format(args.model_save_path))\n","            break\n","\n","    writer.flush()\n","\n","    print('Training end!')"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EMPyQ8A4pGX6"},"source":["## Test and Metrics"]},{"cell_type":"code","metadata":{"id":"nq-_pk2ro-_S","executionInfo":{"status":"ok","timestamp":1635783546716,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def hit(gt_item, pred_items):\n","\tif gt_item in pred_items:\n","\t\treturn 1\n","\treturn 0\n","\n","\n","def ndcg(gt_item, pred_items):\n","\tif gt_item in pred_items:\n","\t\tindex = pred_items.index(gt_item)\n","\t\treturn np.reciprocal(np.log2(index+2))\n","\treturn 0\n","\n","\n","def RecallPrecision_ATk(test_data, r, k):\n","\t\"\"\"\n","    test_data should be a list? cause users may have different amount of pos items. shape (test_batch, k)\n","    pred_data : shape (test_batch, k) NOTE: pred_data should be pre-sorted\n","    k : top-k\n","    \"\"\"\n","\tright_pred = r[:, :k].sum(1)\n","\tprecis_n = k\n","\t\n","\trecall_n = np.array([len(test_data[i]) for i in range(len(test_data))])\n","\trecall_n = np.where(recall_n != 0, recall_n, 1)\n","\trecall = np.sum(right_pred / recall_n)\n","\tprecis = np.sum(right_pred) / precis_n\n","\treturn {'recall': recall, 'precision': precis}\n","\n","\n","def MRRatK_r(r, k):\n","\t\"\"\"\n","    Mean Reciprocal Rank\n","    \"\"\"\n","\tpred_data = r[:, :k]\n","\tscores = np.log2(1. / np.arange(1, k + 1))\n","\tpred_data = pred_data / scores\n","\tpred_data = pred_data.sum(1)\n","\treturn np.sum(pred_data)\n","\n","\n","def NDCGatK_r(test_data, r, k):\n","\t\"\"\"\n","    Normalized Discounted Cumulative Gain\n","    rel_i = 1 or 0, so 2^{rel_i} - 1 = 1 or 0\n","    \"\"\"\n","\tassert len(r) == len(test_data)\n","\tpred_data = r[:, :k]\n","\n","\ttest_matrix = np.zeros((len(pred_data), k))\n","\tfor i, items in enumerate(test_data):\n","\t\tlength = k if k <= len(items) else len(items)\n","\t\ttest_matrix[i, :length] = 1\n","\tmax_r = test_matrix\n","\tidcg = np.sum(max_r * 1. / np.log2(np.arange(2, k + 2)), axis=1)\n","\tdcg = pred_data * (1. / np.log2(np.arange(2, k + 2)))\n","\tdcg = np.sum(dcg, axis=1)\n","\tidcg[idcg == 0.] = 1.\n","\tndcg = dcg / idcg\n","\tndcg[np.isnan(ndcg)] = 0.\n","\treturn np.sum(ndcg)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"5H3IL1K6pLvJ","executionInfo":{"status":"ok","timestamp":1635783547242,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def test_one_batch(X, k):\n","    sorted_items = X[0].numpy()\n","    groundTrue = X[1]\n","    r = getLabel(groundTrue, sorted_items)\n","    ret = RecallPrecision_ATk(groundTrue, r, k)\n","    return ret['precision'], ret['recall'], NDCGatK_r(groundTrue,r,k)\n","\n","def getLabel(test_data, pred_data):\n","    r = []\n","    for i in range(len(test_data)):\n","        groundTrue = test_data[i]\n","        predictTopK = pred_data[i]\n","        pred = list(map(lambda x: x in groundTrue, predictTopK))\n","        pred = np.array(pred).astype(\"float\")\n","        r.append(pred)\n","    return np.array(r).astype('float')\n","\n","\n","def test(model, test_loader, test_ground_truth_list, mask, topk, n_user):\n","    users_list = []\n","    rating_list = []\n","    groundTrue_list = []\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for idx, batch_users in enumerate(test_loader):\n","            \n","            batch_users = batch_users.to(model.get_device())\n","            rating = model.test_foward(batch_users) \n","            rating = rating.cpu()\n","            rating += mask[batch_users]\n","            \n","            _, rating_K = torch.topk(rating, k=topk)\n","            rating_list.append(rating_K)\n","\n","            groundTrue_list.append([test_ground_truth_list[u] for u in batch_users])\n","\n","    X = zip(rating_list, groundTrue_list)\n","    Recall, Precision, NDCG = 0, 0, 0\n","\n","    for i, x in enumerate(X):\n","        precision, recall, ndcg = test_one_batch(x, topk)\n","        Recall += recall\n","        Precision += precision\n","        NDCG += ndcg\n","        \n","\n","    Precision /= n_user\n","    Recall /= n_user\n","    NDCG /= n_user\n","    F1_score = 2 * (Precision * Recall) / (Precision + Recall)\n","\n","    return F1_score, Precision, Recall, NDCG"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crj5MU85pOjY","executionInfo":{"status":"ok","timestamp":1635783811899,"user_tz":-330,"elapsed":262501,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"502cd752-1bba-4418-8be6-2dfd6e863955"},"source":["if __name__ == \"__main__\":\n","\n","    print('###################### UltraGCN ######################')\n","\n","    print('1. Loading Configuration...')\n","    args, constraint_mat, ii_constraint_mat, ii_neighbor_mat, train_loader, test_loader, mask, test_ground_truth_list, interacted_items = data_param_prepare(args)\n","    \n","    print('Load Configuration OK, show them below')\n","    print('Configuration:')\n","    print(args)\n","\n","    ultragcn = UltraGCN(args, constraint_mat, ii_constraint_mat, ii_neighbor_mat)\n","    ultragcn = ultragcn.to(args.device)\n","    optimizer = torch.optim.Adam(ultragcn.parameters(), lr=args.lr)\n","\n","    train(ultragcn, optimizer, train_loader, test_loader, mask, test_ground_truth_list, interacted_items, args)\n","    print('END')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["###################### UltraGCN ######################\n","1. Loading Configuration...\n","Computing \\Omega for the item-item graph... \n","i-i constraint matrix 0 ok\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in true_divide\n","  del sys.path[0]\n"]},{"output_type":"stream","name":"stdout","text":["Computation \\Omega OK!\n","store object in path = ./movielens_ii_neighbor_mat ok\n","store object in path = ./movielens_ii_constraint_mat ok\n","Load Configuration OK, show them below\n","Configuration:\n","<__main__.Args object at 0x7fd31637f790>\n","Total training batches = 625\n","The time for epoch 0 is: train time = 00: 00: 09, test time = 00: 00: 00\n","Loss = 156.07614, F1-score: 0.093775 \t Precision: 0.08749\t Recall: 0.10104\tNDCG: 0.12132\n","The time for epoch 5 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 78.18020, F1-score: 0.092280 \t Precision: 0.08515\t Recall: 0.10071\tNDCG: 0.11994\n","The time for epoch 10 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 81.38260, F1-score: 0.092844 \t Precision: 0.08568\t Recall: 0.10131\tNDCG: 0.11858\n","The time for epoch 15 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 79.72414, F1-score: 0.119181 \t Precision: 0.10530\t Recall: 0.13727\tNDCG: 0.15428\n","The time for epoch 20 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 74.15086, F1-score: 0.136667 \t Precision: 0.11898\t Recall: 0.16053\tNDCG: 0.17487\n","The time for epoch 25 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 71.73530, F1-score: 0.144144 \t Precision: 0.12487\t Recall: 0.17046\tNDCG: 0.18266\n","The time for epoch 30 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 73.49659, F1-score: 0.149085 \t Precision: 0.12831\t Recall: 0.17788\tNDCG: 0.18897\n","The time for epoch 35 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 74.82909, F1-score: 0.152046 \t Precision: 0.13086\t Recall: 0.18142\tNDCG: 0.19366\n","The time for epoch 40 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 72.18040, F1-score: 0.154525 \t Precision: 0.13181\t Recall: 0.18669\tNDCG: 0.19500\n","The time for epoch 45 is: train time = 00: 00: 04, test time = 00: 00: 00\n","Loss = 74.24551, F1-score: 0.153762 \t Precision: 0.13155\t Recall: 0.18500\tNDCG: 0.19499\n","Training end!\n","END\n"]}]}]}