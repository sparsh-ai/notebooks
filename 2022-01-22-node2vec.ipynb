{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-22-node2vec.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T186367%20%7C%20Node2vec%20from%20scratch.ipynb","timestamp":1644661727184}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOUs5jKW71hk4Qc+6X6wYNu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ArIg70Fv6l4b"},"source":["# Node2vec from scratch"]},{"cell_type":"markdown","metadata":{"id":"r3oqLj4JR29b"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"InamF9NZ6Mr-"},"source":["import os\n","import random\n","from collections import defaultdict\n","\n","import gensim\n","import networkx as nx\n","import numpy as np\n","import pkg_resources\n","from joblib import Parallel, delayed\n","from tqdm.auto import tqdm\n","\n","from abc import ABC, abstractmethod\n","from functools import reduce\n","from itertools import combinations_with_replacement\n","\n","from gensim.models import KeyedVectors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ysscohBR4Qv"},"source":["## Random walks"]},{"cell_type":"code","metadata":{"id":"TkKUFZJa6Moy"},"source":["def parallel_generate_walks(d_graph: dict, global_walk_length: int, num_walks: int, cpu_num: int,\n","                            sampling_strategy: dict = None, num_walks_key: str = None, walk_length_key: str = None,\n","                            neighbors_key: str = None, probabilities_key: str = None, first_travel_key: str = None,\n","                            quiet: bool = False) -> list:\n","    \"\"\"\n","    Generates the random walks which will be used as the skip-gram input.\n","    :return: List of walks. Each walk is a list of nodes.\n","    \"\"\"\n","\n","    walks = list()\n","\n","    if not quiet:\n","        pbar = tqdm(total=num_walks, desc='Generating walks (CPU: {})'.format(cpu_num))\n","\n","    for n_walk in range(num_walks):\n","\n","        # Update progress bar\n","        if not quiet:\n","            pbar.update(1)\n","\n","        # Shuffle the nodes\n","        shuffled_nodes = list(d_graph.keys())\n","        random.shuffle(shuffled_nodes)\n","\n","        # Start a random walk from every node\n","        for source in shuffled_nodes:\n","\n","            # Skip nodes with specific num_walks\n","            if source in sampling_strategy and \\\n","                    num_walks_key in sampling_strategy[source] and \\\n","                    sampling_strategy[source][num_walks_key] <= n_walk:\n","                continue\n","\n","            # Start walk\n","            walk = [source]\n","\n","            # Calculate walk length\n","            if source in sampling_strategy:\n","                walk_length = sampling_strategy[source].get(walk_length_key, global_walk_length)\n","            else:\n","                walk_length = global_walk_length\n","\n","            # Perform walk\n","            while len(walk) < walk_length:\n","\n","                walk_options = d_graph[walk[-1]].get(neighbors_key, None)\n","\n","                # Skip dead end nodes\n","                if not walk_options:\n","                    break\n","\n","                if len(walk) == 1:  # For the first step\n","                    probabilities = d_graph[walk[-1]][first_travel_key]\n","                    walk_to = np.random.choice(walk_options, size=1, p=probabilities)[0]\n","                else:\n","                    probabilities = d_graph[walk[-1]][probabilities_key][walk[-2]]\n","                    walk_to = np.random.choice(walk_options, size=1, p=probabilities)[0]\n","\n","                walk.append(walk_to)\n","\n","            walk = list(map(str, walk))  # Convert all to strings\n","\n","            walks.append(walk)\n","\n","    if not quiet:\n","        pbar.close()\n","\n","    return walks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee2lSNViR8bV"},"source":["## Node2vec"]},{"cell_type":"code","metadata":{"id":"tp_zpf6h62lz"},"source":["class Node2Vec:\n","    FIRST_TRAVEL_KEY = 'first_travel_key'\n","    PROBABILITIES_KEY = 'probabilities'\n","    NEIGHBORS_KEY = 'neighbors'\n","    WEIGHT_KEY = 'weight'\n","    NUM_WALKS_KEY = 'num_walks'\n","    WALK_LENGTH_KEY = 'walk_length'\n","    P_KEY = 'p'\n","    Q_KEY = 'q'\n","\n","    def __init__(self, graph: nx.Graph, dimensions: int = 128, walk_length: int = 80, num_walks: int = 10, p: float = 1,\n","                 q: float = 1, weight_key: str = 'weight', workers: int = 1, sampling_strategy: dict = None,\n","                 quiet: bool = False, temp_folder: str = None, seed: int = None):\n","        \"\"\"\n","        Initiates the Node2Vec object, precomputes walking probabilities and generates the walks.\n","        :param graph: Input graph\n","        :param dimensions: Embedding dimensions (default: 128)\n","        :param walk_length: Number of nodes in each walk (default: 80)\n","        :param num_walks: Number of walks per node (default: 10)\n","        :param p: Return hyper parameter (default: 1)\n","        :param q: Inout parameter (default: 1)\n","        :param weight_key: On weighted graphs, this is the key for the weight attribute (default: 'weight')\n","        :param workers: Number of workers for parallel execution (default: 1)\n","        :param sampling_strategy: Node specific sampling strategies, supports setting node specific 'q', 'p', 'num_walks' and 'walk_length'.\n","        :param seed: Seed for the random number generator.\n","        Use these keys exactly. If not set, will use the global ones which were passed on the object initialization\n","        :param temp_folder: Path to folder with enough space to hold the memory map of self.d_graph (for big graphs); to be passed joblib.Parallel.temp_folder\n","        \"\"\"\n","\n","        self.graph = graph\n","        self.dimensions = dimensions\n","        self.walk_length = walk_length\n","        self.num_walks = num_walks\n","        self.p = p\n","        self.q = q\n","        self.weight_key = weight_key\n","        self.workers = workers\n","        self.quiet = quiet\n","        self.d_graph = defaultdict(dict)\n","\n","        if sampling_strategy is None:\n","            self.sampling_strategy = {}\n","        else:\n","            self.sampling_strategy = sampling_strategy\n","\n","        self.temp_folder, self.require = None, None\n","        if temp_folder:\n","            if not os.path.isdir(temp_folder):\n","                raise NotADirectoryError(\"temp_folder does not exist or is not a directory. ({})\".format(temp_folder))\n","\n","            self.temp_folder = temp_folder\n","            self.require = \"sharedmem\"\n","\n","        if seed is not None:\n","            random.seed(seed)\n","            np.random.seed(seed)\n","\n","        self._precompute_probabilities()\n","        self.walks = self._generate_walks()\n","\n","    def _precompute_probabilities(self):\n","        \"\"\"\n","        Precomputes transition probabilities for each node.\n","        \"\"\"\n","\n","        d_graph = self.d_graph\n","\n","        nodes_generator = self.graph.nodes() if self.quiet \\\n","            else tqdm(self.graph.nodes(), desc='Computing transition probabilities')\n","\n","        for source in nodes_generator:\n","\n","            # Init probabilities dict for first travel\n","            if self.PROBABILITIES_KEY not in d_graph[source]:\n","                d_graph[source][self.PROBABILITIES_KEY] = dict()\n","\n","            for current_node in self.graph.neighbors(source):\n","\n","                # Init probabilities dict\n","                if self.PROBABILITIES_KEY not in d_graph[current_node]:\n","                    d_graph[current_node][self.PROBABILITIES_KEY] = dict()\n","\n","                unnormalized_weights = list()\n","                d_neighbors = list()\n","\n","                # Calculate unnormalized weights\n","                for destination in self.graph.neighbors(current_node):\n","\n","                    p = self.sampling_strategy[current_node].get(self.P_KEY,\n","                                                                 self.p) if current_node in self.sampling_strategy else self.p\n","                    q = self.sampling_strategy[current_node].get(self.Q_KEY,\n","                                                                 self.q) if current_node in self.sampling_strategy else self.q\n","\n","                    if destination == source:  # Backwards probability\n","                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1) * 1 / p\n","                    elif destination in self.graph[source]:  # If the neighbor is connected to the source\n","                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1)\n","                    else:\n","                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1) * 1 / q\n","\n","                    # Assign the unnormalized sampling strategy weight, normalize during random walk\n","                    unnormalized_weights.append(ss_weight)\n","                    d_neighbors.append(destination)\n","\n","                # Normalize\n","                unnormalized_weights = np.array(unnormalized_weights)\n","                d_graph[current_node][self.PROBABILITIES_KEY][\n","                    source] = unnormalized_weights / unnormalized_weights.sum()\n","\n","            # Calculate first_travel weights for source\n","            first_travel_weights = []\n","\n","            for destination in self.graph.neighbors(source):\n","                first_travel_weights.append(self.graph[source][destination].get(self.weight_key, 1))\n","\n","            first_travel_weights = np.array(first_travel_weights)\n","            d_graph[source][self.FIRST_TRAVEL_KEY] = first_travel_weights / first_travel_weights.sum()\n","\n","            # Save neighbors\n","            d_graph[source][self.NEIGHBORS_KEY] = list(self.graph.neighbors(source))\n","\n","    def _generate_walks(self) -> list:\n","        \"\"\"\n","        Generates the random walks which will be used as the skip-gram input.\n","        :return: List of walks. Each walk is a list of nodes.\n","        \"\"\"\n","\n","        flatten = lambda l: [item for sublist in l for item in sublist]\n","\n","        # Split num_walks for each worker\n","        num_walks_lists = np.array_split(range(self.num_walks), self.workers)\n","\n","        walk_results = Parallel(n_jobs=self.workers, temp_folder=self.temp_folder, require=self.require)(\n","            delayed(parallel_generate_walks)(self.d_graph,\n","                                             self.walk_length,\n","                                             len(num_walks),\n","                                             idx,\n","                                             self.sampling_strategy,\n","                                             self.NUM_WALKS_KEY,\n","                                             self.WALK_LENGTH_KEY,\n","                                             self.NEIGHBORS_KEY,\n","                                             self.PROBABILITIES_KEY,\n","                                             self.FIRST_TRAVEL_KEY,\n","                                             self.quiet) for\n","            idx, num_walks\n","            in enumerate(num_walks_lists, 1))\n","\n","        walks = flatten(walk_results)\n","\n","        return walks\n","\n","    def fit(self, **skip_gram_params) -> gensim.models.Word2Vec:\n","        \"\"\"\n","        Creates the embeddings using gensim's Word2Vec.\n","        :param skip_gram_params: Parameters for gensim.models.Word2Vec - do not supply 'size' / 'vector_size' it is\n","            taken from the Node2Vec 'dimensions' parameter\n","        :type skip_gram_params: dict\n","        :return: A gensim word2vec model\n","        \"\"\"\n","\n","        if 'workers' not in skip_gram_params:\n","            skip_gram_params['workers'] = self.workers\n","\n","        # Figure out gensim version, naming of output dimensions changed from size to vector_size in v4.0.0\n","        gensim_version = pkg_resources.get_distribution(\"gensim\").version\n","        size = 'size' if gensim_version < '4.0.0' else 'vector_size'\n","        if size not in skip_gram_params:\n","            skip_gram_params[size] = self.dimensions\n","\n","        if 'sg' not in skip_gram_params:\n","            skip_gram_params['sg'] = 1\n","\n","        return gensim.models.Word2Vec(self.walks, **skip_gram_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XMAyOd0vR_AA"},"source":["## Edge embed"]},{"cell_type":"code","metadata":{"id":"8W-kDDU96hhO"},"source":["class EdgeEmbedder(ABC):\n","    INDEX_MAPPING_KEY = 'index2word' if pkg_resources.get_distribution(\"gensim\").version < '4.0.0' else 'index_to_key'\n","\n","    def __init__(self, keyed_vectors: KeyedVectors, quiet: bool = False):\n","        \"\"\"\n","        :param keyed_vectors: KeyedVectors containing nodes and embeddings to calculate edges for\n","        \"\"\"\n","\n","        self.kv = keyed_vectors\n","        self.quiet = quiet\n","\n","    @abstractmethod\n","    def _embed(self, edge: tuple) -> np.ndarray:\n","        \"\"\"\n","        Abstract method for implementing the embedding method\n","        :param edge: tuple of two nodes\n","        :return: Edge embedding\n","        \"\"\"\n","        pass\n","\n","    def __getitem__(self, edge) -> np.ndarray:\n","        if not isinstance(edge, tuple) or not len(edge) == 2:\n","            raise ValueError('edge must be a tuple of two nodes')\n","\n","        if edge[0] not in getattr(self.kv, self.INDEX_MAPPING_KEY):\n","            raise KeyError('node {} does not exist in given KeyedVectors'.format(edge[0]))\n","\n","        if edge[1] not in getattr(self.kv, self.INDEX_MAPPING_KEY):\n","            raise KeyError('node {} does not exist in given KeyedVectors'.format(edge[1]))\n","\n","        return self._embed(edge)\n","\n","    def as_keyed_vectors(self) -> KeyedVectors:\n","        \"\"\"\n","        Generated a KeyedVectors instance with all the possible edge embeddings\n","        :return: Edge embeddings\n","        \"\"\"\n","\n","        edge_generator = combinations_with_replacement(getattr(self.kv, self.INDEX_MAPPING_KEY), r=2)\n","\n","        if not self.quiet:\n","            vocab_size = len(getattr(self.kv, self.INDEX_MAPPING_KEY))\n","            total_size = reduce(lambda x, y: x * y, range(1, vocab_size + 2)) / \\\n","                         (2 * reduce(lambda x, y: x * y, range(1, vocab_size)))\n","\n","            edge_generator = tqdm(edge_generator, desc='Generating edge features', total=total_size)\n","\n","        # Generate features\n","        tokens = []\n","        features = []\n","        for edge in edge_generator:\n","            token = str(tuple(sorted(edge)))\n","            embedding = self._embed(edge)\n","\n","            tokens.append(token)\n","            features.append(embedding)\n","\n","        # Build KV instance\n","        edge_kv = KeyedVectors(vector_size=self.kv.vector_size)\n","        if pkg_resources.get_distribution(\"gensim\").version < '4.0.0':\n","            edge_kv.add(\n","                entities=tokens,\n","                weights=features)\n","        else:\n","            edge_kv.add_vectors(\n","                keys=tokens,\n","                weights=features)\n","\n","        return edge_kv\n","\n","\n","class AverageEmbedder(EdgeEmbedder):\n","    \"\"\"\n","    Average node features\n","    \"\"\"\n","\n","    def _embed(self, edge: tuple):\n","        return (self.kv[edge[0]] + self.kv[edge[1]]) / 2\n","\n","\n","class HadamardEmbedder(EdgeEmbedder):\n","    \"\"\"\n","    Hadamard product node features\n","    \"\"\"\n","\n","    def _embed(self, edge: tuple):\n","        return self.kv[edge[0]] * self.kv[edge[1]]\n","\n","\n","class WeightedL1Embedder(EdgeEmbedder):\n","    \"\"\"\n","    Weighted L1 node features\n","    \"\"\"\n","\n","    def _embed(self, edge: tuple):\n","        return np.abs(self.kv[edge[0]] - self.kv[edge[1]])\n","\n","\n","class WeightedL2Embedder(EdgeEmbedder):\n","    \"\"\"\n","    Weighted L2 node features\n","    \"\"\"\n","\n","    def _embed(self, edge: tuple):\n","        return (self.kv[edge[0]] - self.kv[edge[1]]) ** 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ViE6NF85xEN"},"source":["## Scenario"]},{"cell_type":"code","metadata":{"id":"HUWh2hZC6KNm"},"source":["# Create a graph\n","graph = nx.fast_gnp_random_graph(n=100, p=0.5)\n","\n","# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n","node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200, workers=4)  # Use temp_folder for big graphs\n","\n","# Embed nodes\n","model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n","\n","# Look for most similar nodes\n","model.wv.most_similar('2')  # Output node names are always strings\n","\n","# Save embeddings for later use\n","model.wv.save_word2vec_format('embeddings.p')\n","\n","# Save model for later use\n","model.save('model.p')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbJC2AMX66GR"},"source":["edges_embs = HadamardEmbedder(keyed_vectors=model.wv)\n","\n","# Look for embeddings on the fly - here we pass normal tuples\n","edges_embs[('1', '2')]\n","''' OUTPUT\n","array([ 5.75068220e-03, -1.10937878e-02,  3.76693785e-01,  2.69105062e-02,\n","       ... ... ....\n","       ..................................................................],\n","      dtype=float32)\n","'''\n","\n","# Get all edges in a separate KeyedVectors instance - use with caution could be huge for big networks\n","edges_kv = edges_embs.as_keyed_vectors()\n","\n","# Look for most similar edges - this time tuples must be sorted and as str\n","edges_kv.most_similar(str(('1', '2')))\n","\n","# Save embeddings for later use\n","edges_kv.save_word2vec_format('edge_embeddings.p')"],"execution_count":null,"outputs":[]}]}