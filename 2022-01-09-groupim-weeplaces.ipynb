{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-09-groupim-weeplaces.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/P042235%20%7C%20Training%20GroupIM%20model%20on%20Weeplaces%20dataset.ipynb","timestamp":1644562734612}],"collapsed_sections":[],"authorship_tag":"ABX9TyMXXHMNPlU/PZ5toFfbXGAv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training GroupIM model on Weeplaces dataset"],"metadata":{"id":"_zVKXBtcSwT4"}},{"cell_type":"markdown","source":["## Executive summary"],"metadata":{"id":"uD-PM-u9QCGx"}},{"cell_type":"markdown","source":["| | |\n","| --- | --- |\n","| Problem | Group interactions are sparse in nature which makes it difficult to provide relevant recommendation to the group. |\n","| Solution | Regularize the user-group latent space to overcome group interaction sparsity by: maximizing mutual information between representations of groups and group members; and dynamically prioritizing the preferences of highly informative members through contextual preference weighting. |\n","| Dataset | Weeplaces |\n","| Preprocessing | We extract check-ins on POIs over all major cities in the United States, across various categories including Food, Nightlife, Outdoors, Entertainment and Travel. We randomly split the set of all groups into training (70%), validation (10%), and test (20%) sets, while utilizing the individual interactions of all users for training. Note that each group appears only in one of the three sets. The test set contains strict ephemeral groups (i.e., a specific combination of users) that do not occur in the training set. Thus, we train on ephemeral groups and test on strict ephemeral groups. |\n","| Metrics | NDCG, Recall |\n","| Hyperparams | We tune the latent dimension in the range {32, 64, 128} and other baseline hyper-parameters in ranges centered at author-provided values. In GroupIM, we use two fully connected layers of size 64 each in fenc(·) and tune λ in the range {$2^{−4}$,$2^{−3}$,$\\dots$, $2^{6}$}. We use 5 negatives for each true user-group pair to train the discriminator. |\n","| Models | GroupIM along with Encoder, 3 types of Aggregators to choose from, and a discriminator module. |\n","| Platform | PyTorch, preferable GPU for faster computation. |\n","| Links | [Paper](https://arxiv.org/abs/2006.03736), [Code](https://github.com/RecoHut-Stanzas/S168471) |"],"metadata":{"id":"7DDul7W4PxNH"}},{"cell_type":"code","source":["!pip install -q recohut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQ_O1rPQ1geg","executionInfo":{"status":"ok","timestamp":1640781863463,"user_tz":-330,"elapsed":4272,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"79d0080c-5eaf-4ea2-d649-29986fe021b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.4 MB/s \n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Datasets"],"metadata":{"id":"8Wdr7RzCyw68"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import scipy.sparse as sp\n","from sklearn.preprocessing import normalize\n","from torch.utils import data\n","\n","from recohut.datasets import base\n","from recohut.utils.common_utils import download_url, extract_zip"],"metadata":{"id":"84M64rqgyzz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WeeplacesDataset(base.Dataset, data.Dataset):\n","    url = \"https://github.com/RecoHut-Datasets/weeplaces/raw/v2/data.zip\"\n","\n","    def __init__(self, root, datatype='train', is_group=False, n_items=None, negs_per_group=None, padding_idx=None, verbose=True):\n","        super().__init__(root)\n","        self.datatype = datatype\n","        self.n_items = n_items\n","        self.negs_per_group = negs_per_group\n","        self.is_group = is_group\n","        self.padding_idx = padding_idx\n","        if is_group:\n","            if datatype=='train':\n","                self.user_data = self.load_user_data_train()\n","                self.group_data, self.group_users = self.load_group_data_train()\n","                self.group_inputs = [self.user_data[self.group_users[g]] for g in self.groups_list]\n","            else:\n","                self.eval_groups_list = []\n","                self.user_data = self.load_user_data_tr_te(datatype)\n","                self.eval_group_data, self.eval_group_users = self.load_group_data_tr_te(datatype)\n","        else:\n","            if datatype=='train':\n","                self.train_data_ui = self.load_ui_train()\n","                self.user_list = list(range(self.n_users))\n","            else:\n","                self.data_tr, self.data_te = self.load_ui_tr_te(datatype)\n","    \n","    def __len__(self):\n","        if self.is_group:\n","            if self.datatype=='train':\n","                return len(self.groups_list)\n","            return len(self.eval_groups_list)\n","        return len(self.user_list)\n","\n","    def __train__(self, index):\n","        \"\"\" load user_id, binary vector over items \"\"\"\n","        user = self.user_list[index]\n","        user_items = torch.from_numpy(self.train_data_ui[user, :].toarray()).squeeze()  # [I]\n","        return torch.from_numpy(np.array([user], dtype=np.int32)), user_items\n","\n","    def __test__(self, index):\n","        \"\"\" load user_id, fold-in items, held-out items \"\"\"\n","        user = self.user_list[index]\n","        fold_in, held_out = self.data_tr[user, :].toarray(), self.data_te[user, :].toarray()  # [I], [I]\n","        return user, torch.from_numpy(fold_in).squeeze(), held_out.squeeze()  # user, fold-in items, fold-out items.\n","\n","    def __train_group__(self, index):\n","        \"\"\" load group_id, padded group users, mask, group items, group member items, negative user items \"\"\"\n","        group = self.groups_list[index]\n","        user_ids = torch.from_numpy(np.array(self.group_users[group], np.int32))  # [G] group member ids\n","        group_items = torch.from_numpy(self.group_data[group].toarray().squeeze())  # [I] items per group\n","\n","        corrupted_group = self.get_corrupted_users(group)  # [# negs]\n","        corrupted_user_items = torch.from_numpy(self.user_data[corrupted_group].toarray().squeeze())  # [# negs, I]\n","\n","        # group mask to create fixed-size padded groups.\n","        group_length = self.max_group_size - list(user_ids).count(self.padding_idx)\n","        group_mask = torch.from_numpy(np.concatenate([np.zeros(group_length, dtype=np.float32), (-1) * np.inf *\n","                                                      np.ones(self.max_group_size - group_length,\n","                                                              dtype=np.float32)]))  # [G]\n","\n","        user_items = torch.from_numpy(self.group_inputs[group].toarray())  # [G, |I|] group member items\n","\n","        return torch.tensor([group]), user_ids, group_mask, group_items, user_items, corrupted_user_items\n","\n","    def __test_group__(self, index):\n","        \"\"\" load group_id, padded group users, mask, group items, group member items \"\"\"\n","        group = self.eval_groups_list[index]\n","        user_ids = self.eval_group_users[group]  # [G]\n","        length = self.max_gsize - list(user_ids).count(self.padding_idx)\n","        mask = torch.from_numpy(np.concatenate([np.zeros(length, dtype=np.float32), (-1) * np.inf *\n","                                                np.ones(self.max_gsize - length, dtype=np.float32)]))  # [G]\n","        group_items = torch.from_numpy(self.eval_group_data[group].toarray().squeeze())  # [I]\n","        user_items = torch.from_numpy(self.user_data[user_ids].toarray().squeeze())  # [G, I]\n","\n","        return torch.tensor([group]), torch.tensor(user_ids), mask, group_items, user_items\n","\n","    def __getitem__(self, index):\n","        if self.is_group:\n","            if self.datatype=='train':\n","                return self.__train_group__(index)\n","            return self.__test_group__(index)\n","        else:\n","            if self.datatype=='train':\n","                return self.__train__(index)\n","            return self.__test__(index)\n","\n","    @property\n","    def raw_file_names(self) -> str:\n","        return ['train_ui.csv',\n","                'val_ui_te.csv',\n","                'group_users.csv',\n","                'data.zip',\n","                'train_gi.csv',\n","                'test_ui_tr.csv',\n","                'val_ui_tr.csv',\n","                'test_ui_te.csv',\n","                'val_gi.csv',\n","                'test_gi.csv']\n","\n","    def download(self):\n","        path = download_url(self.url, self.raw_dir)\n","        extract_zip(path, self.raw_dir)\n","\n","    @property\n","    def processed_file_names(self) -> str:\n","        pass\n","\n","    def process(self):\n","        pass\n","\n","    def load_ui_train(self):\n","        \"\"\" load training user-item interactions as a sparse matrix \"\"\"\n","        path_ui = [p for p in self.raw_paths if \"train_ui\" in p][0]\n","        df_ui = pd.read_csv(path_ui)\n","        self.n_users, self.n_items = df_ui['user'].max() + 1, df_ui['item'].max() + 1\n","        rows_ui, cols_ui = df_ui['user'], df_ui['item']\n","        data_ui = sp.csr_matrix((np.ones_like(rows_ui), (rows_ui, cols_ui)), dtype='float32',\n","                                shape=(self.n_users, self.n_items))  # [# train users, I] sparse matrix\n","        print(\"# train users\", self.n_users, \"# items\", self.n_items)\n","        return data_ui\n","\n","    def load_ui_tr_te(self, datatype='val'):\n","        \"\"\" load user-item interactions of val/test user sets as two sparse matrices of fold-in and held-out items \"\"\"\n","        ui_tr_path = [p for p in self.raw_paths if '{}_ui_tr.csv'.format(datatype) in p][0]\n","\n","        ui_te_path = [p for p in self.raw_paths if '{}_ui_te.csv'.format(datatype) in p][0]\n","\n","        ui_df_tr, ui_df_te = pd.read_csv(ui_tr_path), pd.read_csv(ui_te_path)\n","\n","        start_idx = min(ui_df_tr['user'].min(), ui_df_te['user'].min())\n","        end_idx = max(ui_df_tr['user'].max(), ui_df_te['user'].max())\n","\n","        rows_tr, cols_tr = ui_df_tr['user'] - start_idx, ui_df_tr['item']\n","        rows_te, cols_te = ui_df_te['user'] - start_idx, ui_df_te['item']\n","        self.user_list = list(range(0, end_idx - start_idx + 1))\n","\n","        ui_data_tr = sp.csr_matrix((np.ones_like(rows_tr), (rows_tr, cols_tr)), dtype='float32',\n","                                   shape=(end_idx - start_idx + 1, self.n_items))  # [# eval users, I] sparse matrix\n","        ui_data_te = sp.csr_matrix((np.ones_like(rows_te), (rows_te, cols_te)), dtype='float32',\n","                                   shape=(end_idx - start_idx + 1, self.n_items))  # [# eval users, I] sparse matrix\n","        return ui_data_tr, ui_data_te\n","\n","    def get_corrupted_users(self, group):\n","        \"\"\" negative user sampling per group (eta balances item-biased and random sampling) \"\"\"\n","        eta = 0.5\n","        p = np.ones(self.n_users + 1)\n","        p[self.group_users[group]] = 0\n","        p = normalize([p], norm='l1')[0]\n","        item_biased = normalize(self.user_data[:, self.group_data[group].indices].sum(1).squeeze(), norm='l1')[0]\n","        p = eta * item_biased + (1 - eta) * p\n","        negative_users = torch.multinomial(torch.from_numpy(p), self.negs_per_group)\n","        return negative_users\n","\n","    def load_user_data_train(self):\n","        \"\"\" load user-item interactions of all users that appear in training groups, as a sparse matrix \"\"\"\n","        df_ui = pd.DataFrame()\n","        train_path_ui = [p for p in self.raw_paths if 'train_ui.csv' in p][0]\n","        df_train_ui = pd.read_csv(train_path_ui)\n","        df_ui = df_ui.append(df_train_ui)\n","\n","        # include users from the (fold-in item set) of validation and test sets of user-item data.\n","        val_path_ui = [p for p in self.raw_paths if 'val_ui_tr.csv' in p][0]\n","        df_val_ui = pd.read_csv(val_path_ui)\n","        df_ui = df_ui.append(df_val_ui)\n","\n","        test_path_ui = [p for p in self.raw_paths if 'test_ui_tr.csv' in p][0]\n","        df_test_ui = pd.read_csv(test_path_ui)\n","        df_ui = df_ui.append(df_test_ui)\n","\n","        self.n_users = df_ui['user'].max() + 1\n","        self.padding_idx = self.n_users  # padding idx for user when creating groups of fixed size.\n","        assert self.n_items == df_ui['item'].max() + 1\n","        rows_ui, cols_ui = df_ui['user'], df_ui['item']\n","\n","        data_ui = sp.csr_matrix((np.ones_like(rows_ui), (rows_ui, cols_ui)), dtype='float32',\n","                                shape=(self.n_users + 1, self.n_items))  # [U, I] sparse matrix\n","        return data_ui\n","\n","    def load_user_data_tr_te(self, datatype):\n","        \"\"\" load all user-item interactions of users that occur in val/test groups, as a sparse matrix \"\"\"\n","        df_ui = pd.DataFrame()\n","        train_path_ui = [p for p in self.raw_paths if 'train_ui.csv' in p][0]\n","        df_train_ui = pd.read_csv(train_path_ui)\n","        df_ui = df_ui.append(df_train_ui)\n","\n","        val_path_ui = [p for p in self.raw_paths if 'val_ui_tr.csv' in p][0]\n","        df_val_ui = pd.read_csv(val_path_ui)\n","        df_ui = df_ui.append(df_val_ui)\n","\n","        if datatype == 'val' or datatype == 'test':\n","            # include eval user set (tr) items (since they might occur in evaluation set)\n","            test_path_ui = [p for p in self.raw_paths if 'test_ui_tr.csv' in p][0]\n","            df_test_ui = pd.read_csv(test_path_ui)\n","            df_ui = df_ui.append(df_test_ui)\n","\n","        n_users = df_ui['user'].max() + 1\n","        assert self.n_items == df_ui['item'].max() + 1\n","        rows_ui, cols_ui = df_ui['user'], df_ui['item']\n","        data_ui = sp.csr_matrix((np.ones_like(rows_ui), (rows_ui, cols_ui)), dtype='float32',\n","                                shape=(n_users + 1, self.n_items))  # [# users, I] sparse matrix\n","        return data_ui\n","\n","    def load_group_data_train(self):\n","        \"\"\" load training group-item interactions as a sparse matrix and user-group memberships \"\"\"\n","        path_ug = [p for p in self.raw_paths if 'group_users.csv' in p][0]\n","        path_gi = [p for p in self.raw_paths if 'train_gi.csv' in p][0]\n","\n","        df_gi = pd.read_csv(path_gi)  # load training group-item interactions.\n","        start_idx, end_idx = df_gi['group'].min(), df_gi['group'].max()\n","        self.n_groups = end_idx - start_idx + 1\n","        rows_gi, cols_gi = df_gi['group'] - start_idx, df_gi['item']\n","\n","        data_gi = sp.csr_matrix((np.ones_like(rows_gi), (rows_gi, cols_gi)), dtype='float32',\n","                                shape=(self.n_groups, self.n_items))  # [# groups,  I] sparse matrix.\n","\n","        df_ug = pd.read_csv(path_ug).astype(int)  # load user-group memberships.\n","        df_ug_train = df_ug[df_ug.group.isin(range(start_idx, end_idx + 1))]\n","        df_ug_train = df_ug_train.sort_values('group')  # sort in ascending order of group ids.\n","        self.max_group_size = df_ug_train.groupby('group').size().max()  # max group size denoted by G\n","\n","        g_u_list_train = df_ug_train.groupby('group')['user'].apply(list).reset_index()\n","        g_u_list_train['user'] = list(map(lambda x: x + [self.padding_idx] * (self.max_group_size - len(x)),\n","                                          g_u_list_train.user))\n","        data_gu = np.squeeze(np.array(g_u_list_train[['user']].values.tolist()))  # [# groups, G] with padding.\n","        self.groups_list = list(range(0, end_idx - start_idx + 1))\n","\n","        assert len(df_ug_train['group'].unique()) == self.n_groups\n","        print(\"# training groups: {}, # max train group size: {}\".format(self.n_groups, self.max_group_size))\n","\n","        return data_gi, data_gu\n","\n","    def load_group_data_tr_te(self, datatype):\n","        \"\"\" load val/test group-item interactions as a sparse matrix and user-group memberships \"\"\"\n","        path_ug = [p for p in self.raw_paths if 'group_users.csv' in p][0]\n","        path_gi = [p for p in self.raw_paths if '{}_gi.csv'.format(datatype) in p][0]\n","\n","        df_gi = pd.read_csv(path_gi)  # load group-item interactions\n","        start_idx, end_idx = df_gi['group'].min(), df_gi['group'].max()\n","        self.n_groups = end_idx - start_idx + 1\n","        rows_gi, cols_gi = df_gi['group'] - start_idx, df_gi['item']\n","        data_gi = sp.csr_matrix((np.ones_like(rows_gi), (rows_gi, cols_gi)), dtype='float32',\n","                                shape=(self.n_groups, self.n_items))  # [# eval groups, I] sparse matrix\n","\n","        df_ug = pd.read_csv(path_ug)  # load user-group memberships\n","        df_ug_eval = df_ug[df_ug.group.isin(range(start_idx, end_idx + 1))]\n","        df_ug_eval = df_ug_eval.sort_values('group')  # sort in ascending order of group ids\n","        self.max_gsize = df_ug_eval.groupby('group').size().max()  # max group size denoted by G\n","        g_u_list_eval = df_ug_eval.groupby('group')['user'].apply(list).reset_index()\n","        g_u_list_eval['user'] = list(map(lambda x: x + [self.padding_idx] * (self.max_gsize - len(x)),\n","                                         g_u_list_eval.user))\n","        data_gu = np.squeeze(np.array(g_u_list_eval[['user']].values.tolist(), dtype=np.int32))  # [# groups, G]\n","        self.eval_groups_list = list(range(0, end_idx - start_idx + 1))\n","        return data_gi, data_gu"],"metadata":{"id":"KVLWlKBV1AOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Models"],"metadata":{"id":"OBjX6QsQyzww"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"oYz8jin7FPMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"clxmhOVTFQXE"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    \"\"\" User Preference Encoder implemented as fully connected layers over binary bag-of-words vector\n","    (over item set) per user \"\"\"\n","\n","    def __init__(self, n_items, user_layers, embedding_dim, drop_ratio):\n","        super(Encoder, self).__init__()\n","        self.n_items = n_items\n","        self.embedding_dim = embedding_dim\n","        self.drop = nn.Dropout(drop_ratio)\n","        self.user_preference_encoder = torch.nn.ModuleList()  # user individual preference encoder layers.\n","\n","        for idx, (in_size, out_size) in enumerate(zip([self.n_items] + user_layers[:-1], user_layers)):\n","            layer = torch.nn.Linear(in_size, out_size, bias=True)\n","            nn.init.xavier_uniform_(layer.weight)\n","            nn.init.zeros_(layer.bias)\n","            self.user_preference_encoder.append(layer)\n","\n","        self.transform_layer = nn.Linear(self.embedding_dim, self.embedding_dim)\n","        nn.init.xavier_uniform_(self.transform_layer.weight)\n","        nn.init.zeros_(self.transform_layer.bias)\n","\n","        self.user_predictor = nn.Linear(self.embedding_dim, self.n_items, bias=False)  # item embedding for pre-training\n","        nn.init.xavier_uniform_(self.user_predictor.weight)\n","\n","    def pre_train_forward(self, user_items):\n","        \"\"\" user individual preference encoder (excluding final layer) for user-item pre-training\n","            :param user_items: [B, G, I] or [B, I]\n","        \"\"\"\n","        user_items_norm = F.normalize(user_items)  # [B, G, I] or [B, I]\n","        user_pref_embedding = self.drop(user_items_norm)\n","        for idx, _ in enumerate(range(len(self.user_preference_encoder))):\n","            user_pref_embedding = self.user_preference_encoder[idx](user_pref_embedding)  # [B, G, D] or [B, D]\n","            user_pref_embedding = torch.tanh(user_pref_embedding)  # [B, G, D] or [B, D]\n","\n","        logits = self.user_predictor(user_pref_embedding)  # [B, G, D] or [B, D]\n","        return logits, user_pref_embedding\n","\n","    def forward(self, user_items):\n","        \"\"\" user individual preference encoder\n","            :param user_items: [B, G, I]\n","        \"\"\"\n","        _, user_embeds = self.pre_train_forward(user_items)  # [B, G, D]\n","        user_embeds = torch.tanh(self.transform_layer(user_embeds))  # [B, G, D]\n","        return user_embeds"],"metadata":{"id":"4aPpiMu-yzt8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Aggregator"],"metadata":{"id":"IhLIxDOVFSkt"}},{"cell_type":"code","source":["class MaxPoolAggregator(nn.Module):\n","    \"\"\" Group Preference Aggregator implemented as max pooling over group member embeddings \"\"\"\n","\n","    def __init__(self, input_dim, output_dim, drop_ratio=0):\n","        super(MaxPoolAggregator, self).__init__()\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, output_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Dropout(drop_ratio)\n","        )\n","        nn.init.xavier_uniform_(self.mlp[0].weight)\n","        if self.mlp[0].bias is not None:\n","            self.mlp[0].bias.data.fill_(0.0)\n","\n","    def forward(self, x, mask, mlp=False):\n","        \"\"\" max pooling aggregator:\n","            :param x: [B, G, D]  group member embeddings\n","            :param mask: [B, G]  -inf/0 for absent/present\n","            :param mlp: flag to add a linear layer before max pooling\n","        \"\"\"\n","        if mlp:\n","            h = torch.tanh(self.mlp(x))\n","        else:\n","            h = x\n","\n","        if mask is None:\n","            return torch.max(h, dim=1)\n","        else:\n","            res = torch.max(h + mask.unsqueeze(2), dim=1)\n","            return res.values\n","\n","\n","# mask:  -inf/0 for absent/present.\n","class MeanPoolAggregator(nn.Module):\n","    \"\"\" Group Preference Aggregator implemented as mean pooling over group member embeddings \"\"\"\n","\n","    def __init__(self, input_dim, output_dim, drop_ratio=0):\n","        super(MeanPoolAggregator, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, output_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Dropout(drop_ratio)\n","        )\n","        nn.init.xavier_uniform_(self.mlp[0].weight)\n","        if self.mlp[0].bias is not None:\n","            self.mlp[0].bias.data.fill_(0.0)\n","\n","    def forward(self, x, mask, mlp=False):\n","        \"\"\" mean pooling aggregator:\n","            :param x: [B, G, D]  group member embeddings\n","            :param mask: [B, G]  -inf/0 for absent/present\n","            :param mlp: flag to add a linear layer before mean pooling\n","        \"\"\"\n","        if mlp:\n","            h = torch.tanh(self.mlp(x))\n","        else:\n","            h = x\n","        if mask is None:\n","            return torch.mean(h, dim=1)\n","        else:\n","            mask = torch.exp(mask)\n","            res = torch.sum(h * mask.unsqueeze(2), dim=1) / mask.sum(1).unsqueeze(1)\n","            return res\n","\n","\n","class AttentionAggregator(nn.Module):\n","    \"\"\" Group Preference Aggregator implemented as attention over group member embeddings \"\"\"\n","\n","    def __init__(self, input_dim, output_dim, drop_ratio=0):\n","        super(AttentionAggregator, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, output_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Dropout(drop_ratio)\n","        )\n","\n","        self.attention = nn.Linear(output_dim, 1)\n","        self.drop = nn.Dropout(drop_ratio)\n","        nn.init.xavier_uniform_(self.mlp[0].weight)\n","        if self.mlp[0].bias is not None:\n","            self.mlp[0].bias.data.fill_(0.0)\n","\n","    def forward(self, x, mask, mlp=False):\n","        \"\"\" attentive aggregator:\n","            :param x: [B, G, D]  group member embeddings\n","            :param mask: [B, G]  -inf/0 for absent/present\n","            :param mlp: flag to add a linear layer before attention\n","        \"\"\"\n","        if mlp:\n","            h = torch.tanh(self.mlp(x))\n","        else:\n","            h = x\n","\n","        attention_out = torch.tanh(self.attention(h))\n","        if mask is None:\n","            weight = torch.softmax(attention_out, dim=1)\n","        else:\n","            weight = torch.softmax(attention_out + mask.unsqueeze(2), dim=1)\n","        ret = torch.matmul(h.transpose(2, 1), weight).squeeze(2)\n","        return ret"],"metadata":{"id":"Zf3EFFfrFShx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Discriminator"],"metadata":{"id":"ZDAiDRqFFSfk"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    \"\"\" Discriminator for Mutual Information Estimation and Maximization, implemented with bilinear layers and\n","    binary cross-entropy loss training \"\"\"\n","\n","    def __init__(self, embedding_dim=64):\n","        super(Discriminator, self).__init__()\n","        self.embedding_dim = embedding_dim\n","\n","        self.fc_layer = torch.nn.Linear(self.embedding_dim, self.embedding_dim, bias=True)\n","        nn.init.xavier_uniform_(self.fc_layer.weight)\n","        nn.init.zeros_(self.fc_layer.bias)\n","\n","        self.bilinear_layer = nn.Bilinear(self.embedding_dim, self.embedding_dim, 1)  # output_dim = 1 => single score.\n","        nn.init.zeros_(self.bilinear_layer.weight)\n","        nn.init.zeros_(self.bilinear_layer.bias)\n","\n","        self.bce_loss = nn.BCEWithLogitsLoss()\n","\n","    def forward(self, group_inputs, user_inputs, group_mask):\n","        \"\"\" bilinear discriminator:\n","            :param group_inputs: [B, I]\n","            :param user_inputs: [B, n_samples, I] where n_samples is either G or # negs\n","            :param group_mask: [B, G]\n","        \"\"\"\n","        # FC + activation.\n","        group_encoded = self.fc_layer(group_inputs)  # [B, D]\n","        group_embed = torch.tanh(group_encoded)  # [B, D]\n","\n","        # FC + activation.\n","        user_pref_embedding = self.fc_layer(user_inputs)\n","        user_embed = torch.tanh(user_pref_embedding)  # [B, n_samples, D]\n","\n","        return self.bilinear_layer(user_embed, group_embed.unsqueeze(1).repeat(1, user_inputs.shape[1], 1))\n","\n","    def mi_loss(self, scores_group, group_mask, scores_corrupted, device='cpu'):\n","        \"\"\" binary cross-entropy loss over (group, user) pairs for discriminator training\n","            :param scores_group: [B, G]\n","            :param group_mask: [B, G]\n","            :param scores_corrupted: [B, N]\n","            :param device (cpu/gpu)\n","         \"\"\"\n","        batch_size = scores_group.shape[0]\n","        pos_size, neg_size = scores_group.shape[1], scores_corrupted.shape[1]\n","\n","        one_labels = torch.ones(batch_size, pos_size).to(device)  # [B, G]\n","        zero_labels = torch.zeros(batch_size, neg_size).to(device)  # [B, N]\n","\n","        labels = torch.cat((one_labels, zero_labels), 1)  # [B, G+N]\n","        logits = torch.cat((scores_group, scores_corrupted), 1).squeeze(2)  # [B, G + N]\n","\n","        mask = torch.cat((torch.exp(group_mask), torch.ones([batch_size, neg_size]).to(device)),\n","                         1)  # torch.exp(.) to binarize since original mask has -inf.\n","\n","        mi_loss = self.bce_loss(logits * mask, labels * mask) * (batch_size * (pos_size + neg_size)) \\\n","                  / (torch.exp(group_mask).sum() + batch_size * neg_size)\n","\n","        return mi_loss"],"metadata":{"id":"p8tP8cr3FSdk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GroupIM Model"],"metadata":{"id":"DUqPcXSjFhUh"}},{"cell_type":"code","source":["class GroupIM(nn.Module):\n","    \"\"\"\n","    GroupIM framework for Group Recommendation:\n","    (a) User Preference encoding: user_preference_encoder\n","    (b) Group Aggregator: preference_aggregator\n","    (c) InfoMax Discriminator: discriminator\n","    \"\"\"\n","\n","    def __init__(self, n_items, user_layers, lambda_mi=0.1, drop_ratio=0.4, aggregator_type='attention'):\n","        super(GroupIM, self).__init__()\n","        self.n_items = n_items\n","        self.lambda_mi = lambda_mi\n","        self.drop = nn.Dropout(drop_ratio)\n","        self.embedding_dim = user_layers[-1]\n","        self.aggregator_type = aggregator_type\n","\n","        self.user_preference_encoder = Encoder(self.n_items, user_layers, self.embedding_dim, drop_ratio)\n","\n","        if self.aggregator_type == 'maxpool':\n","            self.preference_aggregator = MaxPoolAggregator(self.embedding_dim, self.embedding_dim)\n","        elif self.aggregator_type == 'meanpool':\n","            self.preference_aggregator = MeanPoolAggregator(self.embedding_dim, self.embedding_dim)\n","        elif self.aggregator_type == 'attention':\n","            self.preference_aggregator = AttentionAggregator(self.embedding_dim, self.embedding_dim)\n","        else:\n","            raise NotImplementedError(\"Aggregator type {} not implemented \".format(self.aggregator_type))\n","\n","        self.group_predictor = nn.Linear(self.embedding_dim, self.n_items, bias=False)\n","        nn.init.xavier_uniform_(self.group_predictor.weight)\n","\n","        self.discriminator = Discriminator(embedding_dim=self.embedding_dim)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","            if isinstance(m, nn.Embedding):\n","                nn.init.xavier_uniform_(m.weight)\n","\n","    def forward(self, group, group_users, group_mask, user_items):\n","        \"\"\" compute group embeddings and item recommendations by user preference encoding, group aggregation and\n","        item prediction\n","        :param group: [B] group id\n","        :param group_users: [B, G] group user ids with padding\n","        :param group_mask: [B, G] -inf/0 for absent/present user\n","        :param user_items: [B, G, I] individual item interactions of group members\n","        \"\"\"\n","        user_pref_embeds = self.user_preference_encoder(user_items)\n","        group_embed = self.preference_aggregator(user_pref_embeds, group_mask, mlp=False)  # [B, D]\n","        group_logits = self.group_predictor(group_embed)  # [B, I]\n","\n","        if self.train:\n","            obs_user_embeds = self.user_preference_encoder(user_items)  # [B, G, D]\n","            scores_ug = self.discriminator(group_embed, obs_user_embeds, group_mask).detach()  # [B, G]\n","            return group_logits, group_embed, scores_ug\n","        else:\n","            return group_logits, group_embed\n","\n","    def multinomial_loss(self, logits, items):\n","        \"\"\" multinomial likelihood with softmax over item set \"\"\"\n","        return -torch.mean(torch.sum(F.log_softmax(logits, 1) * items, -1))\n","\n","    def user_loss(self, user_logits, user_items):\n","        return self.multinomial_loss(user_logits, user_items)\n","\n","    def infomax_group_loss(self, group_logits, group_embeds, scores_ug, group_mask, group_items, user_items,\n","                           corrupted_user_items, device='cpu'):\n","        \"\"\" loss function with three terms: L_G, L_UG, L_MI\n","            :param group_logits: [B, G, I] group item predictions\n","            :param group_embeds: [B, D] group embedding\n","            :param scores_ug: [B, G] discriminator scores for group members\n","            :param group_mask: [B, G] -inf/0 for absent/present user\n","            :param group_items: [B, I] item interactions of group\n","            :param user_items: [B, G, I] individual item interactions of group members\n","            :param corrupted_user_items: [B, N, I] individual item interactions of negative user samples\n","            :param device: cpu/gpu\n","        \"\"\"\n","\n","        group_user_embeds = self.user_preference_encoder(user_items)  # [B, G, D]\n","        corrupt_user_embeds = self.user_preference_encoder(corrupted_user_items)  # [B, N, D]\n","\n","        scores_observed = self.discriminator(group_embeds, group_user_embeds, group_mask)  # [B, G]\n","        scores_corrupted = self.discriminator(group_embeds, corrupt_user_embeds, group_mask)  # [B, N]\n","\n","        mi_loss = self.discriminator.mi_loss(scores_observed, group_mask, scores_corrupted, device=device)\n","\n","        ui_sum = user_items.sum(2, keepdim=True)  # [B, G]\n","        user_items_norm = user_items / torch.max(torch.ones_like(ui_sum), ui_sum)  # [B, G, I]\n","        gi_sum = group_items.sum(1, keepdim=True)\n","        group_items_norm = group_items / torch.max(torch.ones_like(gi_sum), gi_sum)  # [B, I]\n","        assert scores_ug.requires_grad is False\n","\n","        group_mask_zeros = torch.exp(group_mask).unsqueeze(2)  # [B, G, 1]\n","        scores_ug = torch.sigmoid(scores_ug)  # [B, G, 1]\n","\n","        user_items_norm = torch.sum(user_items_norm * scores_ug * group_mask_zeros, dim=1) / group_mask_zeros.sum(1)\n","        user_group_loss = self.multinomial_loss(group_logits, user_items_norm)\n","        group_loss = self.multinomial_loss(group_logits, group_items_norm)\n","\n","        return mi_loss, user_group_loss, group_loss\n","\n","    def loss(self, group_logits, summary_embeds, scores_ug, group_mask, group_items, user_items, corrupted_user_items,\n","             device='cpu'):\n","        \"\"\" L_G + lambda L_UG + L_MI \"\"\"\n","        mi_loss, user_group_loss, group_loss = self.infomax_group_loss(group_logits, summary_embeds, scores_ug,\n","                                                                       group_mask, group_items, user_items,\n","                                                                       corrupted_user_items, device)\n","\n","        return group_loss + mi_loss + self.lambda_mi * user_group_loss"],"metadata":{"id":"RrPrpdiQFhR2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trainers"],"metadata":{"id":"r2oN9j_xy2xo"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import gc"],"metadata":{"id":"yW_3qhU2J2Xe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ndcg_binary_at_k_batch_torch(X_pred, heldout_batch, k=100, device='cpu'):\n","    \"\"\"\n","    Normalized Discounted Cumulative Gain@k for for predictions [B, I] and ground-truth [B, I], with binary relevance.\n","    ASSUMPTIONS: all the 0's in heldout_batch indicate 0 relevance.\n","    \"\"\"\n","\n","    batch_users = X_pred.shape[0]  # batch_size\n","    _, idx_topk = torch.topk(X_pred, k, dim=1, sorted=True)\n","    tp = 1. / torch.log2(torch.arange(2, k + 2, device=device).float())\n","    heldout_batch_nonzero = (heldout_batch > 0).float()\n","    DCG = (heldout_batch_nonzero[torch.arange(batch_users, device=device).unsqueeze(1), idx_topk] * tp).sum(dim=1)\n","    heldout_nonzero = (heldout_batch > 0).sum(dim=1)  # num. of non-zero items per batch. [B]\n","    IDCG = torch.tensor([(tp[:min(n, k)]).sum() for n in heldout_nonzero]).to(device)\n","    return DCG / IDCG\n","\n","\n","def recall_at_k_batch_torch(X_pred, heldout_batch, k=100):\n","    \"\"\"\n","    Recall@k for predictions [B, I] and ground-truth [B, I].\n","    \"\"\"\n","    batch_users = X_pred.shape[0]\n","    _, topk_indices = torch.topk(X_pred, k, dim=1, sorted=False)  # [B, K]\n","    X_pred_binary = torch.zeros_like(X_pred)\n","    if torch.cuda.is_available():\n","        X_pred_binary = X_pred_binary.cuda()\n","    X_pred_binary[torch.arange(batch_users).unsqueeze(1), topk_indices] = 1\n","    X_true_binary = (heldout_batch > 0).float()  # .toarray() #  [B, I]\n","    k_tensor = torch.tensor([k], dtype=torch.float32)\n","    if torch.cuda.is_available():\n","        X_true_binary = X_true_binary.cuda()\n","        k_tensor = k_tensor.cuda()\n","    tmp = (X_true_binary * X_pred_binary).sum(dim=1).float()\n","    recall = tmp / torch.min(k_tensor, X_true_binary.sum(dim=1).float())\n","    return recall"],"metadata":{"id":"8FzcPqcWy20h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_user(model, eval_loader, device, mode='pretrain'):\n","    \"\"\" evaluate model on recommending items to users (primarily during pre-training step) \"\"\"\n","    model.eval()\n","    eval_loss = 0.0\n","    n100_list, r20_list, r50_list = [], [], []\n","    eval_preds = []\n","    with torch.no_grad():\n","        for batch_index, eval_data in enumerate(eval_loader):\n","            eval_data = [x.to(device, non_blocking=True) for x in eval_data]\n","            (users, fold_in_items, held_out_items) = eval_data\n","            fold_in_items = fold_in_items.to(device)\n","            if mode == 'pretrain':\n","                recon_batch, emb = model.user_preference_encoder.pre_train_forward(fold_in_items)\n","            else:\n","                recon_batch = model.group_predictor(model.user_preference_encoder(fold_in_items))\n","\n","            loss = model.multinomial_loss(recon_batch, held_out_items)\n","            eval_loss += loss.item()\n","            fold_in_items = fold_in_items.cpu().numpy()\n","            recon_batch = torch.softmax(recon_batch, 1)  # softmax over the item set to get normalized scores.\n","            recon_batch[fold_in_items.nonzero()] = -np.inf\n","\n","            n100 = ndcg_binary_at_k_batch_torch(recon_batch, held_out_items, 100, device=device)\n","            r20 = recall_at_k_batch_torch(recon_batch, held_out_items, 20)\n","            r50 = recall_at_k_batch_torch(recon_batch, held_out_items, 50)\n","\n","            n100_list.append(n100)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n","\n","            eval_preds.append(recon_batch.cpu().numpy())\n","            del users, fold_in_items, held_out_items, recon_batch\n","    gc.collect()\n","    num_batches = max(1, len(eval_loader.dataset) / eval_loader.batch_size)\n","    eval_loss /= num_batches\n","    n100_list = torch.cat(n100_list)\n","    r20_list = torch.cat(r20_list)\n","    r50_list = torch.cat(r50_list)\n","    return eval_loss, torch.mean(n100_list), torch.mean(r20_list), torch.mean(r50_list), np.array(eval_preds)\n","\n","\n","def evaluate_group(model, eval_group_loader, device):\n","    \"\"\" evaluate model on recommending items to groups \"\"\"\n","    model.eval()\n","    eval_loss = 0.0\n","    n100_list, r20_list, r50_list = [], [], []\n","    eval_preds = []\n","\n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(eval_group_loader):\n","            data = [x.to(device, non_blocking=True) for x in data]\n","            group, group_users, group_mask, group_items, user_items = data\n","            recon_batch, _, _ = model(group, group_users, group_mask, user_items)\n","\n","            loss = model.multinomial_loss(recon_batch, group_items)\n","            eval_loss += loss.item()\n","            result = recon_batch.softmax(1)  # softmax over the item set to get normalized scores.\n","            heldout_data = group_items\n","\n","            r20 = recall_at_k_batch_torch(result, heldout_data, 20)\n","            r50 = recall_at_k_batch_torch(result, heldout_data, 50)\n","            n100 = ndcg_binary_at_k_batch_torch(result, heldout_data, 100, device=device)\n","\n","            n100_list.append(n100)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n","\n","            eval_preds.append(recon_batch.cpu().numpy())\n","            del group, group_users, group_mask, group_items, user_items\n","    gc.collect()\n","\n","    n100_list = torch.cat(n100_list)\n","    r20_list = torch.cat(r20_list)\n","    r50_list = torch.cat(r50_list)\n","    return eval_loss, torch.mean(n100_list), torch.mean(r20_list), torch.mean(r50_list), np.array(eval_preds)"],"metadata":{"id":"mrgOyG7sKRMi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"kl-g_0UuFzqC"}},{"cell_type":"code","source":["import argparse\n","import time\n","import gc\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader"],"metadata":{"id":"soNLg-ekF2Y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n","    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n","    gpu_id = int(np.argmax(memory_available))\n","    torch.cuda.set_device(gpu_id)"],"metadata":{"id":"ZLKloOcQF3UQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Args:\n","\n","    # Dataset\n","    dataset = 'weeplaces'\n","    root = '/content/data'\n","\n","    # Training settings\n","    lr = 5e-3 # initial learning rate\n","    wd = 0.00 # weight decay coefficient\n","    lambda_mi = 1.0 # MI lambda hyper param\n","    drop_ratio = 0.4 # Dropout ratio\n","    batch_size = 256 # batch size\n","    epochs = 20 # maximum # training epochs\n","    eval_freq = 5 # frequency to evaluate performance on validation set\n","\n","    # Model settings\n","    emb_size = 64 # layer size\n","    aggregator = 'attention' # choice of group preference aggregator', choices=['maxpool', 'meanpool', 'attention']\n","    negs_per_group = 5 # negative users sampled per group\n","\n","    # Pre-training settings\n","    pretrain_user = True # Pre-train user encoder on user-item interactions\n","    pretrain_mi = True # Pre-train MI estimator for a few epochs\n","    pretrain_epochs = 10 # pre-train epochs for user encoder layer\n","\n","    cuda = True # use CUDA\n","    seed = 1111 # random seed for reproducibility\n","\n","    # Model save file parameters\n","    save = 'model_user.pt' # path to save the final model\n","    save_group = 'model_group.pt' # path to save the final model\n","\n","args = Args()"],"metadata":{"id":"hwBY4kJkGXm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(args.seed)  # Set the random seed manually for reproducibility.\n","\n","if torch.cuda.is_available():\n","    if not args.cuda:\n","        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"],"metadata":{"id":"bbyhnoy2GLFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###############################################################################\n","# Load data\n","###############################################################################\n","\n","train_params = {'batch_size': args.batch_size, 'shuffle': False, 'num_workers': 2, 'pin_memory': True}\n","eval_params = {'batch_size': args.batch_size, 'shuffle': False, 'num_workers': 2, 'pin_memory': True}\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","\n","# Define train/val/test datasets on user interactions.\n","train_dataset = WeeplacesDataset(args.root, is_group=False, datatype='train')  # train dataset for user-item interactions.\n","n_users, n_items = train_dataset.n_users, train_dataset.n_items\n","val_dataset = WeeplacesDataset(args.root, is_group=False, datatype='val', n_items=n_items)\n","test_dataset = WeeplacesDataset(args.root, is_group=False, datatype='test', n_items=n_items)\n","\n","# Define train/val/test datasets on group and user interactions.\n","train_group_dataset = WeeplacesDataset(args.root, is_group=True, datatype='train', negs_per_group=args.negs_per_group, n_items=n_items)\n","padding_idx = train_group_dataset.padding_idx\n","val_group_dataset = WeeplacesDataset(args.root, is_group=True, datatype='val', n_items=n_items, padding_idx=padding_idx)\n","test_group_dataset = WeeplacesDataset(args.root, is_group=True, datatype='test', n_items=n_items, padding_idx=padding_idx)\n","\n","# Define data loaders on user interactions.\n","train_loader = DataLoader(train_dataset, **train_params)\n","val_loader = DataLoader(val_dataset, **eval_params)\n","test_loader = DataLoader(test_dataset, **eval_params)\n","\n","# Define data loaders on group interactions.\n","train_group_loader = DataLoader(train_group_dataset, **train_params)\n","val_group_loader = DataLoader(val_group_dataset, **eval_params)\n","test_group_loader = DataLoader(test_group_dataset, **eval_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVrUjYsSH0n1","executionInfo":{"status":"ok","timestamp":1640782074661,"user_tz":-330,"elapsed":5215,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5723723d-7f41-4de1-f6cd-5edf255fd60b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# train users 6050 # items 25081\n","# training groups: 15913, # max train group size: 22\n"]}]},{"cell_type":"code","source":["###############################################################################\n","# Build the model\n","###############################################################################\n","\n","user_layers = [args.emb_size]  # user encoder layer configuration is tunable.\n","\n","model = GroupIM(n_items, user_layers, drop_ratio=args.drop_ratio, aggregator_type=args.aggregator,\n","                lambda_mi=args.lambda_mi).to(device)\n","optimizer_gr = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n","\n","best_user_n100, best_group_n100 = -np.inf, -np.inf"],"metadata":{"id":"mZnxV1iJIU2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"bYZBkv7NORbK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if args.pretrain_user:\n","    optimizer_ur = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=args.wd)\n","    print(\"Pre-training model on user-item interactions\")\n","    for epoch in range(0, args.pretrain_epochs):\n","        epoch_start_time = time.time()\n","        model.train()\n","        train_user_loss = 0.0\n","        start_time = time.time()\n","\n","        for batch_index, data in enumerate(train_loader):\n","            optimizer_ur.zero_grad()\n","            data = [x.to(device, non_blocking=True) for x in data]\n","            (train_users, train_items) = data\n","            user_logits, user_embeds = model.user_preference_encoder.pre_train_forward(train_items)\n","            user_loss = model.user_loss(user_logits, train_items)\n","            user_loss.backward()\n","            train_user_loss += user_loss.item()\n","            optimizer_ur.step()\n","            del train_users, train_items, user_logits, user_embeds\n","        elapsed = time.time() - start_time\n","        print('| epoch {:3d} |  time {:4.2f} | loss {:4.2f}'.format(epoch + 1, elapsed,\n","                                                                    train_user_loss / len(train_loader)))\n","        if epoch % args.eval_freq == 0:\n","            val_loss, n100, r20, r50, _ = evaluate_user(model, val_loader, device, mode='pretrain')\n","\n","            if n100 > best_user_n100:\n","                torch.save(model.state_dict(), args.save)\n","                best_user_n100 = n100\n","\n","    print(\"Load best pre-trained user encoder\")\n","    model.load_state_dict(torch.load(args.save))\n","    model = model.to(device)\n","\n","    val_loss, n100, r20, r50, _ = evaluate_user(model, val_loader, device, mode='pretrain')\n","    print('=' * 89)\n","    print('| User evaluation | val loss {:4.4f} | n100 {:4.4f} | r20 {:4.4f} | '\n","            'r50 {:4.4f}'.format(val_loss, n100, r20, r50))\n","    print(\"Initializing group recommender with pre-train user encoder\")\n","    # Initialize the group predictor (item embedding) weight based on the pre-trained user predictor.\n","    model.group_predictor.weight.data = model.user_preference_encoder.user_predictor.weight.data\n","\n","if args.pretrain_mi:\n","    # pre-train MI estimator.\n","    for epoch in range(0, 10):\n","        model.train()\n","        t = time.time()\n","        mi_epoch_loss = 0.0\n","        for batch_index, data in enumerate(train_group_loader):\n","            data = [x.to(device, non_blocking=True) for x in data]\n","            group, group_users, group_mask, group_items, user_items, corrupted_user_items = data\n","            optimizer_gr.zero_grad()\n","            model.zero_grad()\n","            model.train()\n","            _, group_embeds, _ = model(group, group_users, group_mask, user_items)\n","            obs_user_embed = model.user_preference_encoder(user_items).detach()  # [B, G, D]\n","            corrupted_user_embed = model.user_preference_encoder(corrupted_user_items).detach()  # [B, # negs, D]\n","\n","            scores_observed = model.discriminator(group_embeds, obs_user_embed, group_mask)  # [B, G]\n","            scores_corrupted = model.discriminator(group_embeds, corrupted_user_embed, group_mask)  # [B, # negs]\n","\n","            mi_loss = model.discriminator.mi_loss(scores_observed, group_mask, scores_corrupted, device=device)\n","            mi_loss.backward()\n","            optimizer_gr.step()\n","            mi_epoch_loss += mi_loss\n","            del group, group_users, group_mask, group_items, user_items, corrupted_user_items, \\\n","                obs_user_embed, corrupted_user_embed\n","        gc.collect()\n","        print(\"MI loss: {}\".format(float(mi_epoch_loss) / len(train_group_loader)))\n","\n","optimizer_gr = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n","\n","for epoch in range(0, args.epochs):\n","    epoch_start_time = time.time()\n","    model.train()\n","    train_group_epoch_loss = 0.0\n","    for batch_index, data in enumerate(train_group_loader):\n","        data = [x.to(device, non_blocking=True) for x in data]\n","        group, group_users, group_mask, group_items, user_items, corrupted_user_items = data\n","        optimizer_gr.zero_grad()\n","        model.zero_grad()\n","        group_logits, group_embeds, scores_ug = model(group.squeeze(), group_users, group_mask, user_items)\n","        group_loss = model.loss(group_logits, group_embeds, scores_ug, group_mask, group_items, user_items,\n","                                corrupted_user_items, device=device)\n","        group_loss.backward()\n","        train_group_epoch_loss += group_loss.item()\n","        optimizer_gr.step()\n","        del group, group_users, group_mask, group_items, user_items, corrupted_user_items, \\\n","            group_logits, group_embeds, scores_ug\n","\n","    gc.collect()\n","\n","    print(\"Train loss: {}\".format(float(train_group_epoch_loss) / len(train_group_loader)))\n","\n","    if epoch % args.eval_freq == 0:\n","        # Group evaluation.\n","        val_loss_group, n100_group, r20_group, r50_group, _ = evaluate_group(model, val_group_loader, device)\n","\n","        print('-' * 89)\n","        print('| end of epoch {:3d} | time: {:4.2f}s | n100 (group) {:5.4f} | r20 (group) {:5.4f} | r50 (group) '\n","                '{:5.4f}'.format(epoch + 1, time.time() - epoch_start_time, n100_group, r20_group, r50_group))\n","        print('-' * 89)\n","\n","        # Save the model if the n100 is the best we've seen so far.\n","        if n100_group > best_group_n100:\n","            with open(args.save_group, 'wb') as f:\n","                torch.save(model, f)\n","            best_group_n100 = n100_group"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZZUqXQBIzYm","outputId":"acd2ab8f-cf51-440b-f3f9-68f6f9b8e031","executionInfo":{"status":"ok","timestamp":1640785403536,"user_tz":-330,"elapsed":3328901,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pre-training model on user-item interactions\n","| epoch   1 |  time 1.81 | loss 551.25\n","| epoch   2 |  time 1.83 | loss 491.16\n","| epoch   3 |  time 1.85 | loss 462.52\n","| epoch   4 |  time 1.82 | loss 446.23\n","| epoch   5 |  time 1.83 | loss 433.30\n","| epoch   6 |  time 1.79 | loss 422.86\n","| epoch   7 |  time 1.80 | loss 413.78\n","| epoch   8 |  time 1.90 | loss 405.75\n","| epoch   9 |  time 1.81 | loss 398.45\n","| epoch  10 |  time 1.83 | loss 391.82\n","Load best pre-trained user encoder\n","=========================================================================================\n","| User evaluation | val loss 218.1074 | n100 0.2767 | r20 0.2295 | r50 0.3257\n","Initializing group recommender with pre-train user encoder\n","MI loss: 2.164947267562624\n","MI loss: 2.0333072722904264\n","MI loss: 1.993176535954551\n","MI loss: 1.9732029021732391\n","MI loss: 1.9563575623527405\n","MI loss: 1.9452165876116072\n","MI loss: 1.9399088299463665\n","MI loss: 1.9283104548378596\n","MI loss: 1.9230254642547122\n","MI loss: 1.915149870372954\n","Train loss: 15.21117102910602\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 120.55s | n100 (group) 0.2932 | r20 (group) 0.4143 | r50 (group) 0.5469\n","-----------------------------------------------------------------------------------------\n","Train loss: 12.936415006243994\n","Train loss: 12.36263246384878\n","Train loss: 11.967980248587471\n","Train loss: 11.641981654696995\n","Train loss: 11.384485562642416\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 122.55s | n100 (group) 0.4271 | r20 (group) 0.5974 | r50 (group) 0.7124\n","-----------------------------------------------------------------------------------------\n","Train loss: 11.143094183906676\n","Train loss: 10.976203191848029\n","Train loss: 10.801382503812276\n","Train loss: 10.679489877488878\n","Train loss: 10.587046698918419\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 115.36s | n100 (group) 0.4728 | r20 (group) 0.6421 | r50 (group) 0.7480\n","-----------------------------------------------------------------------------------------\n","Train loss: 10.498487517947243\n","Train loss: 10.421664782932826\n","Train loss: 10.346160071236747\n","Train loss: 10.296602052355569\n","Train loss: 10.24328315068805\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 122.33s | n100 (group) 0.4916 | r20 (group) 0.6602 | r50 (group) 0.7651\n","-----------------------------------------------------------------------------------------\n","Train loss: 10.204238316369436\n","Train loss: 10.142736480349587\n","Train loss: 10.116823786780948\n","Train loss: 10.0895657766433\n"]}]},{"cell_type":"code","source":["# Load the best saved model.\n","with open(args.save_group, 'rb') as f:\n","    model = torch.load(f, map_location='cuda')\n","    model = model.to(device)\n","\n","# Best validation evaluation\n","val_loss, n100, r20, r50, _ = evaluate_user(model, val_loader, device, mode='group')\n","print('=' * 89)\n","print('| User evaluation | val loss {:4.4f} | n100 {:4.4f} | r20 {:4.4f} | r50 {:4.4f}'\n","      .format(val_loss, n100, r20, r50))\n","\n","# Test evaluation\n","test_loss, n100, r20, r50, _ = evaluate_user(model, test_loader, device, mode='group')\n","print('=' * 89)\n","print('| User evaluation | test loss {:4.4f} | n100 {:4.4f} | r20 {:4.4f} | r50 {:4.4f}'\n","      .format(test_loss, n100, r20, r50))\n","\n","print('=' * 89)\n","_, n100_group, r20_group, r50_group, _ = evaluate_group(model, val_group_loader, device)\n","print('| Group evaluation (val) | n100 (group) {:4.4f} | r20 (group) {:4.4f} | r50 (group) {:4.4f}'\n","      .format(n100_group, r20_group, r50_group))\n","\n","print('=' * 89)\n","_, n100_group, r20_group, r50_group, _ = evaluate_group(model, test_group_loader, device)\n","print('| Group evaluation (test) | n100 (group) {:4.4f} | r20 (group) {:4.4f} | r50 (group) {:4.4f}'\n","      .format(n100_group, r20_group, r50_group))"],"metadata":{"id":"z7MeW-auK822","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2382dde5-3852-4e53-f4c4-b7320761dba2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","| User evaluation | val loss 253.6573 | n100 0.3344 | r20 0.2670 | r50 0.3349\n","=========================================================================================\n","| User evaluation | test loss 235.2826 | n100 0.3255 | r20 0.2735 | r50 0.3307\n","=========================================================================================\n","| Group evaluation (val) | n100 (group) 0.4916 | r20 (group) 0.6602 | r50 (group) 0.7651\n","=========================================================================================\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"1y5VtjP9cDjn"}},{"cell_type":"code","source":["!apt-get -qq install tree"],"metadata":{"id":"ErtS_8LncDjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tree -h --du -C ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPdV96gQcDjq","executionInfo":{"status":"ok","timestamp":1640785622982,"user_tz":-330,"elapsed":536,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"cbde2ebb-8ae3-4099-ec9f-5c1beaa4bdb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34m.\u001b[00m\n","├── [9.1M]  \u001b[01;34mdata\u001b[00m\n","│   └── [9.1M]  \u001b[01;34mraw\u001b[00m\n","│       ├── [2.5M]  \u001b[01;31mdata.zip\u001b[00m\n","│       ├── [794K]  group_users.csv\n","│       ├── [156K]  test_gi.csv\n","│       ├── [433K]  test_ui_te.csv\n","│       ├── [635K]  test_ui_tr.csv\n","│       ├── [498K]  train_gi.csv\n","│       ├── [3.5M]  train_ui.csv\n","│       ├── [ 72K]  val_gi.csv\n","│       ├── [205K]  val_ui_te.csv\n","│       └── [300K]  val_ui_tr.csv\n","├── [ 12M]  model_group.pt\n","├── [ 18M]  model_user.pt\n","└── [  54]  tmp\n","\n","  40M used in 2 directories, 13 files\n"]}]},{"cell_type":"code","source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DD0Xu8BocDjs","executionInfo":{"status":"ok","timestamp":1640785647137,"user_tz":-330,"elapsed":3387,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"805706f3-e262-4530-88ff-2a8923441c1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-12-29 13:47:25\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.144+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","recohut : 0.0.8\n","IPython : 5.5.0\n","pandas  : 1.1.5\n","scipy   : 1.4.1\n","numpy   : 1.19.5\n","argparse: 1.1\n","torch   : 1.10.0+cu111\n","\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"6ws-JR3acDjt"}},{"cell_type":"markdown","source":["**END**"],"metadata":{"id":"dYtXGUdocDju"}}]}