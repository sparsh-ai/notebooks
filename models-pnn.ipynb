{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.pnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product-based Neural Network (PNN)\n",
    "> A pytorch implementation of inner/outer Product Neural Network.\n",
    "\n",
    "PNN uses an embedding layer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between inter-field categories, and further fully connected layers to explore high-order feature interactions.\n",
    "\n",
    "<img src='https://github.com/RecoHut-Stanzas/S021355/raw/main/images/img8.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from recohut.models.layers.embedding import EmbeddingLayer\n",
    "from recohut.models.layers.common import MLP_Layer\n",
    "from recohut.models.layers.interaction import InnerProductLayer\n",
    "\n",
    "from recohut.models.bases.ctr import CTRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PNN(CTRModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"PNN\",\n",
    "                 task=\"binary_classification\",\n",
    "                 learning_rate=1e-3, \n",
    "                 embedding_initializer=\"torch.nn.init.normal_(std=1e-4)\",\n",
    "                 embedding_dim=10,\n",
    "                 hidden_units=[64, 64, 64], \n",
    "                 hidden_activations=\"ReLU\", \n",
    "                 net_dropout=0, \n",
    "                 batch_norm=False, \n",
    "                 product_type=\"inner\", \n",
    "                 **kwargs):\n",
    "        super(PNN, self).__init__(feature_map, \n",
    "                                           model_id=model_id,\n",
    "                                           **kwargs)\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        if product_type != \"inner\":\n",
    "            raise NotImplementedError(\"product_type={} has not been implemented.\".format(product_type))\n",
    "        self.inner_product_layer = InnerProductLayer(feature_map.num_fields, output=\"inner_product\")\n",
    "        input_dim = int(feature_map.num_fields * (feature_map.num_fields - 1) / 2) \\\n",
    "                  + feature_map.num_fields * embedding_dim\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=1, \n",
    "                             hidden_units=hidden_units,\n",
    "                             hidden_activations=hidden_activations,\n",
    "                             output_activation=self.get_final_activation(task),\n",
    "                             dropout_rates=net_dropout, \n",
    "                             batch_norm=batch_norm, \n",
    "                             use_bias=True) \n",
    "        self.init_weights(embedding_initializer=embedding_initializer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature_emb = self.embedding_layer(inputs)\n",
    "        inner_product_vec = self.inner_product_layer(feature_emb)\n",
    "        dense_input = torch.cat([feature_emb.flatten(start_dim=1), inner_product_vec], dim=1)\n",
    "        y_pred = self.dnn(dense_input)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNN(ds.dataset.feature_map, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name                | Type              | Params\n",
      "----------------------------------------------------------\n",
      "0 | embedding_layer     | EmbeddingLayer    | 4.8 K \n",
      "1 | inner_product_layer | InnerProductLayer | 378   \n",
      "2 | dnn                 | MLP_Layer         | 250 K \n",
      "----------------------------------------------------------\n",
      "255 K     Trainable params\n",
      "378       Non-trainable params\n",
      "255 K     Total params\n",
      "1.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9cc2d93d9047e88aa2170407b1d267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99df35967bc4b45add0792e8b92d512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c0e16f0d9446080ca0a92e84ff09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.1413)}}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.1413)}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_trainer(model, ds, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'model_id': 'PNN',\n",
    "              'data_dir': '/content/data',\n",
    "              'model_root': './checkpoints/',\n",
    "              'learning_rate': 1e-3,\n",
    "              'optimizer': 'adamw',\n",
    "              'task': 'binary_classification',\n",
    "              'loss': 'binary_crossentropy',\n",
    "              'metrics': ['logloss', 'AUC'],\n",
    "              'optimizer': 'adamw',\n",
    "              'hidden_units': [300, 300, 300],\n",
    "              'hidden_activations': 'relu',\n",
    "              'batch_size': 64,\n",
    "              'epochs': 3,\n",
    "              'shuffle': True,\n",
    "              'seed': 2019,\n",
    "              'use_hdf5': True,\n",
    "              'workers': 1,\n",
    "              'verbose': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "\n",
    "from recohut.models.layers.common import FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InnerProductNetwork(torch.nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        num_fields = x.shape[1]\n",
    "        row, col = list(), list()\n",
    "        for i in range(num_fields - 1):\n",
    "            for j in range(i + 1, num_fields):\n",
    "                row.append(i), col.append(j)\n",
    "        return torch.sum(x[:, row] * x[:, col], dim=2)\n",
    "\n",
    "\n",
    "class OuterProductNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_fields, embed_dim, kernel_type='mat'):\n",
    "        super().__init__()\n",
    "        num_ix = num_fields * (num_fields - 1) // 2\n",
    "        if kernel_type == 'mat':\n",
    "            kernel_shape = embed_dim, num_ix, embed_dim\n",
    "        elif kernel_type == 'vec':\n",
    "            kernel_shape = num_ix, embed_dim\n",
    "        elif kernel_type == 'num':\n",
    "            kernel_shape = num_ix, 1\n",
    "        else:\n",
    "            raise ValueError('unknown kernel type: ' + kernel_type)\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel = torch.nn.Parameter(torch.zeros(kernel_shape))\n",
    "        torch.nn.init.xavier_uniform_(self.kernel.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        num_fields = x.shape[1]\n",
    "        row, col = list(), list()\n",
    "        for i in range(num_fields - 1):\n",
    "            for j in range(i + 1, num_fields):\n",
    "                row.append(i), col.append(j)\n",
    "        p, q = x[:, row], x[:, col]\n",
    "        if self.kernel_type == 'mat':\n",
    "            kp = torch.sum(p.unsqueeze(1) * self.kernel, dim=-1).permute(0, 2, 1)\n",
    "            return torch.sum(kp * q, -1)\n",
    "        else:\n",
    "            return torch.sum(p * q * self.kernel.unsqueeze(0), -1)\n",
    "\n",
    "class PNN_v2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A pytorch implementation of inner/outer Product Neural Network.\n",
    "    Reference:\n",
    "        Y Qu, et al. Product-based Neural Networks for User Response Prediction, 2016.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims, dropout, method='inner'):\n",
    "        super().__init__()\n",
    "        num_fields = len(field_dims)\n",
    "        if method == 'inner':\n",
    "            self.pn = InnerProductNetwork()\n",
    "        elif method == 'outer':\n",
    "            self.pn = OuterProductNetwork(num_fields, embed_dim)\n",
    "        else:\n",
    "            raise ValueError('unknown product type: ' + method)\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.linear = FeaturesLinear(field_dims, embed_dim)\n",
    "        self.embed_output_dim = num_fields * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(num_fields * (num_fields - 1) // 2 + self.embed_output_dim, mlp_dims, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        embed_x = self.embedding(x)\n",
    "        cross_term = self.pn(embed_x)\n",
    "        x = torch.cat([embed_x.view(-1, self.embed_output_dim), cross_term], dim=1)\n",
    "        x = self.mlp(x)\n",
    "        return torch.sigmoid(x.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **References:-**\n",
    "- Y Qu, et al. Product-based Neural Networks for User Response Prediction, 2016. https://arxiv.org/abs/1611.00144.\n",
    "- https://github.com/rixwew/pytorch-fm/blob/master/torchfm/model/pnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
