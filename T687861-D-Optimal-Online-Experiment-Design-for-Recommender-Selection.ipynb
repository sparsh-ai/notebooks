{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T687861 | D-Optimal Online Experiment Design for Recommender Selection","provenance":[{"file_id":"1n8Qp9JVZ6p4MHhPc5XAErlo3otRhJedE","timestamp":1638731076535},{"file_id":"1noqvdndIt6Y6hwWizVg3PlYbOVul_jSw","timestamp":1628355127982}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1n8Qp9JVZ6p4MHhPc5XAErlo3otRhJedE","authorship_tag":"ABX9TyPVczJcmIFmkeG3WVdoaKqK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# T687861 | D-Optimal Online Experiment Design for Recommender Selection"],"metadata":{"id":"ThCX3ftiawxr"}},{"cell_type":"markdown","source":["## Executive summary\n","\n","| | |\n","| --- | --- |\n","| Problem | Traditional A/B testing method for model selection is slow and costly. |\n","| Hypothesis | Selecting the optimal recommender via online exploration-exploitation is better than the traditional A/B testing, as this traditional method can be slow and costly, and offline evaluations are prone to the bias of history data. |\n","| Solution | Leverage the D-optimal design from the classical statistics literature to achieve the maximum information gain during exploration. Data-generating mechanism - In the beginning stage, 10% of the full data is selected as the training data to fit the candidate recommendation models, and the rest of the data is treated as the testing set which generates the interaction data adaptively. The procedure can be described as follow. In each epoch, we recommend one item to each user. If the item has received a non-zero rating from that particular user in the testing data, we move it to the training data and endow it with a positive label if the rating is high, e.g. ≥ 3 under the five-point scale. Otherwise, we add the item to the rejection list and will not recommend it to this user again. After each epoch, we retrain the candidate models with both the past and the newly collected data. Candidate models - user-based CF, item-based CF, ItemPop, MF. |\n","| Dataset | ML-1m |\n","| Preprocessing | The movie ratings are binarized to {0, 1}, i.e. ≥ 2.5 or < 2.5, and we use the metadata of movies and users as the contextual information for the reward model. In particular, we perform the one-hot transformation for the categorical data to obtain the feature mappings 𝝓(·). For text features such as movie title, we train a word embedding model with 50 dimensions. The final representation is obtained by concatenating all the one-hot encoding and embedding. |\n","| Metrics | Cumulative Recall (the ratio of the total number of successful recommendations (up to the current epoch) against the total number of positive rating in the testing data). |\n","| Cluster | Platform - Python 3, Lib - gensim, acgan. |\n","| Tags | `OnlineEvaluation`, `MultiArmedBandit`, `MovieLens`, `Simulation` |\n","| Links | [Paper (arXiv)](https://arxiv.org/abs/2110.12132v1), [Repo (git)](https://github.com/RecoHut-Stanzas/S691423) |"],"metadata":{"id":"1ouiSbM43xUY"}},{"cell_type":"markdown","metadata":{"id":"bfzyTqq3LfQe"},"source":["## Process flow"]},{"cell_type":"markdown","metadata":{"id":"MrvxgcfnLhCV"},"source":["<img src='https://github.com/RecoHut-Stanzas/S691423/raw/main/images/process_flow_main.svg'>"]},{"cell_type":"markdown","metadata":{"id":"_XBTIV7ZtYdc"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"ilof-Bk8hxmh"},"source":["### Install acgan library"]},{"cell_type":"code","metadata":{"id":"EJAJqNmSVvUb"},"source":["!mkdir acganlib && git clone https://github.com/richardruancw/Adversarial-Counterfactual-Learning-and-Evaluation-for-Recommender-System.git acganlib\n","!cd acganlib && pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRofXkbDh9OW"},"source":["### Download ML-1m dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anVyAveJVunb","executionInfo":{"status":"ok","timestamp":1638770697944,"user_tz":-330,"elapsed":525,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"abe7bd53-e610-4f1e-c361-6fd9b5565637"},"source":["!wget -q --show-progress http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n"]}]},{"cell_type":"markdown","metadata":{"id":"m4dWfBGgiA22"},"source":["### Import required libraries"]},{"cell_type":"code","metadata":{"id":"PYyfYHHdiEN0"},"source":["from __future__ import annotations\n","from typing import Dict, Any, List, Set, Tuple, Optional, Union, cast\n","\n","import os \n","import json\n","import time\n","from pathlib import Path\n","from tqdm import tqdm\n","import sys\n","import random \n","\n","import numpy as np\n","import pandas as pd\n","from scipy import sparse as sp\n","from sklearn.preprocessing import LabelEncoder\n","from matplotlib import pyplot as plt\n","\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","from acgan.recommender import Recommender\n","from acgan.recommender import PopRecommenderV2, SVDRecommenderV2, UserBasedKnn, ContextItemKnn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XnSv_Lknj0F6"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"8CiV8l0Xj-ma"},"source":["# numpy floating-point precision\n","np.set_printoptions(precision=4)\n","\n","# create output folder to store plots and json results\n","Path('./output').mkdir(parents=True, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8C6USmcj0D0"},"source":["class Args:\n","    \"\"\"default arguments\"\"\"\n","    dim = 20\n","    topk = 1\n","    num_epochs = 10 # recommender 200 for optimal performance\n","    epsilon = 0.1\n","    explore_step = 500\n","    feat_map = 'onehot_context' # choices=['onehot', 'context', 'armed_context', 'onehot_context']\n","    algo = 'lin_ct' # choices=['base', 'e_greedy', 'thompson', 'lin_ct', 'optimal']\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Config\n","\n","Taking inputs from user."],"metadata":{"id":"gpq3djdEcoTZ"}},{"cell_type":"code","metadata":{"id":"jJelcDHWk7Mk"},"source":["args.dim = int(input('Embedding dimensions (default=20,type=int):') or '20')\n","\n","args.topk = int(input('Top-K (default=1,type=int):') or '1')\n","\n","args.num_epochs = int(input('No. of epochs (default=10,recommended=200,type=int):') or '10')\n","\n","args.epsilon = float(input('Epsilon (default=0.1,type=float,range=0-1):') or '0.1')\n","\n","args.explore_step = int(input('explore_step (default=500,type=int):') or '500')\n","\n","args.feat_map = input('feat_map (default=onehot_context,choices=onehot/context/armed_context/onehot_context,type=str):') or 'onehot_context'\n","assert(args.feat_map in 'onehot/context/armed_context/onehot_context'.split('/')), 'Invalid feat_map'\n","\n","args.algo = input('algo (default=lin_ct,choices=base/e_greedy/thompson/lin_ct/optimal,type=str):') or 'lin_ct'\n","assert(args.algo in 'base/e_greedy/thompson/lin_ct/optimal'.split('/')), 'Invalid algo'\n","\n","print('Running on these Params: {}'.format([{k:v} for k,v in dict(Args.__dict__).items() if not k.startswith('__')]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"COUjXg3ysn7i"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"S1j2tB8RVvYc"},"source":["We need to generate the movies and users features before running the simulations."]},{"cell_type":"code","metadata":{"id":"_YhUuVW9XxQ5"},"source":["data_path='ml-1m'\n","names = ['uidx', 'iidx', 'rating', 'ts']\n","dtype = {'uidx':int, 'iidx':int, 'rating':float, 'ts':float}\n","data_df = pd.read_csv(os.path.join(data_path, 'ratings.dat'), sep='::', names=names, dtype=dtype, engine='python')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEXkZvhzX_af","executionInfo":{"status":"ok","timestamp":1638771288294,"user_tz":-330,"elapsed":464,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"006c787a-fb87-4bcb-e22e-f2de18305d10"},"source":["# rating 4.0,5.0 -> 1.0, and 1.0,2.0,3.0 -> 0.0\n","data_df['rating'] = (data_df['rating'] >= 4).astype(np.float32)\n","\n","user_num, item_num = data_df.uidx.max() + 1, data_df.iidx.max() + 1\n","print('Before label encoding/correction: user_num={}, item_num={}'.format(user_num, item_num))\n","\n","uidx_encoder = LabelEncoder()\n","iidx_encoder = LabelEncoder()\n","data_df.uidx = uidx_encoder.fit_transform(data_df.uidx)\n","data_df.iidx = iidx_encoder.fit_transform(data_df.iidx)\n","\n","user_num, item_num = data_df.uidx.max() + 1, data_df.iidx.max() + 1\n","\n","print(len(uidx_encoder.classes_))\n","print('After label encoding/correction: user_num={}, item_num={}'.format(user_num, item_num))\n","data_df.to_feather(os.path.join(data_path, 'ratings.feather'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6041 3953\n","6040\n","6040 3706\n"]}]},{"cell_type":"code","metadata":{"id":"KUti9FMdYWNL"},"source":["def movie():\n","    # feature engineering for movies\n","    train_corpus = []\n","    with open(os.path.join(data_path, 'movies.dat'), encoding='ISO-8859-1') as f:\n","        for line in f:\n","            iidx_raw, title_raw, genre_raw = line.strip().split('::')\n","            try:\n","                iidx = int(iidx_encoder.transform([int(iidx_raw)])[0])\n","            except ValueError:\n","                continue\n","            genre_str = genre_raw.strip().replace('|', ' ')\n","            doc = simple_preprocess(title_raw + genre_str)\n","            train_corpus.append(TaggedDocument(doc, [iidx]))\n","\n","    model = Doc2Vec(vector_size=50, min_count=2, epochs=20)\n","    model.build_vocab(train_corpus)\n","    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n","    context_embedding = np.zeros((item_num, 50))\n","    for i in range(item_num):\n","        context_embedding[i, :] = model.docvecs.vectors_docs[i]\n","    np.save(os.path.join(data_path,'item_feat.npy'), context_embedding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0yEPNj1YkH6"},"source":["movie()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_ge6z0qYgU2"},"source":["def user():\n","    # feature engineering for users\n","    # UserID::Gender::Age::Occupation::Zip-code\n","    gender_set = set()\n","    occu_set = set()\n","    zipcode_set = set()\n","    age_set = set()\n","    data = []\n","    max_idx = 0\n","    with open(os.path.join(data_path, 'users.dat'), encoding='ISO-8859-1') as f:\n","        for line in f:\n","            puidx, gender, age, occupation, zipcode = line.strip().split('::')\n","            uidx = uidx_encoder.transform([int(puidx)])[0]\n","            \n","            max_idx = max(max_idx, uidx)\n","            # assert(uidx < user_num)\n","            gender_set.add(gender)\n","            age_set.add(age)\n","            occu_set.add(occupation)\n","            zipcode_set.add(zipcode)\n","            data.append([uidx, gender, age, occupation, zipcode])\n","    print(max_idx)\n","    gender_encoder = LabelEncoder().fit(list(gender_set))\n","    gender_feat = np.zeros((user_num, len(gender_set)))\n","\n","    age_encoder = LabelEncoder().fit(list(age_set))\n","    age_feat = np.zeros((user_num, len(age_set)))\n","\n","    occu_encoder = LabelEncoder().fit(list(occu_set))\n","    occu_feat = np.zeros((user_num, len(occu_set)))\n","\n","    zipcode_encoder = LabelEncoder().fit(list(zipcode_set))\n","    zipcode_feat = np.zeros((user_num, len(zipcode_set)))\n","\n","    for uidx, gender, age, occupation, zipcode in data:\n","        gender = gender_encoder.transform([gender])[0]\n","        gender_feat[uidx, gender] += 1\n","\n","        age = age_encoder.transform([age])[0]\n","        age_feat[uidx, age] += 1\n","\n","        occupation = occu_encoder.transform([occupation])[0]\n","        occu_feat[uidx, age] += 1\n","\n","        zipcode = zipcode_encoder.transform([zipcode])[0]\n","        zipcode_feat[uidx, zipcode] += 1\n","\n","    user_context = np.concatenate([gender_feat, age_feat, occu_feat], axis=1)\n","    print(f'user_context shape: {user_context.shape}')\n","    np.save(os.path.join(data_path,'user_feat.npy'), user_context)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYzNI1MbYgrV","executionInfo":{"status":"ok","timestamp":1638771376785,"user_tz":-330,"elapsed":23272,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"eeea3911-d793-42cc-f2e8-140a2a3a6b3a"},"source":["user()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6039\n","user_context shape: (6040, 30)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mu9KalHtZqkh"},"source":["## Bandits"]},{"cell_type":"code","metadata":{"id":"nfyyEnLDjGrI"},"source":["BanditData = List[Tuple[int, float, Any]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ci38WDtSZqhL"},"source":["class Bandit:\n","    def __init__(self, recom_list: List[Recommender]):\n","        self.recom_list = recom_list\n","        self.k = len(self.recom_list)\n","\n","    def get_arm(self, arm: int) -> Recommender:\n","        return self.recom_list[arm]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FQ1dILcrqEb"},"source":["class BanditAlgorithm:\n","    \"\"\"Implement the interfaces for any bandit algorithms evaluated.\"\"\"\n","    def __init__(self, num_arms: int, rng: Optional[np.random.RandomState] = None):\n","        self.num_arms = num_arms\n","        if rng is None:\n","            self.rng = np.random.RandomState()\n","        self.total_reward_per_arm = np.zeros(num_arms)\n","        self.total_cnt_per_arm = np.zeros(num_arms)\n","        self.curr_cnt_per_arm = np.zeros(num_arms)\n","        self.avg_reward_per_arm = np.zeros(num_arms)\n","        self.arm_arr = np.arange(num_arms)\n","\n","    def predict(self, *args, **kwds) -> int:\n","        \"\"\"Return the estimated return for contextual bandit\"\"\"\n","        raise NotImplementedError()\n","\n","    def update(self, data: BanditData):\n","        \"\"\"Update the algorithms based on observed (action, reward, context)\"\"\"\n","        raise NotImplementedError()\n","\n","    def record_metric(self, data: BanditData):\n","        \"\"\"Record the cumulative performance metrics for this algorithm\"\"\"\n","        self.curr_cnt_per_arm *= 0\n","        for arm, reward, _ in data:\n","            self.total_reward_per_arm[arm] += reward\n","            self.total_cnt_per_arm[arm] += 1\n","            self.curr_cnt_per_arm[arm] += 1\n","        valid = self.total_cnt_per_arm > 0\n","        self.avg_reward_per_arm[valid] = self.total_reward_per_arm[valid] / self.total_cnt_per_arm[valid]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFxGFUQRrryr"},"source":["class RandomBandit(BanditAlgorithm):\n","    def __init__(self, num_arms: int):\n","        super(RandomBandit, self).__init__(num_arms)\n","\n","    def update(self, data: BanditData):\n","        pass\n","\n","    def predict(self):\n","        return int(self.rng.randint(0, self.num_arms))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YmBBHj4LrtVp"},"source":["class EpsilonGreedy(BanditAlgorithm):\n","    def __init__(self, num_arms: int, epsilon: float):\n","        super(EpsilonGreedy, self).__init__(num_arms)\n","        self.epsilon = epsilon\n","\n","    def update(self, data: BanditData):\n","        pass\n","\n","    def predict(self):\n","        if self.rng.rand() <= self.epsilon: # exploration\n","            arm = self.rng.randint(0, self.num_arms)\n","        else: # exploitation - pull the best arm\n","            max_value = self.avg_reward_per_arm.max()\n","            best_arms = self.arm_arr[self.avg_reward_per_arm == max_value]\n","            if (best_arms).sum() > 1:\n","                #break ties randomly\n","                arm = best_arms[np.random.randint(0, len(best_arms))]\n","            else:\n","                arm = best_arms[0]\n","        return arm "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxGPuaCwruJQ"},"source":["class ThompsonSampling(BanditAlgorithm):\n","    def __init__(self, num_arms: int):\n","        super(ThompsonSampling, self).__init__(num_arms)\n","        # alpha,beta are params for beta-distribution, just like mu,siga for normal-distribution\n","        self.alpha = np.ones(num_arms) * 1000\n","        self.beta = np.ones(num_arms)\n","\n","    def update(self, data: BanditData):\n","        for arm, reward, _ in data:\n","            if reward > 0:\n","                self.alpha[arm] += 1\n","            else:\n","                self.beta[arm] += 1\n","\n","    def predict(self):\n","        theta = self.rng.beta(self.alpha, self.beta)\n","        max_value = theta.max()\n","        best_arms = self.arm_arr[theta == max_value]\n","        if (best_arms).sum() > 1:\n","            #break ties randomly\n","            arm = best_arms[np.random.randint(0, len(best_arms))]\n","        else:\n","            arm = best_arms[0]\n","        return arm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJtJYVm2rvD-"},"source":["class Contextual(BanditAlgorithm):\n","    def __init__(self, num_arms: int, feat_dim: int, lambda_: float = 0.001, ucb_weight: float = 0.00):\n","        super(Contextual, self).__init__(num_arms)\n","        self.feat_dim = feat_dim\n","        self.ucb_weight = ucb_weight\n","        self.context_cov = np.zeros((feat_dim, feat_dim))\n","        self.cumu_feat = np.zeros(feat_dim)\n","        self.theta = np.zeros(feat_dim)\n","        self.inv_v = np.eye(feat_dim)\n","        self.lambda_I = lambda_ * np.eye(feat_dim)\n","\n","    def predict(self, feature):\n","        rest = self.theta.dot(feature) \n","        if self.ucb_weight > 0.0001:\n","            rest += self.ucb_weight * np.sqrt(feature.dot(self.inv_v).dot(feature))\n","        return rest\n","\n","    def update(self, data: BanditData):\n","        for arm, reward, feature in data:\n","            self.cumu_feat += feature * reward\n","            self.context_cov += feature.reshape(-1, 1).dot(feature.reshape(1, -1))\n","        #self.theta = np.linalg.solve(self.lambda_I + self.context_cov, self.cumu_feat)\n","        self.inv_v = np.linalg.inv(self.lambda_I + self.context_cov)\n","        self.theta = self.inv_v.dot(self.cumu_feat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nwJUyKtrwBN"},"source":["class OptimalDesign(BanditAlgorithm):\n","    def __init__(self, num_arms: int, feat_dim: int, lambda_: float = 0.001, ucb_weight: float = 0.00):\n","        super(OptimalDesign, self).__init__(num_arms)\n","        self.feat_dim = feat_dim\n","        self.ucb_weight = ucb_weight\n","        self.lambda_I = lambda_ * np.eye(feat_dim)\n","        self.context_cov = np.zeros((feat_dim, feat_dim))\n","        self.cumu_feat = np.zeros(feat_dim)\n","        self.theta = np.random.rand(feat_dim)\n","        self.clear_buffer()\n","\n","    def predict(self, feature):\n","        \"\"\"Predict the reward for the arm\n","        \"\"\"\n","        return self.theta.dot(feature) + self.ucb_weight * np.sqrt(feature.dot(self.inv_v).dot(feature))\n","\n","    def update(self, data: BanditData):\n","        \"\"\"Update prediction perameters\n","        \"\"\"\n","        #self.theta = np.linalg.solve(self.lambda_I + self.context_cov, self.cumu_feat)\n","        for arm, reward, feature in data:\n","            self.cumu_feat += feature * reward\n","            self.context_cov += feature.reshape(-1, 1).dot(feature.reshape(1, -1))\n","        self.inv_v = np.linalg.inv(self.lambda_I + self.context_cov)\n","        self.theta = self.inv_v.dot(self.cumu_feat)\n","\n","    def clear_buffer(self):\n","        feat_dim = self.feat_dim\n","        self.explore_context_cov = np.zeros((feat_dim, feat_dim))\n","        self.context_cov = np.zeros((feat_dim, feat_dim))\n","        self.cumu_feat = np.zeros(feat_dim)\n","        #self.inv_v = np.eye(feat_dim)\n","    \n","    def explore_decision(self, feat_mat: np.ndarray) -> int:\n","        \"\"\"Find the arm that maximize the log(det(V(pi)))\n","        \"\"\"\n","        det_v_arr = np.zeros(self.num_arms)\n","        for arm in range(self.num_arms):\n","            feature = feat_mat[arm, :]\n","            det_v_arr[arm] = np.linalg.det(self.lambda_I + self.explore_context_cov + feature.reshape(-1, 1).dot(feature.reshape(1, -1)))\n","        \n","        arm = det_v_arr.argmax()\n","        feature = feat_mat[arm, :]\n","        self.explore_context_cov += feature.reshape(-1, 1).dot(feature.reshape(1, -1))\n","        return arm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJfXY2wTZqeY"},"source":["## Environment"]},{"cell_type":"code","metadata":{"id":"9VKtbEuVbzjM"},"source":["class Environment:\n","    def __init__(self, user_num: int, item_num: int, data_df: pd.DataFrame, init_ratio: float = 0.05):\n","        # sample initial data and build user history profile.\n","        self.user_num = user_num\n","        self.item_num = item_num\n","        self.item_candidate = list(range(item_num))\n","        self.data_df = data_df\n","        self.user_full_hist_dict = data_df.groupby('uidx').apply(lambda x: set(x.iidx)).to_dict()\n","        self.curr_df = data_df.sample(n=int(data_df.shape[0] * 0.05))\n","        self.init_test_relevant_size = self.data_df[self.data_df.rating > 0].shape[0] - self.curr_df.shape[0]\n","\n","        self.user_curr_hist_dict = self.curr_df.groupby('uidx').apply(lambda x: set(x.iidx)).to_dict()\n","        self.user_curr_reject_dict: Dict[int, Set[int]] = {}\n","\n","        self.rating_dict = {(uidx, iidx):rating for uidx, iidx, rating in zip(data_df.uidx, data_df.iidx, data_df.rating)}\n","        assert(len(self.rating_dict) == len(data_df))\n","\n","        print(f'avg_user_hist_length: {np.mean([len(v) for v in self.user_full_hist_dict.values()])}')\n","        print(f'avg_user_init_hist_length: {np.mean([len(v) for v in self.user_curr_hist_dict.values()])}')\n","\n","        print(self.curr_df.groupby('uidx').count().iidx.mean())\n","        print('build initial recall set')\n","        self.user_recall_dict: Dict[int, List[int]] = {}\n","        for uidx in self.user_full_hist_dict.keys():\n","            self.user_recall_dict[uidx] = self.item_candidate.copy()\n","        print('--initial filter')\n","        for uidx in self.user_recall_dict.keys():\n","            past_set = self.user_curr_hist_dict.get(uidx, set())\n","            self.user_recall_dict[uidx] = [x for x in self.user_recall_dict[uidx] if x not in past_set]\n","\n","    def get_epoch(self, shuffle: bool = True):\n","        return EpochIter(self, shuffle)\n","\n","    def action(self, uidx: int, recommendations: List[int]) -> float:\n","        num_match = 0\n","        for item in recommendations:\n","            assert(item not in self.user_curr_hist_dict.get(uidx, []))\n","            assert(item not in self.user_curr_reject_dict.get(uidx, []))\n","            if item in self.user_full_hist_dict[uidx]:\n","                # mark as positive if the user has positive feedbacks in the test and add to history\n","                num_match += self.rating_dict[(uidx, item)]\n","                if uidx not in self.user_curr_hist_dict:\n","                    self.user_curr_hist_dict[uidx] = set()\n","                self.user_curr_hist_dict[uidx].add(item)\n","            else:\n","                # include to the user's reject history so that dont recommend it again\n","                if uidx not in self.user_curr_reject_dict:\n","                    self.user_curr_reject_dict[uidx] = set()\n","                self.user_curr_reject_dict[uidx].add(item)\n","        reward = float(num_match > 0)\n","        return reward\n","\n","    def _update_recall(self):\n","        #update the user recall set\n","        print('filter recall at the end of epoch')\n","        for uidx in self.user_recall_dict.keys():\n","            reject_set = self.user_curr_reject_dict.get(uidx, set())\n","            past_set = self.user_curr_hist_dict.get(uidx, set())\n","            self.user_recall_dict[uidx] = [x for x in self.user_recall_dict[uidx] if x not in reject_set and x not in past_set]\n","        avg_recall_length = np.mean([len(v) for v in self.user_recall_dict.values()])\n","\n","    def get_train(self):\n","        #re-build the data-frame\n","        u_list, i_list = [], []\n","        for uidx, item_set in self.user_curr_hist_dict.items():\n","            u_list.extend([uidx] * len(item_set))\n","            i_list.extend(list(item_set))\n","        new_df = pd.DataFrame({'uidx': u_list, 'iidx': i_list, \n","        'rating': np.ones(len(u_list)), 'ts': np.ones(len(u_list))})\n","        return new_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2j0baXN9bzmS"},"source":["class EpochIter:\n","    def __init__(self, env: Environment, shuffle: bool):\n","        self.env = env\n","        self.user_lists = list(env.user_full_hist_dict.keys())\n","        self.ptr = 0\n","        self.shuffle = shuffle\n","\n","    def __next__(self) -> Tuple[int, List[int]]:\n","        if self.ptr < len(self.user_lists):\n","            user = self.user_lists[self.ptr]\n","            self.ptr += 1\n","        else:\n","            self.env._update_recall()\n","            raise StopIteration()\n","        return user, self.env.user_recall_dict[user]\n","\n","    def __iter__(self):\n","        if self.shuffle:\n","            random.shuffle(self.user_lists)\n","        return self\n","\n","    def __len__(self):\n","        return len(self.user_lists)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ODGHkZ4Wiykb"},"source":["For each user, we runs the `get_epoch` method, which returns a refreshed simulator based on the last interaction with the user."]},{"cell_type":"markdown","metadata":{"id":"5iMh-lyibRh3"},"source":["## Feature"]},{"cell_type":"code","metadata":{"id":"YCmJPDvPcDnC"},"source":["class FeatureMap:\n","    def __init__(self) -> None:\n","        self.dim = -1\n","    def __call__(self, arm:int, user:int, recommendations: List[int], ) -> np.ndarray:\n","        raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4pGS294rz_C"},"source":["class ArmOneHot(FeatureMap):\n","    def __init__(self, num_arm: int) -> None:\n","        self.num_arm = num_arm\n","        self._cand_slot = np.eye(num_arm)\n","        self.dim = num_arm\n","\n","    def __call__(self, arm:int, user:int, recommendations: List[int], ) -> np.ndarray:\n","        return self._cand_slot[arm, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JAf9cdgr06y"},"source":["class ConcatContext(FeatureMap):\n","    def __init__(self, num_arms: int, user_embed: np.ndarray, item_embed: np.ndarray):\n","        self.num_arms = num_arms\n","        user_embed = user_embed[:, user_embed.std(0) > 0]\n","        item_embed = item_embed[:, item_embed.std(0) > 0]\n","        self.user_embed = (user_embed - user_embed.mean(0)) / user_embed.std(0)\n","        self.item_embed = (item_embed - item_embed.mean(0)) / item_embed.std(0)\n","        self.dim = self.item_embed.shape[1] + self.user_embed.shape[1]\n","        print(self.dim)\n","\n","    def __call__(self, arm:int, user:int, recommendations: List[int], ) -> np.ndarray:\n","        # item_dim = self.item_embed.shape[1]\n","        if len(recommendations) > 1:\n","            recom_pool = self.item_embed[recommendations, :].sum(0) \n","        else:\n","            recom_pool = self.item_embed[recommendations[0], :] \n","        return np.concatenate([self.user_embed[user], recom_pool], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lw3CRDrGr2Qy"},"source":["class ArmedConcatContext(FeatureMap):\n","    def __init__(self, num_arms: int, user_embed: np.ndarray, item_embed: np.ndarray):\n","        self.num_arms = num_arms\n","        user_embed = user_embed[:, user_embed.std(0) > 0]\n","        item_embed = item_embed[:, item_embed.std(0) > 0]\n","        self.user_embed = (user_embed - user_embed.mean(0)) / user_embed.std(0)\n","        self.item_embed = (item_embed - item_embed.mean(0)) / item_embed.std(0)\n","        self.dim = num_arms * self.item_embed.shape[1] + self.user_embed.shape[1]\n","        print(self.dim)\n","\n","    def __call__(self, arm:int, user:int, recommendations: List[int], ) -> np.ndarray:\n","        item_dim = self.item_embed.shape[1]\n","        if len(recommendations) > 1:\n","            recom_pool = self.item_embed[recommendations, :].sum(0) \n","        else:\n","            recom_pool = self.item_embed[recommendations[0], :] \n","        arm_anchor_feat = np.zeros(self.num_arms * item_dim)\n","        arm_anchor_feat[arm*item_dim:(arm + 1)*item_dim] = recom_pool\n","        return np.concatenate([self.user_embed[user], arm_anchor_feat], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMCL46O1r3MQ"},"source":["class ArmOneHotWithContext(FeatureMap):\n","    def __init__(self, num_arms: int, user_embed: np.ndarray, item_embed: np.ndarray):\n","        self.concat_context = ConcatContext(num_arms, user_embed, item_embed)\n","        self.arm_onehot = ArmOneHot(num_arms)\n","        self.dim = self.concat_context.dim + self.arm_onehot.dim\n","\n","    def __call__(self, arm:int, user:int, recommendations: List[int], ) -> np.ndarray:\n","        f1 = self.concat_context(arm, user, recommendations)\n","        f2 = self.arm_onehot(arm, user, recommendations)\n","        return np.concatenate([f1, f2], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FS39u_Q2bRdy"},"source":["## Simulations"]},{"cell_type":"code","metadata":{"id":"zj6GUwsRcPJf"},"source":["def run_basic(env: Environment, algo: BanditAlgorithm, bandit_ins: Bandit, args: Args): \n","    num_epochs=args.num_epochs\n","    top_k=args.topk\n","    epoch_record: Dict[str, Any] = {'epoch':[], 'cumu_recall': []}\n","    epoch_record['recommenders'] = [x.__class__.__name__ for x in bandit_ins.recom_list]\n","    epoch_record['bandit_algorithm'] = algo.__class__.__name__\n","\n","    for epoch in range(num_epochs):\n","        # train the recommendation models\n","        new_train_data = env.get_train()\n","        for recom in bandit_ins.recom_list:\n","            recom.fit(new_train_data)\n","\n","        data: BanditData = []\n","        for uidx, recall_set in env.get_epoch():\n","            arm = algo.predict()\n","            recommendations = bandit_ins.get_arm(arm).recommend(uidx, recall_set, top_k)\n","            reward = env.action(uidx, recommendations)\n","            data.append((arm, reward, None))\n","        algo.update(data)\n","        algo.record_metric(data)\n","\n","        cumu_recall = algo.total_reward_per_arm.sum() / env.init_test_relevant_size\n","        print(f'epoch: {epoch}, cumulative recall: {cumu_recall}, arm_cnt: {algo.total_cnt_per_arm}, curr_arm: {algo.curr_cnt_per_arm}')\n","        epoch_record['epoch'].append(epoch)\n","        epoch_record['cumu_recall'].append(cumu_recall)\n","    return epoch_record"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfzqO1RNEMQU"},"source":["def run_lin_contextual(env: Environment, algo: BanditAlgorithm, bandit_ins: Bandit, feat_map: FeatureMap , args: Args): \n","    num_epochs=args.num_epochs\n","    top_k=args.topk\n","    epoch_record: Dict[str, Any] = {'epoch':[], 'cumu_recall': []}\n","    epoch_record['recommenders'] = [x.__class__.__name__ for x in bandit_ins.recom_list]\n","    epoch_record['bandit_algorithm'] = algo.__class__.__name__\n","\n","    est_list = np.zeros(algo.num_arms)\n","    feat_mat = np.zeros((algo.num_arms, feat_map.dim))\n","    recommendations_mat: List[List[int]] = [[] for _ in range(algo.num_arms)]\n","\n","    for epoch in range(num_epochs):\n","        # train the recommendation models\n","        new_train_data = env.get_train()\n","        for recom in bandit_ins.recom_list:\n","            recom.fit(new_train_data)\n","\n","        data: BanditData = []\n","        for uidx, recall_set in env.get_epoch():\n","            for arm in range(algo.num_arms):\n","                recommendations_mat[arm] = bandit_ins.get_arm(arm).recommend(uidx, recall_set, top_k)\n","                feature = feat_map(arm, uidx, recommendations_mat[arm])\n","                est_list[arm] = algo.predict(feature)\n","                feat_mat[arm, :] = feature\n","\n","            max_value = est_list.max()\n","            best_arms = algo.arm_arr[est_list == max_value]\n","            if (best_arms).sum() > 1:\n","                #break ties randomly\n","                arm = best_arms[np.random.randint(0, len(best_arms))]\n","            else:\n","                arm = best_arms[0]\n","            #recommendations = bandit.get_arm(arm).recommend(uidx, recall_set, top_k)\n","            reward = env.action(uidx, recommendations_mat[arm])\n","            data.append((arm, reward, feat_mat[arm, :]))\n","        algo.update(data)\n","        algo.record_metric(data)\n","\n","        cumu_recall = algo.total_reward_per_arm.sum() / env.init_test_relevant_size\n","        print(f'epoch: {epoch}, cumulative recall: {cumu_recall}, arm_cnt: {algo.total_cnt_per_arm}, curr_arm: {algo.curr_cnt_per_arm}')\n","        epoch_record['epoch'].append(epoch)\n","        epoch_record['cumu_recall'].append(cumu_recall)\n","    return epoch_record"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pID8oL--EOr_"},"source":["def run_optimal_contextual(env: Environment, algo: OptimalDesign, bandit_ins: Bandit, feat_map: FeatureMap, args: Args):\n","    num_epochs:int =args.num_epochs\n","    top_k: int=args.topk\n","    explore_step: int=args.explore_step\n","    epoch_record: Dict[str, Any] = {'epoch':[], 'cumu_recall': []}\n","    epoch_record['recommenders'] = [x.__class__.__name__ for x in bandit_ins.recom_list]\n","    epoch_record['bandit_algorithm'] = algo.__class__.__name__\n","\n","    est_list = np.zeros(algo.num_arms)\n","    feat_mat = np.zeros((algo.num_arms, feat_map.dim))\n","    recommendations_mat: List[List[int]] = [[] for _ in range(algo.num_arms)]\n","\n","    for epoch in range(num_epochs):\n","        # train the recommendation models using latest trainning data\n","        new_train_data = env.get_train()\n","        for recom in bandit_ins.recom_list:\n","            recom.fit(new_train_data)\n","\n","        data: BanditData = []\n","        explore_data: BanditData = []\n","        explore_cnt = 0\n","        wait_explore_update = True\n","\n","        #algo.clear_buffer()\n","        for uidx, recall_set in env.get_epoch():\n","            # update the theta if has done enough exploration\n","            if explore_cnt >= explore_step and wait_explore_update:\n","                algo.update(explore_data)\n","                wait_explore_update = False\n","            \n","            # get system output\n","            for arm in range(algo.num_arms):\n","                recommendations_mat[arm] = bandit_ins.get_arm(arm).recommend(uidx, recall_set, top_k)\n","                feat_mat[arm, :] = feat_map(arm, uidx, recommendations_mat[arm])\n","\n","            # explore or exploit\n","            if explore_cnt < explore_step:\n","                #explore to maximize the information gain\n","                arm = algo.explore_decision(feat_mat)\n","            else:\n","                for arm in range(algo.num_arms):\n","                    est_list[arm] = algo.predict(feat_mat[arm, :])\n","                # interact with environment, add record\n","                max_value = est_list.max()\n","                best_arms = algo.arm_arr[est_list == max_value]\n","                if (best_arms).sum() > 1:\n","                    #break ties randomly\n","                    arm = best_arms[np.random.randint(0, len(best_arms))]\n","                else:\n","                    arm = best_arms[0]\n","            #recommendations = bandit.get_arm(arm).recommend(uidx, recall_set, top_k)\n","            reward = env.action(uidx, recommendations_mat[arm])\n","            data.append((arm, reward, feat_mat[arm, :]))\n","\n","            if explore_cnt < explore_step:\n","                explore_data.append((arm, reward, feat_mat[arm, :]))\n","            explore_cnt += 1\n","        \n","        # update metric at the end epoch, no need to update parameters\n","        algo.record_metric(data)\n","\n","        cumu_recall = algo.total_reward_per_arm.sum() / env.init_test_relevant_size\n","        print(f'epoch: {epoch}, cumulative recall: {cumu_recall}, arm_cnt: {algo.total_cnt_per_arm}, curr_arm: {algo.curr_cnt_per_arm}')\n","        epoch_record['epoch'].append(epoch)\n","        epoch_record['cumu_recall'].append(cumu_recall)\n","    return epoch_record"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vghFacxLYlv6"},"source":["## Running simulations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImgT0CdOcyib","executionInfo":{"status":"ok","timestamp":1638773304515,"user_tz":-330,"elapsed":612,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"8b33a073-45d8-434a-a5ac-3cea504644a4"},"source":["user_embed = np.load('./ml-1m/user_feat.npy')\n","item_embed = np.load('./ml-1m/item_feat.npy')\n","data_df = pd.read_feather('./ml-1m/ratings.feather')\n","user_num, item_num = data_df.uidx.max() + 1, data_df.iidx.max() + 1\n","assert(max(data_df.rating) == 1)\n","assert(min(data_df.rating) == 0)\n","print('average overall rating: {:.4f}'.format(data_df.rating.mean()))\n","print('user_num:{}, item_num:{}'.format(user_num, item_num))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["average overall rating: 0.575160801410675\n","6040 3706\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"qx6rjwGzgCeb","executionInfo":{"status":"ok","timestamp":1638774001300,"user_tz":-330,"elapsed":996,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d05780c6-3047-4b85-cfe5-3fb3a1a40059"},"source":["sv_recom = SVDRecommenderV2(user_num, item_num, args.dim)\n","pop_recom = PopRecommenderV2(user_num, item_num)\n","uknn_recom = UserBasedKnn(user_num, item_num)\n","item_knn_recom = ContextItemKnn(user_num, item_num, item_embed)\n","\n","recom_model_list = [item_knn_recom, pop_recom, sv_recom]\n","\n","num_arms = len(recom_model_list)\n","bandit_ins = Bandit(recom_model_list)\n","\n","\n","feature_map: FeatureMap\n","if args.feat_map == 'onehot':\n","    feature_map = ArmOneHot(num_arms)\n","elif args.feat_map == 'context':\n","    feature_map = ConcatContext(num_arms, user_embed, item_embed)\n","elif args.feat_map == 'armed_context':\n","    feature_map = ArmedConcatContext(num_arms, user_embed, item_embed)\n","elif args.feat_map == 'onehot_context':\n","    feature_map = ArmOneHotWithContext(num_arms, user_embed, item_embed)\n","\n","\n","bandit_algo: BanditAlgorithm\n","if args.algo == 'base':\n","    bandit_algo = RandomBandit(num_arms)\n","elif args.algo == 'e_greedy':\n","    bandit_algo = EpsilonGreedy(num_arms, args.epsilon)\n","elif args.algo == 'thompson':\n","    bandit_algo = ThompsonSampling(num_arms)\n","elif args.algo == 'lin_ct':\n","    bandit_algo = Contextual(num_arms, feature_map.dim)\n","elif args.algo == 'optimal':\n","    bandit_algo = OptimalDesign(num_arms, feature_map.dim)\n","else:\n","    raise ValueError('no known algorithms')\n","\n","\n","env = Environment(user_num, item_num, data_df)\n","if args.algo == 'lin_ct':\n","    epoch_record = run_lin_contextual(env, bandit_algo, bandit_ins, feature_map, args)\n","elif args.algo == 'optimal':\n","    bandit_algo = cast(OptimalDesign, bandit_algo)\n","    epoch_record = run_optimal_contextual(env, bandit_algo, bandit_ins, feature_map, args)\n","else:\n","    epoch_record = run_basic(env, bandit_algo, bandit_ins, args)  \n","\n","record_name = f'{bandit_algo.__class__.__name__}_{time.time()}'\n","with open(f'output/{record_name}.json', 'w') as f:\n","    json.dump(epoch_record, f)\n","\n","plt.plot(epoch_record['epoch'], epoch_record['cumu_recall'])\n","plt.savefig(f'{record_name}_plt.jpg')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"5IZz8Dz6r_l-"},"source":["---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irHWdJ5AsBbt","executionInfo":{"status":"ok","timestamp":1638776472059,"user_tz":-330,"elapsed":6838,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ad6c35c9-b588-454a-bc7d-f988d8deea94"},"source":["# !apt-get -qq install tree\n","# !rm -r sample_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Selecting previously unselected package tree.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n","Unpacking tree (1.7.0-5) ...\n","Setting up tree (1.7.0-5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FVnpyKssHDN","executionInfo":{"status":"ok","timestamp":1638776476217,"user_tz":-330,"elapsed":865,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"874c0e20-f786-41b7-bfd4-e8d70c276e1c"},"source":["# !tree -h --du ."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".\n","├── [ 26M]  acganlib\n","│   ├── [ 70K]  acgan\n","│   │   ├── [ 11K]  data.py\n","│   │   ├── [ 246]  eval.py\n","│   │   ├── [   0]  __init__.py\n","│   │   ├── [ 14K]  module.py\n","│   │   ├── [   0]  py.typed\n","│   │   └── [ 41K]  recommender.py\n","│   ├── [ 23M]  data\n","│   │   ├── [6.4K]  books\n","│   │   │   └── [2.4K]  book_data.py\n","│   │   ├── [5.9K]  lastfm\n","│   │   │   └── [1.9K]  lastfm.py\n","│   │   ├── [4.6K]  ml-1m\n","│   │   │   └── [ 596]  ml_1m.py\n","│   │   └── [ 23M]  ncf_data.tar.gz\n","│   ├── [ 486]  example.sh\n","│   ├── [2.8M]  full_paper.pdf\n","│   ├── [5.1K]  ncf_utils.py\n","│   ├── [1.7K]  NCF_validation.py\n","│   ├── [228K]  PGM_full.png\n","│   ├── [   0]  py.typed\n","│   ├── [3.4K]  README.md\n","│   ├── [6.1K]  robust_simulation.py\n","│   ├── [1.2K]  run.py\n","│   ├── [ 178]  setup.py\n","│   ├── [6.1K]  simulation.py\n","│   ├── [10.0K]  train_on_real.py\n","│   └── [ 11K]  train_on_simulation.py\n","├── [9.8K]  bandits.ipynb\n","├── [ 14K]  Contextual_1638774006.87674_plt.jpg\n","├── [ 34M]  ml-1m\n","│   ├── [1.4M]  item_feat.npy\n","│   ├── [167K]  movies.dat\n","│   ├── [ 23M]  ratings.dat\n","│   ├── [7.4M]  ratings.feather\n","│   ├── [5.4K]  README\n","│   ├── [1.4M]  user_feat.npy\n","│   └── [131K]  users.dat\n","├── [5.6M]  ml-1m.zip\n","└── [4.4K]  output\n","    └── [ 384]  Contextual_1638774006.87674.json\n","\n","  66M used in 8 directories, 34 files\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLHpnou4r_l_","executionInfo":{"status":"ok","timestamp":1638776539731,"user_tz":-330,"elapsed":3488,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"352dee2f-767c-4f8d-da3a-5c5c51c1616d"},"source":["# !pip install -q watermark\n","# %reload_ext watermark\n","# %watermark -a \"Sparsh A.\" -m -iv -u -t -d -p acgan,gensim"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-12-06 07:42:26\n","\n","acgan : 1.0\n","gensim: 3.6.0\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","scipy     : 1.4.1\n","IPython   : 5.5.0\n","argparse  : 1.1\n","numpy     : 1.19.5\n","matplotlib: 3.2.2\n","json      : 2.0.9\n","pandas    : 1.1.5\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"cmKleTL6r_mA"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"As_N11BWr_mA"},"source":["**END**"]}]}