{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-06-24-spark-movie-recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMLXgH2jE5vKpRM8bj6/H8z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTmfWUvx4aUt"
      },
      "source": [
        "# Movie recommender on PySpark\n",
        "> Building a scalable movie recommendation system using PySpark trained on movielens\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [spark, pyspark, movie]\n",
        "- image:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8pr43LABj4a"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d937xTX9ycO"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRwFs7eH97bt"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjoJVzu2_lFK"
      },
      "source": [
        "# import findspark\n",
        "# findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y1d1JrF-ihC"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_3LmCAS-tGw"
      },
      "source": [
        "# df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "# df.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQcZl-WxYgDS"
      },
      "source": [
        "!pip install koalas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY2_c8UOAEnd",
        "outputId": "a4e1fbfd-05c9-4c76-b2a6-63ab8d671ee3"
      },
      "source": [
        "# Default Packages (available by Default in Google Colab)\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import random\n",
        "from pprint import pprint\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# Downloaded Packages (not available by Default)\n",
        "import databricks.koalas\n",
        "\n",
        "# PySpark Utilities\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.recommendation import ALS, ALSModel\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
        "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
        "\n",
        "# Random Seed\n",
        "SEED = 1492\n",
        "\n",
        "# Set-up\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evGR8Qv2Bm09"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv06-6Bm9P1H"
      },
      "source": [
        "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
        "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EOHjq7YCW7J"
      },
      "source": [
        "We also need to define download locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwQ0hd209PyQ"
      },
      "source": [
        "import os\n",
        "\n",
        "datasets_path = os.path.join('.', 'datasets')\n",
        "os.makedirs(datasets_path, exist_ok=True)\n",
        "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
        "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Quh2RCcCUjr"
      },
      "source": [
        "Now we can proceed with both downloads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lb05U_8CLH1"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
        "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPNswlODCSlS"
      },
      "source": [
        "Both of them are zip files containing a folder with ratings, movies, etc. We need to extract them into its individual folders so we can use each file later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvJxk-4aCLE4"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)\n",
        "\n",
        "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdlZMzMMAFY2"
      },
      "source": [
        "## Basic example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJCM51y3AKmu"
      },
      "source": [
        "spark = SparkSession\\\n",
        "    .builder\\\n",
        "    .appName(\"ALSExample\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "lines = spark.read.text(os.path.join(os.getenv('SPARK_HOME'),\"data/mllib/als/sample_movielens_ratings.txt\")).rdd\n",
        "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                      rating=float(p[2]), timestamp=int(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Build the recommendation model using ALS on the training data\n",
        "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
        "# als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "model = als.fit(training)\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))\n",
        "\n",
        "# Generate top 10 movie recommendations for each user\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "userRecs.show()\n",
        "\n",
        "# Generate top 10 user recommendations for each movie\n",
        "movieRecs = model.recommendForAllItems(10)\n",
        "movieRecs.show()\n",
        "\n",
        "# Generate top 10 movie recommendations for a specified set of users\n",
        "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
        "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
        "userSubsetRecs.show()\n",
        "\n",
        "# Generate top 10 user recommendations for a specified set of movies\n",
        "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
        "movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
        "movieSubSetRecs.show()\n",
        "\n",
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAlOk9ppBe2L"
      },
      "source": [
        "## Advanced example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5r5D-_Lpv3"
      },
      "source": [
        "- https://nbviewer.jupyter.org/github/SonalSavaliya/Movie-Recommender-System/blob/master/movie_recommender_using_spark.ipynb\n",
        "- https://nbviewer.jupyter.org/github/Ansu-John/Movie-Recommender-System/blob/main/Movie%20Recommender%20System.ipynb\n",
        "- https://nbviewer.jupyter.org/github/assadullah1467/PySpark-Recommendation-Engine/blob/master/Recommender_System_PySpark.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zybYwD9jGVwO"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Reco-Spark-Example2\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKbE1wi4HD73"
      },
      "source": [
        "data = spark.read.csv(os.path.join(datasets_path,'ml-latest-small','ratings.csv'),\n",
        "                      inferSchema=True, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ746b0eHWnW",
        "outputId": "9e16e10d-9de0-4746-8de6-77abba0ca886"
      },
      "source": [
        "data.show(5)\n",
        "data.printSchema()\n",
        "data.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "|     1|     47|   5.0|964983815|\n",
            "|     1|     50|   5.0|964982931|\n",
            "+------+-------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n",
            "+-------+------------------+----------------+------------------+--------------------+\n",
            "|summary|            userId|         movieId|            rating|           timestamp|\n",
            "+-------+------------------+----------------+------------------+--------------------+\n",
            "|  count|            100836|          100836|            100836|              100836|\n",
            "|   mean|326.12756356856676|19435.2957177992| 3.501556983616962|1.2059460873684695E9|\n",
            "| stddev| 182.6184914635004|35530.9871987003|1.0425292390606342|2.1626103599513078E8|\n",
            "|    min|                 1|               1|               0.5|           828124615|\n",
            "|    max|               610|          193609|               5.0|          1537799250|\n",
            "+-------+------------------+----------------+------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-C0YGyvSHdg",
        "outputId": "491bef48-ca9b-4524-ac50-bdc7dadbc68d"
      },
      "source": [
        "titles = spark.read.csv(os.path.join(datasets_path,'ml-latest-small','movies.csv'),\n",
        "                        inferSchema=True, header=True)\n",
        "\n",
        "titles.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J9hnoYZSL2I",
        "outputId": "c0f8198d-4b87-48f3-e8c7-38dd4a9bae2d"
      },
      "source": [
        "data = data.join(titles,data.movieId==titles.movieId,\"left\").select([data.movieId,\n",
        "                                                              titles.title,\n",
        "                                                              data.userId,\n",
        "                                                              data.rating])\n",
        "data.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+------+------+\n",
            "|movieId|               title|userId|rating|\n",
            "+-------+--------------------+------+------+\n",
            "|      1|    Toy Story (1995)|     1|   4.0|\n",
            "|      3|Grumpier Old Men ...|     1|   4.0|\n",
            "|      6|         Heat (1995)|     1|   4.0|\n",
            "|     47|Seven (a.k.a. Se7...|     1|   5.0|\n",
            "|     50|Usual Suspects, T...|     1|   5.0|\n",
            "+-------+--------------------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWuvHOj9U3eE"
      },
      "source": [
        "from pyspark.sql.functions import rand, col, lit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrgN_LslN5yC",
        "outputId": "56ef1dd8-dff2-43da-f253-81070ad75f44"
      },
      "source": [
        "data.orderBy(rand()).show(10,False)\n",
        "data.groupBy('userId').count().orderBy('count',ascending=False).show(10,False)\n",
        "data.groupBy('userId').count().orderBy('count',ascending=True).show(10,False)\n",
        "data.groupBy('title').count().orderBy('count',ascending=False).show(10,False)\n",
        "data.groupBy('title').count().orderBy('count',ascending=True).show(10,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------------------------------------------------------------------+------+------+\n",
            "|movieId|title                                                                         |userId|rating|\n",
            "+-------+------------------------------------------------------------------------------+------+------+\n",
            "|3676   |Eraserhead (1977)                                                             |387   |4.0   |\n",
            "|1198   |Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)|30    |5.0   |\n",
            "|34405  |Serenity (2005)                                                               |414   |3.5   |\n",
            "|52281  |Grindhouse (2007)                                                             |590   |3.0   |\n",
            "|2278   |Ronin (1998)                                                                  |64    |5.0   |\n",
            "|1676   |Starship Troopers (1997)                                                      |428   |3.5   |\n",
            "|48516  |Departed, The (2006)                                                          |434   |5.0   |\n",
            "|292    |Outbreak (1995)                                                               |379   |4.0   |\n",
            "|50005  |Curse of the Golden Flower (Man cheng jin dai huang jin jia) (2006)           |232   |3.0   |\n",
            "|5060   |M*A*S*H (a.k.a. MASH) (1970)                                                  |514   |3.0   |\n",
            "+-------+------------------------------------------------------------------------------+------+------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+------+-----+\n",
            "|userId|count|\n",
            "+------+-----+\n",
            "|414   |2698 |\n",
            "|599   |2478 |\n",
            "|474   |2108 |\n",
            "|448   |1864 |\n",
            "|274   |1346 |\n",
            "|610   |1302 |\n",
            "|68    |1260 |\n",
            "|380   |1218 |\n",
            "|606   |1115 |\n",
            "|288   |1055 |\n",
            "+------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+------+-----+\n",
            "|userId|count|\n",
            "+------+-----+\n",
            "|569   |20   |\n",
            "|207   |20   |\n",
            "|194   |20   |\n",
            "|257   |20   |\n",
            "|189   |20   |\n",
            "|442   |20   |\n",
            "|278   |20   |\n",
            "|431   |20   |\n",
            "|406   |20   |\n",
            "|53    |20   |\n",
            "+------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-----------------------------------------+-----+\n",
            "|title                                    |count|\n",
            "+-----------------------------------------+-----+\n",
            "|Forrest Gump (1994)                      |329  |\n",
            "|Shawshank Redemption, The (1994)         |317  |\n",
            "|Pulp Fiction (1994)                      |307  |\n",
            "|Silence of the Lambs, The (1991)         |279  |\n",
            "|Matrix, The (1999)                       |278  |\n",
            "|Star Wars: Episode IV - A New Hope (1977)|251  |\n",
            "|Jurassic Park (1993)                     |238  |\n",
            "|Braveheart (1995)                        |237  |\n",
            "|Terminator 2: Judgment Day (1991)        |224  |\n",
            "|Schindler's List (1993)                  |220  |\n",
            "+-----------------------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------------------------------+-----+\n",
            "|title                            |count|\n",
            "+---------------------------------+-----+\n",
            "|Mozart and the Whale (2005)      |1    |\n",
            "|Angel at My Table, An (1990)     |1    |\n",
            "|Wicked Blood (2014)              |1    |\n",
            "|Just Before I Go (2014)          |1    |\n",
            "|Smiley's People (1982)           |1    |\n",
            "|Fat City (1972)                  |1    |\n",
            "|National Lampoon's Bag Boy (2007)|1    |\n",
            "|Damn Yankees! (1958)             |1    |\n",
            "|Tom Segura: Disgraceful (2018)   |1    |\n",
            "|Survive Style 5+ (2004)          |1    |\n",
            "+---------------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSnZO47lKeE1"
      },
      "source": [
        "# Smaller dataset so we will use 0.8 / 0.2\n",
        "(train_data, test_data) = data.randomSplit([0.8, 0.2], seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmmc35sDKuSD"
      },
      "source": [
        "# Build the recommendation model using ALS on the training data\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
        "# als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "model = als.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpE6lxY-Kw8p"
      },
      "source": [
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL0aS_3lKzDg",
        "outputId": "065de754-bf4a-48bf-e5c9-4280820cd4f9"
      },
      "source": [
        "predictions.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+------+------+------------+\n",
            "|movieId|               title|userId|rating|  prediction|\n",
            "+-------+--------------------+------+------+------------+\n",
            "|    471|Hudsucker Proxy, ...|   133|   4.0|-0.023575544|\n",
            "|    471|Hudsucker Proxy, ...|   182|   4.5|   2.7194414|\n",
            "|    471|Hudsucker Proxy, ...|   387|   3.0|   3.3777792|\n",
            "|    471|Hudsucker Proxy, ...|   217|   2.0|   1.9056505|\n",
            "|    471|Hudsucker Proxy, ...|   555|   3.0|   3.0670002|\n",
            "|    471|Hudsucker Proxy, ...|   176|   5.0|   4.4713492|\n",
            "|    471|Hudsucker Proxy, ...|   312|   4.0|   4.0964546|\n",
            "|    471|Hudsucker Proxy, ...|   287|   4.5|  0.77415377|\n",
            "|    471|Hudsucker Proxy, ...|    32|   3.0|     4.56229|\n",
            "|    471|Hudsucker Proxy, ...|   373|   5.0| -0.05078125|\n",
            "|    496|What Happened Was...|   191|   5.0|         NaN|\n",
            "|    833|High School High ...|   609|   3.0|   1.0141177|\n",
            "|    833|High School High ...|   492|   4.0|   1.2495432|\n",
            "|    833|High School High ...|   608|   0.5|   1.1099852|\n",
            "|   1088|Dirty Dancing (1987)|   599|   2.5|   2.0041223|\n",
            "|   1088|Dirty Dancing (1987)|   177|   3.5|   3.2147155|\n",
            "|   1088|Dirty Dancing (1987)|   479|   4.0|   3.3820715|\n",
            "|   1088|Dirty Dancing (1987)|   554|   5.0|    5.179201|\n",
            "|   1088|Dirty Dancing (1987)|   583|   3.5|   4.4660583|\n",
            "|   1088|Dirty Dancing (1987)|   594|   4.5|    4.519591|\n",
            "+-------+--------------------+------+------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcZ_8vvWK21W",
        "outputId": "9942ac68-adfa-4024-f46e-621a6c5a0139"
      },
      "source": [
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root-mean-square error = nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NAYrHKoMVBd"
      },
      "source": [
        "A NaN result is due to SPARK-14489 and because the model can't predict values for users for which there's no data. \n",
        "A temporary workaround is to exclude rows with predicted NaN values or to replace them with a constant, for instance,\n",
        "the general mean rating. However, to map to a real business problem, the data scientist, in collaboration with the \n",
        "business owner, must define what happens if such an event occurs. For example, you can provide no recommendation for \n",
        "a user until that user rates a few items. Alternatively, before user rates five items, you can use a user-based recommender\n",
        "system that's based on the user's profile (that's another recommender system to develop).\n",
        "\n",
        "Replace predicted NaN values with the average rating and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL57PNOYMehn",
        "outputId": "b7ffa688-8289-41d3-d945-710e7f439929"
      },
      "source": [
        "avgRatings = data.select('rating').groupBy().avg().first()[0]\n",
        "print('The average rating in the dataset is: {}'.format(avgRatings))\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
        "print('The root mean squared error for our model is: {}'.format(evaluator.evaluate(predictions.na.fill(avgRatings))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average rating in the dataset is: 3.501556983616962\n",
            "The root mean squared error for our model is: 1.0846835088076119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCX91jluM5sC"
      },
      "source": [
        "Now exclude predicted NaN values and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoQDazzYM7xM",
        "outputId": "a2af389e-e7af-4543-9087-837aa2c24012"
      },
      "source": [
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
        "print ('The root mean squared error for our model is: {}'.format(evaluator.evaluate(predictions.na.drop())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The root mean squared error for our model is: 1.0809233240280964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBQZPavLLXxb",
        "outputId": "8f3426b4-635a-4304-d0a5-502f71745f19"
      },
      "source": [
        "single_user = test_data.filter(test_data['userId']==12).select(['movieId','userId'])\n",
        "single_user.show()\n",
        "\n",
        "recommendations = model.transform(single_user)\n",
        "recommendations.orderBy('prediction', ascending=False).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|movieId|userId|\n",
            "+-------+------+\n",
            "|    357|    12|\n",
            "|    543|    12|\n",
            "|    830|    12|\n",
            "|   2072|    12|\n",
            "|   2717|    12|\n",
            "|   4018|    12|\n",
            "|  40629|    12|\n",
            "+-------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLo5h_suLhQB",
        "outputId": "4d0ebafb-0016-437d-8c02-924b0ce11ded"
      },
      "source": [
        "#create dataset of all distinct movies \n",
        "unique_movies=data.select('movieId').distinct()\n",
        "unique_movies.count()\n",
        "\n",
        "#assigning alias name 'a' to unique movies df\n",
        "a = unique_movies.alias('a')\n",
        "\n",
        "#selecting a user\n",
        "user_id=12\n",
        "\n",
        "#creating another dataframe which contains already watched movie by active user \n",
        "watched_movies=indexed.filter(indexed['userId'] == user_id).select('movieId').distinct()\n",
        "watched_movies.count()\n",
        "\n",
        "#assigning alias name 'b' to watched movies df\n",
        "b=watched_movies.alias('b')\n",
        "\n",
        "#joining both tables on left join \n",
        "total_movies = a.join(b, a.movieId == b.movieId,how='left')\n",
        "\n",
        "#selecting movies which active user is yet to rate or watch\n",
        "remaining_movies=total_movies.where(col(\"b.movieId\").isNull()).select(a.movieId).distinct()\n",
        "remaining_movies=remaining_movies.withColumn(\"userId\",lit(int(user_id)))\n",
        "\n",
        "#making recommendations using ALS recommender model and selecting only top 'n' movies\n",
        "recommendations=model.transform(remaining_movies).orderBy('prediction',ascending=False)\n",
        "recommendations.show(5,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+----------+\n",
            "|movieId|userId|prediction|\n",
            "+-------+------+----------+\n",
            "|6654   |12    |NaN       |\n",
            "|91784  |12    |NaN       |\n",
            "|1507   |12    |NaN       |\n",
            "|100068 |12    |NaN       |\n",
            "|6336   |12    |NaN       |\n",
            "+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}