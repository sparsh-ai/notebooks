{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reco-tut-vrr-02-predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UZiLdUuxlFssVVD_q48I4Zg8akLD_2cx",
      "authorship_tag": "ABX9TyOeFxB6JmxZ3QCAvjpseik3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHfJAkdQk3jv"
      },
      "source": [
        "import os\n",
        "project_name = \"reco-tut-vrr\"; branch = \"main\"; account = \"sparsh-ai\"\n",
        "project_path = os.path.join('/content', project_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3APW7y3clBlH",
        "outputId": "17900773-0b16-41fd-c1d3-57d20c5a748b"
      },
      "source": [
        "if not os.path.exists(project_path):\n",
        "    !cp /content/drive/MyDrive/mykeys.py /content\n",
        "    import mykeys\n",
        "    !rm /content/mykeys.py\n",
        "    path = \"/content/\" + project_name; \n",
        "    !mkdir \"{path}\"\n",
        "    %cd \"{path}\"\n",
        "    import sys; sys.path.append(path)\n",
        "    !git config --global user.email \"recotut@recohut.com\"\n",
        "    !git config --global user.name  \"reco-tut\"\n",
        "    !git init\n",
        "    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n",
        "    !git pull origin \"{branch}\"\n",
        "    !git checkout main\n",
        "else:\n",
        "    %cd \"{project_path}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/reco-tut-vrr\n",
            "Initialized empty Git repository in /content/reco-tut-vrr/.git/\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 22 (delta 3), reused 20 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n",
            "From https://github.com/sparsh-ai/reco-tut-vrr\n",
            " * branch            main       -> FETCH_HEAD\n",
            " * [new branch]      main       -> origin/main\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "Switched to a new branch 'main'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGo_LJd6lBlN"
      },
      "source": [
        "!git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWzR_TDJlBlO",
        "outputId": "1f0aa5a6-f8e0-4bd1-8b83-cea3865fa6dc"
      },
      "source": [
        "!git add . && git commit -m 'commit' && git push origin \"{branch}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[main 58b1e77] commit\n",
            " 2 files changed, 850 deletions(-)\n",
            " delete mode 100644 data/bronze/data.csv\n",
            " create mode 100644 data/silver/reviews.parquet.gzip\n",
            "Counting objects: 6, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (6/6), 33.96 KiB | 16.98 MiB/s, done.\n",
            "Total 6 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/sparsh-ai/reco-tut-vrr.git\n",
            "   bb5b475..58b1e77  main -> main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra084G6QmDcL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrb7EyBKmEmk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras import models\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce393Lpposh_",
        "outputId": "2db10727-181b-4a94-bc29-e6d5422a74cf"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "HF4J7q62mJ7u",
        "outputId": "deeca935-07f5-4b92-9835-da83411264d5"
      },
      "source": [
        "df = pd.read_parquet('./data/silver/reviews.parquet.gzip')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_counts</th>\n",
              "      <th>City</th>\n",
              "      <th>Province</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vacation/Cottage Rental</td>\n",
              "      <td>6</td>\n",
              "      <td>85.0</td>\n",
              "      <td>Niagara Falls</td>\n",
              "      <td>Ontario</td>\n",
              "      <td>This rental felt more like a well-appointed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mistiso's Place Vacation Rentals- Purcell Suite</td>\n",
              "      <td>5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>British Columbia</td>\n",
              "      <td>I can't say enough about this beautiful and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Toronto 4 Bedroom House Spacious Clean Beautif...</td>\n",
              "      <td>6</td>\n",
              "      <td>36.0</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Ontario</td>\n",
              "      <td>back yard! Would recommend the rental for a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our Sweet Escape</td>\n",
              "      <td>6</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Qualicum Beach</td>\n",
              "      <td>British Columbia</td>\n",
              "      <td>enjoyable. I have never stayed in a vacation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Walk to ocean from Lyons Cottage Rentals in PEI</td>\n",
              "      <td>5</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Stanhope</td>\n",
              "      <td>Prince Edward Island</td>\n",
              "      <td>quiet morning as we woke up - perfect vacati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                            Reviews\n",
              "0                            Vacation/Cottage Rental  ...    This rental felt more like a well-appointed ...\n",
              "1    Mistiso's Place Vacation Rentals- Purcell Suite  ...    I can't say enough about this beautiful and ...\n",
              "2  Toronto 4 Bedroom House Spacious Clean Beautif...  ...    back yard! Would recommend the rental for a ...\n",
              "3                                   Our Sweet Escape  ...    enjoyable. I have never stayed in a vacation...\n",
              "4    Walk to ocean from Lyons Cottage Rentals in PEI  ...    quiet morning as we woke up - perfect vacati...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knyLYsCEmT0d",
        "outputId": "d600bbe4-a1f2-4401-8f92-ede0b17210db"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 571 entries, 0 to 570\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Title          571 non-null    object \n",
            " 1   Rating         571 non-null    int64  \n",
            " 2   Review_counts  571 non-null    float64\n",
            " 3   City           571 non-null    object \n",
            " 4   Province       571 non-null    object \n",
            " 5   Reviews        571 non-null    object \n",
            "dtypes: float64(1), int64(1), object(4)\n",
            "memory usage: 26.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdcHVDdS0BOx"
      },
      "source": [
        "#filter punctuations, stemming and stopwords\n",
        "corpus = []\n",
        "for i in range(len(df)):\n",
        "    review = re.sub('[^a-zA-Z0-9]', ' ', df['Reviews'][i])\n",
        "    review = review.lower()\n",
        "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "    stemmer = nltk.PorterStemmer()\n",
        "    lemmatizer = nltk.WordNetLemmatizer()\n",
        "    tokens_list = tokenizer.tokenize(review)\n",
        "    tokens = []\n",
        "    for token in tokens_list:\n",
        "        tokens.append(lemmatizer.lemmatize(token))\n",
        "        stop_words = stopwords.words(\"english\")\n",
        "    filtered_words = [w for w in tokens if w not in stop_words]\n",
        "    review = ' '.join(filtered_words)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe1b_dKWop6y",
        "outputId": "6dd4296d-c2de-4146-cde5-d4876f6510d1"
      },
      "source": [
        "print('length of coprus is {} and first item is \"{}\"'.format(len(corpus), corpus[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of coprus is 571 and first item is \"rental felt like well appointed apartment vacation\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8vG-YKC0Fal"
      },
      "source": [
        "#Bag of Words model to convert corpus into X\n",
        "cv = CountVectorizer()\n",
        "cv.fit(corpus)\n",
        "key = list(cv.vocabulary_.keys())\n",
        "key.sort()\n",
        "X = pd.DataFrame(cv.transform(corpus).toarray(),columns = key)\n",
        "y = df.Rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdLG9_a_0JIv"
      },
      "source": [
        "#TF_IDF model to convert corpus into X\n",
        "tfidf = TfidfVectorizer()\n",
        "X2 = pd.DataFrame(tfidf.fit_transform(corpus).toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo4ZW6-w1cQG"
      },
      "source": [
        "Rating = df.Rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8YKopCu0YiU",
        "outputId": "12db105a-f12a-4397-d031-436b6326d278"
      },
      "source": [
        "# We need to get unique words to determine the vocabulary size\n",
        "reviews = df.Reviews\n",
        "uniq_words=set()\n",
        "\n",
        "for doc in reviews:\n",
        "    for word in doc.split(\" \"):\n",
        "        uniq_words.add(word)\n",
        "vocab_size=len(uniq_words)\n",
        "\n",
        "print (\"Total Unique words:\",vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Unique words: 1856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRpPNRWAy16I"
      },
      "source": [
        "## Review text to rating prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAZX4K6x0oK_"
      },
      "source": [
        "We need to convert each of the words in the reviews to one-hot vectors. Below is the code to get integer indexes of the words for one hot vector.\n",
        "\n",
        "Note that we don't need to store all zeros as only the integer index for the word in a vector will have a value of 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0mbja6W0t_5",
        "outputId": "640d4589-6639-4e4a-ae7a-3f7a15dfd75e"
      },
      "source": [
        "# Integer encode the documents\n",
        "encoded_reviews = [one_hot(review, vocab_size) for review in reviews]\n",
        "print(encoded_reviews[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[83, 255, 1673, 938, 1194, 691, 1432, 1516, 417, 219, 196]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c6xxGn00wES",
        "outputId": "545e1714-5ef0-4d6d-b7a5-3a77fff0b55d"
      },
      "source": [
        "# We fix the maximum length to 100 words.\n",
        "# pad documents to a max length of n words\n",
        "max_length = 100\n",
        "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
        "print(padded_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 691  196  468 ...    0    0    0]\n",
            " [  83  255 1673 ...    0    0    0]\n",
            " [1706 1718 1213 ...    0    0    0]\n",
            " ...\n",
            " [ 219 1675 1281 ...    0    0    0]\n",
            " [ 113 1659  196 ...    0    0    0]\n",
            " [  86    0    0 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKrq1eXG1AdB"
      },
      "source": [
        "# We have completed our pre-processing, it is now time to build the neural network based classifier. We start by splitting the reviews into training and test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_reviews,Rating,test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBUQuT4G1CCd"
      },
      "source": [
        "Now we need to define the basics of model for neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw1F5g8QzhDY",
        "outputId": "aa51c7d8-bbc0-45ce-c420-f5dd3fd3d9d5"
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Define the embedding matrix dimensions. Each vector is of 8 dimensions and there will be total of vocab_size vectors\n",
        "# The input length (window) is 100 words so the output from embedding layer will be a conactenated (flattened) vector of \n",
        "# 800 dimensions\n",
        "model.add(Embedding(vocab_size, 16, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=3, activation='relu'))\n",
        "model.add(Dense(units=2, activation='relu'))\n",
        "model.add(Dense(units=1, activation='relu'))\n",
        "\n",
        "# compile the model with stochastic gradient descent and binary cross entropy\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 16)           29696     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 4803      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 34,510\n",
            "Trainable params: 34,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR1ZNTIG1HuL",
        "outputId": "40185b4e-13d5-49c4-929a-7bfc499fd00f"
      },
      "source": [
        "# Fit the model... there are few docs, so I am trying with batch_size=1, you can delete it for default batch \n",
        "#size or change it to a bigger number\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 14s 2ms/step - loss: -10.6064 - acc: 0.0023\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -67.6475 - acc: 0.0023\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -67.2081 - acc: 0.0033\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -69.0307 - acc: 0.0014\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -67.9948 - acc: 0.0033\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -69.1731 - acc: 0.0016\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -67.9859 - acc: 5.0511e-04\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -68.1371 - acc: 0.0023\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -67.6506 - acc: 0.0033\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 2ms/step - loss: -68.5652 - acc: 0.0020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0dc920790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAm6R4kI1kDf"
      },
      "source": [
        "Now, we shall evaluate our model against the test set that we kep separate earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptyT08xP1T50",
        "outputId": "865a00ea-c763-4504-af67-37d9e1c9fff4"
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 1s 3ms/step - loss: -69.2422 - acc: 0.0058\n",
            "Accuracy: 0.581395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bopd8Ytd1pP7"
      },
      "source": [
        "Precision and Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEDCIkL1oY4",
        "outputId": "e1e1b91d-42b4-4a49-fb8b-4bc24e77072c"
      },
      "source": [
        "predictions = model.predict(X_test, batch_size=100, verbose=1)\n",
        "predictions_bool = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(y_test, predictions_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      1.00      0.01         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         9\n",
            "           5       0.00      0.00      0.00        41\n",
            "           6       0.00      0.00      0.00       117\n",
            "\n",
            "    accuracy                           0.01       172\n",
            "   macro avg       0.00      0.17      0.00       172\n",
            "weighted avg       0.00      0.01      0.00       172\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}