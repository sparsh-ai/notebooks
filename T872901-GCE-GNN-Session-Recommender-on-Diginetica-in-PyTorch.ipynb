{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T872901 | GCE-GNN Session Recommender on Diginetica in PyTorch","provenance":[],"collapsed_sections":[],"mount_file_id":"1kYYqeGM3a_dFbqgXkiBmssXFrPXh_HDa","authorship_tag":"ABX9TyPt5iaH9WH3UUpq2reMwKu/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"610f87238715464b97c0cf337bf26483":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ef7b1be126c14b8ab7bb6f046afd3e53","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28f22a509bc6422b90e683caf97d6628","IPY_MODEL_525d249b3758445d86380e1a7fa3b34b","IPY_MODEL_ace400bc04934452b9ab85a191367a08"]}},"ef7b1be126c14b8ab7bb6f046afd3e53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28f22a509bc6422b90e683caf97d6628":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08c6dd23c6e84d0eb9bf9ffe106e22d4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257e1274e104408ba8019fb3cd77d38b"}},"525d249b3758445d86380e1a7fa3b34b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d0f2a7558fb4c92b20bd8855baf1da0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":6476,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6476,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a848e0ee8df5409ebb5a4d6882e194e3"}},"ace400bc04934452b9ab85a191367a08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_667f479855424c24872c55cb449e6455","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6476/6476 [41:06&lt;00:00,  2.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4037c06eaab24076b0fd4d5dd048d8c7"}},"08c6dd23c6e84d0eb9bf9ffe106e22d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257e1274e104408ba8019fb3cd77d38b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0f2a7558fb4c92b20bd8855baf1da0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a848e0ee8df5409ebb5a4d6882e194e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"667f479855424c24872c55cb449e6455":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4037c06eaab24076b0fd4d5dd048d8c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e105e57817a4dbd94b1269bd71c6a2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f743025b510a462f979bdfb3b807926e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_886cc020295d47b5816bc6e27d513b70","IPY_MODEL_6bab21a428a94b4fbc6bb6da0f21f656","IPY_MODEL_b4f73a1d2c1146099248d4f8dcc34c96"]}},"f743025b510a462f979bdfb3b807926e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"886cc020295d47b5816bc6e27d513b70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a9aff384fa1849b9bdd922b8f16451d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a40b0ff0b694faf841ff6e431b04f84"}},"6bab21a428a94b4fbc6bb6da0f21f656":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e19ced1c2d049dc834f59e6502346fa","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":6476,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6476,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_650b6f9582a54a82a61e51c9482c266a"}},"b4f73a1d2c1146099248d4f8dcc34c96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_830cc50ef31640b3b1e4f91fe09c16f6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6476/6476 [41:05&lt;00:00,  2.62it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_516b8400e7604d868f071fcbdc74e4b5"}},"a9aff384fa1849b9bdd922b8f16451d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a40b0ff0b694faf841ff6e431b04f84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e19ced1c2d049dc834f59e6502346fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"650b6f9582a54a82a61e51c9482c266a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"830cc50ef31640b3b1e4f91fe09c16f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"516b8400e7604d868f071fcbdc74e4b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"5o-1seUfT9a9"},"source":["# GCE-GNN Session Recommender on Diginetica in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"vhEnZ48N2FPy"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"sn50Ffkb2Esp"},"source":["import numpy as np\n","import datetime\n","import math\n","from tqdm.notebook import tqdm\n","import pickle\n","import time\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torch import nn\n","from torch.nn import Module, Parameter\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p26c4bNm3LOt"},"source":["class Args:\n","    def __init__(self, dataset = 'diginetica'):\n","        self.dataset = dataset\n","        self.sample_num = 12\n","        if dataset == 'diginetica':\n","            self.num = 43098\n","            self.n_iter = 2\n","            self.dropout_gcn = 0.2 # Dropout rate\n","            self.dropout_local = 0.0 # Dropout rate\n","        elif dataset == 'tmall':\n","            self.num = 40728\n","            self.n_iter = 1\n","            self.dropout_gcn = 0.6\n","            self.dropout_local = 0.5\n","        elif dataset == 'nowplaying':\n","            self.num = 60417\n","            self.n_iter = 1\n","            self.dropout_gcn = 0.0\n","            self.dropout_local = 0.0\n","        self.hiddenSize = 100\n","        self.epoch = 2\n","        self.activate = 'relu'\n","        self.n_sample_all = 12\n","        self.n_sample = 12\n","        self.batch_size = 100\n","        self.lr = 0.001 # learning rate\n","        self.lr_dc = 0.1 # learning rate decay\n","        self.lr_dc_step = 3 # the number of steps after which the learning rate decay\n","        self.l2 = 1e-5 # l2 penalty\n","        self.dropout_global = 0.5 # Dropout rate\n","        self.validation = True\n","        self.valid_portion = 0.1 # split the portion\n","        self.alpha = 0.2 # Alpha for the leaky_relu.\n","        self.patience = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE9xMI9u3Q9D"},"source":["opt = Args(dataset = 'diginetica')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lDLp5sxJUCFY"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hT2umfIz4gOQ","executionInfo":{"status":"ok","timestamp":1638277316813,"user_tz":-330,"elapsed":3160,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"49f06519-d3d3-4f42-92fe-0e6c490cb7a0"},"source":["!wget -q --show-progress https://github.com/RecoHut-Datasets/diginetica/raw/v2/all_train_seq.txt\n","!wget -q --show-progress https://github.com/RecoHut-Datasets/diginetica/raw/v2/train.txt\n","!wget -q --show-progress https://github.com/RecoHut-Datasets/diginetica/raw/v2/test.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["all_train_seq.txt   100%[===================>]   4.00M  --.-KB/s    in 0.07s   \n","train.txt           100%[===================>]  15.81M  --.-KB/s    in 0.1s    \n","test.txt            100%[===================>]   1.32M  --.-KB/s    in 0.05s   \n"]}]},{"cell_type":"markdown","metadata":{"id":"t8YR0Rts3AKg"},"source":["### Build Graph"]},{"cell_type":"code","metadata":{"id":"BClobEbS3AD3"},"source":["dataset = opt.dataset\n","sample_num = opt.sample_num\n","num = opt.num\n","\n","seq = pickle.load(open('all_train_seq.txt', 'rb'))\n","\n","relation = []\n","neighbor = [] * num\n","\n","all_test = set()\n","\n","adj1 = [dict() for _ in range(num)]\n","adj = [[] for _ in range(num)]\n","\n","for i in range(len(seq)):\n","    data = seq[i]\n","    for k in range(1, 4):\n","        for j in range(len(data)-k):\n","            relation.append([data[j], data[j+k]])\n","            relation.append([data[j+k], data[j]])\n","\n","for tup in relation:\n","    if tup[1] in adj1[tup[0]].keys():\n","        adj1[tup[0]][tup[1]] += 1\n","    else:\n","        adj1[tup[0]][tup[1]] = 1\n","\n","weight = [[] for _ in range(num)]\n","\n","for t in range(num):\n","    x = [v for v in sorted(adj1[t].items(), reverse=True, key=lambda x: x[1])]\n","    adj[t] = [v[0] for v in x]\n","    weight[t] = [v[1] for v in x]\n","\n","for i in range(num):\n","    adj[i] = adj[i][:sample_num]\n","    weight[i] = weight[i][:sample_num]\n","\n","pickle.dump(adj, open('adj_' + str(sample_num) + '.pkl', 'wb'))\n","pickle.dump(weight, open('num_' + str(sample_num) + '.pkl', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkFzOJHT5Pof"},"source":["def init_seed(seed=None):\n","    if seed is None:\n","        seed = int(time.time() * 1000 // 1000)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2AvOltD2LXN"},"source":["def split_validation(train_set, valid_portion):\n","    train_set_x, train_set_y = train_set\n","    n_samples = len(train_set_x)\n","    sidx = np.arange(n_samples, dtype='int32')\n","    np.random.shuffle(sidx)\n","    n_train = int(np.round(n_samples * (1. - valid_portion)))\n","    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n","    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n","    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n","    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n","    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTbsyqEV2PCt"},"source":["def handle_data(inputData, train_len=None):\n","    len_data = [len(nowData) for nowData in inputData]\n","    if train_len is None:\n","        max_len = max(len_data)\n","    else:\n","        max_len = train_len\n","    # reverse the sequence\n","    us_pois = [list(reversed(upois)) + [0] * (max_len - le) if le < max_len else list(reversed(upois[-max_len:]))\n","               for upois, le in zip(inputData, len_data)]\n","    us_msks = [[1] * le + [0] * (max_len - le) if le < max_len else [1] * max_len\n","               for le in len_data]\n","    return us_pois, us_msks, max_len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbL8mMda2Qhp"},"source":["def handle_adj(adj_dict, n_entity, sample_num, num_dict=None):\n","    adj_entity = np.zeros([n_entity, sample_num], dtype=np.int64)\n","    num_entity = np.zeros([n_entity, sample_num], dtype=np.int64)\n","    for entity in range(1, n_entity):\n","        neighbor = list(adj_dict[entity])\n","        neighbor_weight = list(num_dict[entity])\n","        n_neighbor = len(neighbor)\n","        if n_neighbor == 0:\n","            continue\n","        if n_neighbor >= sample_num:\n","            sampled_indices = np.random.choice(list(range(n_neighbor)), size=sample_num, replace=False)\n","        else:\n","            sampled_indices = np.random.choice(list(range(n_neighbor)), size=sample_num, replace=True)\n","        adj_entity[entity] = np.array([neighbor[i] for i in sampled_indices])\n","        num_entity[entity] = np.array([neighbor_weight[i] for i in sampled_indices])\n","    return adj_entity, num_entity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWYw5eoo2USj"},"source":["class Data(Dataset):\n","    def __init__(self, data, train_len=None):\n","        inputs, mask, max_len = handle_data(data[0], train_len)\n","        self.inputs = np.asarray(inputs)\n","        self.targets = np.asarray(data[1])\n","        self.mask = np.asarray(mask)\n","        self.length = len(data[0])\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        u_input, mask, target = self.inputs[index], self.mask[index], self.targets[index]\n","        max_n_node = self.max_len\n","        node = np.unique(u_input)\n","        items = node.tolist() + (max_n_node - len(node)) * [0]\n","        adj = np.zeros((max_n_node, max_n_node))\n","        for i in np.arange(len(u_input) - 1):\n","            u = np.where(node == u_input[i])[0][0]\n","            adj[u][u] = 1\n","            if u_input[i + 1] == 0:\n","                break\n","            v = np.where(node == u_input[i + 1])[0][0]\n","            if u == v or adj[u][v] == 4:\n","                continue\n","            adj[v][v] = 1\n","            if adj[v][u] == 2:\n","                adj[u][v] = 4\n","                adj[v][u] = 4\n","            else:\n","                adj[u][v] = 2\n","                adj[v][u] = 3\n","        alias_inputs = [np.where(node == i)[0][0] for i in u_input]\n","        \n","        return [torch.tensor(alias_inputs), torch.tensor(adj), torch.tensor(items),\n","                torch.tensor(mask), torch.tensor(target), torch.tensor(u_input)]\n","\n","    def __len__(self):\n","        return self.length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iig4FRMX4t2e"},"source":["## Aggregator"]},{"cell_type":"code","metadata":{"id":"c-GdN3UO4ty1"},"source":["class Aggregator(nn.Module):\n","    def __init__(self, batch_size, dim, dropout, act, name=None):\n","        super(Aggregator, self).__init__()\n","        self.dropout = dropout\n","        self.act = act\n","        self.batch_size = batch_size\n","        self.dim = dim\n","\n","    def forward(self):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ZzMV7ov42_o"},"source":["class LocalAggregator(nn.Module):\n","    def __init__(self, dim, alpha, dropout=0., name=None):\n","        super(LocalAggregator, self).__init__()\n","        self.dim = dim\n","        self.dropout = dropout\n","\n","        self.a_0 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_1 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_3 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.bias = nn.Parameter(torch.Tensor(self.dim))\n","\n","        self.leakyrelu = nn.LeakyReLU(alpha)\n","\n","    def forward(self, hidden, adj, mask_item=None):\n","        h = hidden\n","        batch_size = h.shape[0]\n","        N = h.shape[1]\n","\n","        a_input = (h.repeat(1, 1, N).view(batch_size, N * N, self.dim)\n","                   * h.repeat(1, N, 1)).view(batch_size, N, N, self.dim)\n","\n","        e_0 = torch.matmul(a_input, self.a_0)\n","        e_1 = torch.matmul(a_input, self.a_1)\n","        e_2 = torch.matmul(a_input, self.a_2)\n","        e_3 = torch.matmul(a_input, self.a_3)\n","\n","        e_0 = self.leakyrelu(e_0).squeeze(-1).view(batch_size, N, N)\n","        e_1 = self.leakyrelu(e_1).squeeze(-1).view(batch_size, N, N)\n","        e_2 = self.leakyrelu(e_2).squeeze(-1).view(batch_size, N, N)\n","        e_3 = self.leakyrelu(e_3).squeeze(-1).view(batch_size, N, N)\n","\n","        mask = -9e15 * torch.ones_like(e_0)\n","        alpha = torch.where(adj.eq(1), e_0, mask)\n","        alpha = torch.where(adj.eq(2), e_1, alpha)\n","        alpha = torch.where(adj.eq(3), e_2, alpha)\n","        alpha = torch.where(adj.eq(4), e_3, alpha)\n","        alpha = torch.softmax(alpha, dim=-1)\n","\n","        output = torch.matmul(alpha, h)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dLm1v7Y46Vm"},"source":["class GlobalAggregator(nn.Module):\n","    def __init__(self, dim, dropout, act=torch.relu, name=None):\n","        super(GlobalAggregator, self).__init__()\n","        self.dropout = dropout\n","        self.act = act\n","        self.dim = dim\n","\n","        self.w_1 = nn.Parameter(torch.Tensor(self.dim + 1, self.dim))\n","        self.w_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.w_3 = nn.Parameter(torch.Tensor(2 * self.dim, self.dim))\n","        self.bias = nn.Parameter(torch.Tensor(self.dim))\n","\n","    def forward(self, self_vectors, neighbor_vector, batch_size, masks, neighbor_weight, extra_vector=None):\n","        if extra_vector is not None:\n","            alpha = torch.matmul(torch.cat([extra_vector.unsqueeze(2).repeat(1, 1, neighbor_vector.shape[2], 1)*neighbor_vector, neighbor_weight.unsqueeze(-1)], -1), self.w_1).squeeze(-1)\n","            alpha = F.leaky_relu(alpha, negative_slope=0.2)\n","            alpha = torch.matmul(alpha, self.w_2).squeeze(-1)\n","            alpha = torch.softmax(alpha, -1).unsqueeze(-1)\n","            neighbor_vector = torch.sum(alpha * neighbor_vector, dim=-2)\n","        else:\n","            neighbor_vector = torch.mean(neighbor_vector, dim=2)\n","        # self_vectors = F.dropout(self_vectors, 0.5, training=self.training)\n","        output = torch.cat([self_vectors, neighbor_vector], -1)\n","        output = F.dropout(output, self.dropout, training=self.training)\n","        output = torch.matmul(output, self.w_3)\n","        output = output.view(batch_size, -1, self.dim)\n","        output = self.act(output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xAkDD17B2aV5"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"0xKI49N-23aa"},"source":["class CombineGraph(Module):\n","    def __init__(self, opt, num_node, adj_all, num):\n","        super(CombineGraph, self).__init__()\n","        self.opt = opt\n","\n","        self.batch_size = opt.batch_size\n","        self.num_node = num_node\n","        self.dim = opt.hiddenSize\n","        self.dropout_local = opt.dropout_local\n","        self.dropout_global = opt.dropout_global\n","        self.hop = opt.n_iter\n","        self.sample_num = opt.n_sample\n","        self.adj_all = trans_to_cuda(torch.Tensor(adj_all)).long()\n","        self.num = trans_to_cuda(torch.Tensor(num)).float()\n","\n","        # Aggregator\n","        self.local_agg = LocalAggregator(self.dim, self.opt.alpha, dropout=0.0)\n","        self.global_agg = []\n","        for i in range(self.hop):\n","            if opt.activate == 'relu':\n","                agg = GlobalAggregator(self.dim, opt.dropout_gcn, act=torch.relu)\n","            else:\n","                agg = GlobalAggregator(self.dim, opt.dropout_gcn, act=torch.tanh)\n","            self.add_module('agg_gcn_{}'.format(i), agg)\n","            self.global_agg.append(agg)\n","\n","        # Item representation & Position representation\n","        self.embedding = nn.Embedding(num_node, self.dim)\n","        self.pos_embedding = nn.Embedding(200, self.dim)\n","\n","        # Parameters\n","        self.w_1 = nn.Parameter(torch.Tensor(2 * self.dim, self.dim))\n","        self.w_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.glu1 = nn.Linear(self.dim, self.dim)\n","        self.glu2 = nn.Linear(self.dim, self.dim, bias=False)\n","        self.linear_transform = nn.Linear(self.dim, self.dim, bias=False)\n","\n","        self.leakyrelu = nn.LeakyReLU(opt.alpha)\n","        self.loss_function = nn.CrossEntropyLoss()\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr, weight_decay=opt.l2)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt.lr_dc_step, gamma=opt.lr_dc)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1.0 / math.sqrt(self.dim)\n","        for weight in self.parameters():\n","            weight.data.uniform_(-stdv, stdv)\n","\n","    def sample(self, target, n_sample):\n","        # neighbor = self.adj_all[target.view(-1)]\n","        # index = np.arange(neighbor.shape[1])\n","        # np.random.shuffle(index)\n","        # index = index[:n_sample]\n","        # return self.adj_all[target.view(-1)][:, index], self.num[target.view(-1)][:, index]\n","        return self.adj_all[target.view(-1)], self.num[target.view(-1)]\n","\n","    def compute_scores(self, hidden, mask):\n","        mask = mask.float().unsqueeze(-1)\n","\n","        batch_size = hidden.shape[0]\n","        len = hidden.shape[1]\n","        pos_emb = self.pos_embedding.weight[:len]\n","        pos_emb = pos_emb.unsqueeze(0).repeat(batch_size, 1, 1)\n","\n","        hs = torch.sum(hidden * mask, -2) / torch.sum(mask, 1)\n","        hs = hs.unsqueeze(-2).repeat(1, len, 1)\n","        nh = torch.matmul(torch.cat([pos_emb, hidden], -1), self.w_1)\n","        nh = torch.tanh(nh)\n","        nh = torch.sigmoid(self.glu1(nh) + self.glu2(hs))\n","        beta = torch.matmul(nh, self.w_2)\n","        beta = beta * mask\n","        select = torch.sum(beta * hidden, 1)\n","\n","        b = self.embedding.weight[1:]  # n_nodes x latent_size\n","        scores = torch.matmul(select, b.transpose(1, 0))\n","        return scores\n","\n","    def forward(self, inputs, adj, mask_item, item):\n","        batch_size = inputs.shape[0]\n","        seqs_len = inputs.shape[1]\n","        h = self.embedding(inputs)\n","\n","        # local\n","        h_local = self.local_agg(h, adj, mask_item)\n","\n","        # global\n","        item_neighbors = [inputs]\n","        weight_neighbors = []\n","        support_size = seqs_len\n","\n","        for i in range(1, self.hop + 1):\n","            item_sample_i, weight_sample_i = self.sample(item_neighbors[-1], self.sample_num)\n","            support_size *= self.sample_num\n","            item_neighbors.append(item_sample_i.view(batch_size, support_size))\n","            weight_neighbors.append(weight_sample_i.view(batch_size, support_size))\n","\n","        entity_vectors = [self.embedding(i) for i in item_neighbors]\n","        weight_vectors = weight_neighbors\n","\n","        session_info = []\n","        item_emb = self.embedding(item) * mask_item.float().unsqueeze(-1)\n","        \n","        # mean \n","        sum_item_emb = torch.sum(item_emb, 1) / torch.sum(mask_item.float(), -1).unsqueeze(-1)\n","        \n","        # sum\n","        # sum_item_emb = torch.sum(item_emb, 1)\n","        \n","        sum_item_emb = sum_item_emb.unsqueeze(-2)\n","        for i in range(self.hop):\n","            session_info.append(sum_item_emb.repeat(1, entity_vectors[i].shape[1], 1))\n","\n","        for n_hop in range(self.hop):\n","            entity_vectors_next_iter = []\n","            shape = [batch_size, -1, self.sample_num, self.dim]\n","            for hop in range(self.hop - n_hop):\n","                aggregator = self.global_agg[n_hop]\n","                vector = aggregator(self_vectors=entity_vectors[hop],\n","                                    neighbor_vector=entity_vectors[hop+1].view(shape),\n","                                    masks=None,\n","                                    batch_size=batch_size,\n","                                    neighbor_weight=weight_vectors[hop].view(batch_size, -1, self.sample_num),\n","                                    extra_vector=session_info[hop])\n","                entity_vectors_next_iter.append(vector)\n","            entity_vectors = entity_vectors_next_iter\n","\n","        h_global = entity_vectors[0].view(batch_size, seqs_len, self.dim)\n","\n","        # combine\n","        h_local = F.dropout(h_local, self.dropout_local, training=self.training)\n","        h_global = F.dropout(h_global, self.dropout_global, training=self.training)\n","        output = h_local + h_global\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RVP050T27xr"},"source":["def trans_to_cuda(variable):\n","    if torch.cuda.is_available():\n","        return variable.cuda()\n","    else:\n","        return variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuXi-8D626u3"},"source":["def trans_to_cpu(variable):\n","    if torch.cuda.is_available():\n","        return variable.cpu()\n","    else:\n","        return variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5E53SVJQ25xm"},"source":["def forward(model, data):\n","    alias_inputs, adj, items, mask, targets, inputs = data\n","    alias_inputs = trans_to_cuda(alias_inputs).long()\n","    items = trans_to_cuda(items).long()\n","    adj = trans_to_cuda(adj).float()\n","    mask = trans_to_cuda(mask).long()\n","    inputs = trans_to_cuda(inputs).long()\n","\n","    hidden = model(items, adj, mask, inputs)\n","    get = lambda index: hidden[index][alias_inputs[index]]\n","    seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n","    return targets, model.compute_scores(seq_hidden, mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tajDb_Wy24pf"},"source":["def train_test(model, train_data, test_data):\n","    print('start training: ', datetime.datetime.now())\n","    model.train()\n","    total_loss = 0.0\n","    train_loader = torch.utils.data.DataLoader(train_data, num_workers=2, batch_size=model.batch_size,\n","                                               shuffle=True, pin_memory=True)\n","    for data in tqdm(train_loader):\n","        model.optimizer.zero_grad()\n","        targets, scores = forward(model, data)\n","        targets = trans_to_cuda(targets).long()\n","        loss = model.loss_function(scores, targets - 1)\n","        loss.backward()\n","        model.optimizer.step()\n","        total_loss += loss\n","    print('\\tLoss:\\t%.3f' % total_loss)\n","    model.scheduler.step()\n","\n","    print('start predicting: ', datetime.datetime.now())\n","    model.eval()\n","    test_loader = torch.utils.data.DataLoader(test_data, num_workers=2, batch_size=model.batch_size,\n","                                              shuffle=False, pin_memory=True)\n","    result = []\n","    hit, mrr = [], []\n","    for data in test_loader:\n","        targets, scores = forward(model, data)\n","        sub_scores = scores.topk(20)[1]\n","        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n","        targets = targets.numpy()\n","        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n","            hit.append(np.isin(target - 1, score))\n","            if len(np.where(score == target - 1)[0]) == 0:\n","                mrr.append(0)\n","            else:\n","                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n","\n","    result.append(np.mean(hit) * 100)\n","    result.append(np.mean(mrr) * 100)\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H9RRpEwj23XD"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"4hIJPbsv23Uc"},"source":["init_seed(2020)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQADBzqW66dD"},"source":["train_data = pickle.load(open('train.txt', 'rb'))\n","if opt.validation:\n","    train_data, valid_data = split_validation(train_data, opt.valid_portion)\n","    test_data = valid_data\n","else:\n","    test_data = pickle.load(open('test.txt', 'rb'))\n","\n","adj = pickle.load(open('adj_' + str(opt.n_sample_all) + '.pkl', 'rb'))\n","num = pickle.load(open('num_' + str(opt.n_sample_all) + '.pkl', 'rb'))\n","\n","train_data = Data(train_data)\n","test_data = Data(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446,"referenced_widgets":["610f87238715464b97c0cf337bf26483","ef7b1be126c14b8ab7bb6f046afd3e53","28f22a509bc6422b90e683caf97d6628","525d249b3758445d86380e1a7fa3b34b","ace400bc04934452b9ab85a191367a08","08c6dd23c6e84d0eb9bf9ffe106e22d4","257e1274e104408ba8019fb3cd77d38b","7d0f2a7558fb4c92b20bd8855baf1da0","a848e0ee8df5409ebb5a4d6882e194e3","667f479855424c24872c55cb449e6455","4037c06eaab24076b0fd4d5dd048d8c7","3e105e57817a4dbd94b1269bd71c6a2d","f743025b510a462f979bdfb3b807926e","886cc020295d47b5816bc6e27d513b70","6bab21a428a94b4fbc6bb6da0f21f656","b4f73a1d2c1146099248d4f8dcc34c96","a9aff384fa1849b9bdd922b8f16451d3","5a40b0ff0b694faf841ff6e431b04f84","1e19ced1c2d049dc834f59e6502346fa","650b6f9582a54a82a61e51c9482c266a","830cc50ef31640b3b1e4f91fe09c16f6","516b8400e7604d868f071fcbdc74e4b5"]},"id":"HveobxF67avY","executionInfo":{"status":"ok","timestamp":1638282561518,"user_tz":-330,"elapsed":5119596,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"8cb25b71-80bc-4e22-f8a6-b39167a51047"},"source":["adj, num = handle_adj(adj, opt.num, opt.n_sample_all, num)\n","model = trans_to_cuda(CombineGraph(opt, opt.num, adj, num))\n","\n","print(opt)\n","\n","start = time.time()\n","best_result = [0, 0]\n","best_epoch = [0, 0]\n","bad_counter = 0\n","\n","for epoch in range(opt.epoch):\n","    print('-------------------------------------------------------')\n","    print('epoch: ', epoch)\n","    hit, mrr = train_test(model, train_data, test_data)\n","    flag = 0\n","    if hit >= best_result[0]:\n","        best_result[0] = hit\n","        best_epoch[0] = epoch\n","        flag = 1\n","    if mrr >= best_result[1]:\n","        best_result[1] = mrr\n","        best_epoch[1] = epoch\n","        flag = 1\n","    print('Current Result:')\n","    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f' % (hit, mrr))\n","    print('Best Result:')\n","    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d,\\t%d' % (\n","        best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n","    bad_counter += 1 - flag\n","    if bad_counter >= opt.patience:\n","        break\n","print('-------------------------------------------------------')\n","end = time.time()\n","print(\"Run time: %f s\" % (end - start))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Args object at 0x7f9c62373a90>\n","-------------------------------------------------------\n","epoch:  0\n","start training:  2021-11-30 13:04:07.876575\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"610f87238715464b97c0cf337bf26483","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/6476 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\tLoss:\t41743.461\n","start predicting:  2021-11-30 13:45:14.877128\n","Current Result:\n","\tRecall@20:\t52.4400\tMMR@20:\t17.8599\n","Best Result:\n","\tRecall@20:\t52.4400\tMMR@20:\t17.8599\tEpoch:\t0,\t0\n","-------------------------------------------------------\n","epoch:  1\n","start training:  2021-11-30 13:46:45.825277\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e105e57817a4dbd94b1269bd71c6a2d","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/6476 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\tLoss:\t33685.008\n","start predicting:  2021-11-30 14:27:51.831564\n","Current Result:\n","\tRecall@20:\t53.9494\tMMR@20:\t18.4467\n","Best Result:\n","\tRecall@20:\t53.9494\tMMR@20:\t18.4467\tEpoch:\t1,\t1\n","-------------------------------------------------------\n","Run time: 5114.603005 s\n"]}]},{"cell_type":"markdown","metadata":{"id":"CbbpODHA8dr8"},"source":["---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S3rQXBz8dsA","executionInfo":{"status":"ok","timestamp":1638282679736,"user_tz":-330,"elapsed":3398,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a07a3d6b-c6f5-4800-c581-b5af62b37a92"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-11-30 14:31:20\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","torch  : 1.10.0+cu111\n","numpy  : 1.19.5\n","IPython: 5.5.0\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"I0TYBU4w8dsB"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"SYzSMRCX8dsC"},"source":["**END**"]}]}