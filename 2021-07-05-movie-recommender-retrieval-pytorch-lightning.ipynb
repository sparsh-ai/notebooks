{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-07-05-movie-recommender-retrieval-pytorch-lightning.ipynb",
      "provenance": [],
      "mount_file_id": "1U-0HxJZ2llf5cajcKsxs-QwRuKDSZ2uA",
      "authorship_tag": "ABX9TyO1m8bH9KzwdgmTx4O4pOaN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa8a0718bba846af8863604811c539d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24f33c9a9ef54658bb5bd8b623b4cc37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e21c4e39bec54e9b8b26c0c31bb8edc8",
              "IPY_MODEL_82d38bf1a9c343f8a32ff44e4e7fcf8b"
            ]
          }
        },
        "24f33c9a9ef54658bb5bd8b623b4cc37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e21c4e39bec54e9b8b26c0c31bb8edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e932cfbc755544feaf9cb3918c24b4f3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7502047,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7502047,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a1da7d330704c0ea800d4c0a30f56b9"
          }
        },
        "82d38bf1a9c343f8a32ff44e4e7fcf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1607718f934446f796d454654b09a150",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7502047/7502047 [03:18&lt;00:00, 37868.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_662066d58d8446f09979c0de782bf6e8"
          }
        },
        "e932cfbc755544feaf9cb3918c24b4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a1da7d330704c0ea800d4c0a30f56b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1607718f934446f796d454654b09a150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "662066d58d8446f09979c0de782bf6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68bcd7bfc32f4d9ebaba5c08437bca28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2805d9154e374318a467cad92c87d889",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e68d0f42e5284ee5ab6fd8545b789097",
              "IPY_MODEL_857ee1a3d8274f87a2681bbe41a61413"
            ]
          }
        },
        "2805d9154e374318a467cad92c87d889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e68d0f42e5284ee5ab6fd8545b789097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b54f4d631bc643f9830098f40e3221fd",
            "_dom_classes": [],
            "description": "Epoch 3:  83%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 73263,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_934559e820bf4c7793372990727b52b2"
          }
        },
        "857ee1a3d8274f87a2681bbe41a61413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e5512ac9bc54aa59955ed68bb0bdf4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61000/73263 [36:23&lt;07:18, 27.94it/s, loss=0.156]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bfc383196bc4c929c1b6fa503f93cad"
          }
        },
        "b54f4d631bc643f9830098f40e3221fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "934559e820bf4c7793372990727b52b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e5512ac9bc54aa59955ed68bb0bdf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bfc383196bc4c929c1b6fa503f93cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mesNcoILdln4"
      },
      "source": [
        "# Movie Candidate Retrieval with PyTorch Lightning\n",
        "> In this notebook, we will build a simple yet accurate model using movielens-25m dataset and pytorch lightning library. This will be a retrieval model where the objective is to maximize recall over precision.\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [PyTorch, MovieLens, Retrieval]\n",
        "- author: \"<a href='https://towardsdatascience.com/deep-learning-based-recommender-systems-3d120201db7e'>James Loy</a>\"\n",
        "- image:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5dwnLIupPaB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SbNhrnyfIcg",
        "outputId": "410e27d1-6b78-4de5-8f0c-1ea56d6ea2f9"
      },
      "source": [
        "#hide-output\n",
        "!pip install -q pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 819kB 13.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 33.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 41.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.6MB 21.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 42.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 34.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 31.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 38.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 40.5MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc2bntgJezOR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jIQm_WLpR2P"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_ShWD1yfAOb",
        "outputId": "acb871c0-1157-439a-f3e1-377676ba1c32"
      },
      "source": [
        "#hide-output\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip && unzip ml-25m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-05 07:35:12--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: â€˜ml-25m.zipâ€™\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  28.4MB/s    in 9.7s    \n",
            "\n",
            "2021-07-05 07:35:22 (25.8 MB/s) - â€˜ml-25m.zipâ€™ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InLSsx4hfeBm"
      },
      "source": [
        "ratings = pd.read_csv('ml-25m/ratings.csv', infer_datetime_format=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_27d9mBpUl-"
      },
      "source": [
        "## Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-uvTYoAgJSW"
      },
      "source": [
        "In order to keep memory usage manageable within Kaggle's kernel, we will only use data from 30% of the users in this dataset. Let's randomly select 30% of the users and only use data from the selected users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5kxycTAgCUF",
        "outputId": "2f2f6e1b-950e-4f84-d017-b0c6e11b4c18"
      },
      "source": [
        "rand_userIds = np.random.choice(ratings['userId'].unique(), \n",
        "                                size=int(len(ratings['userId'].unique())*0.3), \n",
        "                                replace=False)\n",
        "\n",
        "ratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n",
        "\n",
        "print('There are {} rows of data from {} users'.format(len(ratings), len(rand_userIds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 7550809 rows of data from 48762 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "amSm_bU1gO2C",
        "outputId": "ddbee782-ced5-4fc4-c333-d1faa04e33c9"
      },
      "source": [
        "ratings.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6324829</th>\n",
              "      <td>41013</td>\n",
              "      <td>31696</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1523572998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266955</th>\n",
              "      <td>21561</td>\n",
              "      <td>2809</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1078821411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7673867</th>\n",
              "      <td>49806</td>\n",
              "      <td>85131</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1465692476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5881789</th>\n",
              "      <td>38117</td>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1244431007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7458092</th>\n",
              "      <td>48443</td>\n",
              "      <td>590</td>\n",
              "      <td>4.0</td>\n",
              "      <td>832358637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         userId  movieId  rating   timestamp\n",
              "6324829   41013    31696     3.0  1523572998\n",
              "3266955   21561     2809     1.0  1078821411\n",
              "7673867   49806    85131     3.0  1465692476\n",
              "5881789   38117       32     4.0  1244431007\n",
              "7458092   48443      590     4.0   832358637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7OS6UqDpXdi"
      },
      "source": [
        "## Train/Test Split\n",
        "**Chronological Leave-One-Out Split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaqAMrH-gn_i"
      },
      "source": [
        "Along with the rating, there is also a timestamp column that shows the date and time the review was submitted. Using the timestamp column, we will implement our train-test split strategy using the leave-one-out methodology. For each user, the most recent review is used as the test set (i.e. leave one out), while the rest will be used as training data ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4COa9yVguUO"
      },
      "source": [
        "> Note: Doing a random split would not be fair, as we could potentially be using a user's recent reviews for training and earlier reviews for testing. This introduces data leakage with a look-ahead bias, and the performance of the trained model would not be generalizable to real-world performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtdtS0FMgTez"
      },
      "source": [
        "ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'] \\\n",
        "                                .rank(method='first', ascending=False)\n",
        "\n",
        "train_ratings = ratings[ratings['rank_latest'] != 1]\n",
        "test_ratings = ratings[ratings['rank_latest'] == 1]\n",
        "\n",
        "# drop columns that we no longer need\n",
        "train_ratings = train_ratings[['userId', 'movieId', 'rating']]\n",
        "test_ratings = test_ratings[['userId', 'movieId', 'rating']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFoYAbhqpnPD"
      },
      "source": [
        "## Implicit Conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwYvXqJ6hz2u"
      },
      "source": [
        "We will train a recommender system using implicit feedback. However, the MovieLens dataset that we're using is based on explicit feedback. To convert this dataset into an implicit feedback dataset, we'll simply binarize the ratings such that they are are '1' (i.e. positive class). The value of '1' represents that the user has interacted with the item.\n",
        "\n",
        "> Note: Using implicit feedback reframes the problem that our recommender is trying to solve. Instead of trying to predict movie ratings (when using explicit feedback), we are trying to predict whether the user will interact (i.e. click/buy/watch) with each movie, with the aim of presenting to users the movies with the highest interaction likelihood.\n",
        "\n",
        "> Tip: This setting is suitable at retrieval stage where the objective is to maximize recall by identifying items that user will at least interact with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sQYuW1Otg_Cg",
        "outputId": "5d785fa4-6263-4708-d218-4055a1c86dc8"
      },
      "source": [
        "train_ratings.loc[:, 'rating'] = 1\n",
        "\n",
        "train_ratings.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3823395</th>\n",
              "      <td>25188</td>\n",
              "      <td>7361</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11252225</th>\n",
              "      <td>72983</td>\n",
              "      <td>1196</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10438742</th>\n",
              "      <td>67740</td>\n",
              "      <td>2375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24671965</th>\n",
              "      <td>160317</td>\n",
              "      <td>540</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20929124</th>\n",
              "      <td>136101</td>\n",
              "      <td>4297</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          userId  movieId  rating\n",
              "3823395    25188     7361       1\n",
              "11252225   72983     1196       1\n",
              "10438742   67740     2375       1\n",
              "24671965  160317      540       1\n",
              "20929124  136101     4297       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhwZiaBPpsQl"
      },
      "source": [
        "## Negative Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngZdyoMjizlw"
      },
      "source": [
        "We do have a problem now though. After binarizing our dataset, we see that every sample in the dataset now belongs to the positive class. However we also require negative samples to train our models, to indicate movies that the user has not interacted with. We assume that such movies are those that the user are not interested in - even though this is a sweeping assumption that may not be true, it usually works out rather well in practice.\n",
        "\n",
        "The code below generates 4 negative samples for each row of data. In other words, the ratio of negative to positive samples is 4:1. This ratio is chosen arbitrarily but I found that it works rather well (feel free to find the best ratio yourself!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "fa8a0718bba846af8863604811c539d5",
            "24f33c9a9ef54658bb5bd8b623b4cc37",
            "e21c4e39bec54e9b8b26c0c31bb8edc8",
            "82d38bf1a9c343f8a32ff44e4e7fcf8b",
            "e932cfbc755544feaf9cb3918c24b4f3",
            "8a1da7d330704c0ea800d4c0a30f56b9",
            "1607718f934446f796d454654b09a150",
            "662066d58d8446f09979c0de782bf6e8"
          ]
        },
        "id": "4T0_UVhTizVn",
        "outputId": "8b92d6ca-e2cb-4cfc-a53a-b4f90a0d600d"
      },
      "source": [
        "# Get a list of all movie IDs\n",
        "all_movieIds = ratings['movieId'].unique()\n",
        "\n",
        "# Placeholders that will hold the training data\n",
        "users, items, labels = [], [], []\n",
        "\n",
        "# This is the set of items that each user has interaction with\n",
        "user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId']))\n",
        "\n",
        "# 4:1 ratio of negative to positive samples\n",
        "num_negatives = 4\n",
        "\n",
        "for (u, i) in tqdm(user_item_set):\n",
        "    users.append(u)\n",
        "    items.append(i)\n",
        "    labels.append(1) # items that the user has interacted with are positive\n",
        "    for _ in range(num_negatives):\n",
        "        # randomly select an item\n",
        "        negative_item = np.random.choice(all_movieIds) \n",
        "        # check that the user has not interacted with this item\n",
        "        while (u, negative_item) in user_item_set:\n",
        "            negative_item = np.random.choice(all_movieIds)\n",
        "        users.append(u)\n",
        "        items.append(negative_item)\n",
        "        labels.append(0) # items not interacted with are negative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa8a0718bba846af8863604811c539d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7502047.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brxnZqlpvXD"
      },
      "source": [
        "## PyTorch Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br2u5nn5jAy1"
      },
      "source": [
        "Great! We now have the data in the format required by our model. Before we move on, let's define a PyTorch Dataset to facilitate training. The class below simply encapsulates the code we have written above into a PyTorch Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCn0M346i6Z8"
      },
      "source": [
        "class MovieLensTrainDataset(Dataset):\n",
        "    \"\"\"MovieLens PyTorch Dataset for Training\n",
        "    \n",
        "    Args:\n",
        "        ratings (pd.DataFrame): Dataframe containing the movie ratings\n",
        "        all_movieIds (list): List containing all movieIds\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ratings, all_movieIds):\n",
        "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_dataset(self, ratings, all_movieIds):\n",
        "        users, items, labels = [], [], []\n",
        "        user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
        "\n",
        "        num_negatives = 4\n",
        "        for u, i in user_item_set:\n",
        "            users.append(u)\n",
        "            items.append(i)\n",
        "            labels.append(1)\n",
        "            for _ in range(num_negatives):\n",
        "                negative_item = np.random.choice(all_movieIds)\n",
        "                while (u, negative_item) in user_item_set:\n",
        "                    negative_item = np.random.choice(all_movieIds)\n",
        "                users.append(u)\n",
        "                items.append(negative_item)\n",
        "                labels.append(0)\n",
        "\n",
        "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqMDcEYRjOZN"
      },
      "source": [
        "## Model - Neural Collaborative Filtering (NCF)\n",
        "\n",
        "While there are many deep learning based architecture for recommendation systems, I find that the framework proposed by He et al. is the most straightforward and it is simple enough to be implemented in a tutorial such as this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwlBJpqljJvS"
      },
      "source": [
        "class NCF(pl.LightningModule):\n",
        "    \"\"\" Neural Collaborative Filtering (NCF)\n",
        "    \n",
        "        Args:\n",
        "            num_users (int): Number of unique users\n",
        "            num_items (int): Number of unique items\n",
        "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
        "            all_movieIds (list): List containing all movieIds (train + test)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_users, num_items, ratings, all_movieIds):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
        "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
        "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.output = nn.Linear(in_features=32, out_features=1)\n",
        "        self.ratings = ratings\n",
        "        self.all_movieIds = all_movieIds\n",
        "        \n",
        "    def forward(self, user_input, item_input):\n",
        "        \n",
        "        # Pass through embedding layers\n",
        "        user_embedded = self.user_embedding(user_input)\n",
        "        item_embedded = self.item_embedding(item_input)\n",
        "\n",
        "        # Concat the two embedding layers\n",
        "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
        "\n",
        "        # Pass through dense layer\n",
        "        vector = nn.ReLU()(self.fc1(vector))\n",
        "        vector = nn.ReLU()(self.fc2(vector))\n",
        "\n",
        "        # Output layer\n",
        "        pred = nn.Sigmoid()(self.output(vector))\n",
        "\n",
        "        return pred\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        user_input, item_input, labels = batch\n",
        "        predicted_labels = self(user_input, item_input)\n",
        "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n",
        "                          batch_size=512, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8wT1WK9jzeJ"
      },
      "source": [
        "We instantiate the NCF model using the class that we have defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Bh9dorjww7"
      },
      "source": [
        "num_users = ratings['userId'].max()+1\n",
        "num_items = ratings['movieId'].max()+1\n",
        "\n",
        "all_movieIds = ratings['movieId'].unique()\n",
        "\n",
        "model = NCF(num_users, num_items, train_ratings, all_movieIds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Mw8CdVp5lF"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnYHNWe3kRRD"
      },
      "source": [
        "> Note: One advantage of PyTorch Lightning over vanilla PyTorch is that you don't need to write your own boiler plate training code. Notice how the Trainer class allows us to train our model with just a few lines of code.\n",
        "\n",
        "Let's train our NCF model for 5 epochs using the GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "68bcd7bfc32f4d9ebaba5c08437bca28",
            "2805d9154e374318a467cad92c87d889",
            "e68d0f42e5284ee5ab6fd8545b789097",
            "857ee1a3d8274f87a2681bbe41a61413",
            "b54f4d631bc643f9830098f40e3221fd",
            "934559e820bf4c7793372990727b52b2",
            "2e5512ac9bc54aa59955ed68bb0bdf4a",
            "3bfc383196bc4c929c1b6fa503f93cad"
          ]
        },
        "id": "0JganCIMj2EW",
        "outputId": "6fa64b89-c835-4f39-d6ad-bac6f2369c64"
      },
      "source": [
        "trainer = pl.Trainer(max_epochs=5, gpus=1, reload_dataloaders_every_epoch=True,\n",
        "                     progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
        "\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type      | Params\n",
            "---------------------------------------------\n",
            "0 | user_embedding | Embedding | 1.3 M \n",
            "1 | item_embedding | Embedding | 1.7 M \n",
            "2 | fc1            | Linear    | 1.1 K \n",
            "3 | fc2            | Linear    | 2.1 K \n",
            "4 | output         | Linear    | 33    \n",
            "---------------------------------------------\n",
            "3.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.0 M     Total params\n",
            "11.907    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68bcd7bfc32f4d9ebaba5c08437bca28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6V1Tiw1kIxk"
      },
      "source": [
        "> Note: We are using the argument reload_dataloaders_every_epoch=True. This creates a new randomly chosen set of negative samples for each epoch, which ensures that our model is not biased by the selection of negative samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3BXx1YzlAUq"
      },
      "source": [
        "## Evaluating our Recommender System\n",
        "\n",
        "Now that our model is trained, we are ready to evaluate it using the test data. In traditional Machine Learning projects, we evaluate our models using metrics such as Accuracy (for classification problems) and RMSE (for regression problems). However, such metrics are too simplistic for evaluating recommender systems.\n",
        "\n",
        "The key here is that we don't need the user to interact on every single item in the list of recommendations. Instead, we just need the user to interact with at least one item on the list - as long as the user does that, the recommendations have worked.\n",
        "\n",
        "To simulate this, let's run the following evaluation protocol to generate a list of 10 recommended items for each user.\n",
        "- For each user, randomly select 99 items that the user has not interacted with\n",
        "- Combine these 99 items with the test item (the actual item that the user interacted with). We now have 100 items.\n",
        "- Run the model on these 100 items, and rank them according to their predicted probabilities\n",
        "- Select the top 10 items from the list of 100 items. If the test item is present within the top 10 items, then we say that this is a hit.\n",
        "- Repeat the process for all users. The Hit Ratio is then the average hits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PVVpUflN34"
      },
      "source": [
        "> Note: This evaluation protocol is known as Hit Ratio @ 10, and it is commonly used to evaluate recommender systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSLTYZuhlNEV"
      },
      "source": [
        "# User-item pairs for testing\n",
        "test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
        "\n",
        "# Dict of all items that are interacted with by each user\n",
        "user_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "\n",
        "hits = []\n",
        "for (u,i) in tqdm(test_user_item_set):\n",
        "    interacted_items = user_interacted_items[u]\n",
        "    not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
        "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
        "    test_items = selected_not_interacted + [i]\n",
        "    \n",
        "    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
        "                                        torch.tensor(test_items)).detach().numpy())\n",
        "    \n",
        "    top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
        "    \n",
        "    if i in top10_items:\n",
        "        hits.append(1)\n",
        "    else:\n",
        "        hits.append(0)\n",
        "        \n",
        "print(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XtzBFsllfN"
      },
      "source": [
        "We got a pretty good Hit Ratio @ 10 score! To put this into context, what this means is that 86% of the users were recommended the actual item (among a list of 10 items) that they eventually interacted with. Not bad!"
      ]
    }
  ]
}