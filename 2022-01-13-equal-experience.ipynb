{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-13-equal-experience.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/P525289%20%7C%20Equal%20Experience%20in%20Recommender%20Systems%20on%20ML-1m%20and%20Synthetic%20biased%20data.ipynb","timestamp":1644611257228}],"toc_visible":true,"collapsed_sections":[],"authorship_tag":"ABX9TyOjhhAJyw0mnU04uohhCcZr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Equal Experience in Recommender Systems on ML-1m and Synthetic biased data"],"metadata":{"id":"8OiTWf8-UHea"}},{"cell_type":"markdown","source":["## Executive summary\n","\n","| | |\n","| --- | --- |\n","| Problem | Biased data due to inherent stereotypes of particular groups (e.g., male students’ average rating on mathematics is often higher than that on humanities, and vice versa for females) may yield a limited scope of suggested items to a certain group of users. |\n","| Solution | The novel fairness notion, coined ***Equal Experience***, tries to capture the degree of the equal experience of item recommendations across distinct groups. Specifically, the prediction $\\hat{Y}$ should be independent of the 1) user group $Z_{user}$, and 2) item group $Z_{item}$. Formally, $I(\\hat{Y};Z_{user},Z_{item}) = I(\\hat{Y};Z_{item}) + I(\\hat{Y};Z_{user}|Z_{item}) = I(\\hat{Y};Z_{user}) + I(\\hat{Y};Z_{item}|Z_{user})$ |\n","| Dataset | ML-1m, LastFM-360k, Synthetic. |\n","| Preprocessing | For ML-1m, we divide user and item groups based on gender and genre, respectively. Action, crime, film-noir, war are selected as male-preferred genre, whereas children, fantasy, musical, romance are selected as female-preferred genre. We can select male-preferred and female-preferred genres in a variety of ways based on ratings and observations. In case of LastFM-360k, the associated task is to predict whether the user likes the artist or not. The data for play counts is converted to binary rating. We divide user and item groups based on gender and genre, respectively. We also randomly select 5000 male and 5000 female users. Among 10 genres, we choose hip-hop and musical for male and female preferred genres, respectively. The final rating matrix of 10,000 users and 5,706 artists is 0.55% full. We randomly split the real datasets into 90% train set and 10% test set. In case of MovieLens data, the rating is five-star based, so we set the threshold $\\tau$ = 3, on the other hand, for LastFM and for synthetic dataset, we set $\\tau$ = 0 as $M_{ij} \\in \\{+1, −1\\}$. |\n","| Metrics | RMSE, DEE, VAL, UGF, CVS |\n","| Models | MF class models, AE class models |\n","| Cluster | Python 3.6+, PyTorch |\n","| Tags | `Fairness`, `MatrixFactorization`, `AutoEncoder`,  `ExposureBias`, `PopulationBias` |\n","| Credits | cjw2525 |"],"metadata":{"id":"2TVkI_xCUHb8"}},{"cell_type":"markdown","source":["## Process flow\n","\n","![](https://github.com/RecoHut-Stanzas/S035564/raw/main/images/process_flow.svg)"],"metadata":{"id":"qDzuVLpuUHZv"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"iuYv-2Vn4DIk"}},{"cell_type":"code","source":["!pip install livelossplot"],"metadata":{"id":"7b_o3k0T4HIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","from tqdm.notebook import tqdm\n","import math\n","import collections\n","import itertools\n","\n","import os\n","import sys\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torch.nn import utils\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","from time import sleep\n","from livelossplot import PlotLosses  \n","\n","%matplotlib inline"],"metadata":{"id":"URl1qly74HGN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ppialzra4HD0"}},{"cell_type":"markdown","source":["### ML-1m"],"metadata":{"id":"fs6mK_pG-LCj"}},{"cell_type":"markdown","source":["Download"],"metadata":{"id":"RkfFSurY4YtM"}},{"cell_type":"code","source":["!wget -q --show-progress http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYqYdfh64HBC","executionInfo":{"status":"ok","timestamp":1639234435404,"user_tz":-330,"elapsed":1804,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5e29d399-8902-4a9c-e169-e55cc7a340d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ml-1m.zip           100%[===================>]   5.64M  7.06MB/s    in 0.8s    \n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n"]}]},{"cell_type":"markdown","source":["Preprocessing"],"metadata":{"id":"007w6cqU4G-l"}},{"cell_type":"code","source":["def data_loader_movielens():\n","    path = './ml-1m/'\n","    num_users, num_items = 6040, 3952\n","      \n","    data = load_data(path, num_users, num_items, train_ratio=.9)\n","    user, _ = load_users(path)\n","    genre = load_items(path, option='single')\n","    item = {}\n","    item['M'] = genre['War']+genre['Crime']+genre['Film-Noir']+genre['Sci-Fi']\n","    item['F'] = genre['Children\\'s']+genre['Fantasy']+genre['Musical']+genre['Romance']\n","    \n","    return data, user, item"],"metadata":{"id":"S46eIOrG4bP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_users(path):\n","    f = open(path + \"users.dat\")\n","    lines = f.readlines()\n","\n","    gender, age = {}, {} # generate dictionaries\n","    gender_index, age_index = ['M', 'F'], [1, 18, 25, 35, 45, 50, 56]\n","\n","    for i in gender_index:\n","        gender[i] = []\n","    for i in age_index:\n","        age[i] = []  \n","    for line in lines:\n","        user, g, a, *args = line.split(\"::\")\n","        gender[g].append(int(user) - 1)\n","        age[int(a)].append(int(user) - 1) \n","\n","    return gender, age"],"metadata":{"id":"yEzkuTdz4hhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_items(path, option='multiple_genre'):\n","    f = open(path + \"movies.dat\", encoding = \"ISO-8859-1\")\n","    lines = f.readlines()\n","\n","    genre={}\n","    genre_index = ['Action', 'Adventure', 'Animation', 'Children\\'s', \n","                   'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n","                   'Film-Noir', 'Horror', 'Musical', 'Mystery', \n","                   'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n","\n","    for idx in genre_index:\n","        genre[idx] = []\n","\n","    for line in lines:\n","        item, _, tags = line.split(\"::\")\n","        tags = tags.split('|')\n","        tags[-1] = tags[-1][:-1]\n","        if option=='multiple_genre':\n","            for tag in tags:\n","                genre[tag].append(int(item) - 1)\n","        else:\n","            tag = tags[0]\n","            genre[tag].append(int(item)-1)\n","    return genre"],"metadata":{"id":"bm_fVrwe4s-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(path, num_users, num_items, train_ratio):\n","    '''\n","    Read data by lines and produce train/test data matrices.\n","    '''\n","\n","    f = open(path + \"ratings.dat\")\n","    lines = f.readlines()\n","    random.shuffle(lines)  \n","\n","    num_ratings = len(lines)\n","\n","    X_train = np.zeros((num_users, num_items))\n","    X_test = np.zeros((num_users, num_items))\n","\n","    for i, line in enumerate(lines):\n","        user, item, rating, _ = line.split(\"::\")\n","        user_idx = int(user) - 1\n","        item_idx = int(item) - 1\n","        if i < int(num_ratings * train_ratio):\n","            X_train[user_idx, item_idx] = float(rating)\n","        else:\n","            X_test[user_idx, item_idx] = float(rating)\n","\n","    return (X_train, X_test)"],"metadata":{"id":"DuZ3Eh6n4vI4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Synthetic dataset"],"metadata":{"id":"We9HslPj-bvL"}},{"cell_type":"code","source":["def data_loader_synthetic(p=.2, q=.2, r=.2, s=.2, rank=10, seed=42):\n","    '''\n","    ground truth matrix Y\n","    '''\n","    num_users, num_items = 600, 400\n","    n1, n2 = num_users // 2, num_items // 2\n","    np.random.seed(42)\n","    Y_1 = np.where(np.random.random((rank, n2)) < p, 1, -1)\n","    np.random.seed(42)\n","    Y_2 = np.where(np.random.random((rank, n2)) < q, 1, -1)\n","    Y_rank = np.concatenate((Y_1, Y_2), axis = 1)\n","\n","    Y_m = Y_rank.copy()\n","\n","    for i in range(num_users // (rank * 2) -1):\n","        Y_m = np.concatenate((Y_m, Y_rank))\n","    np.random.seed(43)\n","    Y_1 = np.where(np.random.random((rank, n2)) < q, 1, -1)\n","    np.random.seed(43)\n","    Y_2 = np.where(np.random.random((rank, n2)) < p, 1, -1)\n","    Y_rank = np.concatenate((Y_1, Y_2), axis = 1)\n","\n","    Y_f = Y_rank.copy()\n","\n","    for i in range(num_users // (rank * 2) -1):\n","        Y_f = np.concatenate((Y_f, Y_rank))\n","    \n","    np.random.shuffle(Y_m)\n","    np.random.shuffle(Y_f)\n","    Y = np.concatenate((Y_m, Y_f))\n","    \n","    I_obs_mm = np.where(np.random.random((n1, n2)) < r, 1, 0)\n","    I_obs_mf = np.where(np.random.random((n1, n2)) < s, 1, 0)\n","    I_obs_fm = np.where(np.random.random((n1, n2)) < s, 1, 0)\n","    I_obs_ff = np.where(np.random.random((n1, n2)) < r, 1, 0)\n","\n","    I_obs_m = np.concatenate((I_obs_mm, I_obs_mf), axis = 1)\n","    I_obs_f = np.concatenate((I_obs_fm, I_obs_ff), axis = 1)\n","\n","    I_obs = np.concatenate((I_obs_m, I_obs_f))\n","    \n","    Y_obs = Y * I_obs\n","    \n","    Y_train, Y_test = Y_obs, (Y-Y_obs)\n","#     Y_train, Y_test = np.zeros((num_users, num_items)), np.zeros((num_users, num_items))\n","\n","#     for i in tqdm(range(num_users)):\n","#         for j in range(num_items):\n","#             if Y_obs[i, j] != 0:\n","#                 k = np.random.random()\n","#                 if k > 0.9:\n","#                     Y_test[i, j] = Y_obs[i, j]\n","#                 else:\n","#                     Y_train[i, j] = Y_obs[i, j]\n","                    \n","                    \n","    user, item = {}, {}\n","    user['M'] = [x for x in range(n1)]\n","    user['F'] = [x for x in range(n1, n1*2)]\n","    item['M'] = [x for x in range(n2)]\n","    item['F'] = [x for x in range(n2, n2*2)]\n","                    \n","    return (Y_train, Y_test), user, item"],"metadata":{"id":"0FFfZaP5-esD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Metrics"],"metadata":{"id":"Ud6B5UnK5CFF"}},{"cell_type":"code","source":["def metrics(model, data_tuple, device, model_type='AE', tau=3):\n","    \n","    data, gender, item = data_tuple\n","    measures = {}\n","    \n","    with torch.no_grad(): \n","        model.eval()\n","        Y_train, Y_test = data[0], data[1]\n","        if model_type=='PQ':\n","            identity = torch.from_numpy(np.eye(Y_train.shape[0])).float().to(device)\n","            pred = model(identity).cpu().detach().numpy()\n","        else:\n","            pred = model(torch.tensor(Y_train).float().to(device)).cpu().detach().numpy()   \n","        # 1. rmse\n","        test_rmse = np.sqrt(np.mean((Y_test[Y_test != 0] - pred[Y_test != 0]) ** 2))\n","        # Y_tilde \n","        pred_hat = np.where(pred > tau, 1, 0)\n","        \n","        # 2. DEE\n","        DEE = 0\n","        for g in ['M', 'F']:\n","            for i in ['M', 'F']:\n","                DEE += np.abs(np.mean(pred_hat)-np.mean(pred_hat[gender[g]][:, item[i]]))\n","        # 3. value_fairness\n","        VAL = VAL_measure(pred, data, gender, device)\n","        # 4. DP_user\n","        UGF = 0\n","        for g in ['M', 'F']:\n","            UGF += np.abs(np.mean(pred_hat)-np.mean(pred_hat[gender[g]]))\n","        # 4. DP_item\n","        CVS = 0\n","        for i in ['M', 'F']:\n","            CVS += np.abs(np.mean(pred_hat)-np.mean(pred_hat[:, item[i]]))\n","        measures['RMSE'] = test_rmse\n","        measures['DEE'] = DEE\n","        measures['VAL'] = VAL \n","        measures['UGF'] = UGF\n","        measures['CVS'] = CVS\n","    return measures"],"metadata":{"id":"W9TbcwrE5LEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def VAL_measure(pred, data, gender, device):\n","    train_data = data[0]\n","    mask = np.where(train_data!=0, 1, 0)\n","\n","    y_m = train_data[gender['M']]\n","    y_f = train_data[gender['F']]\n","    y_hat_m = pred[gender['M']]\n","    y_hat_f = pred[gender['F']]\n","\n","    #average ratings\n","    d_m = np.abs(np.sum(y_m, axis=0)/(np.sum(mask[gender['M']], axis=0)+1e-8)-np.sum(y_hat_m, axis=0)/len(gender['M']))\n","    d_f = np.abs(np.sum(y_f, axis=0)/(np.sum(mask[gender['F']], axis=0)+1e-8)-np.sum(y_hat_f, axis=0)/len(gender['F']))\n","\n","    v_fairness = np.mean(np.abs(d_m-d_f))\n","    return v_fairness"],"metadata":{"id":"rQ9GDLXZ5Lt0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Regularizers"],"metadata":{"id":"8W9k77hT4-v8"}},{"cell_type":"code","source":["def normal_pdf(x):\n","    import math\n","    return torch.exp(-0.5 * x**2) / math.sqrt(2 * math.pi)\n","\n","def normal_cdf(y, h=0.01, tau=0.5):\n","    # Approximation of Q-function given by López-Benítez & Casadevall (2011)\n","    # based on a second-order exponential function & Q(x) = 1 - Q(-x):\n","    Q_fn = lambda x: torch.exp(-0.4920*x**2 - 0.2887*x - 1.1893)\n","    m = y.shape[0]*y.shape[1]\n","    y_prime = (tau - y) / h\n","    sum_ = torch.sum(Q_fn(y_prime[y_prime > 0])) \\\n","           + torch.sum(1 - Q_fn(torch.abs(y_prime[y_prime < 0]))) \\\n","           + 0.5 * len(y_prime[y_prime == 0])\n","    return sum_ / m\n","\n","def Huber_loss(x, delta):\n","    if abs(x) < delta:\n","        return (x ** 2) / 2\n","    return delta * (x.abs() - delta / 2)\n","\n","def Huber_loss_derivative(x, delta):\n","    if x > delta:\n","        return delta/2\n","    elif x < -delta:\n","        return -delta/2\n","    return x"],"metadata":{"id":"K_dXakNu5fBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FairnessLoss():\n","    def __init__(self, h, tau, delta, device, data_tuple, type_='EqualExp'):\n","        self.h = h\n","        self.tau = tau\n","        self.delta = delta\n","        self.device = device\n","        self.type_ = type_\n","        self.data_tuple = data_tuple\n","\n","    def DEE(self, y_hat, gender, item):\n","        backward_loss = 0\n","        logging_loss_ = 0 \n","        \n","        for gender_key in ['M','F']:\n","            for item_key in ['M', 'F']:\n","                gender_idx = gender[gender_key] \n","                item_idx = item[item_key]\n","                m_gi = len(gender_idx)*len(item_idx)\n","                y_hat_gender_item = y_hat[gender_idx][:, item_idx]\n","\n","                Prob_diff_Z = normal_cdf(y_hat.detach(), self.h, self.tau)-normal_cdf(y_hat_gender_item.detach(), self.h, self.tau)\n","                \n","                _dummy = Huber_loss_derivative(Prob_diff_Z, self.delta)\n","                _dummy *= \\\n","                    torch.dot(\n","                        normal_pdf((self.tau - y_hat.detach()) / self.h).reshape(-1), \n","                        y_hat.reshape(-1)\n","                    ) / (self.h * y_hat.shape[0]*y_hat.shape[1]) -\\\n","                    torch.dot(\n","                        normal_pdf((self.tau - y_hat_gender_item.detach()) / self.h).reshape(-1), \n","                        y_hat_gender_item.reshape(-1)\n","                    ) / (self.h * m_gi)\n","                backward_loss += _dummy\n","        return backward_loss\n","        \n","    def VAL(self, y_hat, gender, item):\n","        device = self.device\n","        \n","        backward_loss = 0\n","        \n","        data = self.data_tuple[0]\n","        train_data = data[0]\n","        mask = np.where(train_data!=0, 1, 0)\n","\n","        train_data = torch.from_numpy(train_data).to(device)\n","        mask = torch.from_numpy(mask).to(device)\n","\n","        y_m = train_data[gender['M']]\n","        y_f = train_data[gender['F']]\n","        y_hat_m = y_hat[gender['M']]\n","        y_hat_f = y_hat[gender['F']]\n","\n","        #average ratings\n","        d_m = torch.abs(torch.sum(y_m, axis=0)/(torch.sum(mask[gender['M']], axis=0)+1e-8)\n","        -torch.sum(y_hat_m, axis=0)/len(gender['M']))\n","\n","        d_f = torch.abs(torch.sum(y_f, axis=0)/(torch.sum(mask[gender['F']], axis=0)+1e-8)\n","        -torch.sum(y_hat_f, axis=0)/len(gender['F']))\n","\n","\n","        backward_loss = torch.mean(torch.abs(d_m-d_f))\n","        \n","        return backward_loss\n","    \n","    def UGF(self, y_hat, gender, item):\n","        backward_loss = 0\n","        \n","        for key in ['M', 'F']:\n","            \n","            gender_idx = gender[key]\n","            m_i = y_hat.shape[1]*len(gender_idx)\n","            y_hat_group = y_hat[gender_idx]\n","            \n","            Prob_diff_Z = normal_cdf(y_hat.detach(), self.h, self.tau)-normal_cdf(y_hat_group.detach(), self.h, self.tau)\n","\n","            _dummy = Huber_loss_derivative(Prob_diff_Z, self.delta)\n","            _dummy *= \\\n","                torch.dot(\n","                    normal_pdf((self.tau - y_hat.detach()) / self.h).reshape(-1), \n","                    y_hat.reshape(-1)\n","                ) / (self.h * y_hat.shape[0]*y_hat.shape[1]) -\\\n","                torch.dot(\n","                    normal_pdf((self.tau - y_hat_group.detach()) / self.h).reshape(-1), \n","                    y_hat_group.reshape(-1)\n","                ) / (self.h * m_i)\n","            backward_loss += _dummy\n","        return backward_loss\n","    \n","    def CVS(self, y_hat, gender, item):\n","        backward_loss = 0\n","        \n","        for key in ['M', 'F']:\n","            item_idx = item[key]\n","            m_i = y_hat.shape[0]*len(item_idx)\n","            y_hat_group = y_hat[:, item_idx]\n","\n","            Prob_diff_Z = normal_cdf(y_hat.detach(), self.h, self.tau)-normal_cdf(y_hat_group.detach(), self.h, self.tau)\n","\n","            _dummy = Huber_loss_derivative(Prob_diff_Z, self.delta)\n","            _dummy *= \\\n","                torch.dot(\n","                    normal_pdf((self.tau - y_hat.detach()) / self.h).reshape(-1), \n","                    y_hat.reshape(-1)\n","                ) / (self.h * y_hat.shape[0]*y_hat.shape[1]) -\\\n","                torch.dot(\n","                    normal_pdf((self.tau - y_hat_group.detach()) / self.h).reshape(-1), \n","                    y_hat_group.reshape(-1)\n","                ) / (self.h * m_i)\n","            backward_loss += _dummy\n","        return backward_loss\n","        \n","    \n","    def __call__(self, y_hat, gender, item):\n","        if self.type_ == 'EqualExp':\n","            return self.DEE(y_hat, gender, item)\n","        elif self.type_ == 'VAL':\n","            return self.VAL(y_hat, gender, item)\n","        elif self.type_ == 'UGF':\n","            return self.UGF(y_hat, gender, item)\n","        elif self.type_ == 'CVS':\n","            return self.CVS(y_hat, gender, item)"],"metadata":{"id":"moZ6xr6G5iPB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Models"],"metadata":{"id":"2ne-ZTmK5jrW"}},{"cell_type":"markdown","source":["### Matrix factorization"],"metadata":{"id":"U1e_aTnS5nIo"}},{"cell_type":"code","source":["class PQ(nn.Module):\n","    def __init__(self, rating, num_users, num_items, rank):\n","        super(PQ, self).__init__()\n","        \n","        self.rating = rating\n","        \n","        self.encoder = nn.Sequential(nn.Linear(num_users, rank, bias=False))\n","        self.decoder = nn.Sequential(nn.Linear(rank, num_items, bias=False))\n","\n","    def forward(self, x):\n","        if self.rating == 'binary':\n","            x = self.decoder(self.encoder(x))\n","            x = torch.tanh(x)\n","        elif self.rating == 'five-stars':\n","            x = self.decoder(self.encoder(x))\n","            x = torch.clamp(x, 0, 5.0)\n","        else:\n","            raise KeyError(\"unavailable rating scale\")\n","    \n","        return x"],"metadata":{"id":"W98hqtpw5uze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Autoencoder"],"metadata":{"id":"EuGauSWg5vJ-"}},{"cell_type":"code","source":["class AE(nn.Module):\n","    def __init__(self, rating, num_user):\n","        super(AE, self).__init__()\n","        \n","        self.rating = rating\n","        self.encoder = nn.Sequential(\n","          nn.Linear(num_user, 512),\n","          nn.ReLU(),\n","          nn.Linear(512, 512),\n","          nn.Dropout(0.7),\n","          nn.ReLU(),\n","        )\n","        self.decoder = nn.Sequential(\n","          nn.Linear(512, num_user),\n","        )\n","        \n","    def forward(self, x):\n","        x = torch.transpose(x,0,1)\n","        if self.rating == 'binary':\n","            x = self.decoder(self.encoder(x))\n","            x = torch.tanh(x)\n","        elif self.rating == 'five-stars':\n","            x = (x - 1) / 4.0\n","            x = self.decoder(self.encoder(x))\n","            x = torch.clamp(x, 0, 1.0)\n","            x = 4.0 * x + 1\n","        x = torch.transpose(x,0,1)\n","        return x"],"metadata":{"id":"NIxPMCss5yKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trainer"],"metadata":{"id":"Yadz1mj55z0U"}},{"cell_type":"code","source":["def mklogs():\n","    logs = {'train_loss':[], \n","            'train_f_loss':[], \n","            'RMSE':[],\n","            'acc':[], \n","            'DEE':[], \n","            'DP_user':[], \n","            'DP_item':[], \n","            'v_fairness':[]\n","           }\n","    return logs "],"metadata":{"id":"XAGDJQWV53_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_logs(logs, log):\n","    measures=['RMSE',\n","              'acc', \n","              'DEE', \n","              'DP_user', \n","              'DP_item', \n","              'v_fairness']\n","    for measure in measures:\n","        logs[measure].append(log[measure])"],"metadata":{"id":"xSYdzaOm59c1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_PQ(data_tuple, model, optimizer, \n","             num_epochs, device, l_value=0., lambda_=0., f_criterion=None, tau=3):\n","\n","    logs = mklogs()\n","    data, gender, item = data_tuple\n","    \n","    # data_input \n","    train_data = torch.from_numpy(data[0]).float().to(device) \n","    test_data = data[1]\n","    \n","    identity = torch.from_numpy(np.eye(data[0].shape[0])).float().to(device)\n","    \n","    x = train_data\n","    mask = x.clone().detach()\n","    mask = torch.where(mask != 0, torch.ones(1).to(device), torch.zeros(1).to(device)).float().to(device)\n","    count = torch.sum(mask).item()\n","    \n","    #losses\n","    criterion = nn.MSELoss(reduction='sum')\n","    \n","    for epoch in range(num_epochs):\n","        rmse, cost = 0, 0\n","        model.train()\n","        W, V = model.encoder[0].weight, model.decoder[0].weight\n","        W_fro, V_fro = torch.sum(W ** 2), torch.sum(V ** 2)\n","        \n","        x_hat = model(identity)\n","        loss = 0 \n","        loss += (1-lambda_)*(criterion(x * mask, x_hat * mask)/count + l_value / 2 * ( W_fro + V_fro ))\n","        if f_criterion!=None: \n","            f_loss = f_criterion(x_hat, gender, item)\n","            logs['train_f_loss'].append(f_loss.item())\n","            loss += lambda_*f_loss\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        logs['train_loss'].append(loss.item())\n","        \n","    return logs"],"metadata":{"id":"P6CGzYZy5_EM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_AE(data_tuple, model, optimizer, \n","             num_epochs, device, l_value=0., lambda_=0., f_criterion=None, tau=3):\n","\n","    logs = mklogs()\n","    data, gender, item = data_tuple\n","    \n","    # data_input \n","    train_data = torch.from_numpy(data[0]).float().to(device) \n","    test_data = data[1]\n","    \n","    x = train_data\n","    mask = x.clone().detach()\n","    mask = torch.where(mask != 0, torch.ones(1).to(device), torch.zeros(1).to(device)).float().to(device)\n","    count = torch.sum(mask).item()\n","    \n","    #losses\n","    criterion = nn.MSELoss(reduction='sum')\n","    \n","    for epoch in range(num_epochs):\n","        rmse, cost = 0, 0\n","        model.train()\n","        W, V = model.encoder[0].weight, model.decoder[0].weight\n","        W_fro, V_fro = torch.sum(W ** 2), torch.sum(V ** 2)\n","        \n","        x_hat = model(x)\n","        loss = 0 \n","        loss += (1-lambda_)*(criterion(x * mask, x_hat * mask)/count + l_value / 2 * ( W_fro + V_fro ))\n","        if f_criterion!=None: \n","            f_loss = f_criterion(x_hat, gender, item)\n","            logs['train_f_loss'].append(f_loss.item())\n","            loss += lambda_*f_loss\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        logs['train_loss'].append(loss.item())\n","        \n","    return logs"],"metadata":{"id":"3zMMz4wX6Br2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run"],"metadata":{"id":"7Ss_Tjop6DYA"}},{"cell_type":"code","source":["class Args:\n","    def __init__(self, dataset='movielens'):\n","        self.dataset = dataset\n","        self.p0, self.p1 = 0.4, 0.1\n","        self.q0, self.q1 = 0.2, 0.2\n","        self.data_type = 'binary'\n","        self.model_type='PQ' # Choose model type: 'PQ' or 'AE'\n","        self.algorithm_type = 'EqualExp' # Choose algorithm: 'unfair', 'EqualExp', 'VAL', 'UGF', 'CVS'\n","        if self.dataset=='movielens':\n","            self.data_type = 'five-stars'\n","            self.data_tuple = (data_loader_movielens())\n","        # elif self.dataset=='lastfm':\n","        #     self.data_tuple = (data_loader_lastfm())\n","        elif self.dataset=='synthetic':\n","            self.data_tuple = (data_loader_synthetic(self.p0, self.p1, self.q0, self.q1)) # return ((train_data, test_data), user attribute, item attribute)\n","        self.learning_rate = 1e-3\n","        self.l_value = 0\n","        self.num_epochs = 1000\n","        self.lambda_ = 0.99\n","        self.tau=0\n","        self.n, self.m = self.data_tuple[0][0].shape[0], self.data_tuple[0][0].shape[1]\n","        self.r = 20\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        if self.algorithm_type == 'unfair':\n","            self.f_criterion = None \n","        else: \n","            self.f_criterion = FairnessLoss(h=0.01, tau=self.tau, delta=0.01,\n","                                            device=self.device, \n","                                            data_tuple=self.data_tuple, \n","                                            type_=self.algorithm_type)"],"metadata":{"id":"5mNqwf4g67rH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment on ML-1m"],"metadata":{"id":"Ngd5Il6H_Yfw"}},{"cell_type":"code","source":["args = Args(dataset='movielens')\n","\n","results = []\n","\n","model_type = ['PQ','AE']\n","algorithm_type = ['unfair', 'EqualExp', 'VAL', 'UGF', 'CVS']\n","\n","for m in model_type:\n","    for algo in algorithm_type:\n","        try:\n","            args.model_type = m\n","            args.algorithm_type = algo\n","            # train the model\n","            if args.model_type == 'PQ':\n","                model = PQ(args.data_type, args.n, args.m, 20).to(args.device)\n","                optimizer = optim.Adam(model.parameters(), lr = args.learning_rate)\n","                logs = train_PQ(args.data_tuple, model, optimizer, args.num_epochs,\n","                                args.device, l_value=args.l_value, lambda_=args.lambda_,\n","                                f_criterion=args.f_criterion, tau=args.tau)\n","            elif args.model_type == 'AE':\n","                model = AE(args.data_type, args.n).to(args.device)\n","                optimizer = optim.Adam(model.parameters(), lr = args.learning_rate)\n","                logs = train_AE(args.data_tuple, model, optimizer, args.num_epochs,\n","                                args.device, l_value=args.l_value, lambda_=args.lambda_,\n","                                f_criterion=args.f_criterion, tau=args.tau)\n","                \n","            result = metrics(model, args.data_tuple, args.device, args.model_type, args.tau)\n","            print(result)\n","            results.append((m, algo, result))\n","        except:\n","            pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EO2rNtM__cAW","outputId":"6961d4cd-dc9e-47f5-90e0-e999d0b426a2","executionInfo":{"status":"ok","timestamp":1639240054142,"user_tz":-330,"elapsed":231355,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'RMSE': 0.9027500699012365, 'DEE': 0.0012048745340699218, 'VAL': 0.31501372873975914, 'UGF': 0.0002971521526640153, 'CVS': 0.0006153119059790768}\n","{'RMSE': 0.9015563787906975, 'DEE': 0.001095268864150678, 'VAL': 0.30451721083300864, 'UGF': 0.0001496180935723901, 'CVS': 0.0005326444826091459}\n","{'RMSE': 0.9133768224920821, 'DEE': 0.0009910946781319652, 'VAL': 0.307643166842646, 'UGF': 6.867560418755136e-05, 'CVS': 0.00048708791966778353}\n","{'RMSE': 0.9130855504041286, 'DEE': 0.001214569441231883, 'VAL': 0.30696451034405997, 'UGF': 2.6442839102136517e-05, 'CVS': 0.0005941362836467956}\n","{'RMSE': 0.9142809402166817, 'DEE': 0.0009662139592129249, 'VAL': 0.3151116659819781, 'UGF': 1.7062581478044514e-05, 'CVS': 0.0004522546364315039}\n","{'RMSE': 0.8623466023698251, 'DEE': 0.0, 'VAL': 0.3562827773780338, 'UGF': 0.0, 'CVS': 0.0}\n","{'RMSE': 0.8626359054188043, 'DEE': 0.0, 'VAL': 0.3361190263181524, 'UGF': 0.0, 'CVS': 0.0}\n","{'RMSE': 0.8609437988471073, 'DEE': 0.0, 'VAL': 0.3366856844320138, 'UGF': 0.0, 'CVS': 0.0}\n","{'RMSE': 0.8623010810731232, 'DEE': 0.0, 'VAL': 0.3466369815510938, 'UGF': 0.0, 'CVS': 0.0}\n","{'RMSE': 0.8644324054752013, 'DEE': 0.0, 'VAL': 0.33675105885736717, 'UGF': 0.0, 'CVS': 0.0}\n"]}]},{"cell_type":"code","source":["df_ml = pd.DataFrame.from_records(results)\n","df_ml.columns = ['Model','Algorithm','Metrics']\n","df_ml = pd.concat([df_ml.drop('Metrics', axis=1), pd.DataFrame(df_ml['Metrics'].tolist())], axis=1)\n","df_ml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"X0Nn457P6Izo","executionInfo":{"status":"ok","timestamp":1639240444307,"user_tz":-330,"elapsed":677,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"e9fff065-af7f-4047-c2a3-47c6e589048c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Algorithm</th>\n","      <th>RMSE</th>\n","      <th>DEE</th>\n","      <th>VAL</th>\n","      <th>UGF</th>\n","      <th>CVS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PQ</td>\n","      <td>unfair</td>\n","      <td>0.902750</td>\n","      <td>0.001205</td>\n","      <td>0.315014</td>\n","      <td>0.000297</td>\n","      <td>0.000615</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PQ</td>\n","      <td>EqualExp</td>\n","      <td>0.901556</td>\n","      <td>0.001095</td>\n","      <td>0.304517</td>\n","      <td>0.000150</td>\n","      <td>0.000533</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PQ</td>\n","      <td>VAL</td>\n","      <td>0.913377</td>\n","      <td>0.000991</td>\n","      <td>0.307643</td>\n","      <td>0.000069</td>\n","      <td>0.000487</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PQ</td>\n","      <td>UGF</td>\n","      <td>0.913086</td>\n","      <td>0.001215</td>\n","      <td>0.306965</td>\n","      <td>0.000026</td>\n","      <td>0.000594</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PQ</td>\n","      <td>CVS</td>\n","      <td>0.914281</td>\n","      <td>0.000966</td>\n","      <td>0.315112</td>\n","      <td>0.000017</td>\n","      <td>0.000452</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>AE</td>\n","      <td>unfair</td>\n","      <td>0.862347</td>\n","      <td>0.000000</td>\n","      <td>0.356283</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>AE</td>\n","      <td>EqualExp</td>\n","      <td>0.862636</td>\n","      <td>0.000000</td>\n","      <td>0.336119</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>AE</td>\n","      <td>VAL</td>\n","      <td>0.860944</td>\n","      <td>0.000000</td>\n","      <td>0.336686</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>AE</td>\n","      <td>UGF</td>\n","      <td>0.862301</td>\n","      <td>0.000000</td>\n","      <td>0.346637</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>AE</td>\n","      <td>CVS</td>\n","      <td>0.864432</td>\n","      <td>0.000000</td>\n","      <td>0.336751</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Model Algorithm      RMSE       DEE       VAL       UGF       CVS\n","0    PQ    unfair  0.902750  0.001205  0.315014  0.000297  0.000615\n","1    PQ  EqualExp  0.901556  0.001095  0.304517  0.000150  0.000533\n","2    PQ       VAL  0.913377  0.000991  0.307643  0.000069  0.000487\n","3    PQ       UGF  0.913086  0.001215  0.306965  0.000026  0.000594\n","4    PQ       CVS  0.914281  0.000966  0.315112  0.000017  0.000452\n","5    AE    unfair  0.862347  0.000000  0.356283  0.000000  0.000000\n","6    AE  EqualExp  0.862636  0.000000  0.336119  0.000000  0.000000\n","7    AE       VAL  0.860944  0.000000  0.336686  0.000000  0.000000\n","8    AE       UGF  0.862301  0.000000  0.346637  0.000000  0.000000\n","9    AE       CVS  0.864432  0.000000  0.336751  0.000000  0.000000"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["args = Args(dataset='synthetic')\n","\n","results = []\n","\n","model_type = ['PQ','AE']\n","algorithm_type = ['unfair', 'EqualExp', 'VAL', 'UGF', 'CVS']\n","\n","for m in model_type:\n","    for algo in algorithm_type:\n","        try:\n","            args.model_type = m\n","            args.algorithm_type = algo\n","            # train the model\n","            if args.model_type == 'PQ':\n","                model = PQ(args.data_type, args.n, args.m, 20).to(args.device)\n","                optimizer = optim.Adam(model.parameters(), lr = args.learning_rate)\n","                logs = train_PQ(args.data_tuple, model, optimizer, args.num_epochs,\n","                                args.device, l_value=args.l_value, lambda_=args.lambda_,\n","                                f_criterion=args.f_criterion, tau=args.tau)\n","            elif args.model_type == 'AE':\n","                model = AE(args.data_type, args.n).to(args.device)\n","                optimizer = optim.Adam(model.parameters(), lr = args.learning_rate)\n","                logs = train_AE(args.data_tuple, model, optimizer, args.num_epochs,\n","                                args.device, l_value=args.l_value, lambda_=args.lambda_,\n","                                f_criterion=args.f_criterion, tau=args.tau)\n","                \n","            result = metrics(model, args.data_tuple, args.device, args.model_type, args.tau)\n","            print(result)\n","            results.append((m, algo, result))\n","        except:\n","            pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xT93cF71Vsyx","executionInfo":{"status":"ok","timestamp":1639240679604,"user_tz":-330,"elapsed":169936,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"bb4a48f7-505b-417e-c32f-97912e084291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'RMSE': 0.6843796436520339, 'DEE': 0.01281666666666667, 'VAL': 0.1854790271175086, 'UGF': 0.00025833333333333264, 'CVS': 0.0001916666666666733}\n","{'RMSE': 0.6746158616275792, 'DEE': 0.012016666666666648, 'VAL': 0.2008466635558418, 'UGF': 0.00044166666666667354, 'CVS': 0.0001916666666666733}\n","{'RMSE': 0.6793149919984537, 'DEE': 0.012683333333333324, 'VAL': 0.18660142754964093, 'UGF': 0.00019166666666664556, 'CVS': 0.0004250000000000087}\n","{'RMSE': 0.6832201142217881, 'DEE': 0.012466666666666654, 'VAL': 0.17845580133450958, 'UGF': 0.00016666666666667607, 'CVS': 0.0005499999999999949}\n","{'RMSE': 0.6938836450573082, 'DEE': 0.012716666666666682, 'VAL': 0.17499607298075928, 'UGF': 4.166666666668983e-05, 'CVS': 0.00032499999999999196}\n","{'RMSE': 0.7856401140827461, 'DEE': 0.00470000000000001, 'VAL': 0.23203744433583628, 'UGF': 0.0016333333333333477, 'CVS': 0.001366666666666655}\n","{'RMSE': 0.7835545178404618, 'DEE': 0.0076833333333333476, 'VAL': 0.22803320192722268, 'UGF': 0.001758333333333334, 'CVS': 0.0008749999999999869}\n","{'RMSE': 0.7866292590094013, 'DEE': 0.006083333333333357, 'VAL': 0.23135340622980244, 'UGF': 0.001375000000000015, 'CVS': 0.00030833333333332713}\n","{'RMSE': 0.7702876717396616, 'DEE': 0.01795000000000002, 'VAL': 0.23573769919824103, 'UGF': 0.00330833333333333, 'CVS': 0.004041666666666666}\n","{'RMSE': 0.7700274351377913, 'DEE': 0.01801666666666668, 'VAL': 0.2296288573835572, 'UGF': 0.0016583333333333172, 'CVS': 0.002141666666666653}\n"]}]},{"cell_type":"code","source":["df_synthetic = pd.DataFrame.from_records(results)\n","df_synthetic.columns = ['Model','Algorithm','Metrics']\n","df_synthetic = pd.concat([df_synthetic.drop('Metrics', axis=1), pd.DataFrame(df_synthetic['Metrics'].tolist())], axis=1)\n","df_synthetic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"t7ok9CM_WK5v","executionInfo":{"status":"ok","timestamp":1639240711022,"user_tz":-330,"elapsed":493,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"5647825b-3802-4e0a-b9c5-0e6c493f6a43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Algorithm</th>\n","      <th>RMSE</th>\n","      <th>DEE</th>\n","      <th>VAL</th>\n","      <th>UGF</th>\n","      <th>CVS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PQ</td>\n","      <td>unfair</td>\n","      <td>0.684380</td>\n","      <td>0.012817</td>\n","      <td>0.185479</td>\n","      <td>0.000258</td>\n","      <td>0.000192</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PQ</td>\n","      <td>EqualExp</td>\n","      <td>0.674616</td>\n","      <td>0.012017</td>\n","      <td>0.200847</td>\n","      <td>0.000442</td>\n","      <td>0.000192</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PQ</td>\n","      <td>VAL</td>\n","      <td>0.679315</td>\n","      <td>0.012683</td>\n","      <td>0.186601</td>\n","      <td>0.000192</td>\n","      <td>0.000425</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PQ</td>\n","      <td>UGF</td>\n","      <td>0.683220</td>\n","      <td>0.012467</td>\n","      <td>0.178456</td>\n","      <td>0.000167</td>\n","      <td>0.000550</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PQ</td>\n","      <td>CVS</td>\n","      <td>0.693884</td>\n","      <td>0.012717</td>\n","      <td>0.174996</td>\n","      <td>0.000042</td>\n","      <td>0.000325</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>AE</td>\n","      <td>unfair</td>\n","      <td>0.785640</td>\n","      <td>0.004700</td>\n","      <td>0.232037</td>\n","      <td>0.001633</td>\n","      <td>0.001367</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>AE</td>\n","      <td>EqualExp</td>\n","      <td>0.783555</td>\n","      <td>0.007683</td>\n","      <td>0.228033</td>\n","      <td>0.001758</td>\n","      <td>0.000875</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>AE</td>\n","      <td>VAL</td>\n","      <td>0.786629</td>\n","      <td>0.006083</td>\n","      <td>0.231353</td>\n","      <td>0.001375</td>\n","      <td>0.000308</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>AE</td>\n","      <td>UGF</td>\n","      <td>0.770288</td>\n","      <td>0.017950</td>\n","      <td>0.235738</td>\n","      <td>0.003308</td>\n","      <td>0.004042</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>AE</td>\n","      <td>CVS</td>\n","      <td>0.770027</td>\n","      <td>0.018017</td>\n","      <td>0.229629</td>\n","      <td>0.001658</td>\n","      <td>0.002142</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Model Algorithm      RMSE       DEE       VAL       UGF       CVS\n","0    PQ    unfair  0.684380  0.012817  0.185479  0.000258  0.000192\n","1    PQ  EqualExp  0.674616  0.012017  0.200847  0.000442  0.000192\n","2    PQ       VAL  0.679315  0.012683  0.186601  0.000192  0.000425\n","3    PQ       UGF  0.683220  0.012467  0.178456  0.000167  0.000550\n","4    PQ       CVS  0.693884  0.012717  0.174996  0.000042  0.000325\n","5    AE    unfair  0.785640  0.004700  0.232037  0.001633  0.001367\n","6    AE  EqualExp  0.783555  0.007683  0.228033  0.001758  0.000875\n","7    AE       VAL  0.786629  0.006083  0.231353  0.001375  0.000308\n","8    AE       UGF  0.770288  0.017950  0.235738  0.003308  0.004042\n","9    AE       CVS  0.770027  0.018017  0.229629  0.001658  0.002142"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"OSbwthtbXK3Z"}},{"cell_type":"code","source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgwQKjJdXK3a","executionInfo":{"status":"ok","timestamp":1639240756506,"user_tz":-330,"elapsed":3550,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"cf020ca7-97e7-4997-cf71-09285d4caefe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-12-11 16:39:24\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","IPython   : 5.5.0\n","sys       : 3.7.12 (default, Sep 10 2021, 00:21:48) \n","[GCC 7.5.0]\n","matplotlib: 3.2.2\n","torch     : 1.10.0+cu111\n","pandas    : 1.1.5\n","numpy     : 1.19.5\n","\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"PMrh5sONXK3b"}},{"cell_type":"markdown","source":["**END**"],"metadata":{"id":"XTDWWX2IXK3c"}}]}