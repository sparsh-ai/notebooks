{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T445626 | Negative Sampling","provenance":[],"collapsed_sections":[],"mount_file_id":"1d01gFWcCm9PtVSYcAPKW8aKdNs8IDmN6","authorship_tag":"ABX9TyOIS0olyMxJt+T+VazhsI8+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oc9gNLcD9wJK"},"source":["### Negative sampling"]},{"cell_type":"markdown","metadata":{"id":"ESAjkybH-NUO"},"source":["For implicit data with only positive labels, negative sampling is typically needed for model training. There are some special cases, such as user_cf, item_cf, BPR, YouTubeMatch, RNN4Rec with bpr loss, because these models do not need negative sampling during training. However, when evaluating these models using some metrics such as cross_entropy loss, roc_auc, pr_auc, negative labels are indeed needed. So we recommend doing negative sampling as long as the data is implicit and only contains positive labels, no matter which model you choose. Also note that train_data and test_data should use different sampling seed."]},{"cell_type":"code","metadata":{"id":"12gkNqpW_hB8"},"source":["from math import floor\n","from random import random, seed as set_random_seed\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","from contextlib import contextmanager"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEKw3KzY_fpU"},"source":["@contextmanager\n","def time_block(block_name=\"block\", verbose=1):\n","    if verbose > 0:\n","        start = time.perf_counter()\n","        try:\n","            yield\n","        except Exception:\n","            raise\n","        else:\n","            end = time.perf_counter()\n","            print(f\"{block_name} elapsed: {(end - start):3.3f}s\")\n","\n","    else:\n","        try:\n","            yield\n","        except Exception:\n","            raise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shoGskxh_3r2"},"source":["class SamplingBase(object):\n","    def __init__(self, dataset, data_info, num_neg=1):\n","        self.dataset = dataset\n","        self.data_info = data_info\n","        self.num_neg = num_neg\n","\n","    def sample_items_random(self, seed=42):\n","        set_random_seed(seed)\n","        n_items = self.data_info.n_items\n","        item_indices_sampled = list()\n","        # set is much faster for search contains\n","        user_consumed = {\n","            u: set(items) for u, items in self.data_info.user_consumed.items()\n","        }\n","        # sample negative items for every user\n","        with time_block(\"random neg item sampling\"):\n","            for u, i in zip(self.dataset.user_indices,\n","                            self.dataset.item_indices):\n","                item_indices_sampled.append(i)\n","                for _ in range(self.num_neg):\n","                    item_neg = floor(n_items * random())\n","                    if u in user_consumed:\n","                        while item_neg in user_consumed[u]:\n","                            item_neg = floor(n_items * random())\n","                    item_indices_sampled.append(item_neg)\n","        return np.asarray(item_indices_sampled)\n","\n","    def sample_items_popular(self, seed=42):\n","        data = self.data_info.get_indexed_interaction()\n","        item_counts = data.item.value_counts().sort_index().to_numpy()\n","        user_consumed = self.data_info.user_consumed\n","        items = np.arange(self.data_info.n_items)\n","\n","        item_order = list()\n","        item_indices_sampled = list()\n","        with time_block(\"popularity-based neg item sampling\"):\n","            for user, u_data in data.groupby(\"user\", sort=False):\n","                item_indices = u_data.index.to_list()\n","                item_indices = item_indices * (self.num_neg + 1)\n","                item_order.extend(item_indices)\n","\n","                # add positive items\n","                item_indices_sampled.extend(u_data.item.tolist())\n","                u_consumed = user_consumed[user]\n","                u_item_counts = item_counts.copy()\n","                u_item_counts[u_consumed] = 0\n","                item_prob = u_item_counts / np.sum(u_item_counts)\n","                neg_size = len(u_consumed) * self.num_neg\n","\n","                neg_sampled = np.random.choice(\n","                    items, size=neg_size, p=item_prob, replace=True)\n","                item_indices_sampled.extend(neg_sampled)\n","\n","        item_indices_sampled = np.asarray(item_indices_sampled)\n","        # must be stable sort to keep relative order\n","        item_order = np.argsort(item_order, kind=\"mergesort\")\n","        return item_indices_sampled[item_order]\n","\n","    def _label_negative_sampling(self, size):\n","        factor = self.num_neg + 1\n","        total_length = size * factor\n","        labels = np.zeros(total_length, dtype=np.float32)\n","        labels[::factor] = 1.0\n","        return labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xubmN20LAJAN"},"source":["class NegativeSampling(SamplingBase):\n","    def __init__(self, dataset, data_info, num_neg, sparse=None, dense=None,\n","                 batch_sampling=False):\n","        super(NegativeSampling, self).__init__(dataset, data_info, num_neg)\n","\n","        if batch_sampling and dataset.has_sampled:\n","            self.user_indices = dataset.user_indices_orig\n","            self.item_indices = dataset.item_indices_orig\n","            self.sparse_indices = (\n","                dataset.sparse_indices_orig if sparse else None)\n","            self.dense_values = (\n","                dataset.dense_values_orig if dense else None)\n","        else:\n","            self.user_indices = dataset.user_indices\n","            self.item_indices = dataset.item_indices\n","            self.sparse_indices = dataset.sparse_indices if sparse else None\n","            self.dense_values = dataset.dense_values if dense else None\n","        self.data_size = len(self.user_indices)\n","        self.sparse = sparse\n","        self.dense = dense\n","\n","    def generate_all(self, seed=42, item_gen_mode=\"random\"):\n","        user_indices_sampled = np.repeat(\n","            self.user_indices, self.num_neg + 1, axis=0\n","        )\n","\n","        if item_gen_mode not in [\"random\", \"popular\"]:\n","            raise ValueError(\n","                \"sampling item_gen_mode must either be 'random' or 'popular'\"\n","            )\n","        elif item_gen_mode == \"random\":\n","            item_indices_sampled = self.sample_items_random(seed=seed)\n","        elif item_gen_mode == \"popular\":\n","            item_indices_sampled = self.sample_items_popular(seed=seed)\n","\n","        sparse_indices_sampled = self._sparse_indices_sampling(\n","            self.sparse_indices, item_indices_sampled\n","        ) if self.sparse else None\n","        dense_values_sampled = self._dense_values_sampling(\n","            self.dense_values, item_indices_sampled\n","        ) if self.dense else None\n","        label_sampled = self._label_negative_sampling(self.data_size)\n","\n","        return (\n","            user_indices_sampled,\n","            item_indices_sampled,\n","            label_sampled,\n","            sparse_indices_sampled,\n","            dense_values_sampled\n","        )\n","\n","    def __call__(self, shuffle=True, batch_size=None):\n","        if shuffle:\n","            mask = np.random.permutation(range(self.data_size))\n","            self.sparse_indices = (\n","                self.sparse_indices[mask] if self.sparse else None)\n","            self.dense_values = (\n","                self.dense_values[mask] if self.dense else None)\n","\n","        user_consumed = {\n","            u: set(items) for u, items in self.data_info.user_consumed.items()\n","        }\n","        n_items = self.data_info.n_items\n","        return self.sample_batch(user_consumed, n_items, batch_size)\n","\n","    def sample_batch(self, user_consumed, n_items, batch_size):\n","        for k in tqdm(range(0, self.data_size, batch_size),\n","                      desc=\"batch_sampling train\"):\n","            batch_slice = slice(k, k + batch_size)\n","            batch_user_indices = self.user_indices[batch_slice]\n","            batch_item_indices = self.item_indices[batch_slice]\n","            batch_sparse_indices = (\n","                self.sparse_indices[batch_slice] if self.sparse else None)\n","            batch_dense_values = (\n","                self.dense_values[batch_slice] if self.dense else None)\n","\n","            user_indices_sampled = np.repeat(\n","                batch_user_indices, self.num_neg + 1, axis=0\n","            )\n","\n","            item_indices_sampled = list()\n","            for u, i in zip(batch_user_indices, batch_item_indices):\n","                item_indices_sampled.append(i)\n","                for _ in range(self.num_neg):\n","                    item_neg = floor(random() * n_items)\n","                    while item_neg in user_consumed[u]:\n","                        item_neg = floor(random() * n_items)\n","                    item_indices_sampled.append(item_neg)\n","            item_indices_sampled = np.array(item_indices_sampled)\n","\n","            sparse_indices_sampled = self._sparse_indices_sampling(\n","                batch_sparse_indices, item_indices_sampled\n","            ) if self.sparse else None\n","            dense_values_sampled = self._dense_values_sampling(\n","                batch_dense_values, item_indices_sampled\n","            ) if self.dense else None\n","            label_sampled = self._label_negative_sampling(\n","                len(batch_user_indices)\n","            )\n","\n","            yield (\n","                user_indices_sampled,\n","                item_indices_sampled,\n","                label_sampled,\n","                sparse_indices_sampled,\n","                dense_values_sampled\n","            )\n","\n","    def _sparse_indices_sampling(self, sparse_indices, item_indices_sampled):\n","        user_sparse_col = self.data_info.user_sparse_col.index\n","        item_sparse_col = self.data_info.item_sparse_col.index\n","\n","        if user_sparse_col and item_sparse_col:\n","            user_sparse_indices = np.take(\n","                sparse_indices, user_sparse_col, axis=1)\n","            user_sparse_sampled = np.repeat(\n","                user_sparse_indices, self.num_neg + 1, axis=0)\n","            item_sparse_sampled = self.data_info.item_sparse_unique[\n","                item_indices_sampled]\n","\n","            assert len(user_sparse_sampled) == len(item_sparse_sampled), (\n","                \"num of user sampled must equal to num of item sampled\")\n","            # keep column names in original order\n","            orig_cols = user_sparse_col + item_sparse_col\n","            col_reindex = np.arange(len(orig_cols))[np.argsort(orig_cols)]\n","            return np.concatenate(\n","                [user_sparse_sampled, item_sparse_sampled], axis=-1\n","            )[:, col_reindex]\n","\n","        elif user_sparse_col:\n","            user_sparse_indices = np.take(\n","                sparse_indices, user_sparse_col, axis=1)\n","            user_sparse_sampled = np.repeat(\n","                user_sparse_indices, self.num_neg + 1, axis=0)\n","            return user_sparse_sampled\n","\n","        elif item_sparse_col:\n","            item_sparse_sampled = self.data_info.item_sparse_unique[\n","                item_indices_sampled]\n","            return item_sparse_sampled\n","\n","    def _dense_indices_sampling(self, item_indices_sampled):\n","        n_samples = len(item_indices_sampled)\n","        user_dense_col = self.data_info.user_dense_col.index\n","        item_dense_col = self.data_info.item_dense_col.index\n","        total_dense_cols = len(user_dense_col) + len(item_dense_col)\n","        return np.tile(np.arange(total_dense_cols), [n_samples, 1])\n","\n","    def _dense_values_sampling(self, dense_values, item_indices_sampled):\n","        user_dense_col = self.data_info.user_dense_col.index\n","        item_dense_col = self.data_info.item_dense_col.index\n","\n","        if user_dense_col and item_dense_col:\n","            user_dense_values = np.take(dense_values, user_dense_col, axis=1)\n","            user_dense_sampled = np.repeat(\n","                user_dense_values, self.num_neg + 1, axis=0)\n","            item_dense_sampled = self.data_info.item_dense_unique[\n","                item_indices_sampled]\n","\n","            assert len(user_dense_sampled) == len(item_dense_sampled), (\n","                \"num of user sampled must equal to num of item sampled\")\n","            # keep column names in original order\n","            orig_cols = user_dense_col + item_dense_col\n","            col_reindex = np.arange(len(orig_cols))[np.argsort(orig_cols)]\n","            return np.concatenate(\n","                [user_dense_sampled, item_dense_sampled], axis=-1\n","            )[:, col_reindex]\n","\n","        elif user_dense_col:\n","            user_dense_values = np.take(dense_values, user_dense_col, axis=1)\n","            user_dense_sampled = np.repeat(\n","                user_dense_values, self.num_neg + 1, axis=0)\n","            return user_dense_sampled\n","\n","        elif item_dense_col:\n","            item_dense_sampled = self.data_info.item_dense_unique[\n","                item_indices_sampled]\n","            return item_dense_sampled"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAY2Pfsw9xwA"},"source":["class PairwiseSampling(SamplingBase):\n","    def __init__(self, dataset, data_info, num_neg=1):\n","        super(PairwiseSampling, self).__init__(dataset, data_info, num_neg)\n","\n","        if dataset.has_sampled:\n","            self.user_indices = dataset.user_indices_orig\n","            self.item_indices = dataset.item_indices_orig\n","        else:\n","            self.user_indices = dataset.user_indices\n","            self.item_indices = dataset.item_indices\n","        self.data_size = len(self.user_indices)\n","\n","    def __call__(self, shuffle=True, batch_size=None):\n","        if shuffle:\n","            mask = np.random.permutation(range(self.data_size))\n","            self.user_indices = self.user_indices[mask]\n","            self.item_indices = self.item_indices[mask]\n","\n","        user_consumed_set = {\n","            u: set(items) for u, items in self.data_info.user_consumed.items()\n","        }\n","        n_items = self.data_info.n_items\n","        return self.sample_batch(user_consumed_set, n_items, batch_size)\n","\n","    def sample_batch(self, user_consumed_set, n_items, batch_size):\n","        for k in tqdm(range(0, self.data_size, batch_size),\n","                      desc=\"pair_sampling train\"):\n","            batch_slice = slice(k, k + batch_size)\n","            batch_user_indices = self.user_indices[batch_slice]\n","            batch_item_indices_pos = self.item_indices[batch_slice]\n","\n","            batch_item_indices_neg = list()\n","            for u in batch_user_indices:\n","                item_neg = floor(n_items * random())\n","                while item_neg in user_consumed_set[u]:\n","                    item_neg = floor(n_items * random())\n","                batch_item_indices_neg.append(item_neg)\n","\n","            batch_item_indices_neg = np.asarray(batch_item_indices_neg)\n","            yield (\n","                batch_user_indices,\n","                batch_item_indices_pos,\n","                batch_item_indices_neg\n","            )\n","\n","\n","class PairwiseSamplingSeq(PairwiseSampling):\n","    def __init__(self, dataset, data_info, num_neg=1, mode=None, num=None):\n","        super(PairwiseSamplingSeq, self).__init__(dataset, data_info, num_neg)\n","\n","        self.seq_mode = mode\n","        self.seq_num = num\n","        self.n_items = data_info.n_items\n","        self.user_consumed = data_info.user_consumed\n","\n","    def sample_batch(self, user_consumed_set, n_items, batch_size):\n","        # avoid circular import\n","        from ..data.sequence import user_interacted_seq\n","\n","        for k in tqdm(range(0, self.data_size, batch_size),\n","                      desc=\"pair_sampling sequence train\"):\n","            batch_slice = slice(k, k + batch_size)\n","            batch_user_indices = self.user_indices[batch_slice]\n","            batch_item_indices_pos = self.item_indices[batch_slice]\n","\n","            (\n","                batch_interacted,\n","                batch_interacted_len\n","            ) = user_interacted_seq(\n","                batch_user_indices,\n","                batch_item_indices_pos,\n","                self.user_consumed,\n","                self.n_items,\n","                self.seq_mode,\n","                self.seq_num,\n","                user_consumed_set\n","            )\n","\n","            batch_item_indices_neg = list()\n","            for u in batch_user_indices:\n","                item_neg = floor(n_items * random())\n","                while item_neg in user_consumed_set[u]:\n","                    item_neg = floor(n_items * random())\n","                batch_item_indices_neg.append(item_neg)\n","\n","            batch_item_indices_neg = np.asarray(batch_item_indices_neg)\n","            yield (\n","                batch_user_indices,\n","                batch_item_indices_pos,\n","                batch_item_indices_neg,\n","                batch_interacted,\n","                batch_interacted_len\n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15TnI83cAfZp"},"source":["train_data.build_negative_samples(data_info, item_gen_mode=\"random\", num_neg=1, seed=2020)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmPoVU7cAdyA"},"source":["test_data.build_negative_samples(data_info, item_gen_mode=\"random\", num_neg=1, seed=2222)"],"execution_count":null,"outputs":[]}]}