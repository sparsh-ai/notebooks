{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reco-chef-30music-data-layer-scripting.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1oqwvobu2l66D5ePPiXuMwi63jvEny-sQ","authorship_tag":"ABX9TyPmenjnBmt6jzd8TBmPuWUW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rxL9QQCZPx8Q","executionInfo":{"status":"ok","timestamp":1630816987288,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import os\n","project_name = \"reco-chef\"; branch = \"30music\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGWuLt_QRJ3f","executionInfo":{"status":"ok","timestamp":1630817014544,"user_tz":-330,"elapsed":522,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"c6c3527a-4d76-4a65-c91e-e7dd2df3eba9"},"source":["!git checkout \"{branch}\""],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Branch '30music' set up to track remote branch '30music' from 'origin'.\n","Switched to a new branch '30music'\n"]}]},{"cell_type":"code","metadata":{"id":"khIQ-3vH88Yt","executionInfo":{"status":"ok","timestamp":1630816648761,"user_tz":-330,"elapsed":1745,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import os\n","project_name = \"reco-tut-sess\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwLTtRQK88Yz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630816992276,"user_tz":-330,"elapsed":4997,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"946809a0-2785-407c-a2f7-3fd15c94e2b4"},"source":["if not os.path.exists(project_path):\n","    !pip install -U -q dvc dvc[gdrive]\n","    !cp -r /content/drive/MyDrive/git_credentials/. ~\n","    path = \"/content/\" + project_name; \n","    !mkdir \"{path}\"\n","    %cd \"{path}\"\n","    !git init\n","    !git remote add origin https://github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout main\n","else:\n","    %cd \"{project_path}\""],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/reco-chef\n","Initialized empty Git repository in /content/reco-chef/.git/\n","remote: Enumerating objects: 114, done.\u001b[K\n","remote: Counting objects: 100% (114/114), done.\u001b[K\n","remote: Compressing objects: 100% (75/75), done.\u001b[K\n","remote: Total 114 (delta 32), reused 108 (delta 27), pack-reused 0\u001b[K\n","Receiving objects: 100% (114/114), 22.83 KiB | 11.41 MiB/s, done.\n","Resolving deltas: 100% (32/32), done.\n","From https://github.com/sparsh-ai/reco-chef\n"," * branch            30music    -> FETCH_HEAD\n"," * [new branch]      30music    -> origin/30music\n","error: pathspec 'main' did not match any file(s) known to git.\n"]}]},{"cell_type":"code","metadata":{"id":"2jrtc9Bg88Y0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630817448912,"user_tz":-330,"elapsed":440,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"eb1cacf2-73d9-4eb3-a9c3-e548815fd0cf"},"source":["!git status"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch 30music\n","Your branch is up to date with 'origin/30music'.\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\n","\t\u001b[31mdata/bronze/30music/\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}]},{"cell_type":"code","metadata":{"id":"2G4iErkK88Y1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630817459417,"user_tz":-330,"elapsed":1142,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"6fce36a1-365a-46ca-8b91-ff8a22ac25d8"},"source":["!git add . && git commit -m 'commit' && git push origin \"{branch}\""],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[30music 998d26c] commit\n"," 3 files changed, 24 insertions(+)\n"," create mode 100644 data/bronze/30music/.gitignore\n"," create mode 100644 data/bronze/30music/sessions.parquet.snappy.dvc\n"," create mode 100644 data/bronze/30music/sessions_sample_10.parquet.snappy.dvc\n","Counting objects: 8, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (8/8), done.\n","Writing objects: 100% (8/8), 976 bytes | 976.00 KiB/s, done.\n","Total 8 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 1 local object.\u001b[K\n","To https://github.com/sparsh-ai/reco-chef.git\n","   491304b..998d26c  30music -> 30music\n"]}]},{"cell_type":"code","metadata":{"id":"wrKpCfvK_0bB"},"source":["!dvc pull"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqbmXvVB-_s8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630816987286,"user_tz":-330,"elapsed":33371,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"9ac6b558-68ef-414a-c376-3233e53f9bd7"},"source":["!dvc commit && dvc push"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\r!\rIf DVC froze, see `hardlink_lock` in <\u001b[36mhttps://man.dvc.org/config#core\u001b[39m>\r                                                                      \r\r.MN3PzLWPdC2gs2FrMpinUr.tmp:   0% 0/1 [00:00<?, ?it/s]\r.MN3PzLWPdC2gs2FrMpinUr.tmp:   0% 0/1 [00:00<?, ?it/s{'info': ''}]\r                                                                  \routputs ['ml1m/v0/movies.dat'] of stage: 'ml1m/v0/movies.dat.dvc' changed. Are you sure you want to commit it? [y/n] \u001b[31mERROR\u001b[39m: interrupted by the user\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"zv6JRDrHAjVz"},"source":["---"]},{"cell_type":"code","metadata":{"id":"EhvjiARkIQTP"},"source":["import numpy as np\n","import pandas as pd\n","import datetime\n","import calendar\n","import time\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QuPR1snZKTfj"},"source":["class SessionDataset:\n","    def __init__(self, df, seed=42):\n","        self.data = df.copy()\n","        self._standardize()\n","        self.seed = seed\n","        self.train = None\n","        self.test = None\n","\n","    def _standardize(self):\n","        col_names = ['session_id', 'user_id', 'item_id', 'ts'] + self.data.columns.values.tolist()[4:]\n","        self.data.columns = col_names\n","\n","    def _add_months(self, sourcedate, months):\n","        month = sourcedate.month - 1 + months\n","        year = int(sourcedate.year + month / 12)\n","        month = month % 12 + 1\n","        day = min(sourcedate.day, calendar.monthrange(year, month)[1])\n","        return datetime.date(year, month, day)\n","\n","    def filter_by_time(self, last_months=0):\n","        if last_months > 0:\n","            lastdate = datetime.datetime.fromtimestamp(self.data.ts.max())\n","            firstdate = self._add_months(lastdate, -last_months)\n","            initial_unix = time.mktime(firstdate.timetuple())\n","            self.data = self.data[self.data['ts'] >= initial_unix]\n","\n","    def convert_to_sequence(self, topk=0):\n","        c = Counter(list(self.data['item_id']))\n","        if topk > 1:\n","            keeper = set([x[0] for x in c.most_common(topk)])\n","            self.data = self.data[self.data['item_id'].isin(keeper)]\n","\n","        # group by session id and concat song_id\n","        groups = self.data.groupby('session_id')\n","\n","        # convert item ids to string, then aggregate them to lists\n","        aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\n","        init_ts = groups['ts'].min()\n","        users = groups['user_id'].min()  # it's just fast, min doesn't actually make sense\n","\n","        self.data = aggregated.join(init_ts).join(users)\n","        self.data.reset_index(inplace=True)\n","\n","    def get_stats(self):\n","        cnt = Counter()\n","        _stats = []\n","        self.data.sequence.map(cnt.update);\n","        sequence_length = self.data.sequence.map(len).values\n","        n_sessions_per_user = self.data.groupby('user_id').size()\n","\n","        _stats.append('Number of items: {}'.format(len(cnt)))\n","        _stats.append('Number of users: {}'.format(self.data.user_id.nunique()))\n","        _stats.append('Number of sessions: {}'.format(len(self.data)) )\n","\n","        _stats.append('Session length:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n","            sequence_length.mean(), \n","            np.quantile(sequence_length, 0.5), \n","            sequence_length.min(), \n","            sequence_length.max()))\n","\n","        _stats.append('Sessions per user:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n","            n_sessions_per_user.mean(), \n","            np.quantile(n_sessions_per_user, 0.5), \n","            n_sessions_per_user.min(), \n","            n_sessions_per_user.max()))\n","\n","        _stats.append('Most popular items: {}'.format(cnt.most_common(5)))\n","        _stats =  '\\n'.join(_stats)\n","        \n","        return _stats\n","\n","    def random_holdout(self, split=0.8):\n","        \"\"\"\n","        Split sequence data randomly\n","        :param split: the training percentange\n","        \"\"\"\n","        self.data = self.data.sample(frac=1, random_state=self.seed)\n","        nseqs = len(self.data)\n","        train_size = int(nseqs * split)\n","        self.train = self.data[:train_size]\n","        self.test = self.data[train_size:]\n","\n","    def temporal_holdout(self, ts_threshold):\n","        \"\"\"\n","        Split sequence data using timestamps\n","        :param ts_threshold: the timestamp from which test sequences will start\n","        \"\"\"\n","        self.train = self.data.loc[self.data['ts'] < ts_threshold]\n","        self.test = self.data.loc[self.data['ts'] >= ts_threshold]\n","        self.train, self.test = self._clean_split(self.train, self.test)\n","\n","    def last_session_out_split(self,\n","                               user_key='user_id', \n","                               session_key='session_id',\n","                               time_key='ts'):\n","        \"\"\"\n","        Assign the last session of every user to the test set and the remaining ones to the training set\n","        \"\"\"\n","        sessions = self.data.sort_values(by=[user_key, time_key]).groupby(user_key)[session_key]\n","        last_session = sessions.last()\n","        self.train = self.data[~self.data.session_id.isin(last_session.values)].copy()\n","        self.test = self.data[self.data.session_id.isin(last_session.values)].copy()\n","        self.train, self.test = self._clean_split(self.train, self.test)\n","\n","    def _clean_split(self, train, test):\n","        \"\"\"\n","        Remove new items from the test set.\n","        :param train: The training set.\n","        :param test: The test set.\n","        :return: The cleaned training and test sets.\n","        \"\"\"\n","        train = train.copy()\n","        test = test.copy()\n","        train_items = set()\n","        train['sequence'].apply(lambda seq: train_items.update(set(seq)))\n","        test['sequence'] = test['sequence'].apply(lambda seq: [it for it in seq if it in train_items])\n","        return train, test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vt-eccBVIOQe"},"source":["df = pd.read_parquet('./data/bronze/30music/sessions_sample_10.parquet.snappy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"collapsed":true,"id":"uNklfQom19rd","executionInfo":{"status":"ok","timestamp":1630524664008,"user_tz":-330,"elapsed":516,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"d818be6a-ed28-4963-c8bd-3610c15aa5c4"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_id</th>\n","      <th>user_id</th>\n","      <th>song_id</th>\n","      <th>ts</th>\n","      <th>playtime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1902204</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>1421163674</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1902204</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>1421163948</td>\n","      <td>250</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1902204</td>\n","      <td>4</td>\n","      <td>18</td>\n","      <td>1421164198</td>\n","      <td>271</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>780919</td>\n","      <td>10</td>\n","      <td>60</td>\n","      <td>1411009500</td>\n","      <td>228</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>780919</td>\n","      <td>10</td>\n","      <td>61</td>\n","      <td>1411014936</td>\n","      <td>206</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   session_id  user_id  song_id          ts  playtime\n","0     1902204        4       16  1421163674       274\n","1     1902204        4       17  1421163948       250\n","2     1902204        4       18  1421164198       271\n","3      780919       10       60  1411009500       228\n","4      780919       10       61  1411014936       206"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","metadata":{"id":"ZnRsb5CqIgip"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s9wjS0qI5WU"},"source":["### Scratch testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"CxnuEFIM2-Ht","executionInfo":{"status":"ok","timestamp":1630525183222,"user_tz":-330,"elapsed":430,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"301b0689-979f-4d39-fe33-7374e1220b81"},"source":["test_df = [[1,1,1,'2015-01-13',10],\n","             [2,1,1,'2015-02-13',20],\n","             [2,1,3,'2015-02-13',5],\n","             [3,1,3,'2015-02-14',15],\n","             [4,2,1,'2014-12-13',10],\n","             [5,2,2,'2015-02-10',2],\n","             [5,2,1,'2015-02-10',9],\n","             [5,2,3,'2015-02-10',3],\n","             [5,2,3,'2015-02-10',7],\n","             ]\n","test_df = pd.DataFrame(test_df)\n","test_df.columns = ['session_id', 'user_id', 'item_id', 'ts', 'playtime']\n","test_df.ts = test_df.ts.apply(dt_int)\n","test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_id</th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>ts</th>\n","      <th>playtime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1421107200</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1423785600</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1423785600</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1423872000</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1418428800</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1423526400</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1423526400</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1423526400</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1423526400</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   session_id  user_id  item_id          ts  playtime\n","0           1        1        1  1421107200        10\n","1           2        1        1  1423785600        20\n","2           2        1        3  1423785600         5\n","3           3        1        3  1423872000        15\n","4           4        2        1  1418428800        10\n","5           5        2        2  1423526400         2\n","6           5        2        1  1423526400         9\n","7           5        2        3  1423526400         3\n","8           5        2        3  1423526400         7"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","metadata":{"id":"rTJWhov3uytR"},"source":["xx = SessionDataset(test_df)\n","# xx.filter_by_time(last_months=0)\n","# xx.filter_by_time(last_months=1)\n","xx.convert_to_sequence()\n","# xx.convert_to_sequence(topk=2)\n","# xx.get_stats()\n","# xx.data#.to_dict()\n","\n","# xx.random_holdout(0.6)\n","xx.temporal_holdout(1423600000)\n","# xx.temporal_holdout(1423500000)\n","# xx.last_session_out_split()\n","# display(xx.train)\n","# display(xx.test)\n","xx.train.to_dict('list')\n","# xx.train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrHvhGF5I8HV"},"source":["### Unit testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12c7S2zQPfjh","executionInfo":{"status":"ok","timestamp":1630529589585,"user_tz":-330,"elapsed":753,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"a67d62e8-c341-4006-ea76-53d442d675aa"},"source":["import unittest\n","import pandas as pd\n","from pandas.testing import assert_frame_equal\n","\n","\n","test_df = [[1,1,1,'2015-01-13',10],\n","             [2,1,1,'2015-02-13',20],\n","             [2,1,3,'2015-02-13',5],\n","             [3,1,3,'2015-02-14',15],\n","             [4,2,1,'2014-12-13',10],\n","             [5,2,2,'2015-02-10',2],\n","             [5,2,1,'2015-02-10',9],\n","             [5,2,3,'2015-02-10',3],\n","             [5,2,3,'2015-02-10',7],\n","             ]\n","test_df = pd.DataFrame(test_df)\n","test_df.columns = ['session_id', 'user_id', 'item_id', 'ts', 'playtime']\n","\n","\n","def _dt_int(dt, tm='00:00:00'):\n","    \"\"\"converts date (& time) to integer\"\"\"\n","    return int(datetime.datetime.strptime('{} {}'.format(dt,tm), '%Y-%m-%d %H:%M:%S').strftime(\"%s\"))\n","\n","test_df.ts = test_df.ts.apply(dt_int)\n","\n","\n","class TestDataset(unittest.TestCase):\n","    def setUp(self):\n","        pass\n","\n","    def testFilterByTimeNoFilter(self):\n","        \"\"\"If month=0, do not remove any rows\n","        passing first n rows of the test_df,\n","        expected not to remove any rows\n","        \"\"\"\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.filter_by_time(last_months=0)\n","        assert_frame_equal(test_df.iloc[:,:], _dataset.data)\n","\n","    def testFilterByTimeFilter(self):\n","        \"\"\"If month>0, remove rows\n","        passing first n rows of the test_df,\n","        expected to remove some rows\n","        \"\"\"\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.filter_by_time(last_months=1)\n","        assert_frame_equal(test_df.iloc[[1,2,3,5,6,7,8],:], _dataset.data)\n","\n","    def testItemConversionToSequence(self):\n","        \"\"\"convert items to a list in time-based sequence\n","        passing first n rows of the test_df,\n","        expected as per dictionary frame defined below\n","        \"\"\"\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _expecteddf = pd.DataFrame.from_dict({\n","            'session_id': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n","            'sequence': {0: ['1'], 1: ['1', '3'], 2: ['3'], 3: ['1'], 4: ['2', '1', '3', '3']},\n","            'ts': {0: 1421107200, 1: 1423785600, 2: 1423872000, 3: 1418428800, 4: 1423526400},\n","            'user_id': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2}})\n","        assert_frame_equal(_expecteddf, _dataset.data)        \n","\n","    def testItemConversionToSequenceTopK(self):\n","        \"\"\"convert items to a list in time-based sequence\n","        filters topk most interacted items\n","        passing first n rows of the test_df with topk=2,\n","        expected as per dictionary frame defined below\n","        \"\"\"\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence(topk=2)\n","        _expecteddf = pd.DataFrame.from_dict({\n","            'session_id': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n","            'sequence': {0: ['1'], 1: ['1', '3'], 2: ['3'], 3: ['1'], 4: ['1', '3', '3']},\n","            'ts': {0: 1421107200, 1: 1423785600, 2: 1423872000, 3: 1418428800, 4: 1423526400},\n","            'user_id': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2}})\n","        assert_frame_equal(_expecteddf, _dataset.data)   \n","\n","    def testDataStatistics(self):\n","        \"\"\"generate statistics of the dataset\n","        passing first n rows of the test_df,\n","        expected as per string defined below\n","        expected:\n","        Number of items: 3\\nNumber of users: 2\\nNumber of sessions: \n","        5\\nSession length:\\n\\tAverage: 1.80\\n\\tMedian: 1.0\\n\\tMin: \n","        1\\n\\tMax: 4\\nSessions per user:\\n\\tAverage: 2.50\\n\\tMedian: \n","        2.5\\n\\tMin: 2\\n\\tMax: 3\\nMost popular items: \n","        [('1', 4), ('3', 4), ('2', 1)]\"\"\"\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _generated = _dataset.get_stats()        \n","        self.assertIn(\"Number of items: 3\", _generated)    \n","        self.assertIn(\"Most popular items: [('1', 4), ('3', 4), ('2', 1)]\", _generated)    \n","        self.assertIn(\"Session length:\\n\\tAverage: 1.80\\n\\tMedian: 1.0\", _generated)    \n","        self.assertNotIn(\"Number of items: 4\", _generated)     \n","\n","    def testRandomSplit(self):\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _dataset.random_holdout(0.6)\n","        _expecteddf = pd.DataFrame.from_dict(\n","            {'session_id': {1: 2, 2: 3, 4: 5},\n","            'sequence': {1: ['1', '3'], 2: ['3'], 4: ['2', '1', '3', '3']},\n","            'ts': {1: 1423785600, 2: 1423872000, 4: 1423526400},\n","            'user_id': {1: 1, 2: 1, 4: 2}}\n","            )\n","        _expecteddf = _expecteddf.reindex([1,4,2])\n","        assert_frame_equal(_expecteddf, _dataset.train)\n","\n","    def testTemporalSplitThreshold1(self):\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _dataset.temporal_holdout(1423600000)\n","        _expecteddf = pd.DataFrame.from_dict(\n","            {'session_id': {0: 1, 3: 4, 4: 5},\n","            'sequence': {0: ['1'], 3: ['1'], 4: ['2', '1', '3', '3']},\n","            'ts': {0: 1421107200, 3: 1418428800, 4: 1423526400},\n","            'user_id': {0: 1, 3: 2, 4: 2}}\n","            )\n","        assert_frame_equal(_expecteddf, _dataset.train) \n","\n","    def testTemporalSplitThreshold2(self):\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _dataset.temporal_holdout(1423500000)\n","        _expecteddf = pd.DataFrame.from_dict(\n","            {'session_id': {0: 1, 3: 4},\n","            'sequence': {0: ['1'], 3: ['1']},\n","            'ts': {0: 1421107200, 3: 1418428800},\n","            'user_id': {0: 1, 3: 2}}\n","        )\n","        assert_frame_equal(_expecteddf, _dataset.train) \n","\n","    def testSessionOutSplit(self):\n","        _dataset = SessionDataset(test_df.iloc[:9,:])\n","        _dataset.convert_to_sequence()\n","        _dataset.last_session_out_split()\n","        _expecteddf = pd.DataFrame.from_dict(\n","            {'session_id': {0: 1, 1: 2, 3: 4},\n","            'sequence': {0: ['1'], 1: ['1', '3'], 3: ['1']},\n","            'ts': {0: 1421107200, 1: 1423785600, 3: 1418428800},\n","            'user_id': {0: 1, 1: 1, 3: 2}}\n","        )\n","        assert_frame_equal(_expecteddf, _dataset.train)\n","\n","unittest.main(argv=[''], verbosity=2, exit=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["testDataStatistics (__main__.TestMoney)\n","generate statistics of the dataset ... ok\n","testFilterByTimeFilter (__main__.TestMoney)\n","If month>0, remove rows ... ok\n","testFilterByTimeNoFilter (__main__.TestMoney)\n","If month=0, do not remove any rows ... ok\n","testItemConversionToSequence (__main__.TestMoney)\n","convert items to a list in time-based sequence ... ok\n","testItemConversionToSequenceTopK (__main__.TestMoney)\n","convert items to a list in time-based sequence ... ok\n","testRandomSplit (__main__.TestMoney) ... ok\n","testSessionOutSplit (__main__.TestMoney) ... ok\n","testTemporalSplitThreshold1 (__main__.TestMoney) ... ok\n","testTemporalSplitThreshold2 (__main__.TestMoney) ... ok\n","\n","----------------------------------------------------------------------\n","Ran 9 tests in 0.111s\n","\n","OK\n"]},{"output_type":"execute_result","data":{"text/plain":["<unittest.main.TestProgram at 0x7f8cae0d9510>"]},"metadata":{},"execution_count":225}]},{"cell_type":"markdown","metadata":{"id":"GW66CzEQJe9r"},"source":["### Library testing"]},{"cell_type":"code","metadata":{"id":"rlg3-v0xPcXX"},"source":["import sys\n","sys.path.insert(0,'./src')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWwnr0KwJlcC"},"source":["from src.data import SessionDataset as SD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3lZaSzkKEnS"},"source":["df = pd.read_parquet('./data/bronze/30music/sessions_sample_10.parquet.snappy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkNBkOoNJ9Lp"},"source":["sd = SD(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bVNRKS2KKIwP","executionInfo":{"status":"ok","timestamp":1630530107822,"user_tz":-330,"elapsed":1934,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"a8635bec-b42a-4d2d-9289-772edde02502"},"source":["sd.convert_to_sequence()\n","stats = sd.get_stats()\n","print(stats)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of items: 9999\n","Number of users: 14262\n","Number of sessions: 37877\n","Session length:\n","\tAverage: 9.06\n","\tMedian: 7.0\n","\tMin: 3\n","\tMax: 199\n","Sessions per user:\n","\tAverage: 2.66\n","\tMedian: 2.0\n","\tMin: 1\n","\tMax: 28\n","Most popular items: [('2388', 559), ('67', 508), ('531', 489), ('275', 416), ('443', 409)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ek_a9uur02oB"},"source":["### Script testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzG69PlA05L9","executionInfo":{"status":"ok","timestamp":1630557951848,"user_tz":-330,"elapsed":866,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"3c37da14-5be1-4a28-b130-57cd69a9a0ac"},"source":["!make setup"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3 setup.py install\n","running install\n","running bdist_egg\n","running egg_info\n","creating src/src.egg-info\n","writing src/src.egg-info/PKG-INFO\n","writing dependency_links to src/src.egg-info/dependency_links.txt\n","writing top-level names to src/src.egg-info/top_level.txt\n","writing manifest file 'src/src.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","writing manifest file 'src/src.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/utils\n","copying src/utils/__init__.py -> build/lib/utils\n","copying src/utils/gdrive.py -> build/lib/utils\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/utils\n","copying build/lib/utils/__init__.py -> build/bdist.linux-x86_64/egg/utils\n","copying build/lib/utils/gdrive.py -> build/bdist.linux-x86_64/egg/utils\n","byte-compiling build/bdist.linux-x86_64/egg/utils/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/utils/gdrive.py to gdrive.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/src.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/src.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/src.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/src.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/src-0.0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing src-0.0.1-py3.7.egg\n","Copying src-0.0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding src 0.0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/src-0.0.1-py3.7.egg\n","Processing dependencies for src==0.0.1\n","Finished processing dependencies for src==0.0.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rj8sI7WO068g","executionInfo":{"status":"ok","timestamp":1630557999687,"user_tz":-330,"elapsed":1540,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"8caef8ce-2946-4940-9a09-b785b7442e33"},"source":["!make test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PYTHONPATH=. pytest\n","\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1\n","rootdir: /content/reco-tut-sess, inifile:\n","collected 10 items                                                             \u001b[0m\n","\n","tests/test_dataset.py F..FFFFFF\u001b[36m                                          [ 90%]\u001b[0m\n","tests/test_dummy.py .\u001b[36m                                                    [100%]\u001b[0m\n","\n","=================================== FAILURES ===================================\n","\u001b[1m\u001b[31m_________________________ TestMoney.testDataStatistics _________________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testDataStatistics>\n","\n","\u001b[1m    def testDataStatistics(self):\u001b[0m\n","\u001b[1m        \"\"\"generate statistics of the dataset\u001b[0m\n","\u001b[1m            passing first n rows of the test_df,\u001b[0m\n","\u001b[1m            expected as per string defined below\u001b[0m\n","\u001b[1m            expected:\u001b[0m\n","\u001b[1m            Number of items: 3\\nNumber of users: 2\\nNumber of sessions:\u001b[0m\n","\u001b[1m            5\\nSession length:\\n\\tAverage: 1.80\\n\\tMedian: 1.0\\n\\tMin:\u001b[0m\n","\u001b[1m            1\\n\\tMax: 4\\nSessions per user:\\n\\tAverage: 2.50\\n\\tMedian:\u001b[0m\n","\u001b[1m            2.5\\n\\tMin: 2\\n\\tMax: 3\\nMost popular items:\u001b[0m\n","\u001b[1m            [('1', 4), ('3', 4), ('2', 1)]\"\"\"\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:92: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a1864caa0>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m____________________ TestMoney.testItemConversionToSequence ____________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testItemConversionToSequence>\n","\n","\u001b[1m    def testItemConversionToSequence(self):\u001b[0m\n","\u001b[1m        \"\"\"convert items to a list in time-based sequence\u001b[0m\n","\u001b[1m            passing first n rows of the test_df,\u001b[0m\n","\u001b[1m            expected as per dictionary frame defined below\u001b[0m\n","\u001b[1m            \"\"\"\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:58: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a25ac6820>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m__________________ TestMoney.testItemConversionToSequenceTopK __________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testItemConversionToSequenceTopK>\n","\n","\u001b[1m    def testItemConversionToSequenceTopK(self):\u001b[0m\n","\u001b[1m        \"\"\"convert items to a list in time-based sequence\u001b[0m\n","\u001b[1m            filters topk most interacted items\u001b[0m\n","\u001b[1m            passing first n rows of the test_df with topk=2,\u001b[0m\n","\u001b[1m            expected as per dictionary frame defined below\u001b[0m\n","\u001b[1m            \"\"\"\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence(topk=2)\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:73: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a18587500>, topk = 2\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m__________________________ TestMoney.testRandomSplit ___________________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testRandomSplit>\n","\n","\u001b[1m    def testRandomSplit(self):\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:101: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a185734b0>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m________________________ TestMoney.testSessionOutSplit _________________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testSessionOutSplit>\n","\n","\u001b[1m    def testSessionOutSplit(self):\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:138: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a18605dc0>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m____________________ TestMoney.testTemporalSplitThreshold1 _____________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testTemporalSplitThreshold1>\n","\n","\u001b[1m    def testTemporalSplitThreshold1(self):\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:114: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a185d5410>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m____________________ TestMoney.testTemporalSplitThreshold2 _____________________\u001b[0m\n","\n","self = <test_dataset.TestMoney testMethod=testTemporalSplitThreshold2>\n","\n","\u001b[1m    def testTemporalSplitThreshold2(self):\u001b[0m\n","\u001b[1m        _dataset = SessionDataset(test_df.iloc[:9,:])\u001b[0m\n","\u001b[1m>       _dataset.convert_to_sequence()\u001b[0m\n","\n","\u001b[1m\u001b[31mtests/test_dataset.py\u001b[0m:126: \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n","\n","self = <src.data.SessionDataset instance at 0x7f4a185d7140>, topk = 0\n","\n","\u001b[1m    def convert_to_sequence(self, topk=0):\u001b[0m\n","\u001b[1m        c = Counter(list(self.data['item_id']))\u001b[0m\n","\u001b[1m        if topk > 1:\u001b[0m\n","\u001b[1m            keeper = set([x[0] for x in c.most_common(topk)])\u001b[0m\n","\u001b[1m            self.data = self.data[self.data['item_id'].isin(keeper)]\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # group by session id and concat song_id\u001b[0m\n","\u001b[1m        groups = self.data.groupby('session_id')\u001b[0m\n","\u001b[1m    \u001b[0m\n","\u001b[1m        # convert item ids to string, then aggregate them to lists\u001b[0m\n","\u001b[1m>       aggregated = groups['item_id'].agg(sequence = lambda x: list(map(str, x)))\u001b[0m\n","\u001b[1m\u001b[31mE       TypeError: aggregate() takes at least 2 arguments (1 given)\u001b[0m\n","\n","\u001b[1m\u001b[31msrc/data.py\u001b[0m:45: TypeError\n","\u001b[1m\u001b[31m====================== 7 failed, 3 passed in 0.51 seconds ======================\u001b[0m\n","Makefile:3: recipe for target 'test' failed\n","make: *** [test] Error 1\n"]}]},{"cell_type":"code","metadata":{"id":"7oaE8cld1IO1"},"source":[""],"execution_count":null,"outputs":[]}]}