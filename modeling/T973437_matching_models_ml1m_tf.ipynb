{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/RecoHut-Projects/recohut/blob/master/tutorials/modeling/T973437_matching_models_ml1m_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate selection (Item matching) models in Tensorflow on ML-1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1 - Setup the environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Install libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for recohut (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U git+https://github.com/RecoHut-Projects/recohut.git -b v0.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Download datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q --show-progress https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "from recohut.transforms.datasets.movielens import create_ml_1m_dataset\n",
    "from recohut.transforms.datasets.movielens import create_implicit_ml_1m_dataset\n",
    "\n",
    "# models\n",
    "from recohut.models.tf.bpr import BPR\n",
    "from recohut.models.tf.ncf import NCF\n",
    "from recohut.models.tf.caser import Caser\n",
    "from recohut.models.tf.sasrec import SASRec\n",
    "from recohut.models.tf.attrec import AttRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.4 Set params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, model='bpr'):\n",
    "        self.file = '/content/ml-1m/ratings.dat'\n",
    "        self.epochs = 2\n",
    "        self.trans_score = 1\n",
    "        self.test_neg_num = 100\n",
    "        self.embed_dim = 64\n",
    "        self.mode = 'inner'  # dist\n",
    "        self.embed_reg = 1e-6\n",
    "        self.K = 10\n",
    "        self.learning_rate = 0.001\n",
    "        self.batch_size = 512\n",
    "        self.hidden_units = [256, 128, 64]\n",
    "        self.activation = 'relu'\n",
    "        self.dropout = 0.2\n",
    "        self.mode = 'inner'\n",
    "        self.maxlen = 200\n",
    "        self.hor_n = 8\n",
    "        self.hor_h = 2\n",
    "        self.ver_n = 4\n",
    "        self.blocks = 2\n",
    "        self.num_heads = 1\n",
    "        self.ffn_hidden_unit = 64\n",
    "        self.norm_training = True\n",
    "        self.causality = False\n",
    "        self.gamma = 0.5\n",
    "        self.w = 0.5\n",
    "        if model == 'ncf':\n",
    "            self.embed_dim = 32\n",
    "        elif model == 'caser':\n",
    "            self.embed_dim = 50\n",
    "        elif model == 'sasrec':\n",
    "            self.embed_dim = 50\n",
    "            self.embed_reg = 0\n",
    "        elif model == 'attrec':\n",
    "            self.maxlen = 5\n",
    "            self.embed_dim = 100\n",
    "            self.batch_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2 - Training & Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHit(df, ver=1):\n",
    "    \"\"\"\n",
    "    calculate hit rate\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if ver==1:\n",
    "        df = df.sort_values('pred_y', ascending=False).reset_index()\n",
    "        if df[df.true_y == 1].index.tolist()[0] < _K:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def getNDCG(df):\n",
    "    \"\"\"\n",
    "    calculate NDCG\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df = df.sort_values('pred_y', ascending=False).reset_index()\n",
    "    i = df[df.true_y == 1].index.tolist()[0]\n",
    "    if i < _K:\n",
    "        return np.log(2) / np.log(i+2)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def evaluate_model(model, test, K, ver=1):\n",
    "    \"\"\"\n",
    "    evaluate model\n",
    "    :param model: model\n",
    "    :param test: test set\n",
    "    :param K: top K\n",
    "    :return: hit rate, ndcg\n",
    "    \"\"\"\n",
    "    if ver == 1:\n",
    "        if args.mode == 'inner':\n",
    "            pred_y = - model.predict(test)\n",
    "        else:\n",
    "            pred_y = model.predict(test)\n",
    "        rank = pred_y.argsort().argsort()[:, 0]\n",
    "        hr, ndcg = 0.0, 0.0\n",
    "        for r in rank:\n",
    "            if r < K:\n",
    "                hr += 1\n",
    "                ndcg += 1 / np.log2(r + 2)\n",
    "        return hr / len(rank), ndcg / len(rank)\n",
    "\n",
    "    elif ver == 2:\n",
    "        global _K\n",
    "        _K = K\n",
    "        test_X, test_y = test\n",
    "        pred_y = model.predict(test_X)\n",
    "        test_df = pd.DataFrame(test_y, columns=['true_y'])\n",
    "        test_df['user_id'] = test_X[0]\n",
    "        test_df['pred_y'] = pred_y\n",
    "        tg = test_df.groupby('user_id')\n",
    "        hit_rate = tg.apply(getHit).mean()\n",
    "        ndcg = tg.apply(getNDCG).mean()\n",
    "        return hit_rate, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 BPR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='bpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Data Preprocess Start=============\n",
      "============Negative Sampling===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:29<00:00, 203.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Data Preprocess End=============\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        386624      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        252992      input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 64)        0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 1, 64)        0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLambd (None, 1)            0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.math.multiply_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 2)            0           tf.math.reduce_sum_2[0][0]       \n",
      "                                                                 tf.math.reduce_sum_3[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 639,616\n",
      "Trainable params: 639,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "1917/1917 [==============================] - 14s 6ms/step - loss: 0.4852 - val_loss: 0.4024\n",
      "1917/1917 [==============================] - 10s 5ms/step - loss: 0.2838 - val_loss: 0.3519\n",
      "Iteration 2 Fit [10.3 s], Evaluate [1.5 s]: HR = 0.5298, NDCG = 0.2965\n"
     ]
    }
   ],
   "source": [
    "# ========================== Create dataset =======================\n",
    "feature_columns, train, val, test = create_ml_1m_dataset(args.file, args.trans_score, args.embed_dim, args.test_neg_num)\n",
    "\n",
    "# ============================Build Model==========================\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    model = BPR(feature_columns, args.mode, args.embed_reg)\n",
    "    model.summary()\n",
    "    # =========================Compile============================\n",
    "    model.compile(optimizer=Adam(learning_rate=args.learning_rate))\n",
    "\n",
    "results = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    # ===========================Fit==============================\n",
    "    t1 = time()\n",
    "    model.fit(\n",
    "        train,\n",
    "        None,\n",
    "        validation_data=(val, None),\n",
    "        epochs=1,\n",
    "        batch_size=args.batch_size,\n",
    "    )\n",
    "    # ===========================Test==============================\n",
    "    t2 = time()\n",
    "    if epoch % 2 == 0:\n",
    "        hit_rate, ndcg = evaluate_model(model, test, args.K)\n",
    "        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG = %.4f'\n",
    "                % (epoch, t2 - t1, time() - t2, hit_rate, ndcg))\n",
    "        results.append([epoch, t2 - t1, time() - t2, hit_rate, ndcg])\n",
    "\n",
    "# ========================== Write Log ===========================\n",
    "pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time', 'hit_rate', 'ndcg'])\\\n",
    "    .to_csv('BPR_log_dim_{}_mode_{}_K_{}.csv'.format(args.embed_dim, args.mode, args.K), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 NCF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='ncf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Data Preprocess Start=============\n",
      "============Negative Sampling===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:30<00:00, 201.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Data Preprocess End=============\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 32)        193312      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 32)        193312      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 32)        126496      input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 32)        126496      input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, 1, 32)        0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 1, 32)        0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 1, 64)        0           embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 1, 32)        0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 1, 64)        0           tf.tile[0][0]                    \n",
      "                                                                 embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_2 (TFOpLambda)  (None, 1, 32)        0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 1, 64)        57792       tf.concat_2[0][0]                \n",
      "                                                                 tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_3 (TFOpLambda)  (None, 1, 32)        0           tf.math.multiply_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_4 (TFOpLambda)        (None, 1, 96)        0           tf.math.sigmoid_2[0][0]          \n",
      "                                                                 dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (None, 1, 96)        0           tf.math.sigmoid_3[0][0]          \n",
      "                                                                 dnn[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1)         97          tf.concat_4[0][0]                \n",
      "                                                                 tf.concat_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 1)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 1)            0           dense_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_6 (TFOpLambda)        (None, 2)            0           tf.compat.v1.squeeze[0][0]       \n",
      "                                                                 tf.compat.v1.squeeze_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 697,505\n",
      "Trainable params: 697,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "1917/1917 [==============================] - 35s 16ms/step - loss: 0.4639 - val_loss: 0.5004\n",
      "1917/1917 [==============================] - 40s 21ms/step - loss: 0.4163 - val_loss: 0.4560\n",
      "Iteration 2 Fit [39.9 s], Evaluate [4.1 s]: HR = 0.5382, NDCG = 0.2955\n"
     ]
    }
   ],
   "source": [
    "# ========================== Create dataset =======================\n",
    "feature_columns, train, val, test = create_ml_1m_dataset(args.file, args.trans_score, args.embed_dim, args.test_neg_num)\n",
    "\n",
    "# ============================Build Model==========================\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    model = NCF(feature_columns, args.hidden_units, args.dropout, args.activation, args.embed_reg)\n",
    "    model.summary()\n",
    "    # =========================Compile============================\n",
    "    model.compile(optimizer=Adam(learning_rate=args.learning_rate))\n",
    "\n",
    "results = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    # ===========================Fit==============================\n",
    "    t1 = time()\n",
    "    model.fit(\n",
    "        train,\n",
    "        None,\n",
    "        validation_data=(val, None),\n",
    "        epochs=1,\n",
    "        batch_size=args.batch_size,\n",
    "    )\n",
    "    # ===========================Test==============================\n",
    "    t2 = time()\n",
    "    if epoch % 2 == 0:\n",
    "        hit_rate, ndcg = evaluate_model(model, test, args.K)\n",
    "        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG = %.4f'\n",
    "                % (epoch, t2 - t1, time() - t2, hit_rate, ndcg))\n",
    "        results.append([epoch, t2 - t1, time() - t2, hit_rate, ndcg])\n",
    "# ========================== Write Log ===========================\n",
    "pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time', 'hit_rate', 'ndcg'])\\\n",
    "    .to_csv('NCF_log_dim_{}__K_{}.csv'.format(args.embed_dim, args.K), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Caser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='caser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Data Preprocess Start=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:24<00:00, 246.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Padding===================\n",
      "============Data Preprocess End=============\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 50)      197650      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 50, 200)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 199, 8)       808         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 4)        804         tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 8)            0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 200)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 208)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           10450       tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50)           302050      tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None,)              0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 100)          0           dropout[0][0]                    \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100)          395300      tf.compat.v1.squeeze_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 100)          0           tf.concat_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 1)            0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 907,062\n",
      "Trainable params: 907,062\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "3837/3837 [==============================] - 536s 139ms/step - loss: 0.3802 - val_loss: 0.3594\n",
      "3837/3837 [==============================] - 459s 120ms/step - loss: 0.2711 - val_loss: 0.3253\n",
      "Iteration 2 Fit [458.8 s], Evaluate [61.4 s]: HR = 0.7747, NDCG= 0.5149\n"
     ]
    }
   ],
   "source": [
    "# ========================== Create dataset =======================\n",
    "feature_columns, train, val, test = create_implicit_ml_1m_dataset(args.file, args.trans_score, args.embed_dim, args.maxlen)\n",
    "train_X, train_y = train\n",
    "val_X, val_y = val\n",
    "\n",
    "# ============================Build Model==========================\n",
    "model = Caser(feature_columns, args.maxlen, args.hor_n, args.hor_h, args.ver_n, args.dropout, args.activation, args.embed_reg)\n",
    "model.summary()\n",
    "# =========================Compile============================\n",
    "model.compile(loss=BinaryCrossentropy(), optimizer=Adam(learning_rate=args.learning_rate))\n",
    "\n",
    "results = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    # ===========================Fit==============================\n",
    "    t1 = time()\n",
    "    model.fit(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        validation_data=(val_X, val_y),\n",
    "        epochs=1,\n",
    "        batch_size=args.batch_size,\n",
    "    )\n",
    "    # ===========================Test==============================\n",
    "    t2 = time()\n",
    "    if epoch % 2 == 0:\n",
    "        hit_rate, ndcg = evaluate_model(model, test, args.K, ver=2)\n",
    "        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG= %.4f'\n",
    "                % (epoch, t2 - t1, time() - t2, hit_rate, ndcg))\n",
    "        results.append([epoch + 1, t2 - t1, time() - t2, hit_rate, ndcg])\n",
    "\n",
    "# ============================Write============================\n",
    "pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time', 'hit_rate', 'ndcg']).\\\n",
    "    to_csv('Caser_log_maxlen_{}_dim_{}_hor_n_{}_ver_n_{}_K_{}_.csv'.\n",
    "            format(args.maxlen, args.embed_dim, args.hor_n, args.ver_n, args.K), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Closure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, you can refer to https://github.com/RecoHut-Stanzas/S021355."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/RecoHut-Stanzas/S021355/blob/main/reports/S021355.ipynb\" alt=\"S021355_Report\"> <img src=\"https://img.shields.io/static/v1?label=report&message=active&color=green\" /></a> <a href=\"https://github.com/RecoHut-Stanzas/S021355\" alt=\"S021355\"> <img src=\"https://img.shields.io/static/v1?label=code&message=github&color=blue\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2021-12-20 15:45:40\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.104+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "pandas    : 1.1.5\n",
      "tensorflow: 2.5.0\n",
      "IPython   : 5.5.0\n",
      "numpy     : 1.19.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -q watermark\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
