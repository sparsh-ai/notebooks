{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_name = \"reco-tut-sjr\"; branch = \"main\"; account = \"sparsh-ai\"\n",
    "project_path = os.path.join('/content', project_name)\n",
    "\n",
    "if not os.path.exists(project_path):\n",
    "    !cp /content/drive/MyDrive/mykeys.py /content\n",
    "    import mykeys\n",
    "    !rm /content/mykeys.py\n",
    "    path = \"/content/\" + project_name; \n",
    "    !mkdir \"{path}\"\n",
    "    %cd \"{path}\"\n",
    "    import sys; sys.path.append(path)\n",
    "    !git config --global user.email \"recotut@recohut.com\"\n",
    "    !git config --global user.name  \"reco-tut\"\n",
    "    !git init\n",
    "    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n",
    "    !git pull origin \"{branch}\"\n",
    "    !git checkout main\n",
    "else:\n",
    "    %cd \"{project_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "!ls /usr/local/lib/python3.7/dist-packages/en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('/usr/local/lib/python3.7/dist-packages/en_core_web_lg/en_core_web_lg-2.2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle('./data/silver/jobs.p', compression='gzip')\n",
    "df_jobs = df_jobs.reset_index(drop=True)\n",
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_pickle('./data/silver/applicants.p', compression='gzip')\n",
    "df_users = df_users.reset_index(drop=True)\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(top, df_all, scores):\n",
    "  recommendation = pd.DataFrame(columns = ['ApplicantID', 'JobID',  'title', 'score'])\n",
    "  count = 0\n",
    "  for i in top:\n",
    "      recommendation.at[count, 'ApplicantID'] = u\n",
    "      recommendation.at[count, 'JobID'] = df_all['Job.ID'][i]\n",
    "      recommendation.at[count, 'title'] = df_all['Title'][i]\n",
    "      recommendation.at[count, 'score'] =  scores[count]\n",
    "      count += 1\n",
    "  return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 10001\n",
    "index = np.where(df_users['Applicant_id'] == u)[0][0]\n",
    "user_q = df_users.iloc[[index]]\n",
    "user_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing tfidf vectorizer\n",
    "##This is a technique to quantify a word in documents, \n",
    "#we generally compute a weight to each word which signifies the importance of the word in the document and corpus. \n",
    "##This method is a widely used technique in Information Retrieval and Text Mining.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_jobid = tfidf_vectorizer.fit_transform((df_jobs['text'])) #fitting and transforming the vector\n",
    "tfidf_jobid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing cosine similarity using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tfidf = tfidf_vectorizer.transform(user_q['text'])\n",
    "cos_similarity_tfidf = map(lambda x: cosine_similarity(user_tfidf, x), tfidf_jobid)\n",
    "output2 = list(cos_similarity_tfidf)\n",
    "\n",
    "top = sorted(range(len(output2)), key=lambda i: output2[i], reverse=True)[:10]\n",
    "list_scores = [output2[i][0][0] for i in top]\n",
    "get_recommendation(top, df_jobs, list_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_jobid = count_vectorizer.fit_transform((df_jobs['text'])) #fitting and transforming the vector\n",
    "count_jobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = count_vectorizer.transform(user_q['text'])\n",
    "cos_similarity_countv = map(lambda x: cosine_similarity(user_count, x),count_jobid)\n",
    "output2 = list(cos_similarity_countv)\n",
    "\n",
    "top = sorted(range(len(output2)), key=lambda i: output2[i], reverse=True)[:10]\n",
    "list_scores = [output2[i][0][0] for i in top]\n",
    "get_recommendation(top, df_jobs, list_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the copurs text to the *spacy's documents* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_docs = []\n",
    "for i in range(len(df_jobs)):\n",
    "  doc = nlp(\"u'\" + df_jobs['text'][i] + \"'\")\n",
    "  list_docs.append((doc,i))\n",
    "print(len(list_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSimWithSpaCy(nlp, df, user_text, n=6):\n",
    "    # Calculate similarity using spaCy\n",
    "    list_sim =[]\n",
    "    doc1 = nlp(\"u'\" + user_text + \"'\")\n",
    "    for i in df.index:\n",
    "      try:\n",
    "            doc2 = list_docs[i][0]\n",
    "            score = doc1.similarity(doc2)\n",
    "            list_sim.append((doc1, doc2, list_docs[i][1],score))\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "    return  list_sim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_q.text[186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = calculateSimWithSpaCy(nlp, df_jobs, user_q.text[186], n=15)\n",
    "df_recom_spacy = pd.DataFrame(df3).sort_values([3], ascending=False).head(10)\n",
    "df_recom_spacy.reset_index(inplace=True)\n",
    "\n",
    "index_spacy = df_recom_spacy[2]\n",
    "list_scores = df_recom_spacy[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top recommendations using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation(index_spacy, df_jobs, list_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 11\n",
    "KNN = NearestNeighbors(n_neighbors, p=2)\n",
    "KNN.fit(tfidf_jobid)\n",
    "NNs = KNN.kneighbors(user_tfidf, return_distance=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNs[0][0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top recommendations using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = NNs[1][0][1:]\n",
    "index_score = NNs[0][0][1:]\n",
    "\n",
    "get_recommendation(top, df_jobs, index_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNjbXnWWGY8Cb4peXPevvFq",
   "collapsed_sections": [],
   "mount_file_id": "1RMyua340JXnd8_maVZpobMaQwkuslnl6",
   "name": "reco-tut-sjr-03-modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
