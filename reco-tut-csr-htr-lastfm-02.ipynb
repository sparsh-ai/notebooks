{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1629805506511,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"d1o6gvXino6X"},"outputs":[],"source":["import os\n","project_name = \"reco-tut-csr\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3307,"status":"ok","timestamp":1629805510682,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"8MpUlXlWny29","outputId":"4b971fe8-b952-4795-fd41-dee3db05d794"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/reco-tut-csr\n","Initialized empty Git repository in /content/reco-tut-csr/.git/\n","remote: Enumerating objects: 50, done.\u001b[K\n","remote: Counting objects: 100% (50/50), done.\u001b[K\n","remote: Compressing objects: 100% (35/35), done.\u001b[K\n","remote: Total 50 (delta 12), reused 45 (delta 7), pack-reused 0\u001b[K\n","Unpacking objects: 100% (50/50), done.\n","From https://github.com/sparsh-ai/reco-tut-csr\n"," * branch            main       -\u003e FETCH_HEAD\n"," * [new branch]      main       -\u003e origin/main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n","Switched to a new branch 'main'\n"]}],"source":["if not os.path.exists(project_path):\n","    !cp /content/drive/MyDrive/mykeys.py /content\n","    import mykeys\n","    !rm /content/mykeys.py\n","    path = \"/content/\" + project_name; \n","    !mkdir \"{path}\"\n","    %cd \"{path}\"\n","    import sys; sys.path.append(path)\n","    !git config --global user.email \"recotut@recohut.com\"\n","    !git config --global user.name  \"reco-tut\"\n","    !git init\n","    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout main\n","else:\n","    %cd \"{project_path}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ochl7m4B-XB3"},"outputs":[],"source":["!git pull --rebase origin \"{branch}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrUWb0jiny3G"},"outputs":[],"source":["!git status"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":710,"status":"ok","timestamp":1629802744715,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"MpYWa13ony3I","outputId":"67c37cbd-db3a-415f-94e3-fc90100c8203"},"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n"]}],"source":["!git add . \u0026\u0026 git commit -m 'commit' \u0026\u0026 git push origin \"{branch}\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1629805621522,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"XlHj9DTvojCE"},"outputs":[],"source":["!pip install -q dvc dvc[gdrive]\n","!dvc pull"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyixkXS6yuHZ"},"outputs":[],"source":["!dvc commit \u0026\u0026 dvc push"]},{"cell_type":"markdown","metadata":{"id":"z3GIu7oTzohV"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"oKotM2ku9r8C"},"source":["We adopt three different ranking evaluation metrics to evaluate model performance: Precision@k (P@k), Recall@k (R@k) and NDCG@k. We implement the proposed model by Tensorflow and Adam optimizer. For the hyper-parameters, we fix the CF latent factor dimension as 200, and set the learning rate as 0.005, the mini-batch size as 1024. Heater requires pretrained CF representations as input. Hence, we train a Bayesian Personalized Ranking (BPR) model with latent factors of 200 dimensions, L2 regularization weight 0.001, and learning rate as 0.005 and use the learned latent factors of BPR as P and Q."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1629805621523,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"F8QX8zSHzoyX","outputId":"16f840a0-87ce-4f34-f4b9-7ab7fc62340a"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5779,"status":"ok","timestamp":1629805632094,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"-PpBaO4s0O4U"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import time\n","import datetime\n","import scipy\n","from sklearn import preprocessing as prep\n","import pandas as pd\n","import scipy.sparse\n","from sklearn import datasets\n","import scipy.sparse as sp\n","import argparse\n","from tqdm import tqdm\n","import pickle\n","\n","np.random.seed(0)\n","tf.set_random_seed(0)"]},{"cell_type":"markdown","metadata":{"id":"5JLwqkc70Vo5"},"source":["## Utils"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":654,"status":"ok","timestamp":1629805716073,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"qGvmxs1b9aDA"},"outputs":[],"source":["class timer_class(object):\n","    def __init__(self, name='default'):\n","        \"\"\"\n","        timer object to record running time of functions, not for micro-benchmarking\n","        :param name: label for the timer\n","        \"\"\"\n","        self._start_time = None\n","        self._name = name\n","        self.tic()\n","\n","    def tic(self):\n","        self._start_time = time.time()\n","        return self\n","\n","    def toc(self, message):\n","        elapsed = time.time() - self._start_time\n","        message = '' if message is None else message\n","        print('[{0:s}] {1:s} elapsed [{2:s}]'.format(self._name, message, timer_class._format(elapsed)))\n","        return self\n","\n","    def reset(self):\n","        self._start_time = None\n","        return self\n","\n","    @staticmethod\n","    def _format(s):\n","        delta = datetime.timedelta(seconds=s)\n","        d = datetime.datetime(1, 1, 1) + delta\n","        s = ''\n","        if (d.day - 1) \u003e 0:\n","            s = s + '{:d} days'.format(d.day - 1)\n","        if d.hour \u003e 0:\n","            s = s + '{:d} hr'.format(d.hour)\n","        if d.minute \u003e 0:\n","            s = s + '{:d} min'.format(d.minute)\n","        s = s + '{:d} s'.format(d.second)\n","        return s\n","\n","\n","def batch(iterable, _n=1, drop=True):\n","    \"\"\"\n","    returns batched version of some iterable\n","    :param iterable: iterable object as input\n","    :param _n: batch size\n","    :param drop: if true, drop extra if batch size does not divide evenly,\n","        otherwise keep them (last batch might be shorter)\n","    :return: batched version of iterable\n","    \"\"\"\n","    it_len = len(iterable)\n","    for ndx in range(0, it_len, _n):\n","        if ndx + _n \u003c it_len:\n","            yield iterable[ndx:ndx + _n]\n","        elif drop is False:\n","            yield iterable[ndx:it_len]\n","\n","\n","def tfidf(x):\n","    \"\"\"\n","    compute tfidf of numpy array x\n","    :param x: input array, document by terms\n","    :return: csr tfidf array\n","    \"\"\"\n","    x_idf = np.log(x.shape[0] - 1) - np.log(1 + np.asarray(np.sum(x \u003e 0, axis=0)).ravel())\n","    x_idf = np.asarray(x_idf)\n","    x_idf_diag = scipy.sparse.lil_matrix((len(x_idf), len(x_idf)))\n","    x_idf_diag.setdiag(x_idf)\n","    x_tf = x.tocsr()\n","    x_tf.data = np.log(x_tf.data + 1)\n","    x_tfidf = x_tf * x_idf_diag\n","    return x_tfidf\n","\n","\n","def standardize(x):\n","    \"\"\"\n","    takes sparse input and compute standardized version\n","    Note:\n","        cap at 5 std\n","    :param x: 2D scipy sparse data array to standardize (column-wise), must support row indexing\n","    :return: the object to perform scale (stores mean/std) for inference, as well as the scaled x\n","    \"\"\"\n","    x_nzrow = x.any(axis=1)\n","    scaler = prep.StandardScaler().fit(x[x_nzrow, :])\n","    x_scaled = np.copy(x)\n","    x_scaled[x_nzrow, :] = scaler.transform(x_scaled[x_nzrow, :])\n","    x_scaled[x_scaled \u003e 5] = 5\n","    x_scaled[x_scaled \u003c -5] = -5\n","    x_scaled[np.absolute(x_scaled) \u003c 1e-5] = 0\n","    return scaler, x_scaled\n","\n","\n","def standardize_2(x):\n","    \"\"\"\n","    takes sparse input and compute standardized version\n","    Note:\n","        cap at 5 std\n","    :param x: 2D scipy sparse data array to standardize (column-wise), must support row indexing\n","    :return: the object to perform scale (stores mean/std) for inference, as well as the scaled x\n","    \"\"\"\n","    x_nzrow = x.any(axis=1)\n","    scaler = prep.StandardScaler().fit(x[x_nzrow, :])\n","    x_scaled = np.copy(x)\n","    x_scaled[x_nzrow, :] = scaler.transform(x_scaled[x_nzrow, :])\n","    x_scaled[x_scaled \u003e 1] = 1\n","    x_scaled[x_scaled \u003c -1] = -1\n","    x_scaled[np.absolute(x_scaled) \u003c 1e-5] = 0\n","    return scaler, x_scaled\n","\n","\n","def standardize_3(x):\n","    \"\"\"\n","    takes sparse input and compute standardized version\n","    Note:\n","        cap at 5 std\n","    :param x: 2D scipy sparse data array to standardize (column-wise), must support row indexing\n","    :return: the object to perform scale (stores mean/std) for inference, as well as the scaled x\n","    \"\"\"\n","    x_nzrow = x.any(axis=1)\n","    scaler = prep.StandardScaler().fit(x[x_nzrow, :])\n","    x_scaled = np.copy(x)\n","    x_scaled[x_nzrow, :] = scaler.transform(x_scaled[x_nzrow, :])\n","    x_scaled[x_nzrow, :] /= 2.\n","    x_scaled[x_scaled \u003e 1] = 1\n","    x_scaled[x_scaled \u003c -1] = -1\n","    x_scaled[np.absolute(x_scaled) \u003c 1e-5] = 0\n","    return scaler, x_scaled\n","\n","\n","def prep_standardize_dense(x):\n","    \"\"\"\n","    takes dense input and compute standardized version\n","    Note:\n","        cap at 5 std\n","    :param x: 2D numpy data array to standardize (column-wise)\n","    :return: the object to perform scale (stores mean/std) for inference, as well as the scaled x\n","    \"\"\"\n","    scaler = prep.StandardScaler().fit(x)\n","    x_scaled = scaler.transform(x)\n","    x_scaled[x_scaled \u003e 5] = 5\n","    x_scaled[x_scaled \u003c -5] = -5\n","    x_scaled[np.absolute(x_scaled) \u003c 1e-5] = 0\n","    return scaler, x_scaled\n","\n","\n","idcg_array = np.arange(100) + 1\n","idcg_array = 1 / np.log2(idcg_array + 1)\n","idcg_table = np.zeros(100)\n","for i in range(100):\n","    idcg_table[i] = np.sum(idcg_array[:(i + 1)])"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1195,"status":"ok","timestamp":1629805633274,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"I_sREzjM0XEt"},"outputs":[],"source":["def batch_eval_recall(_sess, tf_eval, eval_feed_dict, recall_k, eval_data):\n","    \"\"\"\n","    given EvalData and DropoutNet compute graph in TensorFlow, runs batch evaluation\n","    :param _sess: tf session\n","    :param tf_eval: the evaluate output symbol in tf\n","    :param eval_feed_dict: method to parse tf, pick from EvalData method\n","    :param recall_k: list of thresholds to compute recall at (information retrieval recall)\n","    :param eval_data: EvalData instance\n","    :return: recall array at thresholds matching recall_k\n","    \"\"\"\n","    tf_eval_preds_batch = []\n","    for (batch, (eval_start, eval_stop)) in enumerate(eval_data.eval_batch):\n","        tf_eval_preds = _sess.run(tf_eval,\n","                                  feed_dict=eval_feed_dict(\n","                                      batch, eval_start, eval_stop, eval_data))\n","        tf_eval_preds_batch.append(tf_eval_preds)\n","    tf_eval_preds = np.concatenate(tf_eval_preds_batch)\n","    tf.local_variables_initializer().run()\n","\n","    # filter non-zero targets\n","    y_nz = [len(x) \u003e 0 for x in eval_data.R_test_inf.rows]\n","    y_nz = np.arange(len(eval_data.R_test_inf.rows))[y_nz]\n","\n","    preds_all = tf_eval_preds[y_nz, :]\n","\n","    recall = []\n","    precision = []\n","    ndcg = []\n","    for at_k in recall_k:\n","        preds_k = preds_all[:, :at_k]\n","        y = eval_data.R_test_inf[y_nz, :]\n","\n","        x = scipy.sparse.lil_matrix(y.shape)\n","        x.rows = preds_k\n","        x.data = np.ones_like(preds_k)\n","\n","        z = y.multiply(x)\n","        recall.append(np.mean(np.divide((np.sum(z, 1)), np.sum(y, 1))))\n","        precision.append(np.mean(np.sum(z, 1) / at_k))\n","\n","        x_coo = x.tocoo()\n","        rows = x_coo.row\n","        cols = x_coo.col\n","        y_csr = y.tocsr()\n","        dcg_array = y_csr[(rows, cols)].A1.reshape((preds_k.shape[0], -1))\n","        dcg = np.sum(dcg_array * idcg_array[:at_k].reshape((1, -1)), axis=1)\n","        idcg = np.sum(y, axis=1) - 1\n","        idcg[np.where(idcg \u003e= at_k)] = at_k-1\n","        idcg = idcg_table[idcg.astype(int)]\n","        ndcg.append(np.mean(dcg / idcg))\n","\n","    return recall, precision, ndcg\n","\n","\n","def batch_eval_store(_sess, tf_eval, eval_feed_dict, eval_data, save_path='./data/pred_R.npy'):\n","    \"\"\"\n","    given EvalData and DropoutNet compute graph in TensorFlow, runs batch evaluation\n","    :param _sess: tf session\n","    :param tf_eval: the evaluate output symbol in tf\n","    :param eval_feed_dict: method to parse tf, pick from EvalData method\n","    :param recall_k: list of thresholds to compute recall at (information retrieval recall)\n","    :param eval_data: EvalData instance\n","    :return: recall array at thresholds matching recall_k\n","    \"\"\"\n","    tf_eval_preds_batch = []\n","    for (batch, (eval_start, eval_stop)) in enumerate(eval_data.eval_batch):\n","        tf_eval_preds = _sess.run(tf_eval,\n","                                  feed_dict=eval_feed_dict(\n","                                      batch, eval_start, eval_stop, eval_data))\n","        tf_eval_preds_batch.append(tf_eval_preds)\n","    tf_eval_preds = np.concatenate(tf_eval_preds_batch)\n","    tf.local_variables_initializer().run()\n","\n","    np.save(save_path, tf_eval_preds)\n","\n","\n","def negative_sampling(pos_user_array, pos_item_array, neg, item_warm):\n","    neg = int(neg)\n","    user_pos = pos_user_array.reshape((-1))\n","    user_neg = np.tile(pos_user_array, neg).reshape((-1))\n","    pos = pos_item_array.reshape((-1))\n","    neg = np.random.choice(item_warm, size=(neg * pos_user_array.shape[0]), replace=True).reshape((-1))\n","    target_pos = np.ones_like(pos)\n","    target_neg = np.zeros_like(neg)\n","    return np.concatenate((user_pos, user_neg)), np.concatenate((pos, neg)), \\\n","           np.concatenate((target_pos, target_neg))\n","\n","\n","idcg_array = np.arange(100) + 1\n","idcg_array = 1 / np.log2(idcg_array + 1)\n","idcg_table = np.zeros(100)\n","for i in range(100):\n","    idcg_table[i] = np.sum(idcg_array[:(i + 1)])\n","\n","\n","def evaluate(_sess, tf_eval, eval_feed_dict, eval_data, like, filters, recall_k, test_file, cold_user=False, test_item_ids=None):\n","    tf_eval_preds_batch = []\n","    for (batch, (eval_start, eval_stop)) in enumerate(eval_data.eval_batch):\n","        tf_eval_preds = _sess.run(tf_eval,\n","                                  feed_dict=eval_feed_dict(\n","                                      batch, eval_start, eval_stop, eval_data))\n","        tf_eval_preds_batch.append(tf_eval_preds)\n","    tf_eval_preds = np.concatenate(tf_eval_preds_batch)\n","    tf.local_variables_initializer().run()\n","\n","    test = pd.read_csv(test_file, dtype=np.int32)\n","\n","    if not cold_user:\n","        test_item_ids = list(set(test['iid'].values))\n","\n","    test_data = test.values.ravel().view(dtype=[('uid', np.int32), ('iid', np.int32)])\n","\n","    item_old2new_list = np.zeros(np.max(test_item_ids) + 1)\n","    test_item_ids_map = dict()\n","    for i, iid in enumerate(test_item_ids):\n","        test_item_ids_map[iid] = i\n","        item_old2new_list[iid] = i\n","\n","    _test_ij_for_inf = [(t[0], t[1]) for t in test_data if t[1] in test_item_ids_map]\n","    test_user_ids = np.unique(test_data['uid'])\n","\n","    user_old2new_list = np.zeros(np.max(test_user_ids) + 1)\n","    test_user_ids_map = dict()\n","    for i, uid in enumerate(test_user_ids):\n","        test_user_ids_map[uid] = i\n","        user_old2new_list[uid] = i\n","\n","    _test_i_for_inf = [test_user_ids_map[_t[0]] for _t in _test_ij_for_inf]\n","    _test_j_for_inf = [test_item_ids_map[_t[1]] for _t in _test_ij_for_inf]\n","    R_test_inf = scipy.sparse.coo_matrix(\n","        (np.ones(len(_test_i_for_inf)),\n","         (_test_i_for_inf, _test_j_for_inf)),\n","        shape=[len(test_user_ids), len(test_item_ids)]\n","    ).tolil(copy=False)\n","\n","    # filter non-zero targets\n","    y_nz = [len(x) \u003e 0 for x in R_test_inf.rows]\n","    y_nz = np.arange(len(R_test_inf.rows))[y_nz]\n","\n","    preds_all = tf_eval_preds[y_nz, :]\n","\n","    recall = []\n","    precision = []\n","    ndcg = []\n","    for at_k in recall_k:\n","        preds_k = preds_all[:, :at_k]\n","        y = R_test_inf[y_nz, :]\n","\n","        x = scipy.sparse.lil_matrix(y.shape)\n","        x.rows = preds_k\n","        x.data = np.ones_like(preds_k)\n","\n","        z = y.multiply(x)\n","        recall.append(np.mean(np.divide((np.sum(z, 1)), np.sum(y, 1))))\n","        precision.append(np.mean(np.sum(z, 1) / at_k))\n","\n","        x_coo = x.tocoo()\n","        rows = x_coo.row\n","        cols = x_coo.col\n","        y_csr = y.tocsr()\n","        dcg_array = y_csr[(rows, cols)].A1.reshape((preds_k.shape[0], -1))\n","        dcg = np.sum(dcg_array * idcg_array[:at_k].reshape((1, -1)), axis=1)\n","        idcg = np.sum(y, axis=1) - 1\n","        idcg[np.where(idcg \u003e= at_k)] = at_k - 1\n","        idcg = idcg_table[idcg.astype(int)]\n","        ndcg.append(np.mean(dcg / idcg))\n","\n","    f_measure_1 = 2 * (precision[0] * recall[0]) / (precision[0] + recall[0]) if not precision[0] + recall[\n","        0] == 0 else 0\n","    f_measure_5 = 2 * (precision[1] * recall[1]) / (precision[1] + recall[1]) if not precision[1] + recall[\n","        1] == 0 else 0\n","    f_measure_10 = 2 * (precision[2] * recall[2]) / (precision[2] + recall[2]) if not precision[2] + recall[\n","        2] == 0 else 0\n","    f_score = [f_measure_1, f_measure_5, f_measure_10]\n","\n","    print('\\t\\t' + '\\t '.join([('@' + str(i)).ljust(6) for i in recall_k]))\n","    print('recall\\t\\t%s' % (\n","        ' '.join(['%.6f' % i for i in recall]),\n","    ))\n","    print('precision\\t%s' % (\n","        ' '.join(['%.6f' % i for i in precision]),\n","    ))\n","    print('F1 score\\t%s' % (\n","        ' '.join(['%.6f' % i for i in f_score]),\n","    ))\n","    print('NDCG\\t\\t%s' % (\n","        ' '.join(['%.6f' % i for i in ndcg]),\n","    ))\n","\n","    return precision, recall, f_score, ndcg"]},{"cell_type":"markdown","metadata":{"id":"kuuxYkZD0heu"},"source":["## Data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1629805633276,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"SsyIisVQ0iT-"},"outputs":[],"source":["\"\"\"\n","This module contains class and methods related to data used in Heater  \n","\"\"\"\n","\n","\n","def load_eval_data(test_file, cold_user=False, test_item_ids=None):\n","    timer = timer_class()\n","    test = pd.read_csv(test_file, dtype=np.int32)\n","    if not cold_user:\n","        test_item_ids = list(set(test['iid'].values))\n","    test_data = test.values.ravel().view(dtype=[('uid', np.int32), ('iid', np.int32)])\n","\n","    timer.toc('read %s triplets' % test_data.shape[0]).tic()\n","    eval_data = EvalData(\n","        test_data,\n","        test_item_ids)\n","    print(eval_data.get_stats_string())\n","    return eval_data\n","\n","\n","class EvalData:\n","    \"\"\"\n","    EvalData:\n","        EvalData packages test triplet (user, item, score) into appropriate formats for evaluation\n","        Compact Indices:\n","            Specifically, this builds compact indices and stores mapping between original and compact indices.\n","            Compact indices only contains:\n","                1) items in test set\n","                2) users who interacted with such test items\n","            These compact indices speed up testing significantly by ignoring irrelevant users or items\n","        Args:\n","            test_triplets(int triplets): user-item-interaction_value triplet to build the test data\n","            train(int triplets): user-item-interaction_value triplet from train data\n","        Attributes:\n","            is_cold(boolean): whether test data is used for cold start problem\n","            test_item_ids(list of int): maps compressed item ids to original item ids (via position)\n","            test_item_ids_map(dictionary of int-\u003eint): maps original item ids to compressed item ids\n","            test_user_ids(list of int): maps compressed user ids to original user ids (via position)\n","            test_user_ids_map(dictionary of int-\u003eint): maps original user ids to compressed user ids\n","            R_test_inf(scipy lil matrix): pre-built compressed test matrix\n","            R_train_inf(scipy lil matrix): pre-built compressed train matrix for testing\n","            other relevant input/output exposed from tensorflow graph\n","    \"\"\"\n","\n","    def __init__(self, test_triplets, test_item_ids):\n","        # build map both-ways between compact and original indices\n","        # compact indices only contains:\n","        #  1) items in test set\n","        #  2) users who interacted with such test items\n","\n","        self.test_item_ids = test_item_ids\n","        # test_item_ids_map\n","        self.test_item_ids_map = {iid: i for i, iid in enumerate(self.test_item_ids)}\n","\n","        _test_ij_for_inf = [(t[0], t[1]) for t in test_triplets if t[1] in self.test_item_ids_map]\n","        # test_user_ids\n","        self.test_user_ids = np.unique(test_triplets['uid'])\n","        # test_user_ids_map\n","        self.test_user_ids_map = {user_id: i for i, user_id in enumerate(self.test_user_ids)}\n","\n","        _test_i_for_inf = [self.test_user_ids_map[_t[0]] for _t in _test_ij_for_inf]\n","        _test_j_for_inf = [self.test_item_ids_map[_t[1]] for _t in _test_ij_for_inf]\n","        self.R_test_inf = scipy.sparse.coo_matrix(\n","            (np.ones(len(_test_i_for_inf)),\n","             (_test_i_for_inf, _test_j_for_inf)),\n","            shape=[len(self.test_user_ids), len(self.test_item_ids)]\n","        ).tolil(copy=False)\n","\n","        # allocate fields\n","        self.U_pref_test = None\n","        self.V_pref_test = None\n","        self.V_content_test = None\n","        self.U_content_test = None\n","        self.tf_eval_train = None\n","        self.tf_eval_test = None\n","        self.eval_batch = None\n","\n","    def init_tf(self, user_factors, item_factors, user_content, item_content, eval_run_batchsize,\n","                cold_user=False, cold_item=False):\n","        self.U_pref_test = user_factors[self.test_user_ids, :]\n","        self.V_pref_test = item_factors[self.test_item_ids, :]\n","        if cold_user:\n","            self.U_content_test = user_content[self.test_user_ids, :]\n","            if scipy.sparse.issparse(self.U_content_test):\n","                self.U_content_test = self.U_content_test.todense()\n","        if cold_item:\n","            self.V_content_test = item_content[self.test_item_ids, :]\n","            if scipy.sparse.issparse(self.V_content_test):\n","                self.V_content_test = self.V_content_test.todense()\n","        eval_l = self.R_test_inf.shape[0]\n","        self.eval_batch = [(x, min(x + eval_run_batchsize, eval_l)) for x\n","                           in range(0, eval_l, eval_run_batchsize)]\n","\n","        self.tf_eval_train = []\n","        self.tf_eval_test = []\n","\n","    def get_stats_string(self):\n","        return ('\\tn_test_users:[%d]\\n\\tn_test_items:[%d]' % (len(self.test_user_ids), len(self.test_item_ids))\n","                + '\\n\\tR_train_inf: %s' % (\n","                    'no R_train_inf for cold'\n","                )\n","                + '\\n\\tR_test_inf: shape=%s nnz=[%d]' % (\n","                    str(self.R_test_inf.shape), len(self.R_test_inf.nonzero()[0])\n","                ))"]},{"cell_type":"markdown","metadata":{"id":"RIz0vSgZ0GSx"},"source":["## Model"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1629805633278,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"9fPYLdF10Jcg"},"outputs":[],"source":["def l2_norm(para):\n","    return tf.reduce_sum(tf.square(para))\n","\n","\n","def dense_batch_fc_tanh(x, units, is_training, scope, do_norm=False):\n","    with tf.variable_scope(scope):\n","        init = tf.truncated_normal_initializer(stddev=0.01)\n","        h1_w = tf.get_variable(scope + '_w',\n","                               shape=[x.get_shape().as_list()[1], units],\n","                               initializer=init)\n","        h1_b = tf.get_variable(scope + '_b',\n","                               shape=[1, units],\n","                               initializer=tf.zeros_initializer())\n","        h1 = tf.matmul(x, h1_w) + h1_b\n","        if do_norm:\n","            h2 = tf.contrib.layers.batch_norm(\n","                h1,\n","                decay=0.9,\n","                center=True,\n","                scale=True,\n","                is_training=is_training,\n","                scope=scope + '_bn')\n","            return tf.nn.tanh(h2, scope + '_tanh'), l2_norm(h1_w) + l2_norm(h1_b)\n","        else:\n","            return tf.nn.tanh(h1, scope + '_tanh'), l2_norm(h1_w) + l2_norm(h1_b)\n","\n","\n","def dense_fc(x, units, scope):\n","    with tf.variable_scope(scope):\n","        init = tf.truncated_normal_initializer(stddev=0.01)\n","        h1_w = tf.get_variable(scope + '_w',\n","                               shape=[x.get_shape().as_list()[1], units],\n","                               initializer=init)\n","        h1_b = tf.get_variable(scope + '_b',\n","                               shape=[1, units],\n","                               initializer=tf.zeros_initializer())\n","        h1 = tf.matmul(x, h1_w) + h1_b\n","        return h1, l2_norm(h1_w) + l2_norm(h1_b)\n","\n","\n","class Heater:\n","    def __init__(self, latent_rank_in, user_content_rank, item_content_rank,\n","                 model_select, rank_out, reg, alpha, dim):\n","\n","        self.rank_in = latent_rank_in  # input embedding dimension\n","        self.phi_u_dim = user_content_rank  # user content dimension\n","        self.phi_v_dim = item_content_rank  # item content dimension\n","        self.model_select = model_select  # model architecture\n","        self.rank_out = rank_out  # output dimension\n","        self.reg = reg\n","        self.alpha = alpha\n","        self.dim = dim\n","\n","        # inputs\n","        self.Uin = None  # input user embedding\n","        self.Vin = None  # input item embedding\n","        self.Ucontent = None  # input user content\n","        self.Vcontent = None  # input item content\n","        self.is_training = None\n","        self.target = None  # input training target\n","\n","        self.eval_trainR = None  # input training rating matrix for evaluation\n","        self.U_pref_tf = None\n","        self.V_pref_tf = None\n","        self.rand_target_ui = None\n","\n","        # outputs in the model\n","        self.preds = None  # output of the model, the predicted scores\n","        self.optimizer = None  # the optimizer\n","        self.loss = None\n","\n","        self.U_embedding = None  # new user embedding\n","        self.V_embedding = None  # new item embedding\n","\n","        self.lr_placeholder = None  # learning rate\n","\n","        # predictor\n","        self.tf_topk_vals = None\n","        self.tf_topk_inds = None\n","        self.preds_random = None\n","        self.tf_latent_topk_cold = None\n","        self.tf_latent_topk_warm = None\n","        self.eval_preds_warm = None  # the top-k predicted indices for warm evaluation\n","        self.eval_preds_cold = None  # the top-k predicted indices for cold evaluation\n","\n","    def build_model(self):\n","        self.lr_placeholder = tf.placeholder(tf.float32, shape=[], name='learn_rate')\n","        self.is_training = tf.placeholder(tf.bool, name='is_training')\n","        self.target = tf.placeholder(tf.float32, shape=[None], name='target')\n","\n","        self.Uin = tf.placeholder(tf.float32, shape=[None, self.rank_in], name='U_in_raw')\n","        self.Vin = tf.placeholder(tf.float32, shape=[None, self.rank_in], name='V_in_raw')\n","\n","        dim = self.dim\n","        self.reg_loss = 0.\n","\n","        if self.phi_v_dim \u003e 0:\n","            self.Vcontent = tf.placeholder(tf.float32, shape=[None, self.phi_v_dim], name='V_content')\n","            self.dropout_item_indicator = tf.placeholder(tf.float32, shape=[None, 1], name='dropout_item_indicator')\n","\n","            vcontent_gate, vcontent_gate_reg = dense_fc(self.Vcontent, dim,\n","                                                        'vcontent_gate_layer')  # size: batch_size X dim\n","            vcontent_gate = tf.nn.tanh(vcontent_gate)\n","\n","            self.reg_loss += vcontent_gate_reg\n","\n","            vcontent_expert_list = []\n","            for i in range(dim):\n","                tmp_expert = self.Vcontent\n","                for ihid, hid in enumerate(self.model_select):\n","                    tmp_expert, tmp_reg = dense_fc(tmp_expert, hid, 'Vexpert_' + str(ihid) + '_' + str(i))\n","                    tmp_expert = tf.nn.tanh(tmp_expert)\n","                    self.reg_loss += tmp_reg\n","                vcontent_expert_list.append(tf.reshape(tmp_expert, [-1, 1, self.rank_out]))\n","\n","            vcontent_expert_concat = tf.concat(vcontent_expert_list, 1)  # size: batch_size X dim X self.rank_out\n","\n","            vcontent_expert_concat = tf.linalg.matmul(tf.reshape(vcontent_gate, [-1, 1, dim]),\n","                                                      vcontent_expert_concat)\n","            Vcontent_last = tf.reshape(tf.nn.tanh(vcontent_expert_concat), [-1, self.rank_out])  # size: batch_size X self.rank_out\n","\n","            self.Vin_filter = 1 - self.dropout_item_indicator\n","\n","            diff_item_loss = self.alpha \\\n","                             * (tf.reduce_sum(tf.reduce_sum(tf.square(Vcontent_last - self.Vin),\n","                                                            axis=1, keepdims=True)))\n","            v_last = (self.Vin * self.Vin_filter + Vcontent_last * (1 - self.Vin_filter))\n","        else:\n","            v_last = self.Vin\n","            diff_item_loss = 0\n","\n","        if self.phi_u_dim \u003e 0:\n","            self.Ucontent = tf.placeholder(tf.float32, shape=[None, self.phi_u_dim], name='U_content')\n","            self.dropout_user_indicator = tf.placeholder(tf.float32, shape=[None, 1], name='dropout_user_indicator')\n","\n","            ucontent_gate, ucontent_gate_reg = dense_fc(self.Ucontent, dim,\n","                                                        'ucontent_gate_layer')  # size: batch_size X dim\n","            ucontent_gate = tf.nn.tanh(ucontent_gate)\n","\n","            self.reg_loss += ucontent_gate_reg\n","\n","            ucontent_expert_list = []\n","            for i in range(dim):\n","                tmp_expert = self.Ucontent\n","                for ihid, hid in enumerate(self.model_select):\n","                    tmp_expert, tmp_reg = dense_fc(tmp_expert, hid, 'Uexpert_' + str(ihid) + '_' + str(i))\n","                    tmp_expert = tf.nn.tanh(tmp_expert)\n","                    self.reg_loss += tmp_reg\n","                ucontent_expert_list.append(tf.reshape(tmp_expert, [-1, 1, self.rank_out]))\n","\n","            ucontent_expert_concat = tf.concat(ucontent_expert_list, 1)  # size: batch_size X dim X self.rank_out\n","\n","            ucontent_expert_concat = tf.linalg.matmul(tf.reshape(ucontent_gate, [-1, 1, dim]),\n","                                                      ucontent_expert_concat)\n","            Ucontent_last = tf.reshape(tf.nn.tanh(ucontent_expert_concat), [-1, self.rank_out])  # size: batch_size X self.rank_out\n","\n","            self.Uin_filter = 1 - self.dropout_user_indicator\n","\n","            diff_user_loss = self.alpha \\\n","                             * (tf.reduce_sum(tf.reduce_sum(tf.square(Ucontent_last - self.Uin),\n","                                                            axis=1, keepdims=True)))\n","            u_last = (self.Uin * self.Uin_filter + Ucontent_last * (1 - self.Uin_filter))\n","        else:\n","            u_last = self.Uin\n","            diff_user_loss = 0\n","\n","        for ihid, hid in enumerate([self.rank_out]):\n","            u_last, u_reg = dense_batch_fc_tanh(u_last, hid, self.is_training, 'user_layer_%d'%ihid,\n","                                                do_norm=True)\n","            v_last, v_reg = dense_batch_fc_tanh(v_last, hid, self.is_training, 'item_layer_%d'%ihid,\n","                                                do_norm=True)\n","            self.reg_loss += u_reg\n","            self.reg_loss += v_reg\n","\n","        with tf.variable_scope(\"U_embedding\"):\n","            u_emb_w = tf.Variable(tf.truncated_normal([u_last.get_shape().as_list()[1], self.rank_out], stddev=0.01),\n","                                  name='u_emb_w')\n","            u_emb_b = tf.Variable(tf.zeros([1, self.rank_out]), name='u_emb_b')\n","            self.U_embedding = tf.matmul(u_last, u_emb_w) + u_emb_b\n","\n","        with tf.variable_scope(\"V_embedding\"):\n","            v_emb_w = tf.Variable(tf.truncated_normal([v_last.get_shape().as_list()[1], self.rank_out], stddev=0.01),\n","                                  name='v_emb_w')\n","            v_emb_b = tf.Variable(tf.zeros([1, self.rank_out]), name='v_emb_b')\n","            self.V_embedding = tf.matmul(v_last, v_emb_w) + v_emb_b\n","\n","        self.reg_loss += (l2_norm(v_emb_w) + l2_norm(v_emb_b) + l2_norm(u_emb_w) + l2_norm(u_emb_b))\n","        self.reg_loss *= self.reg\n","\n","        with tf.variable_scope(\"loss\"):\n","            preds = tf.multiply(self.U_embedding, self.V_embedding)\n","            self.preds = tf.reduce_sum(preds, 1)  # output of the model, the predicted scores\n","            self.diff_loss = diff_item_loss + diff_user_loss\n","            self.loss = tf.reduce_mean(tf.squared_difference(self.preds, self.target)) + self.reg_loss + self.diff_loss\n","\n","        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","        with tf.control_dependencies(update_ops):\n","            # Ensures that we execute the update_ops before performing the train_step\n","            self.optimizer = tf.train.MomentumOptimizer(self.lr_placeholder, 0.9).minimize(self.loss)\n","\n","    def build_predictor(self, recall_at):\n","        self.eval_trainR = tf.sparse_placeholder(\n","            dtype=tf.float32, shape=[None, None], name='trainR_sparse')\n","\n","        with tf.variable_scope(\"eval\"):\n","            embedding_prod_cold = tf.matmul(self.U_embedding, self.V_embedding, transpose_b=True, name='pred_all_items')\n","            embedding_prod_warm = tf.sparse_add(embedding_prod_cold, self.eval_trainR)\n","            _, self.eval_preds_cold = tf.nn.top_k(embedding_prod_cold, k=recall_at[-1], sorted=True,\n","                                                  name='topK_net_cold')\n","            _, self.eval_preds_warm = tf.nn.top_k(embedding_prod_warm, k=recall_at[-1], sorted=True,\n","                                                  name='topK_net_warm')\n","\n","    def get_eval_dict(self, _i, _eval_start, _eval_finish, eval_data):\n","        _eval_dict = {\n","            self.Uin: eval_data.U_pref_test[_eval_start:_eval_finish, :],\n","            self.Vin: eval_data.V_pref_test,\n","            self.is_training: False\n","        }\n","\n","        if self.phi_v_dim \u003e 0:\n","            zero_index = np.where(np.sum(eval_data.V_pref_test, axis=1) == 0)[0]\n","            dropout_item_indicator = np.zeros((len(eval_data.test_item_ids), 1))\n","            dropout_item_indicator[zero_index] = 1\n","            _eval_dict[self.dropout_item_indicator] = dropout_item_indicator\n","            _eval_dict[self.Vcontent] = eval_data.V_content_test\n","        if self.phi_u_dim \u003e 0:\n","            zero_index = np.where(np.sum(eval_data.U_pref_test[_eval_start:_eval_finish, :], axis=1) == 0)[0]\n","            dropout_user_indicator = np.zeros((_eval_finish - _eval_start, 1))\n","            dropout_user_indicator[zero_index] = 1\n","            _eval_dict[self.dropout_user_indicator] = dropout_user_indicator\n","            _eval_dict[self.Ucontent] = eval_data.U_content_test[_eval_start:_eval_finish, :]\n","        return _eval_dict\n","\n","    def get_eval_dict_latent(self, _i, _eval_start, _eval_finish, eval_data, u_pref, v_pref):\n","        _eval_dict = {\n","            self.U_pref_tf: u_pref[eval_data.test_user_ids[_eval_start:_eval_finish], :],\n","            self.V_pref_tf: v_pref[eval_data.test_item_ids, :]\n","        }\n","        if not eval_data.is_cold:\n","            _eval_dict[self.eval_trainR] = eval_data.tf_eval_train[_i]\n","        return _eval_dict"]},{"cell_type":"markdown","metadata":{"id":"lTwqzoe-3DwV"},"source":["## Main"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1629805633280,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"RSzE_rbt3e6N","outputId":"519ae0a8-e743-4386-e574-19ba5862e8a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["data:LastFM\n","model_select:[200]\n","rank:200\n","dropout:0.5\n","eval_every:1\n","neg:5\n","lr:0.005\n","alpha:0.0001\n","reg:0.001\n","dim:5\n"]}],"source":["parser = argparse.ArgumentParser(description=\"main_LastFM\",\n","                                    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","\n","parser.add_argument('--data', type=str, default='LastFM', help='path to eval in the downloaded folder')\n","parser.add_argument('--model-select', nargs='+', type=int,\n","                    default=[200],\n","                    help='specify the fully-connected architecture, starting from input,'\n","                            ' numbers indicate numbers of hidden units',\n","                    )\n","parser.add_argument('--rank', type=int, default=200, help='output rank of latent model')\n","parser.add_argument('--dropout', type=float, default=0.5, help='dropout rate')\n","parser.add_argument('--eval-every', type=int, default=1, help='evaluate every X user-batch')\n","parser.add_argument('--neg', type=float, default=5, help='negative sampling rate')\n","parser.add_argument('--lr', type=float, default=0.005, help='starting learning rate')\n","parser.add_argument('--alpha', type=float, default=0.0001, help='diff loss parameter')\n","parser.add_argument('--reg', type=float, default=0.001, help='regularization')\n","parser.add_argument('--dim', type=int, default=5, help='number of experts')\n","\n","args = parser.parse_args(args={})\n","args, _ = parser.parse_known_args()\n","\n","for key in vars(args):\n","    print(key + \":\" + str(vars(args)[key]))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1629805633282,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"JV7omyS33Ywm"},"outputs":[],"source":["def load_data(data_name):\n","    timer = timer_class(name='main').tic()\n","    data_path_silver = './data/silver/lastfm'\n","    u_file = data_path_silver + '/U_BPR.npy'\n","    v_file = data_path_silver + '/V_BPR.npy'\n","    user_content_file = data_path_silver + '/user_content.npz'\n","    train_file = data_path_silver + '/train.csv'\n","    test_file = data_path_silver + '/test.csv'\n","    vali_file = data_path_silver + '/vali.csv'\n","    with open(data_path_silver + '/info.pkl', 'rb') as f:\n","        info = pickle.load(f)\n","        num_user = info['num_user']\n","        num_item = info['num_item']\n","\n","    dat = {}\n","    # load preference data\n","    timer.tic()\n","\n","    u_pref = np.load(u_file)\n","    v_pref = np.load(v_file)\n","\n","    dat['u_pref'] = u_pref\n","    dat['v_pref'] = v_pref\n","\n","    timer.toc('loaded U:%s,V:%s' % (str(u_pref.shape), str(v_pref.shape))).tic()\n","\n","    # pre-process\n","    _, dat['u_pref'] = standardize_2(u_pref)\n","    _, dat['v_pref'] = standardize(v_pref)\n","\n","    timer.toc('standardized U,V').tic()\n","\n","    # load content data\n","    timer.tic()\n","    user_content = scipy.sparse.load_npz(user_content_file)\n","    dat['user_content'] = user_content.tolil(copy=False)\n","    timer.toc('loaded user feature sparse matrix: %s' % (str(user_content.shape))).tic()\n","\n","    # load split\n","    timer.tic()\n","    train = pd.read_csv(train_file, dtype=np.int32)\n","    dat['user_list'] = train['uid'].values\n","    dat['item_list'] = train['iid'].values\n","    dat['warm_item'] = np.unique(train['iid'].values)\n","    timer.toc('read train triplets %s' % str(train.shape)).tic()\n","\n","    dat['test_eval'] = load_eval_data(test_file, cold_user=True, test_item_ids=dat['warm_item'])\n","    dat['vali_eval'] = load_eval_data(vali_file, cold_user=True, test_item_ids=dat['warm_item'])\n","    return dat"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1629805633283,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"yOoWjmtH7DNq"},"outputs":[],"source":["data_name = args.data\n","model_select = args.model_select\n","rank_out = args.rank\n","data_batch_size = 1024\n","dropout = args.dropout\n","recall_at = [20, 50, 100]\n","eval_batch_size = 5000  # the batch size when test\n","eval_every = args.eval_every\n","num_epoch = 100\n","neg = args.neg\n","\n","_lr = args.lr\n","_decay_lr_every = 2\n","_lr_decay = 0.9"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1629805720697,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"Wly5WVFD69sq","outputId":"75d167f0-fa36-4c27-90ef-6553710caac3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[main] loaded U:(1892, 200),V:(17632, 200) elapsed [0 s]\n","[main] standardized U,V elapsed [0 s]\n","[main] loaded user feature sparse matrix: (1892, 1892) elapsed [0 s]\n","[main] read train triplets (55634, 2) elapsed [0 s]\n","[default] read 27922 triplets elapsed [0 s]\n","\tn_test_users:[567]\n","\tn_test_items:[12926]\n","\tR_train_inf: no R_train_inf for cold\n","\tR_test_inf: shape=(567, 12926) nnz=[23997]\n","[default] read 9278 triplets elapsed [0 s]\n","\tn_test_users:[189]\n","\tn_test_items:[12926]\n","\tR_train_inf: no R_train_inf for cold\n","\tR_test_inf: shape=(189, 12926) nnz=[7922]\n"]}],"source":["dat = load_data(data_name)\n","u_pref = dat['u_pref']\n","v_pref = dat['v_pref']\n","test_eval = dat['test_eval']\n","vali_eval = dat['vali_eval']\n","user_content = dat['user_content']\n","user_list = dat['user_list']\n","item_list = dat['item_list']\n","item_warm = np.unique(item_list)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1224091,"status":"ok","timestamp":1629806949019,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"},"user_tz":-330},"id":"BOpn2IwT3EWq"},"outputs":[{"name":"stdout","output_type":"stream","text":["[main] initialized eval data elapsed [0 s]\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","[main] initialized tf elapsed [1 s]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 0 [326]b loss=2453.6826 reg_loss=50.5861 diff_loss=2352.8988 expert_loss=0.0000 best[0] elapsed [1 min15 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.026558 0.042662 0.064798\n","Current precision\t0.060106 0.038404 0.028830\n","Current ndcg\t\t0.084375 0.067754 0.082684\n","Current test recall\t\t0.026954 0.044780 0.064456\n","Current test precision\t0.060406 0.040106 0.028854\n","Current test ndcg\t\t0.080489 0.066627 0.080229\n","best epoch[0]\t vali recall: 0.026558 0.042662 0.064798\n","best epoch[0]\t test recall: 0.026954 0.044780 0.064456\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0045000000000000005\n","[main] 1 [326]b loss=2285.6315 reg_loss=50.0241 diff_loss=2192.8777 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.053935 0.096688 0.136118\n","Current precision\t0.121543 0.087021 0.061117\n","Current ndcg\t\t0.140022 0.126279 0.153717\n","Current test recall\t\t0.055389 0.095759 0.134155\n","Current test precision\t0.124250 0.086102 0.060265\n","Current test ndcg\t\t0.138245 0.123149 0.149875\n","best epoch[1]\t vali recall: 0.053935 0.096688 0.136118\n","best epoch[1]\t test recall: 0.055389 0.095759 0.134155\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 2 [326]b loss=2046.8890 reg_loss=54.7609 diff_loss=1951.7338 expert_loss=0.0000 best[0] elapsed [1 min14 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.057755 0.111238 0.166910\n","Current precision\t0.130319 0.099787 0.074894\n","Current ndcg\t\t0.148945 0.140412 0.179273\n","Current test recall\t\t0.058168 0.110735 0.162405\n","Current test precision\t0.130952 0.099224 0.072698\n","Current test ndcg\t\t0.144546 0.136550 0.172345\n","best epoch[2]\t vali recall: 0.057755 0.111238 0.166910\n","best epoch[2]\t test recall: 0.058168 0.110735 0.162405\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.004050000000000001\n","[main] 3 [326]b loss=1861.0374 reg_loss=63.0254 diff_loss=1758.9007 expert_loss=0.0000 best[0] elapsed [1 min14 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.056854 0.125205 0.180202\n","Current precision\t0.128191 0.112766 0.080851\n","Current ndcg\t\t0.140297 0.148412 0.186372\n","Current test recall\t\t0.058578 0.123716 0.176288\n","Current test precision\t0.131570 0.111041 0.079030\n","Current test ndcg\t\t0.143444 0.146953 0.183338\n","best epoch[3]\t vali recall: 0.056854 0.125205 0.180202\n","best epoch[3]\t test recall: 0.058578 0.123716 0.176288\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 4 [326]b loss=1735.2210 reg_loss=72.3501 diff_loss=1624.6847 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.060861 0.127230 0.188139\n","Current precision\t0.137500 0.114255 0.084574\n","Current ndcg\t\t0.149495 0.151814 0.194451\n","Current test recall\t\t0.061771 0.124412 0.185009\n","Current test precision\t0.138624 0.111781 0.083104\n","Current test ndcg\t\t0.147270 0.147449 0.189522\n","best epoch[4]\t vali recall: 0.060861 0.127230 0.188139\n","best epoch[4]\t test recall: 0.061771 0.124412 0.185009\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0036450000000000007\n","[main] 5 [326]b loss=1647.8556 reg_loss=81.7069 diff_loss=1528.4156 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.060924 0.127037 0.188322\n","Current precision\t0.136968 0.114574 0.084468\n","Current ndcg\t\t0.152276 0.153867 0.196226\n","Current test recall\t\t0.062069 0.129904 0.186599\n","Current test precision\t0.140123 0.116861 0.083616\n","Current test ndcg\t\t0.150560 0.153436 0.192310\n","best epoch[5]\t vali recall: 0.060924 0.127037 0.188322\n","best epoch[5]\t test recall: 0.062069 0.129904 0.186599\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:14\u003c00:00,  4.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 6 [326]b loss=1582.9680 reg_loss=90.7444 diff_loss=1455.0253 expert_loss=0.0000 best[0] elapsed [1 min14 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.060667 0.132365 0.191111\n","Current precision\t0.137234 0.118723 0.085319\n","Current ndcg\t\t0.148639 0.155821 0.196109\n","Current test recall\t\t0.061618 0.130326 0.191679\n","Current test precision\t0.139065 0.117284 0.085873\n","Current test ndcg\t\t0.147695 0.152850 0.194867\n","best epoch[6]\t vali recall: 0.060667 0.132365 0.191111\n","best epoch[6]\t test recall: 0.061618 0.130326 0.191679\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.003280500000000001\n","[main] 7 [326]b loss=1533.4894 reg_loss=99.2769 diff_loss=1397.2952 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.061067 0.126247 0.188916\n","Current precision\t0.137500 0.113830 0.084734\n","Current ndcg\t\t0.145343 0.149245 0.192516\n","Current test recall\t\t0.061618 0.130326 0.191679\n","Current test precision\t0.139065 0.117284 0.085873\n","Current test ndcg\t\t0.147695 0.152850 0.194867\n","best epoch[6]\t vali recall: 0.060667 0.132365 0.191111\n","best epoch[6]\t test recall: 0.061618 0.130326 0.191679\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:15\u003c00:00,  4.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 8 [326]b loss=1494.0083 reg_loss=107.2493 diff_loss=1350.2526 expert_loss=0.0000 best[0] elapsed [1 min15 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074087 0.135013 0.196521\n","Current precision\t0.165426 0.120745 0.087872\n","Current ndcg\t\t0.181466 0.168345 0.211069\n","Current test recall\t\t0.073028 0.133066 0.198160\n","Current test precision\t0.164198 0.119647 0.088748\n","Current test ndcg\t\t0.180062 0.166122 0.210823\n","best epoch[8]\t vali recall: 0.074087 0.135013 0.196521\n","best epoch[8]\t test recall: 0.073028 0.133066 0.198160\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:14\u003c00:00,  4.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.002952450000000001\n","[main] 9 [326]b loss=1462.4122 reg_loss=114.6817 diff_loss=1311.3032 expert_loss=0.0000 best[0] elapsed [1 min14 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.072127 0.132130 0.192275\n","Current precision\t0.160638 0.118085 0.085957\n","Current ndcg\t\t0.174279 0.163674 0.205323\n","Current test recall\t\t0.073028 0.133066 0.198160\n","Current test precision\t0.164198 0.119647 0.088748\n","Current test ndcg\t\t0.180062 0.166122 0.210823\n","best epoch[8]\t vali recall: 0.074087 0.135013 0.196521\n","best epoch[8]\t test recall: 0.073028 0.133066 0.198160\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 10 [326]b loss=1436.0620 reg_loss=121.6266 diff_loss=1278.2966 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.058846 0.128110 0.190019\n","Current precision\t0.132181 0.115319 0.085319\n","Current ndcg\t\t0.136417 0.146376 0.189391\n","Current test recall\t\t0.073028 0.133066 0.198160\n","Current test precision\t0.164198 0.119647 0.088748\n","Current test ndcg\t\t0.180062 0.166122 0.210823\n","best epoch[8]\t vali recall: 0.074087 0.135013 0.196521\n","best epoch[8]\t test recall: 0.073028 0.133066 0.198160\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.002657205000000001\n","[main] 11 [326]b loss=1414.2085 reg_loss=128.0494 diff_loss=1250.1486 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.070610 0.134419 0.195429\n","Current precision\t0.158511 0.120957 0.087553\n","Current ndcg\t\t0.161293 0.158237 0.200191\n","Current test recall\t\t0.073028 0.133066 0.198160\n","Current test precision\t0.164198 0.119647 0.088748\n","Current test ndcg\t\t0.180062 0.166122 0.210823\n","best epoch[8]\t vali recall: 0.074087 0.135013 0.196521\n","best epoch[8]\t test recall: 0.073028 0.133066 0.198160\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 12 [326]b loss=1395.5825 reg_loss=134.0276 diff_loss=1225.7130 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077631 0.134331 0.196858\n","Current precision\t0.173670 0.119787 0.088457\n","Current ndcg\t\t0.196251 0.173881 0.218139\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.002391484500000001\n","[main] 13 [326]b loss=1379.7509 reg_loss=139.5626 diff_loss=1204.4484 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.064845 0.134500 0.194983\n","Current precision\t0.147872 0.120745 0.087287\n","Current ndcg\t\t0.154595 0.157342 0.199258\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 14 [326]b loss=1365.8931 reg_loss=144.7232 diff_loss=1185.6686 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.069806 0.138674 0.198248\n","Current precision\t0.155319 0.124468 0.089202\n","Current ndcg\t\t0.162640 0.163608 0.205406\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.002152336050000001\n","[main] 15 [326]b loss=1354.0340 reg_loss=149.4917 diff_loss=1169.0964 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.071154 0.138779 0.197368\n","Current precision\t0.159840 0.124043 0.088511\n","Current ndcg\t\t0.178735 0.171829 0.212891\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 16 [326]b loss=1343.5193 reg_loss=153.9424 diff_loss=1154.2756 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.071128 0.134624 0.200303\n","Current precision\t0.159043 0.120745 0.090000\n","Current ndcg\t\t0.170975 0.164058 0.210029\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.001937102445000001\n","[main] 17 [326]b loss=1334.3860 reg_loss=158.0630 diff_loss=1141.0511 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.070088 0.136698 0.200707\n","Current precision\t0.157713 0.122340 0.089787\n","Current ndcg\t\t0.186876 0.176220 0.220712\n","Current test recall\t\t0.072872 0.133676 0.200571\n","Current test precision\t0.163139 0.119612 0.090088\n","Current test ndcg\t\t0.186552 0.170974 0.217707\n","best epoch[12]\t vali recall: 0.077631 0.134331 0.196858\n","best epoch[12]\t test recall: 0.072872 0.133676 0.200571\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 18 [326]b loss=1326.0867 reg_loss=161.9043 diff_loss=1129.1222 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.070171 0.139664 0.201381\n","Current precision\t0.156649 0.125319 0.090000\n","Current ndcg\t\t0.167517 0.166723 0.209061\n","Current test recall\t\t0.064365 0.136684 0.198261\n","Current test precision\t0.145414 0.122540 0.088713\n","Current test ndcg\t\t0.156916 0.161247 0.203787\n","best epoch[18]\t vali recall: 0.070171 0.139664 0.201381\n","best epoch[18]\t test recall: 0.064365 0.136684 0.198261\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.001743392200500001\n","[main] 19 [326]b loss=1318.8661 reg_loss=165.4903 diff_loss=1118.3625 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.069200 0.134915 0.202262\n","Current precision\t0.154787 0.121489 0.090745\n","Current ndcg\t\t0.171670 0.166831 0.213413\n","Current test recall\t\t0.064365 0.136684 0.198261\n","Current test precision\t0.145414 0.122540 0.088713\n","Current test ndcg\t\t0.156916 0.161247 0.203787\n","best epoch[18]\t vali recall: 0.070171 0.139664 0.201381\n","best epoch[18]\t test recall: 0.064365 0.136684 0.198261\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 20 [326]b loss=1312.3461 reg_loss=168.8204 diff_loss=1108.5941 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.066509 0.138603 0.201583\n","Current precision\t0.149734 0.124681 0.090638\n","Current ndcg\t\t0.156910 0.162200 0.206112\n","Current test recall\t\t0.064365 0.136684 0.198261\n","Current test precision\t0.145414 0.122540 0.088713\n","Current test ndcg\t\t0.156916 0.161247 0.203787\n","best epoch[18]\t vali recall: 0.070171 0.139664 0.201381\n","best epoch[18]\t test recall: 0.064365 0.136684 0.198261\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.001569052980450001\n","[main] 21 [326]b loss=1306.5146 reg_loss=171.9262 diff_loss=1099.7339 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.071068 0.139516 0.201629\n","Current precision\t0.159309 0.125000 0.090160\n","Current ndcg\t\t0.162119 0.162558 0.205489\n","Current test recall\t\t0.068838 0.132428 0.198544\n","Current test precision\t0.154586 0.118977 0.088854\n","Current test ndcg\t\t0.161875 0.157645 0.202947\n","best epoch[21]\t vali recall: 0.071068 0.139516 0.201629\n","best epoch[21]\t test recall: 0.068838 0.132428 0.198544\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 22 [326]b loss=1301.3009 reg_loss=174.8300 diff_loss=1091.6255 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.069275 0.138301 0.200355\n","Current precision\t0.155585 0.124255 0.089840\n","Current ndcg\t\t0.166178 0.165244 0.208276\n","Current test recall\t\t0.068838 0.132428 0.198544\n","Current test precision\t0.154586 0.118977 0.088854\n","Current test ndcg\t\t0.161875 0.157645 0.202947\n","best epoch[21]\t vali recall: 0.071068 0.139516 0.201629\n","best epoch[21]\t test recall: 0.068838 0.132428 0.198544\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0014121476824050009\n","[main] 23 [326]b loss=1296.5428 reg_loss=177.5495 diff_loss=1084.2189 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.075469 0.139061 0.198951\n","Current precision\t0.169415 0.124681 0.089202\n","Current ndcg\t\t0.182868 0.171374 0.213101\n","Current test recall\t\t0.070150 0.138297 0.199859\n","Current test precision\t0.158995 0.124127 0.089700\n","Current test ndcg\t\t0.176634 0.170204 0.212868\n","best epoch[23]\t vali recall: 0.075469 0.139061 0.198951\n","best epoch[23]\t test recall: 0.070150 0.138297 0.199859\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 24 [326]b loss=1292.0944 reg_loss=180.0856 diff_loss=1077.4174 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.069925 0.139092 0.202759\n","Current precision\t0.156117 0.124574 0.090957\n","Current ndcg\t\t0.168623 0.167110 0.211654\n","Current test recall\t\t0.070150 0.138297 0.199859\n","Current test precision\t0.158995 0.124127 0.089700\n","Current test ndcg\t\t0.176634 0.170204 0.212868\n","best epoch[23]\t vali recall: 0.075469 0.139061 0.198951\n","best epoch[23]\t test recall: 0.070150 0.138297 0.199859\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0012709329141645008\n","[main] 25 [326]b loss=1288.2604 reg_loss=182.4462 diff_loss=1071.1887 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.069457 0.141005 0.204209\n","Current precision\t0.155585 0.126170 0.091596\n","Current ndcg\t\t0.166398 0.167506 0.211654\n","Current test recall\t\t0.068695 0.138808 0.204933\n","Current test precision\t0.154674 0.124515 0.091869\n","Current test ndcg\t\t0.165145 0.164789 0.210569\n","best epoch[25]\t vali recall: 0.069457 0.141005 0.204209\n","best epoch[25]\t test recall: 0.068695 0.138808 0.204933\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 26 [326]b loss=1284.6417 reg_loss=184.6777 diff_loss=1065.4220 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.071246 0.139445 0.203294\n","Current precision\t0.159043 0.124787 0.091277\n","Current ndcg\t\t0.170850 0.167681 0.212354\n","Current test recall\t\t0.068695 0.138808 0.204933\n","Current test precision\t0.154674 0.124515 0.091869\n","Current test ndcg\t\t0.165145 0.164789 0.210569\n","best epoch[25]\t vali recall: 0.069457 0.141005 0.204209\n","best epoch[25]\t test recall: 0.068695 0.138808 0.204933\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0011438396227480508\n","[main] 27 [326]b loss=1281.3770 reg_loss=186.7504 diff_loss=1060.1281 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.063904 0.136734 0.200420\n","Current precision\t0.144149 0.122340 0.089840\n","Current ndcg\t\t0.158174 0.163013 0.207500\n","Current test recall\t\t0.068695 0.138808 0.204933\n","Current test precision\t0.154674 0.124515 0.091869\n","Current test ndcg\t\t0.165145 0.164789 0.210569\n","best epoch[25]\t vali recall: 0.069457 0.141005 0.204209\n","best epoch[25]\t test recall: 0.068695 0.138808 0.204933\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 28 [326]b loss=1278.3272 reg_loss=188.6974 diff_loss=1055.2197 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.072957 0.139916 0.201649\n","Current precision\t0.162234 0.125532 0.090479\n","Current ndcg\t\t0.176859 0.170739 0.213630\n","Current test recall\t\t0.068695 0.138808 0.204933\n","Current test precision\t0.154674 0.124515 0.091869\n","Current test ndcg\t\t0.165145 0.164789 0.210569\n","best epoch[25]\t vali recall: 0.069457 0.141005 0.204209\n","best epoch[25]\t test recall: 0.068695 0.138808 0.204933\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0010294556604732458\n","[main] 29 [326]b loss=1275.6070 reg_loss=190.5207 diff_loss=1050.6854 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074148 0.140216 0.205036\n","Current precision\t0.164096 0.125106 0.092021\n","Current ndcg\t\t0.182453 0.173455 0.219092\n","Current test recall\t\t0.071924 0.137560 0.204363\n","Current test precision\t0.161640 0.123351 0.091658\n","Current test ndcg\t\t0.183940 0.173201 0.219482\n","best epoch[29]\t vali recall: 0.074148 0.140216 0.205036\n","best epoch[29]\t test recall: 0.071924 0.137560 0.204363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 30 [326]b loss=1272.9946 reg_loss=192.2356 diff_loss=1046.4700 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076907 0.138629 0.202416\n","Current precision\t0.172074 0.124149 0.090904\n","Current ndcg\t\t0.190532 0.175148 0.219750\n","Current test recall\t\t0.071924 0.137560 0.204363\n","Current test precision\t0.161640 0.123351 0.091658\n","Current test ndcg\t\t0.183940 0.173201 0.219482\n","best epoch[29]\t vali recall: 0.074148 0.140216 0.205036\n","best epoch[29]\t test recall: 0.071924 0.137560 0.204363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0009265100944259213\n","[main] 31 [326]b loss=1270.6646 reg_loss=193.8430 diff_loss=1042.5689 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074430 0.136887 0.198971\n","Current precision\t0.165160 0.122660 0.089096\n","Current ndcg\t\t0.187004 0.173753 0.216870\n","Current test recall\t\t0.071924 0.137560 0.204363\n","Current test precision\t0.161640 0.123351 0.091658\n","Current test ndcg\t\t0.183940 0.173201 0.219482\n","best epoch[29]\t vali recall: 0.074148 0.140216 0.205036\n","best epoch[29]\t test recall: 0.071924 0.137560 0.204363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 32 [326]b loss=1268.5557 reg_loss=195.3537 diff_loss=1038.9289 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.075073 0.134308 0.201660\n","Current precision\t0.168351 0.120106 0.090426\n","Current ndcg\t\t0.187593 0.170466 0.217550\n","Current test recall\t\t0.071924 0.137560 0.204363\n","Current test precision\t0.161640 0.123351 0.091658\n","Current test ndcg\t\t0.183940 0.173201 0.219482\n","best epoch[29]\t vali recall: 0.074148 0.140216 0.205036\n","best epoch[29]\t test recall: 0.071924 0.137560 0.204363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0008338590849833291\n","[main] 33 [326]b loss=1266.5346 reg_loss=196.7786 diff_loss=1035.5455 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.073522 0.136806 0.203513\n","Current precision\t0.164628 0.122766 0.091436\n","Current ndcg\t\t0.179166 0.168706 0.215368\n","Current test recall\t\t0.071924 0.137560 0.204363\n","Current test precision\t0.161640 0.123351 0.091658\n","Current test ndcg\t\t0.183940 0.173201 0.219482\n","best epoch[29]\t vali recall: 0.074148 0.140216 0.205036\n","best epoch[29]\t test recall: 0.071924 0.137560 0.204363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 34 [326]b loss=1264.7144 reg_loss=198.1114 diff_loss=1032.3905 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078956 0.139891 0.207309\n","Current precision\t0.177128 0.125106 0.092660\n","Current ndcg\t\t0.199910 0.179866 0.226570\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0007504731764849962\n","[main] 35 [326]b loss=1262.9360 reg_loss=199.3630 diff_loss=1029.4569 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074642 0.137465 0.202862\n","Current precision\t0.165957 0.123298 0.091223\n","Current ndcg\t\t0.183294 0.171700 0.217431\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 36 [326]b loss=1261.3430 reg_loss=200.5460 diff_loss=1026.7057 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076333 0.138188 0.204288\n","Current precision\t0.169947 0.123936 0.091755\n","Current ndcg\t\t0.186863 0.172927 0.218946\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0006754258588364966\n","[main] 37 [326]b loss=1259.8762 reg_loss=201.6590 diff_loss=1024.1419 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.075167 0.137693 0.202510\n","Current precision\t0.167819 0.123723 0.090957\n","Current ndcg\t\t0.185235 0.172421 0.217611\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 38 [326]b loss=1258.4992 reg_loss=202.7029 diff_loss=1021.7425 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076757 0.140588 0.205004\n","Current precision\t0.171543 0.125957 0.091862\n","Current ndcg\t\t0.188777 0.175388 0.220170\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.000607883272952847\n","[main] 39 [326]b loss=1257.1537 reg_loss=203.6921 diff_loss=1019.4942 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076556 0.142590 0.204314\n","Current precision\t0.169947 0.127340 0.091702\n","Current ndcg\t\t0.193743 0.180804 0.224155\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 40 [326]b loss=1255.9667 reg_loss=204.6201 diff_loss=1017.3888 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074740 0.139340 0.203719\n","Current precision\t0.166755 0.124255 0.091383\n","Current ndcg\t\t0.183525 0.172389 0.217742\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0005470949456575623\n","[main] 41 [326]b loss=1254.7880 reg_loss=205.4955 diff_loss=1015.4186 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074700 0.140059 0.202667\n","Current precision\t0.166223 0.125213 0.091064\n","Current ndcg\t\t0.178727 0.170664 0.214782\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 42 [326]b loss=1253.7810 reg_loss=206.3260 diff_loss=1013.5609 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078498 0.137896 0.205439\n","Current precision\t0.175532 0.123936 0.092074\n","Current ndcg\t\t0.196410 0.177301 0.223887\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0004923854510918061\n","[main] 43 [326]b loss=1252.8917 reg_loss=207.1032 diff_loss=1011.8262 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076348 0.137959 0.206325\n","Current precision\t0.170479 0.123617 0.092660\n","Current ndcg\t\t0.184713 0.171238 0.219077\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 44 [326]b loss=1251.8689 reg_loss=207.8389 diff_loss=1010.1920 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.073605 0.139682 0.205271\n","Current precision\t0.165691 0.124681 0.092340\n","Current ndcg\t\t0.178940 0.170399 0.216779\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00044314690598262546\n","[main] 45 [326]b loss=1251.0993 reg_loss=208.5323 diff_loss=1008.6611 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.073590 0.137978 0.203850\n","Current precision\t0.165160 0.123617 0.091383\n","Current ndcg\t\t0.180692 0.170898 0.216695\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 46 [326]b loss=1250.1050 reg_loss=209.1884 diff_loss=1007.2161 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077419 0.138919 0.204559\n","Current precision\t0.172872 0.124362 0.091755\n","Current ndcg\t\t0.189396 0.174413 0.220247\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0003988322153843629\n","[main] 47 [326]b loss=1249.4238 reg_loss=209.8065 diff_loss=1005.8619 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074547 0.138970 0.205696\n","Current precision\t0.165426 0.124362 0.092447\n","Current ndcg\t\t0.187084 0.175246 0.222128\n","Current test recall\t\t0.074357 0.137956 0.205135\n","Current test precision\t0.167108 0.123774 0.091869\n","Current test ndcg\t\t0.190475 0.175616 0.221975\n","best epoch[34]\t vali recall: 0.078956 0.139891 0.207309\n","best epoch[34]\t test recall: 0.074357 0.137956 0.205135\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:14\u003c00:00,  4.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 48 [326]b loss=1248.7489 reg_loss=210.3926 diff_loss=1004.5825 expert_loss=0.0000 best[0] elapsed [1 min14 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077459 0.141398 0.207302\n","Current precision\t0.173670 0.127234 0.093138\n","Current ndcg\t\t0.190416 0.177272 0.222972\n","Current test recall\t\t0.074774 0.141666 0.207169\n","Current test precision\t0.168959 0.127125 0.092981\n","Current test ndcg\t\t0.188357 0.176769 0.222180\n","best epoch[48]\t vali recall: 0.077459 0.141398 0.207302\n","best epoch[48]\t test recall: 0.074774 0.141666 0.207169\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0003589489938459266\n","[main] 49 [326]b loss=1248.0181 reg_loss=210.9434 diff_loss=1003.3832 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074325 0.139734 0.207309\n","Current precision\t0.167553 0.125106 0.092872\n","Current ndcg\t\t0.182774 0.172471 0.219450\n","Current test recall\t\t0.074774 0.141666 0.207169\n","Current test precision\t0.168959 0.127125 0.092981\n","Current test ndcg\t\t0.188357 0.176769 0.222180\n","best epoch[48]\t vali recall: 0.077459 0.141398 0.207302\n","best epoch[48]\t test recall: 0.074774 0.141666 0.207169\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 50 [326]b loss=1247.4736 reg_loss=211.4647 diff_loss=1002.2494 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.079372 0.140655 0.206929\n","Current precision\t0.175798 0.126277 0.092872\n","Current ndcg\t\t0.196985 0.179713 0.225760\n","Current test recall\t\t0.074830 0.140192 0.205914\n","Current test precision\t0.168519 0.125961 0.092328\n","Current test ndcg\t\t0.191679 0.178204 0.223624\n","best epoch[50]\t vali recall: 0.079372 0.140655 0.206929\n","best epoch[50]\t test recall: 0.074830 0.140192 0.205914\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00032305409446133396\n","[main] 51 [326]b loss=1246.8107 reg_loss=211.9574 diff_loss=1001.1847 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.074992 0.140029 0.204726\n","Current precision\t0.167287 0.125745 0.091915\n","Current ndcg\t\t0.181306 0.172713 0.217702\n","Current test recall\t\t0.074830 0.140192 0.205914\n","Current test precision\t0.168519 0.125961 0.092328\n","Current test ndcg\t\t0.191679 0.178204 0.223624\n","best epoch[50]\t vali recall: 0.079372 0.140655 0.206929\n","best epoch[50]\t test recall: 0.074830 0.140192 0.205914\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 52 [326]b loss=1246.2251 reg_loss=212.4255 diff_loss=1000.1756 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078792 0.140434 0.207759\n","Current precision\t0.174734 0.126170 0.093191\n","Current ndcg\t\t0.193011 0.177347 0.223900\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00029074868501520056\n","[main] 53 [326]b loss=1245.8203 reg_loss=212.8650 diff_loss=999.2289 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077175 0.141764 0.206227\n","Current precision\t0.172606 0.126915 0.092606\n","Current ndcg\t\t0.191609 0.178102 0.223268\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 54 [326]b loss=1245.2514 reg_loss=213.2824 diff_loss=998.3326 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076774 0.140125 0.207060\n","Current precision\t0.171011 0.125532 0.092872\n","Current ndcg\t\t0.189479 0.175989 0.222752\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00026167381651368053\n","[main] 55 [326]b loss=1244.7741 reg_loss=213.6760 diff_loss=997.4902 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078690 0.140308 0.207596\n","Current precision\t0.175532 0.125851 0.093351\n","Current ndcg\t\t0.198682 0.180610 0.227783\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 56 [326]b loss=1244.3703 reg_loss=214.0490 diff_loss=996.6927 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078318 0.138718 0.205729\n","Current precision\t0.175532 0.124149 0.092340\n","Current ndcg\t\t0.190184 0.173494 0.220382\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.0002355064348623125\n","[main] 57 [326]b loss=1243.9503 reg_loss=214.4013 diff_loss=995.9419 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.079299 0.139977 0.205810\n","Current precision\t0.176596 0.125957 0.092447\n","Current ndcg\t\t0.194735 0.177491 0.223121\n","Current test recall\t\t0.075064 0.139260 0.204726\n","Current test precision\t0.169577 0.125185 0.091922\n","Current test ndcg\t\t0.188377 0.174750 0.220145\n","best epoch[52]\t vali recall: 0.078792 0.140434 0.207759\n","best epoch[52]\t test recall: 0.075064 0.139260 0.204726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 58 [326]b loss=1243.5828 reg_loss=214.7358 diff_loss=995.2301 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078261 0.141619 0.209289\n","Current precision\t0.175798 0.126702 0.093830\n","Current ndcg\t\t0.191803 0.176629 0.223813\n","Current test recall\t\t0.073814 0.141683 0.207629\n","Current test precision\t0.166402 0.126949 0.093122\n","Current test ndcg\t\t0.185053 0.175427 0.221291\n","best epoch[58]\t vali recall: 0.078261 0.141619 0.209289\n","best epoch[58]\t test recall: 0.073814 0.141683 0.207629\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00021195579137608126\n","[main] 59 [326]b loss=1243.1452 reg_loss=215.0511 diff_loss=994.5609 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078941 0.142001 0.208685\n","Current precision\t0.177128 0.127021 0.093670\n","Current ndcg\t\t0.197222 0.179917 0.226507\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 60 [326]b loss=1242.7536 reg_loss=215.3506 diff_loss=993.9261 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077239 0.139385 0.205459\n","Current precision\t0.170745 0.124681 0.092128\n","Current ndcg\t\t0.191771 0.176831 0.223046\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00019076021223847313\n","[main] 61 [326]b loss=1242.5074 reg_loss=215.6330 diff_loss=993.3288 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077079 0.140725 0.206716\n","Current precision\t0.171809 0.125745 0.092926\n","Current ndcg\t\t0.183713 0.172274 0.218792\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 62 [326]b loss=1242.1825 reg_loss=215.9022 diff_loss=992.7606 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.080739 0.140750 0.206846\n","Current precision\t0.180319 0.126170 0.092872\n","Current ndcg\t\t0.201222 0.180641 0.226892\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:10\u003c00:00,  4.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00017168419101462582\n","[main] 63 [326]b loss=1241.9522 reg_loss=216.1550 diff_loss=992.2267 expert_loss=0.0000 best[0] elapsed [1 min10 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078172 0.140646 0.204332\n","Current precision\t0.174734 0.126170 0.091702\n","Current ndcg\t\t0.194112 0.178495 0.222914\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 64 [326]b loss=1241.5918 reg_loss=216.3950 diff_loss=991.7205 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077073 0.140720 0.206330\n","Current precision\t0.172340 0.126064 0.092553\n","Current ndcg\t\t0.194254 0.178991 0.224724\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00015451577191316325\n","[main] 65 [326]b loss=1241.3345 reg_loss=216.6224 diff_loss=991.2430 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077253 0.141140 0.204169\n","Current precision\t0.171809 0.126170 0.091543\n","Current ndcg\t\t0.189811 0.176759 0.220947\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 66 [326]b loss=1241.0781 reg_loss=216.8381 diff_loss=990.7895 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078366 0.141246 0.208693\n","Current precision\t0.175000 0.126596 0.093564\n","Current ndcg\t\t0.197503 0.180770 0.227735\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00013906419472184693\n","[main] 67 [326]b loss=1240.9054 reg_loss=217.0417 diff_loss=990.3622 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.077089 0.140337 0.206902\n","Current precision\t0.172340 0.125851 0.092766\n","Current ndcg\t\t0.195303 0.179618 0.226016\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 68 [326]b loss=1240.6336 reg_loss=217.2352 diff_loss=989.9563 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.076446 0.141609 0.205969\n","Current precision\t0.171543 0.127128 0.092500\n","Current ndcg\t\t0.194044 0.180492 0.225420\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:12\u003c00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00012515777524966224\n","[main] 69 [326]b loss=1240.4120 reg_loss=217.4178 diff_loss=989.5741 expert_loss=0.0000 best[0] elapsed [1 min12 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078710 0.141928 0.207822\n","Current precision\t0.175266 0.127234 0.093245\n","Current ndcg\t\t0.191640 0.177394 0.223297\n","Current test recall\t\t0.074885 0.141273 0.208187\n","Current test precision\t0.168695 0.126702 0.093369\n","Current test ndcg\t\t0.191195 0.178337 0.224714\n","best epoch[59]\t vali recall: 0.078941 0.142001 0.208685\n","best epoch[59]\t test recall: 0.074885 0.141273 0.208187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:13\u003c00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 70 [326]b loss=1240.2496 reg_loss=217.5918 diff_loss=989.2102 expert_loss=0.0000 best[0] elapsed [1 min13 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.079667 0.142399 0.207933\n","Current precision\t0.177660 0.127340 0.093351\n","Current ndcg\t\t0.198610 0.180993 0.226980\n","Current test recall\t\t0.073581 0.141103 0.207957\n","Current test precision\t0.165961 0.126314 0.093298\n","Current test ndcg\t\t0.190413 0.178640 0.225284\n","best epoch[70]\t vali recall: 0.079667 0.142399 0.207933\n","best epoch[70]\t test recall: 0.073581 0.141103 0.207957\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00011264199772469603\n","[main] 71 [326]b loss=1240.1086 reg_loss=217.7560 diff_loss=988.8676 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078609 0.140737 0.209290\n","Current precision\t0.175266 0.125745 0.093883\n","Current ndcg\t\t0.195292 0.178405 0.226627\n","Current test recall\t\t0.073581 0.141103 0.207957\n","Current test precision\t0.165961 0.126314 0.093298\n","Current test ndcg\t\t0.190413 0.178640 0.225284\n","best epoch[70]\t vali recall: 0.079667 0.142399 0.207933\n","best epoch[70]\t test recall: 0.073581 0.141103 0.207957\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[main] 72 [326]b loss=1239.9243 reg_loss=217.9116 diff_loss=988.5420 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.078231 0.139990 0.208590\n","Current precision\t0.173670 0.125426 0.093777\n","Current ndcg\t\t0.198296 0.180503 0.228604\n","Current test recall\t\t0.073581 0.141103 0.207957\n","Current test precision\t0.165961 0.126314 0.093298\n","Current test ndcg\t\t0.190413 0.178640 0.225284\n","best epoch[70]\t vali recall: 0.079667 0.142399 0.207933\n","best epoch[70]\t test recall: 0.073581 0.141103 0.207957\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 326/326 [01:11\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["decayed lr:0.00010137779795222643\n","[main] 73 [326]b loss=1239.7158 reg_loss=218.0584 diff_loss=988.2354 expert_loss=0.0000 best[0] elapsed [1 min11 s]\n","\t\t\t@20   \t @50   \t @100  \n","Current recall\t\t0.080247 0.139533 0.207066\n","Current precision\t0.178191 0.125426 0.092872\n","Current ndcg\t\t0.200065 0.179836 0.226711\n","Current test recall\t\t0.073581 0.141103 0.207957\n","Current test precision\t0.165961 0.126314 0.093298\n","Current test ndcg\t\t0.190413 0.178640 0.225284\n","best epoch[70]\t vali recall: 0.079667 0.142399 0.207933\n","best epoch[70]\t test recall: 0.073581 0.141103 0.207957\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 196/326 [00:42\u003c00:28,  4.51it/s]"]}],"source":["timer = timer_class(name='main').tic()\n","\n","# prep eval\n","eval_batch_size = eval_batch_size\n","timer.tic()\n","test_eval.init_tf(u_pref, v_pref, user_content, None, eval_batch_size, cold_user=True)  # init data for evaluation\n","vali_eval.init_tf(u_pref, v_pref, user_content, None, eval_batch_size, cold_user=True)  # init data for evaluation\n","timer.toc('initialized eval data').tic()\n","\n","heater = Heater(latent_rank_in=u_pref.shape[1],\n","                        user_content_rank=user_content.shape[1],\n","                        item_content_rank=0,\n","                        model_select=model_select,\n","                        rank_out=rank_out, reg=args.reg, alpha=args.alpha, dim=args.dim)\n","\n","config = tf.ConfigProto(allow_soft_placement=True)\n","\n","heater.build_model()\n","heater.build_predictor(recall_at)\n","\n","with tf.Session(config=config) as sess:\n","    tf.global_variables_initializer().run()\n","    tf.local_variables_initializer().run()\n","    timer.toc('initialized tf')\n","\n","    n_step = 0\n","    best_recall = 0\n","    best_test_recall = 0\n","    best_step = 0\n","    tf.local_variables_initializer().run()\n","    for epoch in range(num_epoch):\n","        user_array, item_array, target_array = negative_sampling(user_list, item_list, neg, item_warm)\n","        random_idx = np.random.permutation(user_array.shape[0])\n","        n_targets = len(random_idx)\n","        data_batch = [(n, min(n + data_batch_size, n_targets)) for n in range(0, n_targets, data_batch_size)]\n","        loss_epoch = 0.\n","        reg_loss_epoch = 0.\n","        diff_loss_epoch = 0.\n","        expert_loss_epoch = 0.\n","        gen = data_batch\n","        gen = tqdm(gen)\n","        for (start, stop) in gen:\n","            n_step += 1\n","\n","            batch_idx = random_idx[start:stop]\n","            batch_users = user_array[batch_idx]\n","            batch_items = item_array[batch_idx]\n","            batch_targets = target_array[batch_idx]\n","\n","            # dropout\n","            if dropout != 0:\n","                n_to_drop = int(np.floor(dropout * len(batch_idx)))  # number of u-i pairs to be dropped\n","                zero_index = np.random.choice(np.arange(len(batch_idx)), n_to_drop, replace=False)\n","            else:\n","                zero_index = np.array([])\n","\n","            user_content_batch = user_content[batch_users, :].todense()\n","            dropout_indicator = np.zeros_like(batch_targets).reshape((-1, 1))\n","            if len(zero_index) \u003e 0:\n","                dropout_indicator[zero_index] = 1\n","\n","            _, _, loss_out, reg_loss_out, diff_loss_out = sess.run(\n","                [heater.preds, heater.optimizer, heater.loss,\n","                    heater.reg_loss, heater.diff_loss],\n","                feed_dict={\n","                    heater.Uin: u_pref[batch_users, :],\n","                    heater.Vin: v_pref[batch_items, :],\n","                    heater.Ucontent: user_content_batch,\n","                    heater.dropout_user_indicator: dropout_indicator,\n","                    heater.target: batch_targets,\n","                    heater.lr_placeholder: _lr,\n","                    heater.is_training: True\n","                }\n","            )\n","            loss_epoch += loss_out\n","            reg_loss_epoch += reg_loss_out\n","            diff_loss_epoch += diff_loss_out\n","            if np.isnan(loss_epoch):\n","                raise Exception('f is nan')\n","\n","        if (epoch + 1) % _decay_lr_every == 0:\n","            _lr = _lr_decay * _lr\n","            print('decayed lr:' + str(_lr))\n","\n","        if epoch % eval_every == 0:\n","            recall, precision, ndcg = batch_eval_recall(sess, heater.eval_preds_cold,\n","                                                                eval_feed_dict=heater.get_eval_dict,\n","                                                                recall_k=recall_at, eval_data=vali_eval)\n","\n","        # checkpoint\n","        if np.sum(recall) \u003e np.sum(best_recall):\n","            best_recall = recall\n","            test_recall, test_precision, test_ndcg = batch_eval_recall(sess, heater.eval_preds_cold,\n","                                                                                eval_feed_dict=heater.get_eval_dict,\n","                                                                                recall_k=recall_at,\n","                                                                                eval_data=test_eval)\n","            best_test_recall = test_recall\n","            best_epoch = epoch\n","\n","        timer.toc('%d [%d]b loss=%.4f reg_loss=%.4f diff_loss=%.4f expert_loss=%.4f best[%d]' % (\n","            epoch, len(data_batch), loss_epoch, reg_loss_epoch, diff_loss_epoch, expert_loss_epoch, best_step\n","        )).tic()\n","        print('\\t\\t\\t' + '\\t '.join([('@' + str(i)).ljust(6) for i in recall_at]))\n","        print('Current recall\\t\\t%s' % (\n","            ' '.join(['%.6f' % i for i in recall]),\n","        ))\n","        print('Current precision\\t%s' % (\n","            ' '.join(['%.6f' % i for i in precision]),\n","        ))\n","        print('Current ndcg\\t\\t%s' % (\n","            ' '.join(['%.6f' % i for i in ndcg]),\n","        ))\n","\n","        print('Current test recall\\t\\t%s' % (\n","            ' '.join(['%.6f' % i for i in test_recall]),\n","        ))\n","        print('Current test precision\\t%s' % (\n","            ' '.join(['%.6f' % i for i in test_precision]),\n","        ))\n","        print('Current test ndcg\\t\\t%s' % (\n","            ' '.join(['%.6f' % i for i in test_ndcg]),\n","        ))\n","\n","        print('best epoch[%d]\\t vali recall: %s' % (\n","            best_epoch,\n","            ' '.join(['%.6f' % i for i in best_recall]),\n","        ))\n","        print('best epoch[%d]\\t test recall: %s' % (\n","            best_epoch,\n","            ' '.join(['%.6f' % i for i in best_test_recall]),\n","        ))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPO/lTwf1wShZii98RrjuJC","collapsed_sections":[],"mount_file_id":"1zyFO6ZQVBEltY0pxBlaqOydi8U2iXVnh","name":"reco-tut-csr-htr-lastfm-02.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}