{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Diginetica Baseline Recommender"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":728,"status":"ok","timestamp":1631276623063,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"aVC5awU1jAzf"},"outputs":[],"source":["import os\n","project_name = \"chef-session\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1631276623065,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"},"user_tz":-330},"id":"8WqnA1xDjAzj","outputId":"abc73563-fa3c-4af1-daf9-27783f9794ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/chef-session\n"]}],"source":["if not os.path.exists(project_path):\n","    !pip install -U -q dvc dvc[gdrive]\n","    !cp -r /content/drive/MyDrive/git_credentials/. ~\n","    path = \"/content/\" + project_name; \n","    !mkdir \"{path}\"\n","    %cd \"{path}\"\n","    !git init\n","    !git remote add origin https://github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout \"{branch}\"\n","else:\n","    %cd \"{project_path}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoaSr0CxjAzk"},"outputs":[],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBsuxRGMjAzl"},"outputs":[],"source":["!git add . && git commit -m 'commit' && git push origin \"{branch}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jo4GmFulkgAJ"},"outputs":[],"source":["# This is sample baseline for CIKM Personalization Cup 2016\n","# by Alexander Laktionov & Vladislav Grozin\n","\n","import numpy as np\n","import pandas as pd\n","import datetime\n","\n","start_time = datetime.datetime.now()\n","print(\"Running baseline. Now it's\", start_time.isoformat())\n","\n","# Loading queries (assuming data placed in <dataset-train/>\n","queries = pd.read_csv('dataset-train/train-queries.csv', sep=';')[['queryId', 'items', 'is.test']]\n","print('Total queries', len(queries))\n","\n","# Leaving only test queries (the ones which items we have to sort)\n","queries = queries[queries['is.test'] == True][['queryId', 'items']]\n","print('Test queries', len(queries))\n","queries.reset_index(inplace=True)\n","queries.drop(['index'], axis=1, inplace=True)\n","\n","# Loading item views; taking itemId column\n","item_views = pd.read_csv('dataset-train/train-item-views.csv', sep=';')[['itemId']]\n","print('Item views', len(item_views))\n","\n","# Loading clicks; taking itemId column\n","clicks = pd.read_csv('dataset-train/train-clicks.csv', sep=';')[['itemId']]\n","print('Clicks', len(clicks))\n","\n","# Loading purchases; taking itemId column\n","purchases = pd.read_csv('dataset-train/train-purchases.csv', sep=';')[['itemId']]\n","print('Purchases', len(purchases))\n","\n","# Calculating popularity as [Amount of views] * 1 + Amount of clicks * 2 + [Amount of purchases] * 3\n","print('Scoring popularity for each item ...')\n","prod_pop = {}\n","for cost, container in enumerate([item_views, clicks, purchases]):\n","    for prod in container.values:\n","        product = str(prod[0])\n","        if product not in prod_pop:\n","            prod_pop[product] = cost\n","        else:\n","            prod_pop[product] += cost\n","\n","print('Popularity scored for', len(prod_pop), 'products')\n","\n","# For each query:\n","#   parse items (comma-separated values in last column)\n","#   sort them by score;\n","#   write them to the submission file.\n","# This is longest part; it usually takes around 5 minutes.\n","print('Sorting items per query by popularity...')\n","\n","answers = []\n","step = int(len(queries) / 20)\n","\n","with open('submission.txt', 'w+') as submission:\n","    for i, q in enumerate(queries.values):\n","\n","        # Fancy progressbar\n","        if i % step == 0:\n","            print(5 * i / step, '%...')\n","\n","        # Splitting last column which contains comma-separated items\n","        items = q[-1].split(',')\n","        # Getting scores for each item. Also, inverting scores here, so we can use argsort\n","        items_scores = list(map(lambda x: -prod_pop.get(x, 0), items))\n","        # Sorting items using items_scores order permutation\n","        sorted_items = np.array(items)[np.array(items_scores).argsort()]\n","        # Squashing items together\n","        s = ','.join(sorted_items)\n","        # and writing them to submission\n","        submission.write(str(q[0]) + \" \" + s + \"\\n\")\n","\n","end_time = datetime.datetime.now()\n","print(\"Done. Now it's \", end_time.isoformat())\n","print(\"Calculated baseline in \", (end_time - start_time).seconds, \" seconds\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPOk42FZskiJIA2LyA6Z3EV","collapsed_sections":[],"mount_file_id":"11henBPiTkmil5zHQAaazl-G-5WrNacJB","name":"chef-session-diginetica-baseline.ipynb","provenance":[{"file_id":"1noqvdndIt6Y6hwWizVg3PlYbOVul_jSw","timestamp":1628490733710}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
