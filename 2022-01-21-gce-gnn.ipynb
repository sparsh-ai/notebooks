{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-21-gce-gnn.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T119461%20%7C%20GCE-GNN%20Session%20Recommender%20on%20NowPlaying%20in%20PyTorch.ipynb","timestamp":1644659660312},{"file_id":"1bsP-aKssmTjr6phN9HhWndos_D5Q4fSn","timestamp":1638279525260},{"file_id":"1kYYqeGM3a_dFbqgXkiBmssXFrPXh_HDa","timestamp":1638277542449}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e26c6c12f93840bc886812d4cb1a99af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06f85218263c43469527fc00d49e6843","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c436fe4c4d04ae79fe616adba623638","IPY_MODEL_a61b1a6def6c43f2b1febc0dc127cb31","IPY_MODEL_914607e9897a44ab808ee9e8f5017d36"]}},"06f85218263c43469527fc00d49e6843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c436fe4c4d04ae79fe616adba623638":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c002ce1ada9d49bbba0ff6c80ead0c53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_624dfb1fd79c439f87f3f1323e250d18"}},"a61b1a6def6c43f2b1febc0dc127cb31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9f1505b46a224d90a95538492faa6f79","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":7428,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7428,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee1ae38a2a6342f08b5f60f0e4b5e734"}},"914607e9897a44ab808ee9e8f5017d36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2dce44bdd2f74c46a1f4ab5f35863f72","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7428/7428 [09:25&lt;00:00, 14.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a110f09c87b490292f67df2f4949df2"}},"c002ce1ada9d49bbba0ff6c80ead0c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"624dfb1fd79c439f87f3f1323e250d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f1505b46a224d90a95538492faa6f79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee1ae38a2a6342f08b5f60f0e4b5e734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2dce44bdd2f74c46a1f4ab5f35863f72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a110f09c87b490292f67df2f4949df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0561f6f1d60e4cc39674f3f6d7df9fb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ee075b8912c447bae2d65ea8feabbf9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_670559f3fc9c4c0b93d9ad8ed498e503","IPY_MODEL_7a8b2970f29844f994f1bea946f6282a","IPY_MODEL_9234f7fc0bb14c208325130847e2fedd"]}},"5ee075b8912c447bae2d65ea8feabbf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"670559f3fc9c4c0b93d9ad8ed498e503":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ce61317d8aa47099408390ed3a1dd43","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_178ae75750614b4899adbfbe48491288"}},"7a8b2970f29844f994f1bea946f6282a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79ed5b5c1f034223838be07691f91db3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":7428,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7428,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_764a8e1c1019416eadabcd1fcda32db7"}},"9234f7fc0bb14c208325130847e2fedd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b12fa09ce5b54ad8a967ffd7114f7d1a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7428/7428 [09:26&lt;00:00, 14.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ef8a196c2d04344a4659cdc891c11c7"}},"0ce61317d8aa47099408390ed3a1dd43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"178ae75750614b4899adbfbe48491288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79ed5b5c1f034223838be07691f91db3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"764a8e1c1019416eadabcd1fcda32db7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b12fa09ce5b54ad8a967ffd7114f7d1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ef8a196c2d04344a4659cdc891c11c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"dY--55OUYQ-7"},"source":["# GCE-GNN Session Recommender on NowPlaying in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"vhEnZ48N2FPy"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"sn50Ffkb2Esp"},"source":["import numpy as np\n","import datetime\n","import math\n","from tqdm.notebook import tqdm\n","import pickle\n","import time\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torch import nn\n","from torch.nn import Module, Parameter\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p26c4bNm3LOt"},"source":["class Args:\n","    def __init__(self, dataset = 'diginetica'):\n","        self.dataset = dataset\n","        self.sample_num = 12\n","        if dataset == 'diginetica':\n","            self.num = 43098\n","            self.n_iter = 2\n","            self.dropout_gcn = 0.2 # Dropout rate\n","            self.dropout_local = 0.0 # Dropout rate\n","        elif dataset == 'tmall':\n","            self.num = 40728\n","            self.n_iter = 1\n","            self.dropout_gcn = 0.6\n","            self.dropout_local = 0.5\n","        elif dataset == 'nowplaying':\n","            self.num = 60417\n","            self.n_iter = 1\n","            self.dropout_gcn = 0.0\n","            self.dropout_local = 0.0\n","        self.hiddenSize = 100\n","        self.epoch = 2\n","        self.activate = 'relu'\n","        self.n_sample_all = 12\n","        self.n_sample = 12\n","        self.batch_size = 100\n","        self.lr = 0.001 # learning rate\n","        self.lr_dc = 0.1 # learning rate decay\n","        self.lr_dc_step = 3 # the number of steps after which the learning rate decay\n","        self.l2 = 1e-5 # l2 penalty\n","        self.dropout_global = 0.5 # Dropout rate\n","        self.validation = True\n","        self.valid_portion = 0.1 # split the portion\n","        self.alpha = 0.2 # Alpha for the leaky_relu.\n","        self.patience = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE9xMI9u3Q9D"},"source":["opt = Args(dataset = 'nowplaying')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hy3oGaMP2H8G"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hT2umfIz4gOQ","executionInfo":{"status":"ok","timestamp":1638277603910,"user_tz":-330,"elapsed":6994,"user":{"displayName":"sparsh agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00322518567794762549"}},"outputId":"8e516d15-959d-449e-8789-964ee5f2e342"},"source":["!wget -q --show-progress https://github.com/RecoHut-Datasets/nowplaying/raw/v1/all_train_seq.txt\n","!wget -q --show-progress https://github.com/RecoHut-Datasets/nowplaying/raw/v1/train.txt\n","!wget -q --show-progress https://github.com/RecoHut-Datasets/nowplaying/raw/v1/test.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["all_train_seq.txt   100%[===================>]   3.69M  --.-KB/s    in 0.08s   \n","train.txt           100%[===================>]  21.52M   107MB/s    in 0.2s    \n","test.txt            100%[===================>]   2.35M  --.-KB/s    in 0.08s   \n"]}]},{"cell_type":"markdown","metadata":{"id":"t8YR0Rts3AKg"},"source":["### Build Graph"]},{"cell_type":"code","metadata":{"id":"BClobEbS3AD3"},"source":["dataset = opt.dataset\n","sample_num = opt.sample_num\n","num = opt.num\n","\n","seq = pickle.load(open('all_train_seq.txt', 'rb'))\n","\n","relation = []\n","neighbor = [] * num\n","\n","all_test = set()\n","\n","adj1 = [dict() for _ in range(num)]\n","adj = [[] for _ in range(num)]\n","\n","for i in range(len(seq)):\n","    data = seq[i]\n","    for k in range(1, 4):\n","        for j in range(len(data)-k):\n","            relation.append([data[j], data[j+k]])\n","            relation.append([data[j+k], data[j]])\n","\n","for tup in relation:\n","    if tup[1] in adj1[tup[0]].keys():\n","        adj1[tup[0]][tup[1]] += 1\n","    else:\n","        adj1[tup[0]][tup[1]] = 1\n","\n","weight = [[] for _ in range(num)]\n","\n","for t in range(num):\n","    x = [v for v in sorted(adj1[t].items(), reverse=True, key=lambda x: x[1])]\n","    adj[t] = [v[0] for v in x]\n","    weight[t] = [v[1] for v in x]\n","\n","for i in range(num):\n","    adj[i] = adj[i][:sample_num]\n","    weight[i] = weight[i][:sample_num]\n","\n","pickle.dump(adj, open('adj_' + str(sample_num) + '.pkl', 'wb'))\n","pickle.dump(weight, open('num_' + str(sample_num) + '.pkl', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkFzOJHT5Pof"},"source":["def init_seed(seed=None):\n","    if seed is None:\n","        seed = int(time.time() * 1000 // 1000)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2AvOltD2LXN"},"source":["def split_validation(train_set, valid_portion):\n","    train_set_x, train_set_y = train_set\n","    n_samples = len(train_set_x)\n","    sidx = np.arange(n_samples, dtype='int32')\n","    np.random.shuffle(sidx)\n","    n_train = int(np.round(n_samples * (1. - valid_portion)))\n","    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n","    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n","    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n","    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n","    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTbsyqEV2PCt"},"source":["def handle_data(inputData, train_len=None):\n","    len_data = [len(nowData) for nowData in inputData]\n","    if train_len is None:\n","        max_len = max(len_data)\n","    else:\n","        max_len = train_len\n","    # reverse the sequence\n","    us_pois = [list(reversed(upois)) + [0] * (max_len - le) if le < max_len else list(reversed(upois[-max_len:]))\n","               for upois, le in zip(inputData, len_data)]\n","    us_msks = [[1] * le + [0] * (max_len - le) if le < max_len else [1] * max_len\n","               for le in len_data]\n","    return us_pois, us_msks, max_len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbL8mMda2Qhp"},"source":["def handle_adj(adj_dict, n_entity, sample_num, num_dict=None):\n","    adj_entity = np.zeros([n_entity, sample_num], dtype=np.int64)\n","    num_entity = np.zeros([n_entity, sample_num], dtype=np.int64)\n","    for entity in range(1, n_entity):\n","        neighbor = list(adj_dict[entity])\n","        neighbor_weight = list(num_dict[entity])\n","        n_neighbor = len(neighbor)\n","        if n_neighbor == 0:\n","            continue\n","        if n_neighbor >= sample_num:\n","            sampled_indices = np.random.choice(list(range(n_neighbor)), size=sample_num, replace=False)\n","        else:\n","            sampled_indices = np.random.choice(list(range(n_neighbor)), size=sample_num, replace=True)\n","        adj_entity[entity] = np.array([neighbor[i] for i in sampled_indices])\n","        num_entity[entity] = np.array([neighbor_weight[i] for i in sampled_indices])\n","    return adj_entity, num_entity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWYw5eoo2USj"},"source":["class Data(Dataset):\n","    def __init__(self, data, train_len=None):\n","        inputs, mask, max_len = handle_data(data[0], train_len)\n","        self.inputs = np.asarray(inputs)\n","        self.targets = np.asarray(data[1])\n","        self.mask = np.asarray(mask)\n","        self.length = len(data[0])\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        u_input, mask, target = self.inputs[index], self.mask[index], self.targets[index]\n","        max_n_node = self.max_len\n","        node = np.unique(u_input)\n","        items = node.tolist() + (max_n_node - len(node)) * [0]\n","        adj = np.zeros((max_n_node, max_n_node))\n","        for i in np.arange(len(u_input) - 1):\n","            u = np.where(node == u_input[i])[0][0]\n","            adj[u][u] = 1\n","            if u_input[i + 1] == 0:\n","                break\n","            v = np.where(node == u_input[i + 1])[0][0]\n","            if u == v or adj[u][v] == 4:\n","                continue\n","            adj[v][v] = 1\n","            if adj[v][u] == 2:\n","                adj[u][v] = 4\n","                adj[v][u] = 4\n","            else:\n","                adj[u][v] = 2\n","                adj[v][u] = 3\n","        alias_inputs = [np.where(node == i)[0][0] for i in u_input]\n","        \n","        return [torch.tensor(alias_inputs), torch.tensor(adj), torch.tensor(items),\n","                torch.tensor(mask), torch.tensor(target), torch.tensor(u_input)]\n","\n","    def __len__(self):\n","        return self.length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iig4FRMX4t2e"},"source":["## Aggregator"]},{"cell_type":"code","metadata":{"id":"c-GdN3UO4ty1"},"source":["class Aggregator(nn.Module):\n","    def __init__(self, batch_size, dim, dropout, act, name=None):\n","        super(Aggregator, self).__init__()\n","        self.dropout = dropout\n","        self.act = act\n","        self.batch_size = batch_size\n","        self.dim = dim\n","\n","    def forward(self):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ZzMV7ov42_o"},"source":["class LocalAggregator(nn.Module):\n","    def __init__(self, dim, alpha, dropout=0., name=None):\n","        super(LocalAggregator, self).__init__()\n","        self.dim = dim\n","        self.dropout = dropout\n","\n","        self.a_0 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_1 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.a_3 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.bias = nn.Parameter(torch.Tensor(self.dim))\n","\n","        self.leakyrelu = nn.LeakyReLU(alpha)\n","\n","    def forward(self, hidden, adj, mask_item=None):\n","        h = hidden\n","        batch_size = h.shape[0]\n","        N = h.shape[1]\n","\n","        a_input = (h.repeat(1, 1, N).view(batch_size, N * N, self.dim)\n","                   * h.repeat(1, N, 1)).view(batch_size, N, N, self.dim)\n","\n","        e_0 = torch.matmul(a_input, self.a_0)\n","        e_1 = torch.matmul(a_input, self.a_1)\n","        e_2 = torch.matmul(a_input, self.a_2)\n","        e_3 = torch.matmul(a_input, self.a_3)\n","\n","        e_0 = self.leakyrelu(e_0).squeeze(-1).view(batch_size, N, N)\n","        e_1 = self.leakyrelu(e_1).squeeze(-1).view(batch_size, N, N)\n","        e_2 = self.leakyrelu(e_2).squeeze(-1).view(batch_size, N, N)\n","        e_3 = self.leakyrelu(e_3).squeeze(-1).view(batch_size, N, N)\n","\n","        mask = -9e15 * torch.ones_like(e_0)\n","        alpha = torch.where(adj.eq(1), e_0, mask)\n","        alpha = torch.where(adj.eq(2), e_1, alpha)\n","        alpha = torch.where(adj.eq(3), e_2, alpha)\n","        alpha = torch.where(adj.eq(4), e_3, alpha)\n","        alpha = torch.softmax(alpha, dim=-1)\n","\n","        output = torch.matmul(alpha, h)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dLm1v7Y46Vm"},"source":["class GlobalAggregator(nn.Module):\n","    def __init__(self, dim, dropout, act=torch.relu, name=None):\n","        super(GlobalAggregator, self).__init__()\n","        self.dropout = dropout\n","        self.act = act\n","        self.dim = dim\n","\n","        self.w_1 = nn.Parameter(torch.Tensor(self.dim + 1, self.dim))\n","        self.w_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.w_3 = nn.Parameter(torch.Tensor(2 * self.dim, self.dim))\n","        self.bias = nn.Parameter(torch.Tensor(self.dim))\n","\n","    def forward(self, self_vectors, neighbor_vector, batch_size, masks, neighbor_weight, extra_vector=None):\n","        if extra_vector is not None:\n","            alpha = torch.matmul(torch.cat([extra_vector.unsqueeze(2).repeat(1, 1, neighbor_vector.shape[2], 1)*neighbor_vector, neighbor_weight.unsqueeze(-1)], -1), self.w_1).squeeze(-1)\n","            alpha = F.leaky_relu(alpha, negative_slope=0.2)\n","            alpha = torch.matmul(alpha, self.w_2).squeeze(-1)\n","            alpha = torch.softmax(alpha, -1).unsqueeze(-1)\n","            neighbor_vector = torch.sum(alpha * neighbor_vector, dim=-2)\n","        else:\n","            neighbor_vector = torch.mean(neighbor_vector, dim=2)\n","        # self_vectors = F.dropout(self_vectors, 0.5, training=self.training)\n","        output = torch.cat([self_vectors, neighbor_vector], -1)\n","        output = F.dropout(output, self.dropout, training=self.training)\n","        output = torch.matmul(output, self.w_3)\n","        output = output.view(batch_size, -1, self.dim)\n","        output = self.act(output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xAkDD17B2aV5"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"0xKI49N-23aa"},"source":["class CombineGraph(Module):\n","    def __init__(self, opt, num_node, adj_all, num):\n","        super(CombineGraph, self).__init__()\n","        self.opt = opt\n","\n","        self.batch_size = opt.batch_size\n","        self.num_node = num_node\n","        self.dim = opt.hiddenSize\n","        self.dropout_local = opt.dropout_local\n","        self.dropout_global = opt.dropout_global\n","        self.hop = opt.n_iter\n","        self.sample_num = opt.n_sample\n","        self.adj_all = trans_to_cuda(torch.Tensor(adj_all)).long()\n","        self.num = trans_to_cuda(torch.Tensor(num)).float()\n","\n","        # Aggregator\n","        self.local_agg = LocalAggregator(self.dim, self.opt.alpha, dropout=0.0)\n","        self.global_agg = []\n","        for i in range(self.hop):\n","            if opt.activate == 'relu':\n","                agg = GlobalAggregator(self.dim, opt.dropout_gcn, act=torch.relu)\n","            else:\n","                agg = GlobalAggregator(self.dim, opt.dropout_gcn, act=torch.tanh)\n","            self.add_module('agg_gcn_{}'.format(i), agg)\n","            self.global_agg.append(agg)\n","\n","        # Item representation & Position representation\n","        self.embedding = nn.Embedding(num_node, self.dim)\n","        self.pos_embedding = nn.Embedding(200, self.dim)\n","\n","        # Parameters\n","        self.w_1 = nn.Parameter(torch.Tensor(2 * self.dim, self.dim))\n","        self.w_2 = nn.Parameter(torch.Tensor(self.dim, 1))\n","        self.glu1 = nn.Linear(self.dim, self.dim)\n","        self.glu2 = nn.Linear(self.dim, self.dim, bias=False)\n","        self.linear_transform = nn.Linear(self.dim, self.dim, bias=False)\n","\n","        self.leakyrelu = nn.LeakyReLU(opt.alpha)\n","        self.loss_function = nn.CrossEntropyLoss()\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr, weight_decay=opt.l2)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt.lr_dc_step, gamma=opt.lr_dc)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1.0 / math.sqrt(self.dim)\n","        for weight in self.parameters():\n","            weight.data.uniform_(-stdv, stdv)\n","\n","    def sample(self, target, n_sample):\n","        # neighbor = self.adj_all[target.view(-1)]\n","        # index = np.arange(neighbor.shape[1])\n","        # np.random.shuffle(index)\n","        # index = index[:n_sample]\n","        # return self.adj_all[target.view(-1)][:, index], self.num[target.view(-1)][:, index]\n","        return self.adj_all[target.view(-1)], self.num[target.view(-1)]\n","\n","    def compute_scores(self, hidden, mask):\n","        mask = mask.float().unsqueeze(-1)\n","\n","        batch_size = hidden.shape[0]\n","        len = hidden.shape[1]\n","        pos_emb = self.pos_embedding.weight[:len]\n","        pos_emb = pos_emb.unsqueeze(0).repeat(batch_size, 1, 1)\n","\n","        hs = torch.sum(hidden * mask, -2) / torch.sum(mask, 1)\n","        hs = hs.unsqueeze(-2).repeat(1, len, 1)\n","        nh = torch.matmul(torch.cat([pos_emb, hidden], -1), self.w_1)\n","        nh = torch.tanh(nh)\n","        nh = torch.sigmoid(self.glu1(nh) + self.glu2(hs))\n","        beta = torch.matmul(nh, self.w_2)\n","        beta = beta * mask\n","        select = torch.sum(beta * hidden, 1)\n","\n","        b = self.embedding.weight[1:]  # n_nodes x latent_size\n","        scores = torch.matmul(select, b.transpose(1, 0))\n","        return scores\n","\n","    def forward(self, inputs, adj, mask_item, item):\n","        batch_size = inputs.shape[0]\n","        seqs_len = inputs.shape[1]\n","        h = self.embedding(inputs)\n","\n","        # local\n","        h_local = self.local_agg(h, adj, mask_item)\n","\n","        # global\n","        item_neighbors = [inputs]\n","        weight_neighbors = []\n","        support_size = seqs_len\n","\n","        for i in range(1, self.hop + 1):\n","            item_sample_i, weight_sample_i = self.sample(item_neighbors[-1], self.sample_num)\n","            support_size *= self.sample_num\n","            item_neighbors.append(item_sample_i.view(batch_size, support_size))\n","            weight_neighbors.append(weight_sample_i.view(batch_size, support_size))\n","\n","        entity_vectors = [self.embedding(i) for i in item_neighbors]\n","        weight_vectors = weight_neighbors\n","\n","        session_info = []\n","        item_emb = self.embedding(item) * mask_item.float().unsqueeze(-1)\n","        \n","        # mean \n","        sum_item_emb = torch.sum(item_emb, 1) / torch.sum(mask_item.float(), -1).unsqueeze(-1)\n","        \n","        # sum\n","        # sum_item_emb = torch.sum(item_emb, 1)\n","        \n","        sum_item_emb = sum_item_emb.unsqueeze(-2)\n","        for i in range(self.hop):\n","            session_info.append(sum_item_emb.repeat(1, entity_vectors[i].shape[1], 1))\n","\n","        for n_hop in range(self.hop):\n","            entity_vectors_next_iter = []\n","            shape = [batch_size, -1, self.sample_num, self.dim]\n","            for hop in range(self.hop - n_hop):\n","                aggregator = self.global_agg[n_hop]\n","                vector = aggregator(self_vectors=entity_vectors[hop],\n","                                    neighbor_vector=entity_vectors[hop+1].view(shape),\n","                                    masks=None,\n","                                    batch_size=batch_size,\n","                                    neighbor_weight=weight_vectors[hop].view(batch_size, -1, self.sample_num),\n","                                    extra_vector=session_info[hop])\n","                entity_vectors_next_iter.append(vector)\n","            entity_vectors = entity_vectors_next_iter\n","\n","        h_global = entity_vectors[0].view(batch_size, seqs_len, self.dim)\n","\n","        # combine\n","        h_local = F.dropout(h_local, self.dropout_local, training=self.training)\n","        h_global = F.dropout(h_global, self.dropout_global, training=self.training)\n","        output = h_local + h_global\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RVP050T27xr"},"source":["def trans_to_cuda(variable):\n","    if torch.cuda.is_available():\n","        return variable.cuda()\n","    else:\n","        return variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuXi-8D626u3"},"source":["def trans_to_cpu(variable):\n","    if torch.cuda.is_available():\n","        return variable.cpu()\n","    else:\n","        return variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5E53SVJQ25xm"},"source":["def forward(model, data):\n","    alias_inputs, adj, items, mask, targets, inputs = data\n","    alias_inputs = trans_to_cuda(alias_inputs).long()\n","    items = trans_to_cuda(items).long()\n","    adj = trans_to_cuda(adj).float()\n","    mask = trans_to_cuda(mask).long()\n","    inputs = trans_to_cuda(inputs).long()\n","\n","    hidden = model(items, adj, mask, inputs)\n","    get = lambda index: hidden[index][alias_inputs[index]]\n","    seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n","    return targets, model.compute_scores(seq_hidden, mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tajDb_Wy24pf"},"source":["def train_test(model, train_data, test_data):\n","    print('start training: ', datetime.datetime.now())\n","    model.train()\n","    total_loss = 0.0\n","    train_loader = torch.utils.data.DataLoader(train_data, num_workers=2, batch_size=model.batch_size,\n","                                               shuffle=True, pin_memory=True)\n","    for data in tqdm(train_loader):\n","        model.optimizer.zero_grad()\n","        targets, scores = forward(model, data)\n","        targets = trans_to_cuda(targets).long()\n","        loss = model.loss_function(scores, targets - 1)\n","        loss.backward()\n","        model.optimizer.step()\n","        total_loss += loss\n","    print('\\tLoss:\\t%.3f' % total_loss)\n","    model.scheduler.step()\n","\n","    print('start predicting: ', datetime.datetime.now())\n","    model.eval()\n","    test_loader = torch.utils.data.DataLoader(test_data, num_workers=2, batch_size=model.batch_size,\n","                                              shuffle=False, pin_memory=True)\n","    result = []\n","    hit, mrr = [], []\n","    for data in test_loader:\n","        targets, scores = forward(model, data)\n","        sub_scores = scores.topk(20)[1]\n","        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n","        targets = targets.numpy()\n","        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n","            hit.append(np.isin(target - 1, score))\n","            if len(np.where(score == target - 1)[0]) == 0:\n","                mrr.append(0)\n","            else:\n","                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n","\n","    result.append(np.mean(hit) * 100)\n","    result.append(np.mean(mrr) * 100)\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H9RRpEwj23XD"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"4hIJPbsv23Uc"},"source":["init_seed(2020)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQADBzqW66dD"},"source":["train_data = pickle.load(open('train.txt', 'rb'))\n","if opt.validation:\n","    train_data, valid_data = split_validation(train_data, opt.valid_portion)\n","    test_data = valid_data\n","else:\n","    test_data = pickle.load(open('test.txt', 'rb'))\n","\n","adj = pickle.load(open('adj_' + str(opt.n_sample_all) + '.pkl', 'rb'))\n","num = pickle.load(open('num_' + str(opt.n_sample_all) + '.pkl', 'rb'))\n","\n","train_data = Data(train_data)\n","test_data = Data(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446,"referenced_widgets":["e26c6c12f93840bc886812d4cb1a99af","06f85218263c43469527fc00d49e6843","1c436fe4c4d04ae79fe616adba623638","a61b1a6def6c43f2b1febc0dc127cb31","914607e9897a44ab808ee9e8f5017d36","c002ce1ada9d49bbba0ff6c80ead0c53","624dfb1fd79c439f87f3f1323e250d18","9f1505b46a224d90a95538492faa6f79","ee1ae38a2a6342f08b5f60f0e4b5e734","2dce44bdd2f74c46a1f4ab5f35863f72","8a110f09c87b490292f67df2f4949df2","0561f6f1d60e4cc39674f3f6d7df9fb5","5ee075b8912c447bae2d65ea8feabbf9","670559f3fc9c4c0b93d9ad8ed498e503","7a8b2970f29844f994f1bea946f6282a","9234f7fc0bb14c208325130847e2fedd","0ce61317d8aa47099408390ed3a1dd43","178ae75750614b4899adbfbe48491288","79ed5b5c1f034223838be07691f91db3","764a8e1c1019416eadabcd1fcda32db7","b12fa09ce5b54ad8a967ffd7114f7d1a","0ef8a196c2d04344a4659cdc891c11c7"]},"id":"HveobxF67avY","executionInfo":{"status":"ok","timestamp":1638278874762,"user_tz":-330,"elapsed":1221246,"user":{"displayName":"sparsh agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00322518567794762549"}},"outputId":"e6c1da35-cd58-4341-b326-c0a0229b0d59"},"source":["adj, num = handle_adj(adj, opt.num, opt.n_sample_all, num)\n","model = trans_to_cuda(CombineGraph(opt, opt.num, adj, num))\n","\n","print(opt)\n","\n","start = time.time()\n","best_result = [0, 0]\n","best_epoch = [0, 0]\n","bad_counter = 0\n","\n","for epoch in range(opt.epoch):\n","    print('-------------------------------------------------------')\n","    print('epoch: ', epoch)\n","    hit, mrr = train_test(model, train_data, test_data)\n","    flag = 0\n","    if hit >= best_result[0]:\n","        best_result[0] = hit\n","        best_epoch[0] = epoch\n","        flag = 1\n","    if mrr >= best_result[1]:\n","        best_result[1] = mrr\n","        best_epoch[1] = epoch\n","        flag = 1\n","    print('Current Result:')\n","    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f' % (hit, mrr))\n","    print('Best Result:')\n","    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d,\\t%d' % (\n","        best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n","    bad_counter += 1 - flag\n","    if bad_counter >= opt.patience:\n","        break\n","print('-------------------------------------------------------')\n","end = time.time()\n","print(\"Run time: %f s\" % (end - start))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Args object at 0x7fdddc5f4e10>\n","-------------------------------------------------------\n","epoch:  0\n","start training:  2021-11-30 13:07:46.488445\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e26c6c12f93840bc886812d4cb1a99af","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/7428 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\tLoss:\t60035.262\n","start predicting:  2021-11-30 13:17:11.760036\n","Current Result:\n","\tRecall@20:\t31.5582\tMMR@20:\t10.7643\n","Best Result:\n","\tRecall@20:\t31.5582\tMMR@20:\t10.7643\tEpoch:\t0,\t0\n","-------------------------------------------------------\n","epoch:  1\n","start training:  2021-11-30 13:17:50.700701\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0561f6f1d60e4cc39674f3f6d7df9fb5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/7428 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\tLoss:\t50942.418\n","start predicting:  2021-11-30 13:27:17.205622\n","Current Result:\n","\tRecall@20:\t34.1173\tMMR@20:\t11.6879\n","Best Result:\n","\tRecall@20:\t34.1173\tMMR@20:\t11.6879\tEpoch:\t1,\t1\n","-------------------------------------------------------\n","Run time: 1209.316648 s\n"]}]},{"cell_type":"markdown","metadata":{"id":"CbbpODHA8dr8"},"source":["---"]},{"cell_type":"code","metadata":{"id":"SsNqDkWE8dr_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638279047169,"user_tz":-330,"elapsed":6514,"user":{"displayName":"sparsh agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00322518567794762549"}},"outputId":"c0938d6f-af93-4193-8a90-bfacdd1afa4f"},"source":["!apt-get -qq install tree\n","!rm -r sample_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Selecting previously unselected package tree.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n","Unpacking tree (1.7.0-5) ...\n","Setting up tree (1.7.0-5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","metadata":{"id":"luP0BjVC8dr_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638279048053,"user_tz":-330,"elapsed":893,"user":{"displayName":"sparsh agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00322518567794762549"}},"outputId":"c50fcaa9-9405-4142-819e-58abaf37cf55"},"source":["!tree -h --du ."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".\n","├── [2.4M]  adj_12.pkl\n","├── [3.7M]  all_train_seq.txt\n","├── [1.8M]  num_12.pkl\n","├── [2.3M]  test.txt\n","└── [ 22M]  train.txt\n","\n","  32M used in 0 directories, 5 files\n"]}]},{"cell_type":"code","metadata":{"id":"_S3rQXBz8dsA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638279493625,"user_tz":-330,"elapsed":3497,"user":{"displayName":"sparsh agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00322518567794762549"}},"outputId":"7fc388ce-7737-44d2-bb99-965e782021ab"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2021-11-30 13:38:14\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","IPython: 5.5.0\n","torch  : 1.10.0+cu111\n","numpy  : 1.19.5\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"I0TYBU4w8dsB"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"SYzSMRCX8dsC"},"source":["**END**"]}]}