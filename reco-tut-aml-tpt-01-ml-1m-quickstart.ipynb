{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reco-tut-aml-tpt-01-ml-1m-quickstart.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Rld4fxcETCiOnHrzlcBWt1mZn8pDuJdF","authorship_tag":"ABX9TyPz635Zo3GwIcrA/v5CrgTS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e368a6b6897f44eab08ebdf82ca033b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ec270f418e24abeba033ca52d9200dd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9be43b61843949008b663a1376526b9f","IPY_MODEL_edb6ffabccd445f6b6cae6ef7569c778","IPY_MODEL_1d7077e691644795a0633f5764741cbf"]}},"6ec270f418e24abeba033ca52d9200dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9be43b61843949008b663a1376526b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a3dc72e38b474406bf22452a76cfff59","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Optimization Progress: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4df27d9bd9f04e0baa8c3dcdf72ddad3"}},"edb6ffabccd445f6b6cae6ef7569c778":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_61d5eab7e93947ae8740b3ca6d7c65a2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":30,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":30,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_811ae8843fd645778c2d4018bf034e03"}},"1d7077e691644795a0633f5764741cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb06e3c690af4160b6b90c02f51717e7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 30/30 [02:47&lt;00:00,  2.03s/pipeline]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76d4d86ce8fd4baf931c58bf0521d329"}},"a3dc72e38b474406bf22452a76cfff59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4df27d9bd9f04e0baa8c3dcdf72ddad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61d5eab7e93947ae8740b3ca6d7c65a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"811ae8843fd645778c2d4018bf034e03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb06e3c690af4160b6b90c02f51717e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"76d4d86ce8fd4baf931c58bf0521d329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47592c68e0c4436e8905a0bf1ded673e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de9c2792569748658ed1e10c854d7067","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e00526f957054e959ad4f0b574b4314e","IPY_MODEL_d4f44f7e93d34b72969d5d036c77bedf","IPY_MODEL_6bfdfcaf8a074ab8ad265111eadd51ea"]}},"de9c2792569748658ed1e10c854d7067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e00526f957054e959ad4f0b574b4314e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fcf6ee7ba257479c870e780152e6479b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Optimization Progress: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_665edf9f2227408298aa86f74b282c1a"}},"d4f44f7e93d34b72969d5d036c77bedf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91c96a6ec9ca4b4698f397dc89e737c6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":30,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":30,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53fbeebd64734f93a21e97f0ae43117f"}},"6bfdfcaf8a074ab8ad265111eadd51ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a426d81aedd54802a68be27b20698689","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 34/? [41:11&lt;00:00, 53.20s/pipeline]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b9fa9ff2ec44622bc004172a0c41d1a"}},"fcf6ee7ba257479c870e780152e6479b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"665edf9f2227408298aa86f74b282c1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91c96a6ec9ca4b4698f397dc89e737c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53fbeebd64734f93a21e97f0ae43117f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a426d81aedd54802a68be27b20698689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b9fa9ff2ec44622bc004172a0c41d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"y9BH6x2NfQyG","executionInfo":{"status":"ok","timestamp":1629795076255,"user_tz":-330,"elapsed":1388,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import os\n","project_name = \"reco-tut-aml\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', project_name)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDk0gUSSfatt"},"source":["if not os.path.exists(project_path):\n","    !cp /content/drive/MyDrive/mykeys.py /content\n","    import mykeys\n","    !rm /content/mykeys.py\n","    path = \"/content/\" + project_name; \n","    !mkdir \"{path}\"\n","    %cd \"{path}\"\n","    import sys; sys.path.append(path)\n","    !git config --global user.email \"recotut@recohut.com\"\n","    !git config --global user.name  \"reco-tut\"\n","    !git init\n","    !git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout main\n","else:\n","    %cd \"{project_path}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q71TF7O6fatx"},"source":["!git status"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6x2rPTifaty"},"source":["!git add . && git commit -m 'commit' && git push origin \"{branch}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"nD65sfIhW5GY","executionInfo":{"status":"ok","timestamp":1629795160657,"user_tz":-330,"elapsed":61090,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"f4b6b894-a441-40d4-b21c-b9c22aded01b"},"source":["!pip install -U -q dvc dvc[gdrive]\n","!dvc pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 644 kB 7.5 MB/s \n","\u001b[K     |████████████████████████████████| 170 kB 57.5 MB/s \n","\u001b[K     |████████████████████████████████| 209 kB 68.3 MB/s \n","\u001b[K     |████████████████████████████████| 530 kB 67.1 MB/s \n","\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n","\u001b[K     |████████████████████████████████| 40 kB 15 kB/s \n","\u001b[K     |████████████████████████████████| 44 kB 2.5 MB/s \n","\u001b[K     |████████████████████████████████| 296 kB 64.2 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 40.5 MB/s \n","\u001b[K     |████████████████████████████████| 4.6 MB 66.7 MB/s \n","\u001b[K     |████████████████████████████████| 108 kB 68.3 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 2.6 MB 46.5 MB/s \n","\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n","\u001b[K     |████████████████████████████████| 201 kB 67.7 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 546 kB 69.4 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n","\u001b[K     |████████████████████████████████| 3.2 MB 47.3 MB/s \n","\u001b[?25h  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for dpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flufl.lock (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for atpublic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for mailchecker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Querying remote cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]Go to the following link in your browser:\n","\n","    https://accounts.google.com/o/oauth2/auth?client_id=710796635688-iivsgbgsb6uv1fap6635dhvuei09o66c.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n","\n","Enter verification code: 4/1AX4XfWgVu6SqT_b2GCxkpxBVBZYI_Sx3ZGzQ4FPrTntG2vKPEpzZF5cYmAY\n","Authentication successful.\n","Transferring:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n","!\u001b[A\n","  0%|          |faaa5d8f939c81f518db52ae270ec3.dir 0.00/? [00:00<?,        ?B/s]\u001b[A\n","faaa5d8f939c81f518db52ae270ec3.dir:   0% 0.00/261 [00:00<?, ?B/s{'info': ''}]   \u001b[A\n","Transferring:   0% 0/3 [00:00<?, ?file/s{'info': ''}]\n","!\u001b[A\n","  0%|          |aa520761ee9ab2795ed92fa23c009a     0.00/? [00:00<?,        ?B/s]\u001b[A\n","\n","!\u001b[A\u001b[A\n","\n","  0%|          |395f2ff9a0f452a24334a381d9eff5     0.00/? [00:00<?,        ?B/s]\u001b[A\u001b[A\n","\n","\n","  0%|          |f9303c9192091fe1511eb68d04f7f1     0.00/? [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","395f2ff9a0f452a24334a381d9eff5:   0% 0.00/623k [00:00<?, ?B/s{'info': ''}]      \u001b[A\u001b[A\n","\n","\n","f9303c9192091fe1511eb68d04f7f1:   0% 0.00/3.46M [00:00<?, ?B/s{'info': ''}]     \u001b[A\u001b[A\u001b[A\n","aa520761ee9ab2795ed92fa23c009a:   0% 0.00/8.53M [00:00<?, ?B/s{'info': ''}]     \u001b[A\n","\n","\n","Transferring:  33% 1/3 [00:01<00:02,  1.23s/file{'info': ''}]\n","Transferring:  67% 2/3 [00:01<00:00,  1.50file/s{'info': ''}]\n","\n","Checkout:   0% 0/3 [00:00<?, ?file/s{'info': ''}]\n",".jDpk48e5YNsq2cjP8mQTfE.tmp:   0% 0.00/8.94M [00:00<?, ?it/s]\u001b[A\n",".jDpk48e5YNsq2cjP8mQTfE.tmp:   0% 0.00/8.94M [00:00<?, ?it/s{'info': ''}]\u001b[A\n","                                                                         \u001b[A\n",".d2vR2q6W5oKfEfwwqayN8o.tmp:   0% 0.00/3.63M [00:00<?, ?it/s]\u001b[A\n",".d2vR2q6W5oKfEfwwqayN8o.tmp:   0% 0.00/3.63M [00:00<?, ?it/s{'info': ''}]\u001b[A\n","                                                                         \u001b[A\n",".hdkeEpUfuMqufFbJyZqXa7.tmp:   0% 0.00/638k [00:00<?, ?it/s]\u001b[A\n",".hdkeEpUfuMqufFbJyZqXa7.tmp:   0% 0.00/638k [00:00<?, ?it/s{'info': ''}]\u001b[A\n","\u001b[32mA\u001b[0m       data/bronze/\n","1 file added and 3 files fetched\n","\u001b[0m"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QsZrsE9SUKKI"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"JnKB63tiWmSr"},"source":["In this simple scenario, we are building a recommendation system for movies based on a streaming service. I used a Kafka service that streamed data about movie files watched by users and movie ratings they submitted. The original data had ~1 million users and ~27 thousand movies. I streamed this data, parsed it, and saved it in a database.\n","\n","In this scenario, we are going to use data regarding the user and movie to predict how the user would rate the movie on a scale of 1-5. This can be used in a recommendation service to sort the highest predicted ratings and recommend a movie."]},{"cell_type":"code","metadata":{"id":"lWmR334gYo8m"},"source":["!pip install tpot xgboost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InJtmFcMXA1b","executionInfo":{"status":"ok","timestamp":1629795499289,"user_tz":-330,"elapsed":600,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from tpot import TPOTRegressor"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OVsyqIESXZ5y"},"source":["## Data loading"]},{"cell_type":"code","metadata":{"id":"Ph8FQQSGXNWf","executionInfo":{"status":"ok","timestamp":1629795353583,"user_tz":-330,"elapsed":1274,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["movies_raw = pd.read_parquet('./data/bronze/ml-1m-movies.parquet.snappy')\n","users_raw = pd.read_parquet('./data/bronze/ml-1m-users.parquet.snappy')\n","ratings_raw = pd.read_parquet('./data/bronze/ml-1m-ratings.parquet.snappy')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnSg73QwX4Js","executionInfo":{"status":"ok","timestamp":1629795394023,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"ccef7529-ef21-4033-f295-913f334cf881"},"source":["movies_raw.shape, users_raw.shape, ratings_raw.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((26617, 18), (72691, 4), (741356, 3))"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"p0yCT15qXP6C","executionInfo":{"status":"ok","timestamp":1629795401419,"user_tz":-330,"elapsed":573,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["users_raw.set_index('user_id', inplace=True)\n","movies_raw.set_index('movie_id', inplace=True)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vok1UNDhql4g"},"source":["## Data Cleaning\n","Before we pass the data into TPOT we should do some basic cleaning of the data. Currently, TPOT works with numerical data although there is some work being done to add some auto [data cleaning](https://github.com/rhiever/datacleaner/issues/1). Therefore, we need to transform some of our data into a format that TPOT will understand. The best way to do this is with scikit-learn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [column transformers](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). This makes the transformations a repeatable process, which is important because we are going to need to apply the same transformations when a making a prediction in our hypothetical production system.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M8iyxmbrzxJV"},"source":["### Categorical Features\n","Some of our features are categorical, such as `genres`. I decided to turn the categorical features into binary features. For example, instead of `genres`, I would have `Action` with a value of `1` if the movie was an action movie and `0` if it was not an action movie.\n","\n","To do this, I created a pipeline to apply scikit-learn's [MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html?highlight=multilabel%20binarizer#sklearn.preprocessing.MultiLabelBinarizer). First I needed to turn the cells of the columns into arrays instead of strings that resembled arrays. "]},{"cell_type":"code","metadata":{"id":"mVenTsJItaap","executionInfo":{"status":"ok","timestamp":1629795471387,"user_tz":-330,"elapsed":490,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class MultiLabelStringToArray(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    This shapes the data to be passed into the MultiLabelBinarizer. It takes\n","    columns that are array-like strings and turns them into arrays.\n","    \"\"\"\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        df = X.copy()\n","        for column_name in df.columns:\n","            df[column_name] = self._transform_column_to_array(df[column_name])\n","        return df\n","\n","    def _transform_column_to_array(self, pd_column):\n","        transformed_column = pd_column.copy()\n","        \n","        # replace null cells with empty array\n","        transformed_column.loc[transformed_column.isnull()] = transformed_column.loc[\n","            transformed_column.isnull()\n","        ].apply(lambda x: '[]')\n","\n","        # parse string into array\n","        transformed_column = transformed_column.apply(self._parse_arraystr)\n","        return transformed_column\n","\n","    def _parse_arraystr(self, str):\n","        \"\"\"\n","        Applies a number of rules to turn an array looking string into an array\n","          - remove brackets\n","          - remove quotes\n","          - remove extra spaces\n","          - deliminate by comma\n","          - remove empty string entries in the array\n","        \"\"\"\n","        str_without_brackets = str.replace(\"[\",\"\").replace(\"]\",\"\")\n","        str_without_quotes = str_without_brackets.replace(\"'\",\"\")\n","        str_without_spaces = str_without_quotes.replace(\" \",\"\")\n","        list_with_empties = str_without_spaces.split(',')\n","        if '' in list_with_empties:\n","            while(\"\" in list_with_empties) : \n","                list_with_empties.remove(\"\") \n","        return np.array(list_with_empties)\n","    \n","class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    This tranformer creates a MultiLabelBinarizer for every column passed in.\n","    \"\"\"\n","    def __init__(self):\n","        self.mlbs = {}\n","    def fit(self, X, y=None):\n","        \"\"\"Fit the MultiLabelBinarizer to the data passed in\"\"\"\n","        df = X.copy()\n","        for column_name in df.columns:\n","            mlb = MultiLabelBinarizer()\n","            mlb.fit(df[column_name])\n","            # Uncomment the following line if you want to print out the values\n","            # that the MultiLabelbinarizer discovered.\n","            #print('Column: {NAME} Values: {VALUES}'.format(NAME=column_name, VALUES=mlb.classes_))\n","            self.mlbs[column_name] = mlb\n","        return self\n","    def transform(self, X, y=None):\n","        \"\"\"\n","        Returns a dataframe with the binarized columns. When applied in a\n","        ColumnTransformer this will effectively remove the original column and \n","        replace it with the binary columns\n","        \"\"\"\n","        df = X.copy()\n","        binarized_cols = pd.DataFrame()\n","        for column_name in df.columns:\n","            mlb = self.mlbs.get(column_name)\n","            new_cols = pd.DataFrame(mlb.transform(df[column_name]),columns=mlb.classes_)\n","            binarized_cols = pd.concat([binarized_cols, new_cols], axis=1)\n","        return binarized_cols"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fO3EidIKwtHZ"},"source":["### Date Features\n","We have a `release_date` feature; however, it is currently stored as a string so we want to extract meaningful data from the string. Since I do not believe that the day has much impact on how a user would rate something I am going to leave it out. I think the year could have some impact because users could be more excited by new movies or our streaming service might only contain very popular old movies. Also, I think the month could be helpful. It could discover that users are more likely to rate a movie highly if it is released during \"Oscar season\"."]},{"cell_type":"code","metadata":{"id":"I5Q2Nzr5xiJN","executionInfo":{"status":"ok","timestamp":1629795491172,"user_tz":-330,"elapsed":688,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["class ExtractReleaseDateFeatures(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    This transformer takes a column with a date string formatted as \n","    'YYYY-mm-dd', extracts the year and month, and returns a DataFrame with\n","    those columns.\n","    \"\"\"\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        \"\"\"\n","        Returns a dataframe with the year and month as integer fields. When \n","        applied in a ColumnTransformer this will effectively remove the\n","        original column and replace it with the new columns.\n","        \"\"\"\n","        df = X.copy()\n","\n","        # fill nulls values that wont show up in valid data\n","        df = df.fillna('0000-00-00') \n","\n","        df['year'] = df.iloc[:,0].apply(lambda x: str(x)[:4])\n","        df['month'] = df.iloc[:,0].apply(lambda x: str(x)[5:7])\n","        df = df.astype({'year':'int64', 'month':'int64'})\n","\n","        return df.loc[:,['year','month']]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mEjln8HzoyC"},"source":["### Column Transformation\n","Now let's combine all those transformations to create our pipeline. First, we create a pipeline to sequentially execute the steps for our categorical columns. Next, we define a `ColumnTransformer` which will apply the categorical transformations, date transformations, and will pass our other feature columns through into the final data. All other columns not specified here will be dropped."]},{"cell_type":"code","metadata":{"id":"EQJu-3Djy-dm","executionInfo":{"status":"ok","timestamp":1629795508078,"user_tz":-330,"elapsed":453,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["# Pipeline to create binary columns\n","multilabel_binarizer_pipeline = Pipeline([\n","    ('multilabel_str_to_array',MultiLabelStringToArray()),\n","    ('binarizer', MultiLabelBinarizerTransformer()),\n","],verbose=True)\n","\n","MULTILABEL_BINARIZER_COLUMNS = ['genres','production_countries', 'spoken_languages', 'gender', 'occupation']\n","RELEASE_DATE_COLUMNS = ['release_date']\n","PASSTHROUGH_COLUMNS = ['age','budget','popularity','revenue', 'runtime', 'vote_average', 'vote_count']\n","\n","full_data_clean_pipeline = ColumnTransformer([\n","    ('multilabel_binarizer', multilabel_binarizer_pipeline, MULTILABEL_BINARIZER_COLUMNS),\n","    ('release_date', ExtractReleaseDateFeatures(), RELEASE_DATE_COLUMNS),\n","    ('passthrough_columns','passthrough', PASSTHROUGH_COLUMNS)\n","],remainder='drop',verbose=True)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1L5aoDhC0zP-"},"source":["## Training\n","With our pipeline setup, we are ready to try it out on some data. First, I combine all our raw data loaded from GitHub into a single DataFrame. Next, we sort the data based on `userid` because we want to train and test our model on different users, to see if what the model learned about one user's preferences apply to other users. Finally, I've decided to drop rows that contain nulls in columns that we are not applying transformations to. I chose to do this because there were only ~650 rows to which this applied. If there were more rows with null values I might consider a different approach because it could mean losing too much data. Another possibility is that there could be hidden meaning in the null values, such as null values being a proxy for old movies where that data could be harder to get. Either way, 650 rows is not even 1/100th of our data set so I'm not going to lose sleep over it."]},{"cell_type":"code","metadata":{"id":"CX-gqq1w4YEM","colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"status":"ok","timestamp":1629795523399,"user_tz":-330,"elapsed":1902,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"4726f079-26f3-4606-f6b9-bf20fffdb790"},"source":["records = ratings_raw.join(users_raw, on='user_id', how='left')\n","records = records.join(movies_raw, on='movie_id', how='left')\n","\n","records = records.sort_values(by=['user_id'])\n","records = records.dropna(subset=['budget','popularity','revenue','runtime','vote_average','vote_count'])\n","records.head()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movie_id</th>\n","      <th>rating</th>\n","      <th>user_id</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>occupation</th>\n","      <th>budget</th>\n","      <th>genres</th>\n","      <th>imdb_id</th>\n","      <th>original_language</th>\n","      <th>original_title</th>\n","      <th>overview</th>\n","      <th>popularity</th>\n","      <th>production_companies</th>\n","      <th>production_countries</th>\n","      <th>release_date</th>\n","      <th>revenue</th>\n","      <th>runtime</th>\n","      <th>spoken_languages</th>\n","      <th>title</th>\n","      <th>tmdb_id</th>\n","      <th>vote_average</th>\n","      <th>vote_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>18981</th>\n","      <td>legends+of+the+fall+1994</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>college/grad student</td>\n","      <td>30000000.0</td>\n","      <td>['Adventure', 'Drama', 'Romance', 'War']</td>\n","      <td>tt0110322</td>\n","      <td>en</td>\n","      <td>Legends of the Fall</td>\n","      <td>An epic tale of three brothers and their fathe...</td>\n","      <td>12.19900</td>\n","      <td>['Bedford Falls Productions', 'TriStar Picture...</td>\n","      <td>['United States of America']</td>\n","      <td>1994-12-16</td>\n","      <td>160639000.0</td>\n","      <td>133.0</td>\n","      <td>['', 'English']</td>\n","      <td>Legends of the Fall</td>\n","      <td>4476.0</td>\n","      <td>7.2</td>\n","      <td>636.0</td>\n","    </tr>\n","    <tr>\n","      <th>18869</th>\n","      <td>miracle+on+34th+street+1994</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>college/grad student</td>\n","      <td>0.0</td>\n","      <td>['Fantasy', 'Drama', 'Family']</td>\n","      <td>tt0110527</td>\n","      <td>en</td>\n","      <td>Miracle on 34th Street</td>\n","      <td>A little girl discovers dreams can come true i...</td>\n","      <td>5.83162</td>\n","      <td>['Twentieth Century Fox Film Corporation']</td>\n","      <td>['United States of America']</td>\n","      <td>1994-11-18</td>\n","      <td>46264400.0</td>\n","      <td>114.0</td>\n","      <td>['English']</td>\n","      <td>Miracle on 34th Street</td>\n","      <td>10510.0</td>\n","      <td>6.4</td>\n","      <td>199.0</td>\n","    </tr>\n","    <tr>\n","      <th>20104</th>\n","      <td>four+weddings+and+a+funeral+1994</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>college/grad student</td>\n","      <td>6000000.0</td>\n","      <td>['Comedy', 'Drama', 'Romance']</td>\n","      <td>tt0109831</td>\n","      <td>en</td>\n","      <td>Four Weddings and a Funeral</td>\n","      <td>Four Weddings And A Funeral is a British comed...</td>\n","      <td>8.99035</td>\n","      <td>['Channel Four Films', 'PolyGram Filmed Entert...</td>\n","      <td>['United Kingdom']</td>\n","      <td>1994-03-09</td>\n","      <td>254701000.0</td>\n","      <td>117.0</td>\n","      <td>['English']</td>\n","      <td>Four Weddings and a Funeral</td>\n","      <td>712.0</td>\n","      <td>6.6</td>\n","      <td>654.0</td>\n","    </tr>\n","    <tr>\n","      <th>20117</th>\n","      <td>jurassic+park+1993</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>college/grad student</td>\n","      <td>63000000.0</td>\n","      <td>['Adventure', 'Science Fiction']</td>\n","      <td>tt0107290</td>\n","      <td>en</td>\n","      <td>Jurassic Park</td>\n","      <td>A wealthy entrepreneur secretly creates a them...</td>\n","      <td>8.86378</td>\n","      <td>['Universal Pictures', 'Amblin Entertainment']</td>\n","      <td>['United States of America']</td>\n","      <td>1993-06-11</td>\n","      <td>920100000.0</td>\n","      <td>127.0</td>\n","      <td>['English', 'Español']</td>\n","      <td>Jurassic Park</td>\n","      <td>329.0</td>\n","      <td>7.6</td>\n","      <td>4956.0</td>\n","    </tr>\n","    <tr>\n","      <th>17547</th>\n","      <td>braveheart+1995</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>college/grad student</td>\n","      <td>72000000.0</td>\n","      <td>['Action', 'Drama', 'History', 'War']</td>\n","      <td>tt0112573</td>\n","      <td>en</td>\n","      <td>Braveheart</td>\n","      <td>Enraged at the slaughter of Murron, his new br...</td>\n","      <td>20.75510</td>\n","      <td>['Icon Entertainment International', 'The Ladd...</td>\n","      <td>['United States of America']</td>\n","      <td>1995-05-24</td>\n","      <td>210000000.0</td>\n","      <td>177.0</td>\n","      <td>['English', 'Français', 'Latin', '']</td>\n","      <td>Braveheart</td>\n","      <td>197.0</td>\n","      <td>7.7</td>\n","      <td>3404.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               movie_id  rating  ...  vote_average  vote_count\n","18981          legends+of+the+fall+1994       5  ...           7.2       636.0\n","18869       miracle+on+34th+street+1994       4  ...           6.4       199.0\n","20104  four+weddings+and+a+funeral+1994       4  ...           6.6       654.0\n","20117                jurassic+park+1993       4  ...           7.6      4956.0\n","17547                   braveheart+1995       5  ...           7.7      3404.0\n","\n","[5 rows x 23 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"Sma5FEDQKLKX"},"source":["Before we start playing around with TPOT we need to grab some train and test data. In this scenario, I'm going to put all my faith in TPOT to come up with the best model so I don't need to create a verification dataset. Let's start with a small amount of data just to see TPOT in action. First, we will fit and transform our dataset with the data cleaning pipeline we built then I'm going to select 10,000 records for both training and testing. We have a lot more data, but the more data there is the longer TPOT takes so, let's just start with 10k."]},{"cell_type":"code","metadata":{"id":"XPLJ2HGg5RUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629795669086,"user_tz":-330,"elapsed":38561,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"77013439-aaa1-4dac-d593-14d0154f09b5"},"source":["X_all = full_data_clean_pipeline.fit_transform(records)\n","y_all = records['rating']\n","\n","X_train = X_all[:10000]\n","y_train = y_all[:10000]\n","X_test = X_all[10000:20000]\n","y_test = y_all[10000:20000]"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[Pipeline]  (step 1 of 2) Processing multilabel_str_to_array, total=  13.1s\n","[Pipeline] ......... (step 2 of 2) Processing binarizer, total=  22.0s\n","[ColumnTransformer]  (1 of 3) Processing multilabel_binarizer, total=  36.2s\n","[ColumnTransformer] .. (2 of 3) Processing release_date, total=   0.8s\n","[ColumnTransformer]  (3 of 3) Processing passthrough_columns, total=   0.0s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ause_3b5GooK"},"source":["Now the time you've all been waiting for... afternoon tea (or whatever time of day you happen to be reading this). TPOT supports both regression and classification problems. I decided that this would be better as a regression problem because too many movies would tie for the top spot otherwise. \n","Let's review some of the configuration options I chose:\n","\n","* `generations` - This is the number of iterations of pipeline generation that \n","TPOT will run for. Alternatively, you could specify a `max_time_minutes` to stop TPOT after a certain amount of time.\n","\n","* `population_size` - This is the number of pipelines trained during each generation.\n","\n","* `verbosity` - This just gives us some feedback to let us know that TPOT is boiling away. It can take a long time I find this reassuring to make sure nothing is frozen. \n","\n","* `random_state` - This ensures that if we run this a second time we start with the same seed.\n","\n","* `template` - This describes how I want my pipeline to look. Since I have done little feature engineering I want to start with a Selector to find the best features, then transform those features and finally use a regressor. If I were to not specify a template TPOT would pick whatever combination worked best. In my trials, the shape of the pipeline would end up\n","`Regressor-Regresssor-Regressor`.\n","\n","* `n_jobs` - The number of parallel processes to use for evaluation\n","\n","* `warm_start` - This tells TPOT whether to reuse populations from the last call to fit. This is good if you want to stop and restart the fit process.\n","\n","* `periodic_checkpoint_folder` - Where to intermittently save pipelines during the training. This can help make sure you get an output even if TPOT suddenly dies or you decide to stop the training early.\n","\n","For a full list of TPOT's configurations checkout their [documentation](https://epistasislab.github.io/tpot/api/).\n","\n","The configuration below will train 10,100 pipelines and compare them using 5-fold (another config options, but I just used the default) cross-validation and a negative mean squared error scoring function. It may not generate 10,100 unique pipelines; so, it will skip over any repeat pipelines that are generated. This example generates about 2,500 unique pipelines. \n","\n","**Warning:** This training takes about 6 hours to run. If you want to shorten the example you can change the `generations` and `population_size` to 10 and it will only generate 110 pipelines. This shorter process should take around 30 minutes to train.  "]},{"cell_type":"code","metadata":{"id":"Mava9Y6OZfpb","executionInfo":{"status":"ok","timestamp":1629795782414,"user_tz":-330,"elapsed":434,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["!mkdir -p ./extras/tpot/checkpoints"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"cEAVUfaB5x3J","colab":{"base_uri":"https://localhost:8080/","height":377,"referenced_widgets":["e368a6b6897f44eab08ebdf82ca033b8","6ec270f418e24abeba033ca52d9200dd","9be43b61843949008b663a1376526b9f","edb6ffabccd445f6b6cae6ef7569c778","1d7077e691644795a0633f5764741cbf","a3dc72e38b474406bf22452a76cfff59","4df27d9bd9f04e0baa8c3dcdf72ddad3","61d5eab7e93947ae8740b3ca6d7c65a2","811ae8843fd645778c2d4018bf034e03","fb06e3c690af4160b6b90c02f51717e7","76d4d86ce8fd4baf931c58bf0521d329"]},"executionInfo":{"status":"ok","timestamp":1629795972095,"user_tz":-330,"elapsed":173428,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"84dac757-671c-4f35-b10d-7a8319df70bb"},"source":["pipeline_optimizer = TPOTRegressor(generations=5, population_size=5, verbosity=2, random_state=42,\n","                                   template='Selector-Transformer-Regressor', n_jobs=-1,\n","                                   warm_start=True, periodic_checkpoint_folder='./extras/tpot/checkpoints')\n","pipeline_optimizer.fit(X_train, y_train)"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e368a6b6897f44eab08ebdf82ca033b8","version_minor":0,"version_major":2},"text/plain":["Optimization Progress:   0%|          | 0/30 [00:00<?, ?pipeline/s]"]},"metadata":{}},{"output_type":"stream","text":["\n","Generation 1 - Current best internal CV score: -0.9712462936500948\n","\n","Generation 2 - Current best internal CV score: -0.9498868519221821\n","\n","Generation 3 - Current best internal CV score: -0.9498868519221821\n","\n","Generation 4 - Current best internal CV score: -0.9498868519221821\n","\n","Generation 5 - Current best internal CV score: -0.9498868519221821\n","\n","Best pipeline: LassoLarsCV(PCA(SelectPercentile(input_matrix, percentile=70), iterated_power=8, svd_solver=randomized), normalize=False)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TPOTRegressor(config_dict=None, crossover_rate=0.1, cv=5,\n","              disable_update_check=False, early_stop=None, generations=5,\n","              log_file=None, max_eval_time_mins=5, max_time_mins=None,\n","              memory=None, mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n","              periodic_checkpoint_folder='./extras/tpot/checkpoints',\n","              population_size=5, random_state=42, scoring=None, subsample=1.0,\n","              template='Selector-Transformer-Regressor', use_dask=False,\n","              verbosity=2, warm_start=True)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"eVzjX8u1Qdux"},"source":["## Evaluation\n","Just like scikit-learn TPOT comes with a built-in evaluation mechanism. We can use the test data to evaluate our pipeline with the same scoring function that we used in training (we used the default which is negative mean squared error). We can see that our test data gives similar results as the cross validation scores seen during training. \n","\n","It looks like our model is off by almost a whole number in its predictions. This is likely in adequite for our scenario however, we would need to examine what sort of errors the model is making. For exmaple, if the model just estimates one point too low everytime then the model is perfect because we would recommend the correct movie; However, if the direction of error is variable it would cause some unfavorable movies to be recommended (at least personally the difference between a 3 and a 4 on a 5 point scale is enormous).\n","\n","**Note**: I want to point out that this evaluation strategy is not really the most appropriate for our use case because we are not actually that concerned with the actual predicted value of a movie rating. We should be more concerned about whether the ranked order of predicted ratings resemble the users actual ratings. However, since this example is mostly evaluating the value of TPOT as a tool the negative mean squared error is a good evauluation of the model that is generated without considering the context that the model is being applied to."]},{"cell_type":"code","metadata":{"id":"BtTJbRVTKnRR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629796033448,"user_tz":-330,"elapsed":424,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"d0414e3a-bb63-4da8-88de-2743f20e0721"},"source":["pipeline_optimizer.score(X_test, y_test)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.9942553567922114"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"KUBwraJ3OVXY"},"source":["## More Data is Better (maybe)\n","Since we have so much data and machine learning models are almost always better when trained on more data, let's use everything we've got. I'm going to split the data into 500k rows for training and the remaining ~240k for testings. "]},{"cell_type":"code","metadata":{"id":"y7kFbftqS33p","executionInfo":{"status":"ok","timestamp":1629796037346,"user_tz":-330,"elapsed":461,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["X_train_large = X_all[:500000]\n","y_train_large = y_all[:500000]\n","X_test_large = X_all[500000:]\n","y_test_large = y_all[500000:]"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SoRToIZJUHDS"},"source":["More is not always better. TPOT is already a timely process because there are so many pipelines generated and evaluated using k-fold cross-validation. The larger the dataset that the models are trained on, the longer this process is going to take. If you noticed I added one parameter to the configuration. `config_dict=\"TPOT light\"` tells TPOT that I am using a large data set so it will limit the model search to only model features that are simpler and fast running. Therefore, it finds a pipeline that works well for large datasets.\n","\n","**Warning**: This training takes somewhere between 12 and 20 hours to complete. Google Colab's runtime may timeout before you are complete. You may need to clone or fork my repo and use the [Jupyter Lab notebook](https://github.com/bialesdaniel/se4ai-i5-tpot/blob/master/notebooks/TPOT_Movies_Explained.ipynb) there to run this."]},{"cell_type":"code","metadata":{"id":"sSFnYDA3SbOc","colab":{"base_uri":"https://localhost:8080/","height":377,"referenced_widgets":["47592c68e0c4436e8905a0bf1ded673e","de9c2792569748658ed1e10c854d7067","e00526f957054e959ad4f0b574b4314e","d4f44f7e93d34b72969d5d036c77bedf","6bfdfcaf8a074ab8ad265111eadd51ea","fcf6ee7ba257479c870e780152e6479b","665edf9f2227408298aa86f74b282c1a","91c96a6ec9ca4b4698f397dc89e737c6","53fbeebd64734f93a21e97f0ae43117f","a426d81aedd54802a68be27b20698689","0b9fa9ff2ec44622bc004172a0c41d1a"]},"executionInfo":{"status":"ok","timestamp":1629798553574,"user_tz":-330,"elapsed":2498739,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"4e259f07-1139-4f71-cc2c-8ba0aa485e2f"},"source":["pipeline_optimizer_large = TPOTRegressor(generations=5, population_size=5, verbosity=2, random_state=42,\n","                                      template='Selector-Transformer-Regressor', config_dict=\"TPOT light\", n_jobs=-1,\n","                                     warm_start=True, periodic_checkpoint_folder='./extras/tpot/checkpoints_large/')\n","pipeline_optimizer_large.fit(X_train_large, y_train_large)"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47592c68e0c4436e8905a0bf1ded673e","version_minor":0,"version_major":2},"text/plain":["Optimization Progress:   0%|          | 0/30 [00:00<?, ?pipeline/s]"]},"metadata":{}},{"output_type":"stream","text":["\n","Generation 1 - Current best internal CV score: -0.9748474866127209\n","\n","Generation 2 - Current best internal CV score: -0.9657643256515426\n","\n","Generation 3 - Current best internal CV score: -0.9657643256515426\n","\n","Generation 4 - Current best internal CV score: -0.9657643256515426\n","\n","Generation 5 - Current best internal CV score: -0.9657643256515426\n","\n","Best pipeline: DecisionTreeRegressor(StandardScaler(SelectPercentile(input_matrix, percentile=88)), max_depth=9, min_samples_leaf=2, min_samples_split=2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TPOTRegressor(config_dict='TPOT light', crossover_rate=0.1, cv=5,\n","              disable_update_check=False, early_stop=None, generations=5,\n","              log_file=None, max_eval_time_mins=5, max_time_mins=None,\n","              memory=None, mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n","              periodic_checkpoint_folder='./extras/tpot/checkpoints_large/',\n","              population_size=5, random_state=42, scoring=None, subsample=1.0,\n","              template='Selector-Transformer-Regressor', use_dask=False,\n","              verbosity=2, warm_start=True)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"KPPJfcNUDcXg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629798569840,"user_tz":-330,"elapsed":1244,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"e5500cf8-28f3-4a7f-cd77-217df1f798cd"},"source":["pipeline_optimizer_large.score(X_test_large, y_test_large)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.971707625601248"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"YHbyS-mIW3hg"},"source":["## Conclusions\n","As we have seen, TPOT is quite easy to use.  The autoML process can save some valuable time and effort in feature engineering and hyperparameter tuning. On the other hand, TPOT is slow. It can take a long time to generate the optimal pipeline. \n","\n","Sorry, these conclusions are rather shallow because this notebook is mostly focused on how to set up and use TPOT for our movie recommendation system. For more in-depth analysis of the tool please continue reading the [Medium article](https://medium.com/@daniel.biales/automl-taking-tpot-to-the-movies-cf7e6f67f876?sk=6737cdd9d4cf2ff3c7322ee25f80fe70)."]}]}