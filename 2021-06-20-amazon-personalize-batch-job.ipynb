{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc-autonumbering": true,
    "toc-showmarkdowntxt": false,
    "colab": {
      "name": "2021-06-20-amazon-personalize-batch-job.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "M2uc816aYJ7j",
        "HJngfs71YJ7l",
        "l_g_mGaoYJ7m",
        "l2TIRnBTYJ7o",
        "kSKWcCO9YJ7p",
        "sWAfdnn-YJ7q",
        "-4CtiR6iYJ7r",
        "pLb6oC84YJ7t",
        "qpyzK67_YJ7u",
        "ET7p3lQNYJ7v",
        "pK-eqHBgYJ71",
        "HdVamw3GYJ72",
        "J3qg6QyGYJ73",
        "Z-da6aESYJ74",
        "z8yqiKFOYJ79",
        "DlqVkxe6YJ8A",
        "wWubD_JCYJ8A"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdNLiW3fYNJW"
      },
      "source": [
        "# Amazon Personalize Batch Job\n",
        "> Train and create batch recommendations using Amazon Personalize. Expected completion time is 1.5-2 hours\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [amazonpersonalize, batch, movie, hrnn]\n",
        "- image: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmXmEqzGYJ7Q"
      },
      "source": [
        "**Amazon Personalize Workflow**\n",
        "\n",
        "The general workflow for training, deploying, and getting recommendations from a campaign is as follows:\n",
        "\n",
        "1. Prepare data\n",
        "\n",
        "2. Create related datasets and a dataset group.\n",
        "\n",
        "3. Get training data.\n",
        "\n",
        "    - Import historical data to the dataset group.\n",
        "\n",
        "    - Record user events to the dataset group.\n",
        "\n",
        "4. Create a solution version (trained model) using a recipe.\n",
        "\n",
        "5. Evaluate the solution version using metrics.\n",
        "\n",
        "6. Create a campaign (deploy the solution version).\n",
        "\n",
        "7. Provide recommendations for users by running Batch Recommendation.\n",
        "\n",
        "In this lab, we will step through the workflow and with some additional steps to setup your IAM permissions and S3 buckets as a data source for your dataset and output for the batch recommendations. \n",
        "\n",
        "**Note:** This lab will not cover the deployment of a real-time personalize campaign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7j_gy-NYJ7S"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhhAxqIkYJ7T"
      },
      "source": [
        "### Get dataset\n",
        "In thie lab, we will be using the the [Movielens dataset](http://grouplens.org/datasets/movielens/) to train and make movie recommendations.\n",
        "\n",
        "Movielens provide several datasets. To achieve better model accuracy, it is recommendeded to train the Personalize model with a large dataset, however the tradeoff would mean a longer training time. To minimise the time required to complete this lab, we will be sacrificing accuracy for time and will be using the small dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh3XWFHMYJ7V",
        "outputId": "db24260f-19ce-4302-924c-faff1d9fd681"
      },
      "source": [
        "data_dir = \"movie_data\"\n",
        "!mkdir $data_dir\n",
        "!cd $data_dir && wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!cd $data_dir && unzip ml-latest-small.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 06:45:48--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  5.70MB/s    in 0.2s    \n",
            "\n",
            "2020-04-16 06:45:48 (5.70 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WokCPN9cYJ7Z"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xarb5ZYYJ7a"
      },
      "source": [
        "import time\n",
        "from time import sleep\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import uuid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfXGh3bIYJ7b"
      },
      "source": [
        "Load the dataset and preview the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn4I2lpbYJ7c",
        "outputId": "e66b796b-d1b6-4147-f640-1f0556f6089c"
      },
      "source": [
        "original_data = pd.read_csv(data_dir + '/ml-latest-small/ratings.csv')\n",
        "original_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>3.0</td>\n",
              "      <td>964982400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>157</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931\n",
              "5       1       70     3.0  964982400\n",
              "6       1      101     5.0  964980868\n",
              "7       1      110     4.0  964982176\n",
              "8       1      151     5.0  964984041\n",
              "9       1      157     5.0  964984100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4y6j3NHYJ7e"
      },
      "source": [
        "In the lab, we will be using the movie rating dataset and considering movies with ratings greater or equal to 4 to use for the recommendation as we only want to recommend movies that have been positively rated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1DeDnLYJ7f",
        "outputId": "0fd1b46d-d2f0-48b6-9f55-09b6b287764f"
      },
      "source": [
        "interactions_df = original_data.copy()\n",
        "\n",
        "# Only want ratings greater or equal to 4, filter out ratings less than 4\n",
        "interactions_df = interactions_df[interactions_df['rating'] >= 4.0]\n",
        "\n",
        "interactions_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>157</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  movieId  rating  timestamp\n",
              "0        1        1     4.0  964982703\n",
              "1        1        3     4.0  964981247\n",
              "2        1        6     4.0  964982224\n",
              "3        1       47     5.0  964983815\n",
              "4        1       50     5.0  964982931\n",
              "6        1      101     5.0  964980868\n",
              "7        1      110     4.0  964982176\n",
              "8        1      151     5.0  964984041\n",
              "9        1      157     5.0  964984100\n",
              "10       1      163     5.0  964983650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1kJRg6gYJ7g"
      },
      "source": [
        "The next step is to map the dataset to the personalize schema by renaming the column name.\n",
        "\n",
        "For more information about the schema, refer to the following URL: https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5enBhlJYJ7h"
      },
      "source": [
        "interactions_df = interactions_df[['userId', 'movieId', 'timestamp']]\n",
        "interactions_df.head()\n",
        "interactions_df.rename(columns = {'userId':'USER_ID', 'movieId':'ITEM_ID', \n",
        "                              'timestamp':'TIMESTAMP'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Wo4Ip8YJ7h"
      },
      "source": [
        "Finally, we save the dataset to CSV file which we will later upload to S3 for Personalize to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXUZ8FoYJ7i"
      },
      "source": [
        "interactions_filename = \"interactions.csv\"\n",
        "interactions_df.to_csv((data_dir+\"/\"+interactions_filename), index=False, float_format='%.0f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2uc816aYJ7j"
      },
      "source": [
        "## Create related datasets and a dataset group.\n",
        "\n",
        "In this section, we will setup the Amazon Personalize dataset group and load the inteaction dataset into Amazon Personalize which will be used for training.\n",
        "\n",
        "Amazon Personalize requires data, stored in Amazon Personalize datasets, in order to train a model.\n",
        "\n",
        "There are two ways to provide the training data. You can import historical data from an Amazon S3 bucket, and you can record event data as it is created.\n",
        "\n",
        "A dataset group contains related datasets. Three types of historical datasets are created by the customer (users, items, and interactions), and one type is created by Amazon Personalize for live-event interactions. A dataset group can contain only one of each kind of dataset.\n",
        "\n",
        "You can create dataset groups to serve different purposes. For example, you might have an application that provides recommendations for purchasing shoes and another that provides recommendations for places to visit in Europe. In Amazon Personalize, each application would have its own dataset group.\n",
        "\n",
        "Historical data must be provided in a CSV file. Each dataset type has a unique schema that specifies the contents of the CSV file.\n",
        "\n",
        "There is a [minimum amount of data](https://docs.aws.amazon.com/personalize/latest/dg/limits.html) that is necessary to train a model. Using existing data allows you to immediately start training a model. If you rely on recorded data as it is created, and there is no historical data, it can take a while before training can begin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnkHMWk7YJ7k"
      },
      "source": [
        "# Configure the SDK to Personalize:\n",
        "personalize = boto3.client('personalize')\n",
        "personalize_runtime = boto3.client('personalize-runtime')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJngfs71YJ7l"
      },
      "source": [
        "### Create the personalize dataset group\n",
        "We start by creating the personalize dataset group named \"**personalize-devlab-movies-dataset-group**\" which will be used to to store our interactive (ratings) dataset we prepared earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsbY7FHHYJ7m",
        "outputId": "0808569c-6f3b-4e4b-fc15-57b0c8c73868"
      },
      "source": [
        "create_dataset_group_response = personalize.create_dataset_group(\n",
        "    name = \"personalize-devlab-movies-dataset-group\"\n",
        ")\n",
        "\n",
        "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
        "print(json.dumps(create_dataset_group_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-2:931343413930:dataset-group/personalize-devlab-movies-dataset-group\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"0374647e-baae-470f-87b1-0664f3d225d5\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 06:46:00 GMT\",\n",
            "      \"x-amzn-requestid\": \"0374647e-baae-470f-87b1-0664f3d225d5\",\n",
            "      \"content-length\": \"118\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_g_mGaoYJ7m"
      },
      "source": [
        "### CHECKPOINT #1 - Wait for dataset group creation to complete\n",
        "The dataset group will take some time to be created. **Execute the following cell and wait for it to show \"ACTIVE\" before proceeding to the next step.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N-x3w80YJ7n",
        "outputId": "990d0937-149f-45d3-ac28-d12f50aee19c"
      },
      "source": [
        "current_time = datetime.now()\n",
        "print(\"Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
        "\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
        "        datasetGroupArn = dataset_group_arn\n",
        "    )\n",
        "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
        "    print(\"DatasetGroup: {}\".format(status))\n",
        "    \n",
        "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
        "        break\n",
        "        \n",
        "    time.sleep(60)\n",
        "\n",
        "current_time = datetime.now()\n",
        "print(\"Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started on:  06:46:03 AM\n",
            "DatasetGroup: CREATE PENDING\n",
            "DatasetGroup: ACTIVE\n",
            "Completed on:  06:47:03 AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2TIRnBTYJ7o"
      },
      "source": [
        "### Create the dataset\n",
        "Once the dataset group have been complete, the next step is to defined the interaction schema and we will name it \"**personalize-devlab-movies-interactions-schema**\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUCNSq1eYJ7o",
        "outputId": "4e263641-5991-450c-dbb1-9459530d99f7"
      },
      "source": [
        "interactions_schema = schema = {\n",
        "    \"type\": \"record\",\n",
        "    \"name\": \"Interactions\",\n",
        "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
        "    \"fields\": [\n",
        "        {\n",
        "            \"name\": \"USER_ID\",\n",
        "            \"type\": \"string\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ITEM_ID\",\n",
        "            \"type\": \"string\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"TIMESTAMP\",\n",
        "            \"type\": \"long\"\n",
        "        }\n",
        "    ],\n",
        "    \"version\": \"1.0\"\n",
        "}\n",
        "\n",
        "create_schema_response = personalize.create_schema(\n",
        "    name = \"personalize-devlab-movies-interactions-schema\",\n",
        "    schema = json.dumps(interactions_schema)\n",
        ")\n",
        "\n",
        "schema_arn = create_schema_response['schemaArn']\n",
        "print(json.dumps(create_schema_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"schemaArn\": \"arn:aws:personalize:us-east-2:931343413930:schema/personalize-devlab-movies-interactions-schema\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"82e560cc-a51a-4061-9b1e-38c607985d04\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 06:47:20 GMT\",\n",
            "      \"x-amzn-requestid\": \"82e560cc-a51a-4061-9b1e-38c607985d04\",\n",
            "      \"content-length\": \"111\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9s_stG4YJ7o"
      },
      "source": [
        "Once the schema has been defined, we will define the interactiion dataset using the schema we created above and provide it with the following name \"personalize-devlab-movies-interactions-dataset\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARNtsrMYJ7p",
        "outputId": "d8fde9f3-1281-448b-e909-391d828fb6cd"
      },
      "source": [
        "dataset_type = \"INTERACTIONS\"\n",
        "create_dataset_response = personalize.create_dataset(\n",
        "    name = \"personalize-devlab-movies-interactions-dataset\",\n",
        "    datasetType = dataset_type,\n",
        "    datasetGroupArn = dataset_group_arn,\n",
        "    schemaArn = schema_arn\n",
        ")\n",
        "\n",
        "dataset_arn = create_dataset_response['datasetArn']\n",
        "print(json.dumps(create_dataset_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"datasetArn\": \"arn:aws:personalize:us-east-2:931343413930:dataset/personalize-devlab-movies-dataset-group/INTERACTIONS\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"8d113327-296b-45fd-8f40-1b97a195f699\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 06:47:21 GMT\",\n",
            "      \"x-amzn-requestid\": \"8d113327-296b-45fd-8f40-1b97a195f699\",\n",
            "      \"content-length\": \"120\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBO7X8yRYJ7p"
      },
      "source": [
        "# Record the interaction dataset arn to be used later\n",
        "interactions_dataset_arn = dataset_arn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKWcCO9YJ7p"
      },
      "source": [
        "## Configuring S3 and IAM \n",
        "\n",
        "\n",
        "Amazon Personalize will need an S3 bucket to act as the source of your data, as well as IAM roles for accessing it. The code below will set all that up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjyKXo4zYJ7p"
      },
      "source": [
        "Now using the metada stored on this instance of a SageMaker Notebook determine the region we are operating in. If you are using a Jupyter Notebook outside of SageMaker simply define region as the string that indicates the region you would like to use for Forecast and S3.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymh7wuwmYJ7q",
        "outputId": "d9f0b97c-4b49-48b5-d84c-4acd71d7cc7e"
      },
      "source": [
        "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
        "    data = json.load(notebook_info)\n",
        "    resource_arn = data['ResourceArn']\n",
        "    region = resource_arn.split(':')[3]\n",
        "    \n",
        "session = boto3.Session(region_name=region)\n",
        "\n",
        "print(region)\n",
        "s3 = boto3.client('s3')\n",
        "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
        "bucket_name = account_id + \"personalizedevlab\"\n",
        "print(bucket_name)\n",
        "if region != \"us-east-1\":\n",
        "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
        "else:\n",
        "    s3.create_bucket(Bucket=bucket_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "us-east-2\n",
            "931343413930personalizedevlab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAfdnn-YJ7q"
      },
      "source": [
        "### Attach Policy to S3 Bucket\n",
        "Amazon Personalize needs to be able to read the content of your S3 bucket that you created earlier. The lines below will do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFWQOgdJYJ7q",
        "outputId": "84b51a0e-094a-4fa3-c465-12c1d1041f3e"
      },
      "source": [
        "s3 = boto3.client(\"s3\")\n",
        "\n",
        "policy = {\n",
        "    \"Version\": \"2012-10-17\",\n",
        "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
        "    \"Statement\": [\n",
        "        {\n",
        "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
        "            \"Effect\": \"Allow\",\n",
        "            \"Principal\": {\n",
        "                \"Service\": \"personalize.amazonaws.com\"\n",
        "            },\n",
        "            \"Action\": [\n",
        "                \"s3:*Object\",\n",
        "                \"s3:ListBucket\"\n",
        "            ],\n",
        "            \"Resource\": [\n",
        "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
        "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ResponseMetadata': {'RequestId': '039C39BD0ADB3BFE',\n",
              "  'HostId': 'C6i18rymISNGlhn+y6WXKM/YIw/lVDWD6082jKgk3ggJq43St4JOKljBFBSRd07X+1h6jNRczCA=',\n",
              "  'HTTPStatusCode': 204,\n",
              "  'HTTPHeaders': {'x-amz-id-2': 'C6i18rymISNGlhn+y6WXKM/YIw/lVDWD6082jKgk3ggJq43St4JOKljBFBSRd07X+1h6jNRczCA=',\n",
              "   'x-amz-request-id': '039C39BD0ADB3BFE',\n",
              "   'date': 'Thu, 16 Apr 2020 06:48:30 GMT',\n",
              "   'server': 'AmazonS3'},\n",
              "  'RetryAttempts': 0}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4CtiR6iYJ7r"
      },
      "source": [
        "### Create Personalize Role\n",
        "Also Amazon Personalize needs the ability to assume Roles in AWS in order to have the permissions to execute certain tasks, the lines below grant that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV8ia7jJYJ7r",
        "outputId": "129fc6e6-c344-4cbe-e94e-7a33d2406e4d"
      },
      "source": [
        "iam = boto3.client(\"iam\")\n",
        "\n",
        "role_name = \"PersonalizeRoleDevLab\"\n",
        "assume_role_policy_document = {\n",
        "    \"Version\": \"2012-10-17\",\n",
        "    \"Statement\": [\n",
        "        {\n",
        "          \"Effect\": \"Allow\",\n",
        "          \"Principal\": {\n",
        "            \"Service\": \"personalize.amazonaws.com\"\n",
        "          },\n",
        "          \"Action\": \"sts:AssumeRole\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "create_role_response = iam.create_role(\n",
        "    RoleName = role_name,\n",
        "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
        ")\n",
        "\n",
        "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
        "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
        "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
        "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
        "iam.attach_role_policy(\n",
        "    RoleName = role_name,\n",
        "    PolicyArn = policy_arn\n",
        ")\n",
        "\n",
        "# Now add S3 support\n",
        "iam.attach_role_policy(\n",
        "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
        "    RoleName=role_name\n",
        ")\n",
        "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
        "\n",
        "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
        "print(role_arn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arn:aws:iam::931343413930:role/PersonalizeRoleDevLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLb6oC84YJ7t"
      },
      "source": [
        "## Upload dataset to S3\n",
        "\n",
        "Before Personalize can import the data, it needs to be in S3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKLxG4KYJ7t"
      },
      "source": [
        "# Upload Interactions File\n",
        "interactions_file_path = data_dir + \"/\" + interactions_filename\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(interactions_filename).upload_file(interactions_file_path)\n",
        "interactions_s3DataPath = \"s3://\"+bucket_name+\"/\"+interactions_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpyzK67_YJ7u"
      },
      "source": [
        "## Importing the Interactions Data\n",
        "\n",
        "Earlier you created the DatasetGroup and Dataset to house your information, now you will execute an import job that will load the data from S3 into Amazon Personalize for usage building your model.\n",
        "\n",
        "#### Create Dataset Import Job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1FngPBJYJ7u",
        "outputId": "4d5f189f-2e5a-4ecf-8013-dc1415d3e2d4"
      },
      "source": [
        "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
        "    jobName = \"personalize-devlab-import1\",\n",
        "    datasetArn = interactions_dataset_arn,\n",
        "    dataSource = {\n",
        "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
        "    },\n",
        "    roleArn = role_arn\n",
        ")\n",
        "\n",
        "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
        "print(json.dumps(create_dataset_import_job_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-2:931343413930:dataset-import-job/personalize-devlab-import1\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"185c9da7-fa80-4af1-b6ca-ed7dafc83c17\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 06:59:06 GMT\",\n",
            "      \"x-amzn-requestid\": \"185c9da7-fa80-4af1-b6ca-ed7dafc83c17\",\n",
            "      \"content-length\": \"114\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET7p3lQNYJ7v"
      },
      "source": [
        "### CHECKPOINT #2 - Wait for Dataset Import Job to Have ACTIVE Status\n",
        "\n",
        "It can take a while before the import job completes. **Execute the following cell and wait for it to show \"ACTIVE\" before proceeding to the next step.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y16w9gC2YJ7w",
        "outputId": "c91b3910-32cd-433d-e37b-7a72c7ca84b2"
      },
      "source": [
        "current_time = datetime.now()\n",
        "print(\"Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
        "\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
        "        datasetImportJobArn = dataset_import_job_arn\n",
        "    )\n",
        "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
        "    print(\"DatasetImportJob: {}\".format(status))\n",
        "    \n",
        "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
        "        break\n",
        "        \n",
        "    time.sleep(60)\n",
        "\n",
        "current_time = datetime.now()\n",
        "print(\"Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started on:  06:59:09 AM\n",
            "DatasetImportJob: CREATE PENDING\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: CREATE IN_PROGRESS\n",
            "DatasetImportJob: ACTIVE\n",
            "Completed on:  07:11:09 AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoEIVqp2YJ7w"
      },
      "source": [
        "## Create solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWid0wrlYJ70"
      },
      "source": [
        "In this section we will define a solution using the HRNN recipe to generate user personalization recommendation. There are several other recipes available such as HRNN-Metadata, HRNN-Coldstart etc. More information about the additional recipes can be found here:\n",
        "https://docs.aws.amazon.com/personalize/latest/dg/working-with-predefined-recipes.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOqsLWEkYJ70"
      },
      "source": [
        "HRNN_recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8AxBjoXYJ71",
        "outputId": "99fdcc2e-7f87-4e70-810f-f5680c682255"
      },
      "source": [
        "hrnn_create_solution_response = personalize.create_solution(\n",
        "    name = \"personalize-devlab-hrnn\",\n",
        "    datasetGroupArn = dataset_group_arn,\n",
        "    recipeArn = HRNN_recipe_arn\n",
        ")\n",
        "\n",
        "hrnn_solution_arn = hrnn_create_solution_response['solutionArn']\n",
        "print(json.dumps(hrnn_create_solution_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"solutionArn\": \"arn:aws:personalize:us-east-2:931343413930:solution/personalize-devlab-hrnn\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"ab61bc26-fe23-471e-8ebc-9929535840c8\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 07:11:17 GMT\",\n",
            "      \"x-amzn-requestid\": \"ab61bc26-fe23-471e-8ebc-9929535840c8\",\n",
            "      \"content-length\": \"93\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK-eqHBgYJ71"
      },
      "source": [
        "## Create the solution version\n",
        "\n",
        "In this section we will train a solution version using the dataset that we loaded and using the HRNN recipe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUD_T6DYJ72"
      },
      "source": [
        "hrnn_create_solution_version_response = personalize.create_solution_version(\n",
        "    solutionArn = hrnn_solution_arn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkUVxOyNYJ72",
        "outputId": "8fc4e5a3-e536-4088-d132-26b2c2df5a88"
      },
      "source": [
        "hrnn_solution_version_arn = hrnn_create_solution_version_response['solutionVersionArn']\n",
        "print(json.dumps(hrnn_create_solution_version_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-2:931343413930:solution/personalize-devlab-hrnn/960341f6\",\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"007a14cd-6ac0-4248-97a0-5e666c8a03e8\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 07:11:19 GMT\",\n",
            "      \"x-amzn-requestid\": \"007a14cd-6ac0-4248-97a0-5e666c8a03e8\",\n",
            "      \"content-length\": \"109\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdVamw3GYJ72"
      },
      "source": [
        "### CHECKPOINT #3 - Wait for solution version creation to be completed\n",
        "Training the solution version will take some time to complete training. **Execute the following cell and wait for it to show \"ACTIVE\" before proceeding to the next step.**\n",
        "\n",
        "#### Viewing Solution Creation Status\n",
        "\n",
        "You can also view the status updates in the console. To do so,\n",
        "\n",
        "* In another browser tab you should already have the AWS Console up from opening this notebook instance. \n",
        "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
        "* Click `View dataset groups`.\n",
        "* Click the name of your dataset group, most likely something with DevLab in the name.\n",
        "* Click `Solutions and recipes`.\n",
        "* You will now see a list of all of the solutions you created above. Click any one of them. \n",
        "* Note in `Solution versions` the job that is in progress. Once it is `Active` you solution is ready to be reviewed. It is also capable of being deployed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkJvTtvfYJ73",
        "outputId": "5f0b6f62-1fa1-41db-c3f9-2a64a1930c8b"
      },
      "source": [
        "current_time = datetime.now()\n",
        "print(\"Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
        "\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    describe_solution_version_response = personalize.describe_solution_version(\n",
        "        solutionVersionArn = hrnn_solution_version_arn\n",
        "    )\n",
        "    status = describe_solution_version_response[\"solutionVersion\"]['status']\n",
        "    print(\"SolutionVersion Status: {}\".format(status))\n",
        "    \n",
        "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
        "        break\n",
        "        \n",
        "    time.sleep(60)\n",
        "    \n",
        "current_time = datetime.now()\n",
        "print(\"Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started on:  07:11:21 AM\n",
            "SolutionVersion Status: CREATE PENDING\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: CREATE IN_PROGRESS\n",
            "SolutionVersion Status: ACTIVE\n",
            "Completed on:  07:45:24 AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3qg6QyGYJ73"
      },
      "source": [
        "## Evaluate solution metrics\n",
        "\n",
        "In this section we will run the function to get the solution metrics. More information about the Personalize solution metrics can be found here: https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFA2CKFFYJ74",
        "outputId": "d358e73b-bf26-4b94-eeda-c3f277d19efb"
      },
      "source": [
        "hrnn_solution_metrics_response = personalize.get_solution_metrics(\n",
        "    solutionVersionArn = hrnn_solution_version_arn\n",
        ")\n",
        "\n",
        "print(json.dumps(hrnn_solution_metrics_response, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-2:931343413930:solution/personalize-devlab-hrnn/960341f6\",\n",
            "  \"metrics\": {\n",
            "    \"coverage\": 0.0149,\n",
            "    \"mean_reciprocal_rank_at_25\": 0.0241,\n",
            "    \"normalized_discounted_cumulative_gain_at_10\": 0.0267,\n",
            "    \"normalized_discounted_cumulative_gain_at_25\": 0.0544,\n",
            "    \"normalized_discounted_cumulative_gain_at_5\": 0.0174,\n",
            "    \"precision_at_10\": 0.0091,\n",
            "    \"precision_at_25\": 0.0095,\n",
            "    \"precision_at_5\": 0.0109\n",
            "  },\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"85884607-49b5-44a8-9459-83a61b954ade\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"content-type\": \"application/x-amz-json-1.1\",\n",
            "      \"date\": \"Thu, 16 Apr 2020 07:45:56 GMT\",\n",
            "      \"x-amzn-requestid\": \"85884607-49b5-44a8-9459-83a61b954ade\",\n",
            "      \"content-length\": \"407\",\n",
            "      \"connection\": \"keep-alive\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-da6aESYJ74"
      },
      "source": [
        "## Batch Recommendation\n",
        "In the section, we will generate a random sample of users to generate batch recommendations for.\n",
        "\n",
        "First, we will load the movie database so that we can visualize the recommended movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XleAFQtLYJ75",
        "outputId": "460b115c-55c2-4609-bdf2-a9ebec30ceef"
      },
      "source": [
        "# Create a dataframe for the items by reading in the correct source CSV.\n",
        "items_df = pd.read_csv(data_dir + '/ml-latest-small/movies.csv', index_col=0)\n",
        "# Render some sample data\n",
        "items_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title  \\\n",
              "movieId                                       \n",
              "1                          Toy Story (1995)   \n",
              "2                            Jumanji (1995)   \n",
              "3                   Grumpier Old Men (1995)   \n",
              "4                  Waiting to Exhale (1995)   \n",
              "5        Father of the Bride Part II (1995)   \n",
              "\n",
              "                                              genres  \n",
              "movieId                                               \n",
              "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
              "2                         Adventure|Children|Fantasy  \n",
              "3                                     Comedy|Romance  \n",
              "4                               Comedy|Drama|Romance  \n",
              "5                                             Comedy  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju4euVo6YJ76"
      },
      "source": [
        "# Create a function to get movie by id\n",
        "def get_movie_by_id(movie_id, movie_df=items_df):\n",
        "    try:\n",
        "        return movie_df.loc[int(movie_id)]['title'] + \" - \" + movie_df.loc[int(movie_id)]['genres']\n",
        "    except:\n",
        "        return \"Error obtaining movie\" + movie_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H66T7iIVYJ76"
      },
      "source": [
        "# Get the user list\n",
        "users_df = pd.read_csv(data_dir + '/ml-latest-small/ratings.csv', index_col=0)\n",
        "\n",
        "batch_users = users_df.sample(3).index.tolist()\n",
        "\n",
        "# Write the file to disk\n",
        "json_input_filename = \"json_input.json\"\n",
        "with open(data_dir + \"/\" + json_input_filename, 'w') as json_input:\n",
        "    for user_id in batch_users:\n",
        "        json_input.write('{\"userId\": \"' + str(user_id) + '\"}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHRqcOsGYJ76",
        "outputId": "f344c548-1e89-4d80-8a2c-07edf69f1d5d"
      },
      "source": [
        "# Showcase the input file:\n",
        "!cat $data_dir\"/\"$json_input_filename"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"userId\": \"302\"}\n",
            "{\"userId\": \"393\"}\n",
            "{\"userId\": \"57\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Mb6WlCYJ77"
      },
      "source": [
        "Upload the users generate batch recommendations for to S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXpiDDB_YJ77",
        "outputId": "8793787e-8ed0-4cd8-db30-366c55c8489e"
      },
      "source": [
        "# Upload files to S3\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(json_input_filename).upload_file(data_dir+\"/\"+json_input_filename)\n",
        "s3_input_path = \"s3://\" + bucket_name + \"/\" + json_input_filename\n",
        "print(s3_input_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s3://931343413930personalizedevlab/json_input.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIUfX7ZkYJ78"
      },
      "source": [
        "In the next cell, we define output bucket of where we will store the batch recommendation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71Z7gAiYJ78",
        "outputId": "aad75e6f-2cb9-4016-f236-814f5f672f91"
      },
      "source": [
        "# Define the output path\n",
        "s3_output_path = \"s3://\" + bucket_name + \"/\"\n",
        "print(s3_output_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s3://931343413930personalizedevlab/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtDmY1PeYJ78"
      },
      "source": [
        "Run the batch inference process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNDv1zsYJ79"
      },
      "source": [
        "current_time = datetime.now()\n",
        "batchInferenceJobArn = personalize.create_batch_inference_job (\n",
        "    solutionVersionArn = hrnn_solution_version_arn,\n",
        "    jobName = \"Personalize-devlab-Batch-Inference-Job-HRNN\"+current_time.strftime(\"%I%M%S\"),\n",
        "    roleArn = role_arn,\n",
        "    jobInput = \n",
        "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
        "    jobOutput = \n",
        "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
        ")\n",
        "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8yqiKFOYJ79"
      },
      "source": [
        "### CHECKPOINT #4 - Wait for batch recommendation job to complete\n",
        "\n",
        "It can take a while before the batch recommendation job completes. **Execute the following cell and wait for it to show \"ACTIVE\" before proceeding to the next step.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i87sKMrNYJ7-",
        "outputId": "dfd20926-7d21-4042-9a7f-578a6896f68a"
      },
      "source": [
        "current_time = datetime.now()\n",
        "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
        "\n",
        "max_time = time.time() + 3*60*60 # 3 hours\n",
        "while time.time() < max_time:\n",
        "    describe_dataset_inference_job_response = personalize.describe_batch_inference_job(\n",
        "        batchInferenceJobArn = batchInferenceJobArn\n",
        "    )\n",
        "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
        "    print(\"DatasetInferenceJob: {}\".format(status))\n",
        "    \n",
        "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
        "        break\n",
        "        \n",
        "    time.sleep(60)\n",
        "    \n",
        "current_time = datetime.now()\n",
        "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import Started on:  07:49:42 AM\n",
            "DatasetInferenceJob: CREATE PENDING\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: CREATE IN_PROGRESS\n",
            "DatasetInferenceJob: ACTIVE\n",
            "Import Completed on:  08:14:43 AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ndY8QdYJ7-"
      },
      "source": [
        "**Download and Visualize batch recommendation**\n",
        "\n",
        "Once the batch recommendation job has been completed, we will now download and visualize the results from the batch job.\n",
        "\n",
        "The results of the batch job will be stored in the S3 output folder that was specified earlier. It will be returned in a json format similar to the following:\n",
        "\n",
        "```\n",
        "{\"input\":{\"userId\":\"448\"},\"output\":{\"recommendedItems\":[\"5810\",\"53322\",\"2003\",\"6957\",\"92535\",\"8917\",\"3105\",\"6873\",\"1249\",\"26133\",\"2657\",\"4865\",\"2420\",\"1345\",\"4621\",\"34437\",\"2010\",\"4128\",\"2076\",\"1203\",\"52973\",\"4246\",\"2871\",\"8641\",\"162\"],\"scores\":[0.0031413,0.0022093,0.0021377,0.0020497,0.001922,0.0018058,0.0017834,0.0017671,0.0017457,0.0016255,0.0015854,0.001539,0.0014838,0.0014573,0.001374,0.001372,0.0013563,0.0013385,0.0013196,0.0013065,0.0012714,0.0012507,0.001228,0.0012243,0.0012083]},\"error\":null}\n",
        "{\"input\":{\"userId\":\"409\"},\"output\":{\"recommendedItems\":[\"2571\",\"50\",\"527\",\"296\",\"1196\",\"111\",\"110\",\"1258\",\"2858\",\"1214\",\"6874\",\"1265\",\"648\",\"750\",\"912\",\"588\",\"608\",\"2329\",\"858\",\"2762\",\"1291\",\"541\",\"1387\",\"260\",\"1200\"],\"scores\":[0.0151337,0.0129099,0.0094722,0.0081178,0.0070135,0.0061934,0.0059672,0.0049986,0.0048773,0.0048134,0.0046837,0.0044422,0.0044251,0.0042917,0.0042376,0.0042309,0.0039795,0.0038287,0.0037793,0.0036532,0.0036527,0.0035218,0.0035178,0.0034306,0.0034158]},\"error\":null}\n",
        "{\"input\":{\"userId\":\"288\"},\"output\":{\"recommendedItems\":[\"5989\",\"49272\",\"6377\",\"4963\",\"4995\",\"68157\",\"4886\",\"48394\",\"8368\",\"80463\",\"54001\",\"8961\",\"91658\",\"8950\",\"5418\",\"5445\",\"109374\",\"8360\",\"1136\",\"81834\",\"5618\",\"1265\",\"48780\",\"8949\",\"4720\"],\"scores\":[0.0177912,0.0114374,0.0107343,0.0098669,0.009329,0.0067548,0.0057784,0.0057611,0.0056522,0.0053493,0.0050671,0.0050291,0.0047089,0.0046453,0.0045933,0.0045281,0.0041894,0.0040642,0.0040296,0.003935,0.0037718,0.0036896,0.0036616,0.0036362,0.0036019]},\"error\":null}\n",
        "\n",
        "```\n",
        "\n",
        "An typical use case for this is to use the batch recommendation output to generate a personalized recommendation email that can be fed into a popular email marketing service such as **[Amazon Pinpoint](https://aws.amazon.com/pinpoint/)** or your favourate email marketing service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCoA3l3uYJ7_",
        "outputId": "4f53dbbe-3485-4a82-9c6f-80b6037e22d2"
      },
      "source": [
        "s3 = boto3.client('s3')\n",
        "export_name = json_input_filename + \".out\"\n",
        "s3.download_file(bucket_name, export_name, data_dir+\"/\"+export_name)\n",
        "\n",
        "# Update DF rendering\n",
        "pd.set_option('display.max_rows', 30)\n",
        "with open(data_dir+\"/\"+export_name) as json_file:\n",
        "    # Get the first line and parse it\n",
        "    line = json.loads(json_file.readline())\n",
        "    # Do the same for the other lines\n",
        "    while line:\n",
        "        # extract the user ID \n",
        "        col_header = \"User: \" + line['input']['userId']\n",
        "        # Create a list for all the artists\n",
        "        recommendation_list = []\n",
        "        # Add all the entries\n",
        "        for item in line['output']['recommendedItems']:\n",
        "            movie = get_movie_by_id(item)\n",
        "            recommendation_list.append(movie)\n",
        "        if 'bulk_recommendations_df' in locals():\n",
        "            new_rec_DF = pd.DataFrame(recommendation_list, columns = [col_header])\n",
        "            bulk_recommendations_df = bulk_recommendations_df.join(new_rec_DF)\n",
        "        else:\n",
        "            bulk_recommendations_df = pd.DataFrame(recommendation_list, columns=[col_header])\n",
        "        try:\n",
        "            line = json.loads(json_file.readline())\n",
        "        except:\n",
        "            line = None\n",
        "bulk_recommendations_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User: 302</th>\n",
              "      <th>User: 393</th>\n",
              "      <th>User: 57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Braveheart (1995) - Action|Drama|War</td>\n",
              "      <td>Star Trek: First Contact (1996) - Action|Adven...</td>\n",
              "      <td>Pulp Fiction (1994) - Comedy|Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Raiders of the Lost Ark (Indiana Jones and the...</td>\n",
              "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
              "      <td>Star Trek: First Contact (1996) - Action|Adven...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
              "      <td>Pulp Fiction (1994) - Comedy|Crime|Drama|Thriller</td>\n",
              "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Seven (a.k.a. Se7en) (1995) - Mystery|Thriller</td>\n",
              "      <td>Heat (1995) - Action|Crime|Thriller</td>\n",
              "      <td>Heat (1995) - Action|Crime|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Die Hard: With a Vengeance (1995) - Action|Cri...</td>\n",
              "      <td>2001: A Space Odyssey (1968) - Adventure|Drama...</td>\n",
              "      <td>X-Men (2000) - Action|Adventure|Sci-Fi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Shawshank Redemption, The (1994) - Crime|Drama</td>\n",
              "      <td>Shrek (2001) - Adventure|Animation|Children|Co...</td>\n",
              "      <td>2001: A Space Odyssey (1968) - Adventure|Drama...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Terminator 2: Judgment Day (1991) - Action|Sci-Fi</td>\n",
              "      <td>Avatar (2009) - Action|Adventure|Sci-Fi|IMAX</td>\n",
              "      <td>Forrest Gump (1994) - Comedy|Drama|Romance|War</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Jurassic Park (1993) - Action|Adventure|Sci-Fi...</td>\n",
              "      <td>Fifth Element, The (1997) - Action|Adventure|C...</td>\n",
              "      <td>Avatar (2009) - Action|Adventure|Sci-Fi|IMAX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Star Wars: Episode IV - A New Hope (1977) - Ac...</td>\n",
              "      <td>X-Men (2000) - Action|Adventure|Sci-Fi</td>\n",
              "      <td>Fifth Element, The (1997) - Action|Adventure|C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Schindler's List (1993) - Drama|War</td>\n",
              "      <td>Dead Poets Society (1989) - Drama</td>\n",
              "      <td>Dead Poets Society (1989) - Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
              "      <td>Harry Potter and the Chamber of Secrets (2002)...</td>\n",
              "      <td>Shrek (2001) - Adventure|Animation|Children|Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Indiana Jones and the Last Crusade (1989) - Ac...</td>\n",
              "      <td>Green Mile, The (1999) - Crime|Drama</td>\n",
              "      <td>Harry Potter and the Chamber of Secrets (2002)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Gladiator (2000) - Action|Adventure|Drama</td>\n",
              "      <td>Rear Window (1954) - Mystery|Thriller</td>\n",
              "      <td>Rear Window (1954) - Mystery|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Crimson Tide (1995) - Drama|Thriller|War</td>\n",
              "      <td>Ratatouille (2007) - Animation|Children|Drama</td>\n",
              "      <td>Bourne Identity, The (2002) - Action|Mystery|T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Star Wars: Episode VI - Return of the Jedi (19...</td>\n",
              "      <td>28 Days Later (2002) - Action|Horror|Sci-Fi</td>\n",
              "      <td>Willy Wonka &amp; the Chocolate Factory (1971) - C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Usual Suspects, The (1995) - Crime|Mystery|Thr...</td>\n",
              "      <td>Spider-Man (2002) - Action|Adventure|Sci-Fi|Th...</td>\n",
              "      <td>Green Mile, The (1999) - Crime|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fugitive, The (1993) - Thriller</td>\n",
              "      <td>Inside Out (2015) - Adventure|Animation|Childr...</td>\n",
              "      <td>Patriot, The (2000) - Action|Drama|War</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Saving Private Ryan (1998) - Action|Drama|War</td>\n",
              "      <td>Dark Knight Rises, The (2012) - Action|Adventu...</td>\n",
              "      <td>Spider-Man (2002) - Action|Adventure|Sci-Fi|Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Aladdin (1992) - Adventure|Animation|Children|...</td>\n",
              "      <td>Patriot, The (2000) - Action|Drama|War</td>\n",
              "      <td>Indiana Jones and the Temple of Doom (1984) - ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Silence of the Lambs, The (1991) - Crime|Horro...</td>\n",
              "      <td>Scarface (1983) - Action|Crime|Drama</td>\n",
              "      <td>Ratatouille (2007) - Animation|Children|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>True Lies (1994) - Action|Adventure|Comedy|Rom...</td>\n",
              "      <td>Bourne Identity, The (2002) - Action|Mystery|T...</td>\n",
              "      <td>Breakfast Club, The (1985) - Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Lion King, The (1994) - Adventure|Animation|Ch...</td>\n",
              "      <td>Forrest Gump (1994) - Comedy|Drama|Romance|War</td>\n",
              "      <td>Die Hard (1988) - Action|Crime|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Inception (2010) - Action|Crime|Drama|Mystery|...</td>\n",
              "      <td>Beautiful Mind, A (2001) - Drama|Romance</td>\n",
              "      <td>Beautiful Mind, A (2001) - Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Dark Knight, The (2008) - Action|Crime|Drama|IMAX</td>\n",
              "      <td>Breakfast Club, The (1985) - Comedy|Drama</td>\n",
              "      <td>Dark Knight Rises, The (2012) - Action|Adventu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Die Hard (1988) - Action|Crime|Thriller</td>\n",
              "      <td>Willy Wonka &amp; the Chocolate Factory (1971) - C...</td>\n",
              "      <td>Spirited Away (Sen to Chihiro no kamikakushi) ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            User: 302  \\\n",
              "0                Braveheart (1995) - Action|Drama|War   \n",
              "1   Raiders of the Lost Ark (Indiana Jones and the...   \n",
              "2   Lord of the Rings: The Fellowship of the Ring,...   \n",
              "3      Seven (a.k.a. Se7en) (1995) - Mystery|Thriller   \n",
              "4   Die Hard: With a Vengeance (1995) - Action|Cri...   \n",
              "5      Shawshank Redemption, The (1994) - Crime|Drama   \n",
              "6   Terminator 2: Judgment Day (1991) - Action|Sci-Fi   \n",
              "7   Jurassic Park (1993) - Action|Adventure|Sci-Fi...   \n",
              "8   Star Wars: Episode IV - A New Hope (1977) - Ac...   \n",
              "9                 Schindler's List (1993) - Drama|War   \n",
              "10  Star Wars: Episode V - The Empire Strikes Back...   \n",
              "11  Indiana Jones and the Last Crusade (1989) - Ac...   \n",
              "12          Gladiator (2000) - Action|Adventure|Drama   \n",
              "13           Crimson Tide (1995) - Drama|Thriller|War   \n",
              "14  Star Wars: Episode VI - Return of the Jedi (19...   \n",
              "15  Usual Suspects, The (1995) - Crime|Mystery|Thr...   \n",
              "16                    Fugitive, The (1993) - Thriller   \n",
              "17      Saving Private Ryan (1998) - Action|Drama|War   \n",
              "18  Aladdin (1992) - Adventure|Animation|Children|...   \n",
              "19  Silence of the Lambs, The (1991) - Crime|Horro...   \n",
              "20  True Lies (1994) - Action|Adventure|Comedy|Rom...   \n",
              "21  Lion King, The (1994) - Adventure|Animation|Ch...   \n",
              "22  Inception (2010) - Action|Crime|Drama|Mystery|...   \n",
              "23  Dark Knight, The (2008) - Action|Crime|Drama|IMAX   \n",
              "24            Die Hard (1988) - Action|Crime|Thriller   \n",
              "\n",
              "                                            User: 393  \\\n",
              "0   Star Trek: First Contact (1996) - Action|Adven...   \n",
              "1   Harry Potter and the Sorcerer's Stone (a.k.a. ...   \n",
              "2   Pulp Fiction (1994) - Comedy|Crime|Drama|Thriller   \n",
              "3                 Heat (1995) - Action|Crime|Thriller   \n",
              "4   2001: A Space Odyssey (1968) - Adventure|Drama...   \n",
              "5   Shrek (2001) - Adventure|Animation|Children|Co...   \n",
              "6        Avatar (2009) - Action|Adventure|Sci-Fi|IMAX   \n",
              "7   Fifth Element, The (1997) - Action|Adventure|C...   \n",
              "8              X-Men (2000) - Action|Adventure|Sci-Fi   \n",
              "9                   Dead Poets Society (1989) - Drama   \n",
              "10  Harry Potter and the Chamber of Secrets (2002)...   \n",
              "11               Green Mile, The (1999) - Crime|Drama   \n",
              "12              Rear Window (1954) - Mystery|Thriller   \n",
              "13      Ratatouille (2007) - Animation|Children|Drama   \n",
              "14        28 Days Later (2002) - Action|Horror|Sci-Fi   \n",
              "15  Spider-Man (2002) - Action|Adventure|Sci-Fi|Th...   \n",
              "16  Inside Out (2015) - Adventure|Animation|Childr...   \n",
              "17  Dark Knight Rises, The (2012) - Action|Adventu...   \n",
              "18             Patriot, The (2000) - Action|Drama|War   \n",
              "19               Scarface (1983) - Action|Crime|Drama   \n",
              "20  Bourne Identity, The (2002) - Action|Mystery|T...   \n",
              "21     Forrest Gump (1994) - Comedy|Drama|Romance|War   \n",
              "22           Beautiful Mind, A (2001) - Drama|Romance   \n",
              "23          Breakfast Club, The (1985) - Comedy|Drama   \n",
              "24  Willy Wonka & the Chocolate Factory (1971) - C...   \n",
              "\n",
              "                                             User: 57  \n",
              "0   Pulp Fiction (1994) - Comedy|Crime|Drama|Thriller  \n",
              "1   Star Trek: First Contact (1996) - Action|Adven...  \n",
              "2   Harry Potter and the Sorcerer's Stone (a.k.a. ...  \n",
              "3                 Heat (1995) - Action|Crime|Thriller  \n",
              "4              X-Men (2000) - Action|Adventure|Sci-Fi  \n",
              "5   2001: A Space Odyssey (1968) - Adventure|Drama...  \n",
              "6      Forrest Gump (1994) - Comedy|Drama|Romance|War  \n",
              "7        Avatar (2009) - Action|Adventure|Sci-Fi|IMAX  \n",
              "8   Fifth Element, The (1997) - Action|Adventure|C...  \n",
              "9                   Dead Poets Society (1989) - Drama  \n",
              "10  Shrek (2001) - Adventure|Animation|Children|Co...  \n",
              "11  Harry Potter and the Chamber of Secrets (2002)...  \n",
              "12              Rear Window (1954) - Mystery|Thriller  \n",
              "13  Bourne Identity, The (2002) - Action|Mystery|T...  \n",
              "14  Willy Wonka & the Chocolate Factory (1971) - C...  \n",
              "15               Green Mile, The (1999) - Crime|Drama  \n",
              "16             Patriot, The (2000) - Action|Drama|War  \n",
              "17  Spider-Man (2002) - Action|Adventure|Sci-Fi|Th...  \n",
              "18  Indiana Jones and the Temple of Doom (1984) - ...  \n",
              "19      Ratatouille (2007) - Animation|Children|Drama  \n",
              "20          Breakfast Club, The (1985) - Comedy|Drama  \n",
              "21            Die Hard (1988) - Action|Crime|Thriller  \n",
              "22           Beautiful Mind, A (2001) - Drama|Romance  \n",
              "23  Dark Knight Rises, The (2012) - Action|Adventu...  \n",
              "24  Spirited Away (Sen to Chihiro no kamikakushi) ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmYuYJj2YJ7_"
      },
      "source": [
        "Congratulations, you have now completed the lab. You can either continue to the challenge section to see if you can improve the model by using a larger dataset or proceed to the cleanup section to delete the resources from this lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlqVkxe6YJ8A"
      },
      "source": [
        "## Challenge\n",
        "Before wrapping up the lab, let's see if you can try and improve the recommendation accuracy by usingn the large dataset from [movielens](https://grouplens.org/datasets/movielens/).\n",
        "\n",
        "You can use the same dataset group, however, please note that you don't need to redefine the data set schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWubD_JCYJ8A"
      },
      "source": [
        "## Cleanup\n",
        "\n",
        "**IMPORTANT**\n",
        "Once you're done with the lab, the final step is to clean up your environment by decommissioning the resources we created for this devlab. Please run the following cells in the following order to clean up your environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moVOx3PjYJ8A"
      },
      "source": [
        "**1. Delete the solution**\n",
        "\n",
        "Delete the HRNN solution we created for the Personalize dataset group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ua9goKhYJ8B"
      },
      "source": [
        "personalize.delete_solution(\n",
        "    solutionArn = hrnn_solution_arn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDq7eQ_vYJ8B"
      },
      "source": [
        "**2. Delete the dataset**\n",
        "\n",
        "Delete the datasets created for the personalize dataset group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMsJbY0YJ8B"
      },
      "source": [
        "personalize.delete_dataset(\n",
        "    datasetArn = dataset_arn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZNWAFvFYJ8B"
      },
      "source": [
        "Run the following cell to verify that non-required dataset has been deleted and if required run the subsequent cell with the correct ARN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v04CD74DYJ8B"
      },
      "source": [
        "paginator = personalize.get_paginator('list_datasets')\n",
        "for paginate_result in paginator.paginate():\n",
        "    for datasets in paginate_result[\"datasets\"]:\n",
        "        print(datasets[\"datasetArn\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hBY--ZKYJ8C"
      },
      "source": [
        "# Replace the ARN and run the following cell to delete any additional datasets\n",
        "personalize.delete_dataset(\n",
        "    datasetArn = \"INSERT ARN HERE\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYFJ9JMZYJ8C"
      },
      "source": [
        "**3. Delete the schema**\n",
        "\n",
        "Delete the personalize schema used for the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmoPLnMOYJ8C"
      },
      "source": [
        "personalize.delete_schema(\n",
        "    schemaArn = schema_arn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ys-Xp1uYJ8C"
      },
      "source": [
        "Run the following cell to verify that non-required schema has been deleted and if required run the subsequent cell with the correct ARN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS5oNjo6YJ8D"
      },
      "source": [
        "paginator = personalize.get_paginator('list_schemas')\n",
        "for paginate_result in paginator.paginate():\n",
        "    for schema in paginate_result[\"schemas\"]:\n",
        "        print(schema[\"schemaArn\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTpZYNP3YJ8E"
      },
      "source": [
        "# Replace the ARN and run the following cell to delete any additional schema\n",
        "personalize.delete_schema(\n",
        "    schemaArn = \"INSERT ARN HERE\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Ln05nxYJ8F"
      },
      "source": [
        "**4. Delete the dataset group**\n",
        "\n",
        "Deletes the personalize dataset group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBGFw8FVYJ8G"
      },
      "source": [
        "personalize.delete_dataset_group(\n",
        "    datasetGroupArn = dataset_group_arn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBVledKNYJ8G"
      },
      "source": [
        "**5. Detach the policy from the personalize devlab role**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P8BZiasYJ8G"
      },
      "source": [
        "iam.detach_role_policy(\n",
        "    RoleName = \"PersonalizeRoleDevLab\",\n",
        "    PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2EQRaEYJ8H"
      },
      "source": [
        "iam.detach_role_policy(\n",
        "    RoleName = \"PersonalizeRoleDevLab\",\n",
        "    PolicyArn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPQcf158YJ8H"
      },
      "source": [
        "Check that all policies have been detached from the role, if not run the subsequent cell to detached the appropriate roles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vzDRK8tYJ8H"
      },
      "source": [
        "# Lists all policities attached to the personalize devlab role\n",
        "iam.list_attached_role_policies(\n",
        "    RoleName = \"PersonalizeRoleDevLab\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T514IOjdYJ8I"
      },
      "source": [
        "# Detach policy from rule\n",
        "iam.detach_role_policy(\n",
        "    RoleName = \"PersonalizeRoleDevLab\",\n",
        "    PolicyArn = \"INSERT ARN HERE\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RUp0f5HYJ8I"
      },
      "source": [
        "**6. Delete the IAM role**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYTJ_edLYJ8J"
      },
      "source": [
        "iam.delete_role(\n",
        "    RoleName = \"PersonalizeRoleDevLab\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}