{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "efcc6a0b-3f6d-4ec3-8434-e59ee6748c78",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpkJPaPKLMp7"
      },
      "source": [
        "## UNIX deployed version\n",
        "- **Model**: Logistic regression\n",
        "- **Encoding**: Onehot sparse\n",
        "- **Model explainer**: LIME (Local Interpretable Model-Agnostic Explanations)\n",
        "- **Server address**: http://[ip]:5000/predict\n",
        "\n",
        "\n",
        "#### API consuming variables\n",
        "[[redacted]]\n",
        "\n",
        "\n",
        "#### Model consuming variables\n",
        "[[redacted]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJDU0AFDLMp8"
      },
      "source": [
        "source_files = '/local_home/ml/output/'\n",
        "server_ip = [ip]\n",
        "server_port = 5000\n",
        "\n",
        "# #### windows >>>>\n",
        "# source_files = 'Automation/output/'\n",
        "# server_ip = [ip]\n",
        "# server_port = 8000\n",
        "\n",
        "from flask import Flask, request, render_template, jsonify, make_response, abort\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.externals import joblib\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "import datetime\n",
        "import dill\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "############ Error Handling ############\n",
        "class BaseError(Exception):\n",
        "    \"\"\"Base Error Class\"\"\"\n",
        "\n",
        "    def __init__(self, code=400, message='', detail='', status='', exceptioncode=None):\n",
        "        Exception.__init__(self)\n",
        "        self.code = code\n",
        "        self.message = message\n",
        "        self.status = status\n",
        "        self.detail = detail\n",
        "        self.exceptioncode = exceptioncode\n",
        "\n",
        "    def to_dict(self):\n",
        "        return jsonify({\"exceptions\": {\"type\":\"E\", \"code\":self.code, \"message\":self.message, \"detail\":self.detail, \"exceptioncode\":self.exceptioncode}})\n",
        "\n",
        "class ValidationError(BaseError):\n",
        "    def __init__(self, message='X', detail='Mandatory input parameter Id is missing in the Request.', custom_msg=0):\n",
        "        BaseError.__init__(self)\n",
        "        self.code = 400\n",
        "        self.status = ''\n",
        "        self.exceptioncode = 4000\n",
        "        self.message = message\n",
        "        if custom_msg==0:\n",
        "            self.detail = 'Mandatory input parameter ' + detail + ' is invalid.'\n",
        "        else:\n",
        "            self.detail = detail\n",
        "\n",
        "class ServerError(BaseError):\n",
        "    def __init__(self, message='Internal server error'):\n",
        "        BaseError.__init__(self)\n",
        "        self.code = 500\n",
        "        self.message = message\n",
        "        self.status = 'SERVER_ERROR'\n",
        "\n",
        "@app.errorhandler(ServerError)\n",
        "@app.errorhandler(ValidationError)\n",
        "def handle_error(error):\n",
        "    return error.to_dict(), getattr(error, 'code')\n",
        "\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    ################# data-loading #################\n",
        "    try:\n",
        "        test_json = request.get_json()\n",
        "        if(type(test_json)==str):\n",
        "            data = pd.read_json(test_json, orient='records')\n",
        "        else:\n",
        "            data = pd.DataFrame.from_dict(test_json, orient='columns')\n",
        "\n",
        "        api_collist = [[redacted]]\n",
        "        data = data[api_collist]\n",
        "        \n",
        "    except Exception as e:\n",
        "        m = re.search(\"'([^']*)'\", repr(e))\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail=str(key), custom_msg=0)\n",
        "\n",
        "    model_collist = [[redacted]]\n",
        "    data = data[model_collist]\n",
        "    \n",
        "    ################# data-preprocessing #################\n",
        "    \n",
        "    #convert empty values to null\n",
        "    data = data.replace(r'^\\s*$', np.nan, regex=True)\n",
        "    \n",
        "    #removing whitespace\n",
        "    data['A'] = data['A'].str.strip()\n",
        "    data['B'] = data['B'].str.strip()\n",
        "    data['C'] = data['C'].str.strip()\n",
        "    \n",
        "    #null values data-validation\n",
        "    for column in data:\n",
        "        if data[column].isnull().any():\n",
        "            raise ValidationError(detail='Mandatory input parameter '+ str(column) +' contains null value', custom_msg=1)\n",
        "    \n",
        "    #drop duplicate records\n",
        "    data = data.drop_duplicates(subset=['D'], keep='first')\n",
        "\n",
        "    #change\n",
        "    try:\n",
        "        data['E'] =  pd.to_datetime(data['E'], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "        data['E'] = (datetime.datetime.now() - data['E']).astype('<m8[Y]')\n",
        "        data = data.drop('E', axis=1)\n",
        "    except Exception as e:\n",
        "        m = re.search(\"time data (.*) doesn't match format specified\", str(e))\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail='datetime format '+ str(key) +' is invalid. Correct format is YYYY-MM-DD HH:MM:SS', custom_msg=1)\n",
        "\n",
        "    #combine 3 request_type INPATIENT categories into single category\n",
        "    try:\n",
        "        data['x'] = data['x'].replace(['x-x', 'x-x x', 'x-x'], 'x')\n",
        "        data['x'] = data['x'].str.upper()\n",
        "    except:\n",
        "        raise ValidationError(detail='x')\n",
        "\n",
        "    #invalid-datatypes\n",
        "    try:\n",
        "        data['x'] = data['x'].astype(np.int64)\n",
        "    except Exception as e:\n",
        "        raise ValidationError(detail='x')\n",
        "    \n",
        "    try:\n",
        "        data['x'] = data['x'].astype(np.int64)\n",
        "    except Exception as e:\n",
        "        raise ValidationError(detail='x')\n",
        "\n",
        "    proc_ids = data.pop('x')\n",
        "    \n",
        "    \n",
        "    ################# data-encoding #################\n",
        "\n",
        "    categorical_features = [0,1,2,3,4,5,6,7,8,9,10,11,13]\n",
        "    categorical_names = {}\n",
        "    for feature in categorical_features:\n",
        "        try:\n",
        "            le = joblib.load(source_files+str(feature)+'.joblib')\n",
        "            data.iloc[:, feature] = le.transform(data.iloc[:, feature].values)\n",
        "            categorical_names[feature] = le.classes_\n",
        "        except Exception as e:\n",
        "            class_namex = list(data.columns)[feature]\n",
        "            raise ValidationError(detail = str(class_namex))\n",
        "    data = data.astype(float)\n",
        "\n",
        "    try:\n",
        "        #onehot encoding\n",
        "        encoder = joblib.load(source_files+'ohe.joblib')\n",
        "        encoded_data = encoder.transform(data)\n",
        "    except Exception as e:\n",
        "        m = re.search(\"'([^']*)'\", repr(e))\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail=str(key), custom_msg=0)\n",
        "\n",
        "        \n",
        "    ################# data-prediction #################\n",
        "    try:\n",
        "        logmodel = joblib.load(source_files+'logistic_model.joblib')\n",
        "        predictions = logmodel.predict(encoder.transform(data)).astype(float)\n",
        "        predictions_prob = logmodel.predict_proba(encoder.transform(data)).astype(float)\n",
        "        for i,val in enumerate(predictions):\n",
        "            if val==0:\n",
        "                predictions_prob[i] = predictions_prob[i,0]\n",
        "            elif val==1:\n",
        "                predictions_prob[i] = predictions_prob[i,1]\n",
        "        mydict = {0: 'x', 1: 'y'}\n",
        "        predictions_mapped = [mydict.get(n, n) for n in predictions]\n",
        "        predictions = predictions_mapped\n",
        "        confidence = np.round(predictions_prob[:,0]*100,2)\n",
        "        \n",
        "        df = pd.DataFrame({'x':proc_ids, 'decision':predictions, 'confidence':confidence})\n",
        "    except Exception as e:\n",
        "        m = re.search(\"'([^']*)'\", repr(e))\n",
        "        print(m)\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail=str(key), custom_msg=0)\n",
        "    \n",
        "    \n",
        "    ################# data-explanation #################\n",
        "    try:        \n",
        "        with open(source_files+'logistic_lime_explainer.pickle', 'rb') as f:\n",
        "            explainer = dill.load(f)\n",
        "        predict_fn = lambda x: logmodel.predict_proba(encoder.transform(x)).astype(float)\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            exp = explainer.explain_instance(data.iloc[i], predict_fn, num_features=18)\n",
        "            y = pd.DataFrame(exp.as_list(), columns=['key', 'value'])\n",
        "            scores = y.sort_values(by='value', ascending=False).reset_index(drop=True).iloc[0:5]\n",
        "            keyval = scores[\"key\"].str.split(\"=\", n=1, expand=True)\n",
        "            #df.loc[i,'significantVariableInfo'] = [scores.set_index('key')['value'].to_dict()]\n",
        "            df.loc[i,'significantVariableInfo'] = [keyval.set_index(0)[1].to_dict()]\n",
        "    except Exception as e:\n",
        "        m = re.search(\"'([^']*)'\", repr(e))\n",
        "        print(m)\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail=str(key), custom_msg=0)\n",
        "        \n",
        "        \n",
        "    ################# Sending-back response in JSON #################\n",
        "    try:\n",
        "        response_json_string = pd.DataFrame()\n",
        "        response_json_string = df.to_json(orient=\"records\")\n",
        "        response_json_dict = ast.literal_eval(response_json_string)\n",
        "        responses = jsonify(prediction = response_json_dict)\n",
        "        return(responses)\n",
        "    except Exception as e:\n",
        "        m = re.search(\"'([^']*)'\", repr(e))\n",
        "        print(m)\n",
        "        key = m.group(1)\n",
        "        raise ValidationError(detail=str(key), custom_msg=0)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host=server_ip, port=server_port)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}