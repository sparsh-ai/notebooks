{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.dcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCN\n",
    "> A pytorch implementation of Deep & Cross Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Any, Iterable, List, Optional, Tuple, Union, Callable\n",
    "\n",
    "from recohut.models.layers.common import MLP_Layer\n",
    "from recohut.models.layers.embedding import EmbeddingLayer\n",
    "from recohut.models.bases.ctr import CTRModel\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class CrossNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_net = nn.ModuleList(CrossInteractionLayer(input_dim)\n",
    "                                       for _ in range(self.num_layers))\n",
    "\n",
    "    def forward(self, X_0):\n",
    "        X_i = X_0 # b x dim\n",
    "        for i in range(self.num_layers):\n",
    "            X_i = X_i + self.cross_net[i](X_0, X_i)\n",
    "        return X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class CrossInteractionLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossInteractionLayer, self).__init__()\n",
    "        self.weight = nn.Linear(input_dim, 1, bias=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, X_0, X_i):\n",
    "        interaction_out = self.weight(X_i) * X_0 + self.bias\n",
    "        return interaction_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DCN(CTRModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"DCN\",\n",
    "                 task=\"binary_classification\",\n",
    "                 embedding_initializer=\"torch.nn.init.normal_(std=1e-4)\",\n",
    "                 embedding_dim=10, \n",
    "                 dnn_hidden_units=[], \n",
    "                 dnn_activations=\"ReLU\",\n",
    "                 crossing_layers=3, \n",
    "                 embedding_dropout=0,\n",
    "                 net_dropout=0, \n",
    "                 batch_norm=False,\n",
    "                 **kwargs):\n",
    "        super(DCN, self).__init__(feature_map, \n",
    "                                  model_id=model_id,\n",
    "                                  **kwargs)\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        input_dim = feature_map.num_fields * embedding_dim\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=None, # output hidden layer\n",
    "                             hidden_units=dnn_hidden_units,\n",
    "                             hidden_activations=dnn_activations,\n",
    "                             output_activation=None, \n",
    "                             dropout_rates=net_dropout, \n",
    "                             batch_norm=batch_norm, \n",
    "                             use_bias=True) \\\n",
    "                   if dnn_hidden_units else None # in case of only crossing net used\n",
    "        self.crossnet = CrossNet(input_dim, crossing_layers)\n",
    "        final_dim = input_dim\n",
    "        if isinstance(dnn_hidden_units, list) and len(dnn_hidden_units) > 0: # if use dnn\n",
    "            final_dim += dnn_hidden_units[-1]\n",
    "        self.fc = nn.Linear(final_dim, 1) # [cross_part, dnn_part] -> logit\n",
    "        self.final_activation = self.get_final_activation(task)\n",
    "        self.init_weights(embedding_initializer=embedding_initializer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature_emb = self.embedding_layer(inputs)\n",
    "        flat_feature_emb = feature_emb.flatten(start_dim=1)\n",
    "        cross_out = self.crossnet(flat_feature_emb)\n",
    "        if self.dnn is not None:\n",
    "            dnn_out = self.dnn(flat_feature_emb)\n",
    "            final_out = torch.cat([cross_out, dnn_out], dim=-1)\n",
    "        else:\n",
    "            final_out = cross_out\n",
    "        y_pred = self.fc(final_out)\n",
    "        if self.final_activation is not None:\n",
    "            y_pred = self.final_activation(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCN(ds.dataset.feature_map, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name             | Type           | Params\n",
      "----------------------------------------------------\n",
      "0 | embedding_layer  | EmbeddingLayer | 4.8 K \n",
      "1 | dnn              | MLP_Layer      | 13.2 K\n",
      "2 | crossnet         | CrossNet       | 840   \n",
      "3 | fc               | Linear         | 205   \n",
      "4 | final_activation | Sigmoid        | 0     \n",
      "----------------------------------------------------\n",
      "19.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.0 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:429: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a2fa49139d4b258f0439bca018bbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e373f81a244e73b5a7af4261f7faf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e438f5d51bbc4b27a7b0c1957f4aea3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.4742)}}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Test Metrics': {'AUC': tensor(1.), 'logloss': tensor(0.4742)}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recohut.trainers.pl_trainer import pl_trainer\n",
    "\n",
    "pl_trainer(model, ds, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "\n",
    "from recohut.models.layers.common import FeaturesEmbedding, MultiLayerPerceptron\n",
    "\n",
    "\n",
    "class CrossNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.w = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(input_dim, 1, bias=False) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.b = torch.nn.ParameterList([\n",
    "            torch.nn.Parameter(torch.zeros((input_dim,))) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        x0 = x\n",
    "        for i in range(self.num_layers):\n",
    "            xw = self.w[i](x)\n",
    "            x = x0 * xw + self.b[i] + x\n",
    "        return x\n",
    "\n",
    "class DCNv2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A pytorch implementation of Deep & Cross Network.\n",
    "    Reference:\n",
    "        R Wang, et al. Deep & Cross Network for Ad Click Predictions, 2017.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, num_layers, mlp_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.cn = CrossNetwork(self.embed_output_dim, num_layers)\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.linear = torch.nn.Linear(mlp_dims[-1] + self.embed_output_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        embed_x = self.embedding(x).view(-1, self.embed_output_dim)\n",
    "        x_l1 = self.cn(embed_x)\n",
    "        h_l2 = self.mlp(embed_x)\n",
    "        x_stack = torch.cat([x_l1, h_l2], dim=1)\n",
    "        p = self.linear(x_stack)\n",
    "        return torch.sigmoid(p.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, inputs_dim, hidden_units, dropout_rate):\n",
    "        super(DNN, self).__init__()\n",
    "        self.inputs_dim = inputs_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.hidden_units = [inputs_dim] + list(self.hidden_units)\n",
    "        self.linear = nn.ModuleList([\n",
    "            nn.Linear(self.hidden_units[i], self.hidden_units[i+1]) for i in range(len(self.hidden_units)-1)\n",
    "        ])\n",
    "        for name, tensor in self.linear.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=0.0001)\n",
    "\n",
    "        # self.bn = nn.ModuleList([\n",
    "        #     nn.Linear(self.hidden_units[i], self.hidden_units[i + 1]) for i in range(len(self.hidden_units) - 1)\n",
    "        # ])\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        inputs = X\n",
    "        for i in range(len(self.linear)):\n",
    "            fc = self.linear[i](inputs)\n",
    "            fc = self.activation(fc)\n",
    "            fc - self.dropout(fc)\n",
    "            inputs = fc\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class CrossNet(nn.Module):\n",
    "    def __init__(self, in_features, layer_num=2, parameterization='vector', seed=2022):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.parameterization = parameterization\n",
    "        if self.parameterization == 'vector':\n",
    "            self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        elif self.parameterization == 'matrix':\n",
    "            self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[0])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_1 = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            if self.parameterization == 'vector':\n",
    "                x1_w = torch.tensordot(x_1, self.kernels[i], dims=([1], [0]))\n",
    "                dot_ = torch.matmul(x_0, x1_w)\n",
    "                x_1 = dot_ + self.bias[i] + x_1\n",
    "            else:\n",
    "                x1_w = torch.tensordot(self.kernels[i], x_1)\n",
    "                dot_ = x1_w + self.bias[i]\n",
    "                x_1 = x_0 * dot_ + x_1\n",
    "        x_1 = torch.squeeze(x_1, dim=2)\n",
    "        return x_1\n",
    "\n",
    "\n",
    "class DCNv3(nn.Module):\n",
    "    \"\"\"DCN model implementation in pytorch\n",
    "\n",
    "    Reference:\n",
    "        1. https://github.com/huangjunheng/recommendation_model/blob/master/DCN/dcn.py\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_size, embedding_size, linear_feature_columns, dnn_feature_columns, cross_num=2,\n",
    "                 cross_param='vector', dnn_hidden_units=(128, 128,), init_std=0.0001, seed=2022, l2_reg=0.00001,\n",
    "                 drop_rate=0.5):\n",
    "        super(DCNv3, self).__init__()\n",
    "        self.feat_size = feat_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dnn_hidden_units = dnn_hidden_units\n",
    "        self.cross_num = 2\n",
    "        self.cross_param = cross_param\n",
    "        self.drop_rate = drop_rate\n",
    "        self.l2_reg = 0.00001\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "        self.dense_feature_columns = list(filter(lambda x:x[1]=='dense', dnn_feature_columns))\n",
    "        self.sparse_feature_columns = list(filter(lambda x:x[1]=='sparse', dnn_feature_columns))\n",
    "\n",
    "        self.embedding_dic = nn.ModuleDict({feat[0]:nn.Embedding(feat_size[feat[0]], self.embedding_size, sparse=False)\n",
    "                                            for feat in self.sparse_feature_columns})\n",
    "\n",
    "        self.feature_index = defaultdict(int)\n",
    "        start = 0\n",
    "        for feat in self.feat_size:\n",
    "            self.feature_index[feat] = start\n",
    "            start += 1\n",
    "\n",
    "        inputs_dim = len(self.dense_feature_columns)+self.embedding_size*len(self.sparse_feature_columns)\n",
    "        self.dnn = DNN(inputs_dim,self.dnn_hidden_units, 0.5)\n",
    "        self.crossnet = CrossNet(inputs_dim, layer_num=self.cross_num, parameterization=self.cross_param)\n",
    "        self.dnn_linear = nn.Linear(inputs_dim+dnn_hidden_units[-1], 1, bias=False)\n",
    "        dnn_hidden_units = [len(feat_size)] + list(dnn_hidden_units) + [1]\n",
    "        self.linear = nn.ModuleList([\n",
    "            nn.Linear(dnn_hidden_units[i], dnn_hidden_units[i+1]) for i in range(len(dnn_hidden_units)-1)\n",
    "        ])\n",
    "        for name, tensor in self.linear.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "    def forward(self, X):\n",
    "        logit = X\n",
    "        for i in range(len(self.linear)):\n",
    "            fc = self.linear[i](logit)\n",
    "            fc = self.act(fc)\n",
    "            fc = self.dropout(fc)\n",
    "            logit = fc\n",
    "\n",
    "        sparse_embedding = [self.embedding_dic[feat[0]](X[:, self.feature_index[feat[0]]].long()).reshape(X.shape[0], 1, -1)\n",
    "                            for feat in self.sparse_feature_columns]\n",
    "        dense_values = [X[:, self.feature_index[feat[0]]].reshape(-1, 1) for feat in self.dense_feature_columns]\n",
    "        dense_input = torch.cat(dense_values, dim=1)\n",
    "        sparse_input = torch.cat(sparse_embedding, dim=1)\n",
    "        sparse_input = torch.flatten(sparse_input, start_dim=1)\n",
    "        dnn_input = torch.cat((dense_input, sparse_input), dim=1)\n",
    "\n",
    "        # print('sparse input size', sparse_input.shape)\n",
    "        # print('dense input size', dense_input.shape)\n",
    "        # print('dnn input size', dnn_input.shape)\n",
    "\n",
    "        deep_out = self.dnn(dnn_input)\n",
    "        cross_out = self.crossnet(dnn_input)\n",
    "        stack_out = torch.cat((cross_out, deep_out), dim=-1)\n",
    "\n",
    "        logit += self.dnn_linear(stack_out)\n",
    "        #print('logit size', logit.shape)\n",
    "        y_pred = torch.sigmoid(logit)\n",
    "        #print('y_pred', y_pred.shape)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **References:-**\n",
    "- R Wang, et al. Deep & Cross Network for Ad Click Predictions, 2017.\n",
    "- https://github.com/rixwew/pytorch-fm/blob/master/torchfm/model/dcn.py\n",
    "- https://github.com/huangjunheng/recommendation_model/blob/master/DCN/dcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
