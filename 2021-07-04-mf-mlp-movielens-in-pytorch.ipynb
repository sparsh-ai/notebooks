{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-07-04-mf-mlp-movielens-in-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1shqJTD+PgZZ93ogbNNyZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thC-jHYLJKkz"
      },
      "source": [
        "# Training neural factorization model on movielens dataset\n",
        "> Training MF, MF+bias, and MLP model on movielens-100k dataset in PyTorch\n",
        "\n",
        "- toc: false\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [Pytorch, Movie, MF, MLP, RecoChef]\n",
        "- author: \"<a href='https://github.com/yanneta/pytorch-tutorials'>Yannet</a>\"\n",
        "- image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9XYsONJClRh",
        "outputId": "f32b3306-07df-47de-ae54-92e2c2c2333c"
      },
      "source": [
        "!pip install -q git+https://github.com/sparsh-ai/recochef.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for recochef (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LS69WtgCuxJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from recochef.datasets.synthetic import Synthetic\n",
        "from recochef.datasets.movielens import MovieLens\n",
        "from recochef.preprocessing.split import chrono_split\n",
        "from recochef.preprocessing.encode import label_encode as le\n",
        "from recochef.models.factorization import MF, MF_bias\n",
        "from recochef.models.dnn import CollabFNet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7-2sy7dDJte"
      },
      "source": [
        "# # generate synthetic implicit data\n",
        "# synt = Synthetic()\n",
        "# df = synt.implicit()\n",
        "\n",
        "movielens = MovieLens()\n",
        "df = movielens.load_interactions()\n",
        "\n",
        "# changing rating colname to event following implicit naming conventions\n",
        "df = df.rename(columns={'RATING': 'EVENT'})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGLNfBJBCw38",
        "outputId": "06429212-3b1c-4a95-df70-927b8e8a3e43"
      },
      "source": [
        "# drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# chronological split\n",
        "df_train, df_valid = chrono_split(df, ratio=0.8, min_rating=10)\n",
        "print(f\"Train set:\\n\\n{df_train}\\n{'='*100}\\n\")\n",
        "print(f\"Validation set:\\n\\n{df_valid}\\n{'='*100}\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set:\n",
            "\n",
            "       USERID  ITEMID  EVENT  TIMESTAMP\n",
            "59972       1     168    5.0  874965478\n",
            "92487       1     172    5.0  874965478\n",
            "74577       1     165    5.0  874965518\n",
            "48214       1     156    4.0  874965556\n",
            "22971       1     166    5.0  874965677\n",
            "...       ...     ...    ...        ...\n",
            "98752     943     139    1.0  888640027\n",
            "89336     943     426    4.0  888640027\n",
            "80660     943     720    1.0  888640048\n",
            "93177     943      80    2.0  888640048\n",
            "87415     943      53    3.0  888640067\n",
            "\n",
            "[80000 rows x 4 columns]\n",
            "====================================================================================================\n",
            "\n",
            "Validation set:\n",
            "\n",
            "       USERID  ITEMID  EVENT  TIMESTAMP\n",
            "10508       1     208    5.0  878542960\n",
            "83307       1       3    4.0  878542960\n",
            "8976        1      12    5.0  878542960\n",
            "78171       1      58    4.0  878542960\n",
            "9811        1     201    3.0  878542960\n",
            "...       ...     ...    ...        ...\n",
            "81005     943     450    1.0  888693158\n",
            "92536     943     227    1.0  888693158\n",
            "95003     943     230    1.0  888693158\n",
            "94914     943     229    2.0  888693158\n",
            "92880     943     234    3.0  888693184\n",
            "\n",
            "[20000 rows x 4 columns]\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68zLUPlvC5LK",
        "outputId": "46c0f8b6-dd84-4c54-8d55-8eb61fb3fc47"
      },
      "source": [
        "# label encoding\n",
        "df_train, uid_maps = le(df_train, col='USERID')\n",
        "df_train, iid_maps = le(df_train, col='ITEMID')\n",
        "df_valid = le(df_valid, col='USERID', maps=uid_maps)\n",
        "df_valid = le(df_valid, col='ITEMID', maps=iid_maps)\n",
        "\n",
        "# # event implicit to rating conversion\n",
        "# event_weights = {'click':1, 'add':2, 'purchase':4}\n",
        "# event_maps = dict({'EVENT_TO_IDX':event_weights})\n",
        "# df_train = le(df_train, col='EVENT', maps=event_maps)\n",
        "# df_valid = le(df_valid, col='EVENT', maps=event_maps)\n",
        "\n",
        "print(f\"Processed Train set:\\n\\n{df_train}\\n{'='*100}\\n\")\n",
        "print(f\"Processed Validation set:\\n\\n{df_valid}\\n{'='*100}\\n\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed Train set:\n",
            "\n",
            "       USERID  ITEMID  EVENT  TIMESTAMP\n",
            "59972       0       0    5.0  874965478\n",
            "92487       0       1    5.0  874965478\n",
            "74577       0       2    5.0  874965518\n",
            "48214       0       3    4.0  874965556\n",
            "22971       0       4    5.0  874965677\n",
            "...       ...     ...    ...        ...\n",
            "98752     942     933    1.0  888640027\n",
            "89336     942     990    4.0  888640027\n",
            "80660     942     643    1.0  888640048\n",
            "93177     942     155    2.0  888640048\n",
            "87415     942     166    3.0  888640067\n",
            "\n",
            "[80000 rows x 4 columns]\n",
            "====================================================================================================\n",
            "\n",
            "Processed Validation set:\n",
            "\n",
            "       USERID  ITEMID  EVENT  TIMESTAMP\n",
            "10508       0   341.0    5.0  878542960\n",
            "83307       0   983.0    4.0  878542960\n",
            "8976        0   425.0    5.0  878542960\n",
            "78171       0   639.0    4.0  878542960\n",
            "9811        0   490.0    3.0  878542960\n",
            "...       ...     ...    ...        ...\n",
            "81005     942   314.0    1.0  888693158\n",
            "92536     942   154.0    1.0  888693158\n",
            "95003     942   183.0    1.0  888693158\n",
            "94914     942   176.0    2.0  888693158\n",
            "92880     942   132.0    3.0  888693184\n",
            "\n",
            "[19917 rows x 4 columns]\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnhEaj5QC8j1",
        "outputId": "f15ef434-6b1d-4f51-f11c-4bfbe4af649b"
      },
      "source": [
        "# get number of unique users and items\n",
        "num_users = len(df_train.USERID.unique())\n",
        "num_items = len(df_train.ITEMID.unique())\n",
        "\n",
        "num_users_t = len(df_valid.USERID.unique())\n",
        "num_items_t = len(df_valid.ITEMID.unique())\n",
        "\n",
        "print(f\"There are {num_users} users and {num_items} items in the train set.\\n{'='*100}\\n\")\n",
        "print(f\"There are {num_users_t} users and {num_items_t} items in the validation set.\\n{'='*100}\\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 943 users and 1613 items in the train set.\n",
            "====================================================================================================\n",
            "\n",
            "There are 943 users and 1429 items in the validation set.\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTiGbb5UCpwM"
      },
      "source": [
        "# training and testing related helper functions\n",
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        users = torch.LongTensor(df_train.USERID.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train.ITEMID.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train.EVENT.values) #.cuda()\n",
        "        if unsqueeze:\n",
        "            ratings = ratings.unsqueeze(1)\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item()) \n",
        "    test_loss(model, unsqueeze)\n",
        "\n",
        "def test_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_valid.USERID.values) #.cuda()\n",
        "    items = torch.LongTensor(df_valid.ITEMID.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_valid.EVENT.values) #.cuda()\n",
        "    if unsqueeze:\n",
        "        ratings = ratings.unsqueeze(1)\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxhbI4ECC_Jb",
        "outputId": "fa326841-1e15-4900-c0e4-fc7790beb762"
      },
      "source": [
        "# training MF model\n",
        "model = MF(num_users, num_items, emb_size=100) # .cuda() if you have a GPU\n",
        "print(f\"Training MF model:\\n\")\n",
        "train_epocs(model, epochs=10, lr=0.1)\n",
        "print(f\"\\n{'='*100}\\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MF model:\n",
            "\n",
            "13.594555854797363\n",
            "5.292399883270264\n",
            "2.558849573135376\n",
            "3.584117889404297\n",
            "1.0360910892486572\n",
            "1.9875222444534302\n",
            "2.920832633972168\n",
            "2.4130148887634277\n",
            "1.2886441946029663\n",
            "1.112807273864746\n",
            "test loss 2.085 \n",
            "\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnbkknGIDAs6",
        "outputId": "e8466582-7078-49ab-dda7-eeffaa65c8de"
      },
      "source": [
        "# training MF with bias model\n",
        "model = MF_bias(num_users, num_items, emb_size=100) #.cuda()\n",
        "print(f\"Training MF+bias model:\\n\")\n",
        "train_epocs(model, epochs=10, lr=0.05, wd=1e-5)\n",
        "print(f\"\\n{'='*100}\\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MF+bias model:\n",
            "\n",
            "13.59664535522461\n",
            "9.730958938598633\n",
            "4.798837184906006\n",
            "1.3603413105010986\n",
            "2.697232723236084\n",
            "4.214857578277588\n",
            "2.871798276901245\n",
            "1.3329992294311523\n",
            "0.9624974727630615\n",
            "1.459389328956604\n",
            "test loss 2.269 \n",
            "\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9ltu-ISDCUY",
        "outputId": "06c01140-05a4-4b06-9819-546a7ecdba66"
      },
      "source": [
        "# training MLP model\n",
        "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()\n",
        "print(f\"Training MLP model:\\n\")\n",
        "train_epocs(model, epochs=15, lr=0.05, wd=1e-6, unsqueeze=True)\n",
        "print(f\"\\n{'='*100}\\n\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MLP model:\n",
            "\n",
            "12.962654113769531\n",
            "1.4028953313827515\n",
            "15.373563766479492\n",
            "2.177295207977295\n",
            "2.6291019916534424\n",
            "5.752542495727539\n",
            "6.88251256942749\n",
            "6.2746357917785645\n",
            "4.8090314865112305\n",
            "3.095308303833008\n",
            "1.6791961193084717\n",
            "1.1257785558700562\n",
            "1.678966760635376\n",
            "2.615834951400757\n",
            "2.80102276802063\n",
            "test loss 2.559 \n",
            "\n",
            "====================================================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}