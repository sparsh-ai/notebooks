{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T542323 | DRL for Movie Recommendation | Model","provenance":[{"file_id":"11JcWhJ0OSlIYvNU4McILdgyerowbxk_O","timestamp":1634805541916}],"collapsed_sections":[],"authorship_tag":"ABX9TyNI/xwjcTFsiooUlxBAvT9L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ntMjzC8bOKqY"},"source":["!git clone https://github.com/backgom2357/Recommender_system_via_deep_RL.git\n","%cd Recommender_system_via_deep_RL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1zfOQb08nff"},"source":["!wget -q --show-progress http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngfgl9m8OSQ2"},"source":["!apt-get -qq install tree"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gux9nvVROZd7","executionInfo":{"status":"ok","timestamp":1634893152987,"user_tz":-330,"elapsed":484,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"635b3ef7-2f23-458c-f522-4db97ad19eb7"},"source":["!tree --du -h ."],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[".\n","├── [2.3K]  actor.py\n","├── [3.2K]  critic.py\n","├── [ 65M]  data\n","│   ├── [ 65M]  user_dict.npy\n","│   └── [ 47K]  users_histroy_len.npy\n","├── [3.6K]  embedding.py\n","├── [9.7M]  embed_ids.ipynb\n","├── [2.9K]  envs.py\n","├── [ 21K]  evaluation.ipynb\n","├── [ 24M]  ml-1m\n","│   ├── [167K]  movies.dat\n","│   ├── [ 23M]  ratings.dat\n","│   ├── [5.4K]  README\n","│   └── [131K]  users.dat\n","├── [5.6M]  ml-1m.zip\n","├── [1.6K]  README.md\n","├── [ 10K]  recommender.py\n","├── [3.3K]  replay_buffer.py\n","├── [1.7K]  replay_memory.py\n","├── [ 19M]  save_weights\n","│   ├── [1.5M]  m_g_model_weights.h5\n","│   ├── [2.3M]  u_m_model_weights.h5\n","│   ├── [3.8M]  user_movie_at_once.h5\n","│   ├── [3.8M]  user_movie_embedding_98accu.h5\n","│   ├── [3.8M]  user_movie_embedding_case3.h5\n","│   └── [3.8M]  user_movie_embedding_case4.h5\n","├── [ 749]  state_representation.py\n","├── [2.2K]  train.py\n","└── [2.4K]  tree.py\n","\n"," 123M used in 3 directories, 26 files\n"]}]},{"cell_type":"markdown","metadata":{"id":"MUf_5x895cOH"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"rUbmetdC5hlx","executionInfo":{"status":"ok","timestamp":1634893655938,"user_tz":-330,"elapsed":2796,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["from collections import deque\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","import itertools\n","import logging, os\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","\n","import time\n","import tqdm\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","\n","from tensorflow.keras.layers import InputLayer, Embedding, Dot, Reshape, Dense\n","from tensorflow.keras.models import Model\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","ROOT_DIR = os.getcwd()\n","DATA_DIR = os.path.join(ROOT_DIR, 'ml-1m/')\n","STATE_SIZE = 10\n","\n","logging.disable(logging.WARNING)\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Czu9bcvBCUc5"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rN2sgigB2Ts","executionInfo":{"status":"ok","timestamp":1634806022404,"user_tz":-330,"elapsed":3404,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"ab46eb3f-f198-43c1-a635-dd380c4c201f"},"source":["#Loading datasets\n","ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n","users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n","movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n","ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n","movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n","movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n","\n","movies_id_to_movies = {movie[0]: movie[1:] for movie in movies_list}\n","\n","print(len(set(ratings_df[\"UserID\"])) == max([int(i) for i in set(ratings_df[\"UserID\"])]))\n","print(max([int(i) for i in set(ratings_df[\"UserID\"])]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","6040\n"]}]},{"cell_type":"code","metadata":{"id":"zA7LWOGTCBmm","executionInfo":{"status":"ok","timestamp":1634893799297,"user_tz":-330,"elapsed":8898,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["ratings_df = ratings_df.applymap(int)\n","users_dict = {user : [] for user in set(ratings_df[\"UserID\"])}\n","ratings_df = ratings_df.sort_values(by='Timestamp', ascending=True)\n","ratings_df_gen = ratings_df.iterrows()\n","users_dict_for_history_len = {user : [] for user in set(ratings_df[\"UserID\"])}\n","\n","for data in ratings_df_gen:\n","    users_dict[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n","    if data[1]['Rating'] >= 4:\n","        users_dict_for_history_len[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n","\n","users_history_lens = [len(users_dict_for_history_len[u]) for u in set(ratings_df[\"UserID\"])]\n","\n","np.save(\"user_dict.npy\", users_dict)\n","np.save(\"users_histroy_len.npy\", users_history_lens)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHSwKv037rLw"},"source":["### Tree"]},{"cell_type":"code","metadata":{"id":"1dKx_4kF7spP","executionInfo":{"status":"ok","timestamp":1634893658734,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class SumTree:\n","    def __init__(self, buffer_size):\n","        self.buffer_size = buffer_size\n","        self.tree = np.zeros((buffer_size * 2 - 1))\n","        self.index = buffer_size - 1\n","\n","    def update_tree(self, index):\n","        while True:\n","            index = (index - 1) // 2\n","            left = (index * 2) + 1\n","            right = (index * 2) + 2\n","            self.tree[index] = self.tree[left] + self.tree[right]\n","            if index == 0:\n","                break\n","\n","    def add_data(self, priority):\n","        if self.index == self.buffer_size * 2 - 1:\n","            self.index = self.buffer_size - 1\n","\n","        self.tree[self.index] = priority\n","        self.update_tree(self.index)\n","        self.index += 1\n","\n","    def search(self, num):\n","        current = 0\n","        while True:\n","            left = (current * 2) + 1\n","            right = (current * 2) + 2\n","\n","            if num <= self.tree[left]:\n","                current = left\n","            else:\n","                num -= self.tree[left]\n","                current = right\n","            \n","            if current >= self.buffer_size - 1:\n","                break\n","\n","        return self.tree[current], current, current - self.buffer_size + 1\n","\n","    def update_prioirty(self, priority, index):\n","        self.tree[index] = priority\n","        self.update_tree(index)\n","\n","    def sum_all_prioirty(self):\n","        return float(self.tree[0])\n","\n","\n","class MinTree:\n","    def __init__(self, buffer_size):\n","        self.buffer_size = buffer_size\n","        self.tree = np.ones((buffer_size * 2 - 1))\n","        self.index = buffer_size - 1\n","\n","    def update_tree(self, index):\n","        while True:\n","            index = (index - 1) // 2\n","            left = (index * 2) + 1\n","            right = (index * 2) + 2\n","            if self.tree[left] > self.tree[right]:\n","                self.tree[index] = self.tree[right]\n","            else:\n","                self.tree[index] = self.tree[left]\n","            if index == 0:\n","                break\n","\n","    def add_data(self, priority):\n","        if self.index == self.buffer_size * 2 - 1:\n","            self.index = self.buffer_size - 1\n","\n","        self.tree[self.index] = priority\n","        self.update_tree(self.index)\n","        self.index += 1\n","\n","    def update_prioirty(self, priority, index):\n","        self.tree[index] = priority\n","        self.update_tree(index)\n","\n","    def min_prioirty(self):\n","        return float(self.tree[0])"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mP-6ocWh7f5J"},"source":["### Replay buffer"]},{"cell_type":"code","metadata":{"id":"UHWHnCvv7f2a","executionInfo":{"status":"ok","timestamp":1634893661262,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class PriorityExperienceReplay(object):\n","\n","    '''\n","    apply PER\n","    '''\n","\n","    def __init__(self, buffer_size, embedding_dim):\n","        self.buffer_size = buffer_size\n","        self.crt_idx = 0\n","        self.is_full = False\n","        \n","        '''\n","            state : (300,), \n","            next_state : (300,) 변할 수 잇음, \n","            actions : (100,), \n","            rewards : (1,), \n","            dones : (1,)\n","        '''\n","        self.states = np.zeros((buffer_size, 3*embedding_dim), dtype=np.float32)\n","        self.actions = np.zeros((buffer_size, embedding_dim), dtype=np.float32)\n","        self.rewards = np.zeros((buffer_size), dtype=np.float32)\n","        self.next_states = np.zeros((buffer_size, 3*embedding_dim), dtype=np.float32)\n","        self.dones = np.zeros(buffer_size, np.bool)\n","\n","        self.sum_tree = SumTree(buffer_size)\n","        self.min_tree = MinTree(buffer_size)\n","\n","        self.max_prioirty = 1.0\n","        self.alpha = 0.6\n","        self.beta = 0.4\n","        self.beta_constant = 0.00001\n","\n","    def append(self, state, action, reward, next_state, done):\n","        self.states[self.crt_idx] = state\n","        self.actions[self.crt_idx] = action\n","        self.rewards[self.crt_idx] = reward\n","        self.next_states[self.crt_idx] = next_state\n","        self.dones[self.crt_idx] = done\n","\n","        self.sum_tree.add_data(self.max_prioirty ** self.alpha)\n","        self.min_tree.add_data(self.max_prioirty ** self.alpha)\n","        \n","        self.crt_idx = (self.crt_idx + 1) % self.buffer_size\n","        if self.crt_idx == 0:\n","            self.is_full = True\n","\n","    def sample(self, batch_size):\n","        rd_idx = []\n","        weight_batch = []\n","        index_batch = []\n","        sum_priority = self.sum_tree.sum_all_prioirty()\n","        \n","        N = self.buffer_size if self.is_full else self.crt_idx\n","        min_priority = self.min_tree.min_prioirty() / sum_priority\n","        max_weight = (N * min_priority) ** (-self.beta)\n","\n","        segment_size = sum_priority/batch_size\n","        for j in range(batch_size):\n","            min_seg = segment_size * j\n","            max_seg = segment_size * (j + 1)\n","\n","            random_num = random.uniform(min_seg, max_seg)\n","            priority, tree_index, buffer_index = self.sum_tree.search(random_num)\n","            rd_idx.append(buffer_index)\n","\n","            p_j = priority / sum_priority\n","            w_j = (p_j * N) ** (-self.beta) / max_weight\n","            weight_batch.append(w_j)\n","            index_batch.append(tree_index)\n","        self.beta = min(1.0, self.beta + self.beta_constant)\n","\n","        batch_states = self.states[rd_idx]\n","        batch_actions = self.actions[rd_idx]\n","        batch_rewards = self.rewards[rd_idx]\n","        batch_next_states = self.next_states[rd_idx]\n","        batch_dones = self.dones[rd_idx]\n","\n","        return batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones, np.array(weight_batch), index_batch\n","\n","    def update_priority(self, priority, index):\n","        self.sum_tree.update_prioirty(priority ** self.alpha, index)\n","        self.min_tree.update_prioirty(priority ** self.alpha, index)\n","        self.update_max_priority(priority ** self.alpha)\n","\n","    def update_max_priority(self, priority):\n","        self.max_prioirty = max(self.max_prioirty, priority)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"heHg41DN7fy9"},"source":["### Replay memory"]},{"cell_type":"code","metadata":{"id":"0wxthxqm7yHA","executionInfo":{"status":"ok","timestamp":1634893664386,"user_tz":-330,"elapsed":538,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class ReplayMemory(object):\n","\n","    '''\n","    apply PER, later\n","    '''\n","\n","    def __init__(self, replay_memory_size, embedding_dim):\n","        self.rm_size = replay_memory_size\n","        self.crt_idx = 0\n","        \n","        '''\n","            state : (300,), \n","            next_state : (300,) 변할 수 잇음, \n","            actions : (100,), \n","            rewards : (1,), \n","            dones : (1,)\n","        '''\n","\n","        self.states = np.zeros((replay_memory_size, 3*embedding_dim), dtype=np.float32)\n","        self.actions = np.zeros((replay_memory_size, embedding_dim), dtype=np.float32)\n","        self.rewards = np.zeros((replay_memory_size), dtype=np.float32)\n","        self.rewards[replay_memory_size-1] = 777\n","        self.next_states = np.zeros((replay_memory_size, 3*embedding_dim), dtype=np.float32)\n","        self.dones = np.zeros(replay_memory_size, np.bool)\n","\n","    def is_full(self):\n","        return self.rewards[-1] != 777\n","\n","    def append(self, state, action, reward, next_state, done):\n","        self.states[self.crt_idx] = state\n","        self.actions[self.crt_idx] = action\n","        self.rewards[self.crt_idx] = reward\n","        self.next_states[self.crt_idx] = next_state\n","        self.dones[self.crt_idx] = done\n","\n","        self.crt_idx = (self.crt_idx + 1) % self.rm_size\n","\n","    def sample(self, batch_size):\n","        rd_idx = np.random.choice((1 - self.is_full())*self.crt_idx + self.is_full()*self.rm_size-1, batch_size)\n","        batch_states = self.states[rd_idx]\n","        batch_actions = self.actions[rd_idx]\n","        batch_rewards = self.rewards[rd_idx]\n","        batch_next_states = self.next_states[rd_idx]\n","        batch_dones = self.dones[rd_idx]\n","\n","        return batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJaA7IWX50TG"},"source":["### Embedding"]},{"cell_type":"code","metadata":{"id":"09oqGUMN510H","executionInfo":{"status":"ok","timestamp":1634893667652,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class MovieGenreEmbedding(tf.keras.Model):\n","    def __init__(self, len_movies, len_genres, embedding_dim):\n","        super(MovieGenreEmbedding, self).__init__()\n","        self.m_g_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n","        # embedding\n","        self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n","        self.g_embedding = tf.keras.layers.Embedding(name='genre_embedding', input_dim=len_genres, output_dim=embedding_dim)\n","        # dot product\n","        self.m_g_merge = tf.keras.layers.Dot(name='movie_genre_dot', normalize=True, axes=1)\n","        # output\n","        self.m_g_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n","        \n","    def call(self, x):\n","        x = self.m_g_input(x)\n","        memb = self.m_embedding(x[0])\n","        gemb = self.g_embedding(x[1])\n","        m_g = self.m_g_merge([memb, gemb])\n","        return self.m_g_fc(m_g)\n","\n","# class UserMovieEmbedding(tf.keras.Model):\n","#     def __init__(self, len_users, embedding_dim):\n","#         super(UserMovieEmbedding, self).__init__()\n","#         self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n","#         # embedding\n","#         self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n","#         # dot product\n","#         self.m_u_merge = tf.keras.layers.Dot(name='movie_user_dot', normalize=False, axes=1)\n","#         # output\n","#         self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n","        \n","#     def call(self, x):\n","#         x = self.m_u_input(x)\n","#         uemb = self.u_embedding(x[0])\n","#         m_u = self.m_u_merge([x[1], uemb])\n","#         return self.m_u_fc(m_u)\n","\n","\n","class UserMovieEmbedding(tf.keras.Model):\n","    def __init__(self, len_users, len_movies, embedding_dim):\n","        super(UserMovieEmbedding, self).__init__()\n","        self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n","        # embedding\n","        self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n","        self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n","        # dot product\n","        self.m_u_merge = tf.keras.layers.Dot(name='movie_user_dot', normalize=False, axes=1)\n","        # output\n","        self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n","        \n","    def call(self, x):\n","        x = self.m_u_input(x)\n","        uemb = self.u_embedding(x[0])\n","        memb = self.m_embedding(x[1])\n","        m_u = self.m_u_merge([memb, uemb])\n","        return self.m_u_fc(m_u)\n","\n","# class UserMovieEmbedding(tf.keras.Model):\n","#     def __init__(self, len_users, len_movies, embedding_dim):\n","#         super(UserMovieEmbedding, self).__init__()\n","#         self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n","#         # embedding\n","#         self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n","#         self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n","#         # dot product\n","#         self.m_u_concat = tf.keras.layers.Concatenate(name='movie_user_concat', axis=1)\n","#         # output\n","#         self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n","        \n","#     def call(self, x):\n","#         x = self.m_u_input(x)\n","#         uemb = self.u_embedding(x[0])\n","#         memb = self.m_embedding(x[1])\n","#         m_u = self.m_u_concat([memb, uemb])\n","#         return self.m_u_fc(m_u)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNXw90Fm7YMt"},"source":["### Environments"]},{"cell_type":"code","metadata":{"id":"dTJUXGCS7ZK_","executionInfo":{"status":"ok","timestamp":1634893670252,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class OfflineEnv(object):\n","    \n","    def __init__(self, users_dict, users_history_lens, movies_id_to_movies, state_size, fix_user_id=None):\n","\n","        self.users_dict = users_dict\n","        self.users_history_lens = users_history_lens\n","        self.items_id_to_name = movies_id_to_movies\n","        \n","        self.state_size = state_size\n","        self.available_users = self._generate_available_users()\n","\n","        self.fix_user_id = fix_user_id\n","\n","        self.user = fix_user_id if fix_user_id else np.random.choice(self.available_users)\n","        self.user_items = {data[0]:data[1] for data in self.users_dict[self.user]}\n","        self.items = [data[0] for data in self.users_dict[self.user][:self.state_size]]\n","        self.done = False\n","        self.recommended_items = set(self.items)\n","        self.done_count = 3000\n","        \n","    def _generate_available_users(self):\n","        available_users = []\n","        for i, length in zip(self.users_dict.keys(), self.users_history_lens):\n","            if length > self.state_size:\n","                available_users.append(i)\n","        return available_users\n","    \n","    def reset(self):\n","        self.user = self.fix_user_id if self.fix_user_id else np.random.choice(self.available_users)\n","        self.user_items = {data[0]:data[1] for data in self.users_dict[self.user]}\n","        self.items = [data[0] for data in self.users_dict[self.user][:self.state_size]]\n","        self.done = False\n","        self.recommended_items = set(self.items)\n","        return self.user, self.items, self.done\n","        \n","    def step(self, action, top_k=False):\n","\n","        reward = -0.5\n","        \n","        if top_k:\n","            correctly_recommended = []\n","            rewards = []\n","            for act in action:\n","                if act in self.user_items.keys() and act not in self.recommended_items:\n","                    correctly_recommended.append(act)\n","                    rewards.append((self.user_items[act] - 3)/2)\n","                else:\n","                    rewards.append(-0.5)\n","                self.recommended_items.add(act)\n","            if max(rewards) > 0:\n","                self.items = self.items[len(correctly_recommended):] + correctly_recommended\n","            reward = rewards\n","\n","        else:\n","            if action in self.user_items.keys() and action not in self.recommended_items:\n","                reward = self.user_items[action] -3  # reward\n","            if reward > 0:\n","                self.items = self.items[1:] + [action]\n","            self.recommended_items.add(action)\n","\n","        if len(self.recommended_items) > self.done_count or len(self.recommended_items) >= self.users_history_lens[self.user-1]:\n","            self.done = True\n","            \n","        return self.items, reward, self.done, self.recommended_items\n","\n","    def get_items_names(self, items_ids):\n","        items_names = []\n","        for id in items_ids:\n","            try:\n","                items_names.append(self.items_id_to_name[str(id)])\n","            except:\n","                items_names.append(list(['Not in list']))\n","        return items_names"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Doz1pRW73Ao"},"source":["### State representation"]},{"cell_type":"code","metadata":{"id":"PVaHNAAE74uM","executionInfo":{"status":"ok","timestamp":1634893673743,"user_tz":-330,"elapsed":865,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class DRRAveStateRepresentation(tf.keras.Model):\n","    def __init__(self, embedding_dim):\n","        super(DRRAveStateRepresentation, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.wav = tf.keras.layers.Conv1D(1, 1, 1)\n","        self.concat = tf.keras.layers.Concatenate()\n","        self.flatten = tf.keras.layers.Flatten()\n","        \n","    def call(self, x):\n","        items_eb = tf.transpose(x[1], perm=(0,2,1))/self.embedding_dim\n","        wav = self.wav(items_eb)\n","        wav = tf.transpose(wav, perm=(0,2,1))\n","        wav = tf.squeeze(wav, axis=1)\n","        user_wav = tf.keras.layers.multiply([x[0], wav])\n","        concat = self.concat([x[0], user_wav, wav])\n","        return self.flatten(concat)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-05RUU3T5jBI"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"qqbhZWiM5m2W"},"source":["### Actor"]},{"cell_type":"code","metadata":{"id":"2-UDQp7T5lgx","executionInfo":{"status":"ok","timestamp":1634893675206,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class ActorNetwork(tf.keras.Model):\n","    def __init__(self, embedding_dim, hidden_dim):\n","        super(ActorNetwork, self).__init__()\n","        self.inputs = tf.keras.layers.InputLayer(name='input_layer', input_shape=(3*embedding_dim,))\n","        self.fc = tf.keras.Sequential([\n","            tf.keras.layers.Dense(hidden_dim, activation='relu'),\n","            tf.keras.layers.Dense(hidden_dim, activation='relu'),\n","            tf.keras.layers.Dense(embedding_dim, activation='tanh')\n","        ])\n","        \n","    def call(self, x):\n","        x = self.inputs(x)\n","        return self.fc(x)\n","\n","class Actor(object):\n","    \n","    def __init__(self, embedding_dim, hidden_dim, learning_rate, state_size, tau):\n","        \n","        self.embedding_dim = embedding_dim\n","        self.state_size = state_size\n","        \n","        # 엑터 네트워크 actor network / 타겟 네트워크 target network\n","        self.network = ActorNetwork(embedding_dim, hidden_dim)\n","        self.target_network = ActorNetwork(embedding_dim, hidden_dim)\n","        # 옵티마이저 optimizer\n","        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n","        # 소프트 타겟 네트워크 업데이트 하이퍼파라미터 soft target network update hyperparameter\n","        self.tau = tau\n","    \n","    def build_networks(self):\n","        # 네트워크들 빌딩 / Build networks\n","        self.network(np.zeros((1, 3*self.embedding_dim)))\n","        self.target_network(np.zeros((1, 3*self.embedding_dim)))\n","    \n","    def update_target_network(self):\n","        # 소프트 타겟 네트워크 업데이트 soft target network update\n","        c_theta, t_theta = self.network.get_weights(), self.target_network.get_weights()\n","        for i in range(len(c_theta)):\n","            t_theta[i] = self.tau * c_theta[i] + (1 - self.tau) * t_theta[i]\n","        self.target_network.set_weights(t_theta)\n","        \n","    def train(self, states, dq_das):\n","        with tf.GradientTape() as g:\n","            outputs = self.network(states)\n","            # loss = outputs*dq_das\n","        dj_dtheta = g.gradient(outputs, self.network.trainable_weights, -dq_das)\n","        grads = zip(dj_dtheta, self.network.trainable_weights)\n","        self.optimizer.apply_gradients(grads)\n","        \n","    def save_weights(self, path):\n","        self.network.save_weights(path)\n","        \n","    def load_weights(self, path):\n","        self.network.load_weights(path)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZS48eRq5tXb"},"source":["### Critic"]},{"cell_type":"code","metadata":{"id":"KbGCQ25y5pRI","executionInfo":{"status":"ok","timestamp":1634893678654,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["class CriticNetwork(tf.keras.Model):\n","    def __init__(self, embedding_dim,hidden_dim):\n","        super(CriticNetwork, self).__init__()\n","        self.inputs = tf.keras.layers.InputLayer(input_shape=(embedding_dim, 3*embedding_dim))\n","        self.fc1 = tf.keras.layers.Dense(embedding_dim, activation = 'relu')\n","        self.concat = tf.keras.layers.Concatenate()\n","        self.fc2 = tf.keras.layers.Dense(hidden_dim, activation = 'relu')\n","        self.fc3 = tf.keras.layers.Dense(hidden_dim, activation = 'relu')\n","        self.out = tf.keras.layers.Dense(1, activation = 'linear')\n","        \n","    def call(self, x):\n","        s = self.fc1(x[1])\n","        s = self.concat([x[0],s])\n","        s = self.fc2(s)\n","        s = self.fc3(s)\n","        return self.out(s)\n","\n","class Critic(object):\n","    \n","    def __init__(self, hidden_dim, learning_rate, embedding_dim, tau):\n","        \n","        self.embedding_dim = embedding_dim\n","\n","        # 크리틱 네트워크 critic network / 타겟 네트워크 target network\n","        self.network = CriticNetwork(embedding_dim, hidden_dim)\n","        self.target_network = CriticNetwork(embedding_dim, hidden_dim)\n","        # 옵티마이저 optimizerq\n","        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","        # MSE\n","        self.loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n","\n","        # 소프트 타겟 네트워크 업데이트 하이퍼파라미터 soft target network update hyperparameter\n","        self.tau = tau\n","\n","    def build_networks(self):\n","        self.network([np.zeros((1,self.embedding_dim)), np.zeros((1,3*self.embedding_dim))])\n","        self.target_network([np.zeros((1,self.embedding_dim)), np.zeros((1,3*self.embedding_dim))])\n","        self.network.compile(self.optimizer, self.loss)\n","\n","    def update_target_network(self):\n","        c_omega = self.network.get_weights()\n","        t_omega = self.target_network.get_weights()\n","        for i in range(len(c_omega)):\n","            t_omega[i] = self.tau * c_omega[i] + (1 - self.tau) * t_omega[i]\n","        self.target_network.set_weights(t_omega)\n","        \n","    def dq_da(self, inputs):\n","        actions = inputs[0]\n","        states = inputs[1]\n","        with tf.GradientTape() as g:\n","            actions = tf.convert_to_tensor(actions)\n","            g.watch(actions)\n","            outputs = self.network([actions, states])\n","        q_grads = g.gradient(outputs, actions)\n","        return q_grads\n","\n","    def train(self, inputs, td_targets, weight_batch):\n","        weight_batch = tf.convert_to_tensor(weight_batch, dtype=tf.float32)\n","        with tf.GradientTape() as g:\n","            outputs = self.network(inputs)\n","            loss = self.loss(td_targets, outputs)\n","            weighted_loss = tf.reduce_mean(loss*weight_batch)\n","        dl_domega = g.gradient(weighted_loss, self.network.trainable_weights)\n","        grads = zip(dl_domega, self.network.trainable_weights)\n","        self.optimizer.apply_gradients(grads)\n","        return weighted_loss\n","\n","\n","    def train_on_batch(self, inputs, td_targets, weight_batch):\n","        loss = self.network.train_on_batch(inputs, td_targets, sample_weight=weight_batch)\n","        return loss\n","            \n","    def save_weights(self, path):\n","        self.network.save_weights(path)\n","        \n","    def load_weights(self, path):\n","        self.network.load_weights(path)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2icy-3fu5uTW"},"source":["## Recommender"]},{"cell_type":"code","metadata":{"id":"XdkHhrVI8SFQ"},"source":["!mkdir -p save_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HASNEhqU8H0G","executionInfo":{"status":"ok","timestamp":1634893696310,"user_tz":-330,"elapsed":1446,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["# from replay_buffer import PriorityExperienceReplay\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.python.ops.gen_math_ops import Exp\n","\n","# from actor import Actor\n","# from critic import Critic\n","# from replay_memory import ReplayMemory\n","# from embedding import MovieGenreEmbedding, UserMovieEmbedding\n","# from state_representation import DRRAveStateRepresentation\n","\n","import matplotlib.pyplot as plt\n","\n","# import wandb\n","\n","class DRRAgent:\n","    \n","    def __init__(self, env, users_num, items_num, state_size, is_test=False, use_wandb=False):\n","        \n","        self.env = env\n","\n","        self.users_num = users_num\n","        self.items_num = items_num\n","        \n","        self.embedding_dim = 100\n","        self.actor_hidden_dim = 128\n","        self.actor_learning_rate = 0.001\n","        self.critic_hidden_dim = 128\n","        self.critic_learning_rate = 0.001\n","        self.discount_factor = 0.9\n","        self.tau = 0.001\n","\n","        self.replay_memory_size = 1000000\n","        self.batch_size = 32\n","        \n","        self.actor = Actor(self.embedding_dim, self.actor_hidden_dim, self.actor_learning_rate, state_size, self.tau)\n","        self.critic = Critic(self.critic_hidden_dim, self.critic_learning_rate, self.embedding_dim, self.tau)\n","        \n","        # self.m_embedding_network = MovieGenreEmbedding(items_num, 19, self.embedding_dim)\n","        # self.m_embedding_network([np.zeros((1,)),np.zeros((1,))])\n","        # self.m_embedding_network.load_weights('save_weights/m_g_model_weights.h5')\n","\n","        self.embedding_network = UserMovieEmbedding(users_num, items_num, self.embedding_dim)\n","        self.embedding_network([np.zeros((1,)),np.zeros((1,))])\n","        # self.embedding_network = UserMovieEmbedding(users_num, self.embedding_dim)\n","        # self.embedding_network([np.zeros((1)),np.zeros((1,100))])\n","        self.embedding_network.load_weights('save_weights/user_movie_embedding_case4.h5')\n","\n","        self.srm_ave = DRRAveStateRepresentation(self.embedding_dim)\n","        self.srm_ave([np.zeros((1, 100,)),np.zeros((1,state_size, 100))])\n","\n","        # PER\n","        self.buffer = PriorityExperienceReplay(self.replay_memory_size, self.embedding_dim)\n","        self.epsilon_for_priority = 1e-6\n","\n","        # ε-탐욕 탐색 하이퍼파라미터 ε-greedy exploration hyperparameter\n","        self.epsilon = 1.\n","        self.epsilon_decay = (self.epsilon - 0.1)/500000\n","        self.std = 1.5\n","\n","        self.is_test = is_test\n","\n","        # wandb\n","        self.use_wandb = use_wandb\n","        if use_wandb:\n","            wandb.init(project=\"drr\", \n","            entity=\"diominor\",\n","            config={'users_num':users_num,\n","            'items_num' : items_num,\n","            'state_size' : state_size,\n","            'embedding_dim' : self.embedding_dim,\n","            'actor_hidden_dim' : self.actor_hidden_dim,\n","            'actor_learning_rate' : self.actor_learning_rate,\n","            'critic_hidden_dim' : self.critic_hidden_dim,\n","            'critic_learning_rate' : self.critic_learning_rate,\n","            'discount_factor' : self.discount_factor,\n","            'tau' : self.tau,\n","            'replay_memory_size' : self.replay_memory_size,\n","            'batch_size' : self.batch_size,\n","            'std_for_exploration': self.std})\n","\n","    def calculate_td_target(self, rewards, q_values, dones):\n","        y_t = np.copy(q_values)\n","        for i in range(q_values.shape[0]):\n","            y_t[i] = rewards[i] + (1 - dones[i])*(self.discount_factor * q_values[i])\n","        return y_t\n","\n","    def recommend_item(self, action, recommended_items, top_k=False, items_ids=None):\n","        if items_ids == None:\n","            items_ids = np.array(list(set(i for i in range(self.items_num)) - recommended_items))\n","\n","        items_ebs = self.embedding_network.get_layer('movie_embedding')(items_ids)\n","        # items_ebs = self.m_embedding_network.get_layer('movie_embedding')(items_ids)\n","        action = tf.transpose(action, perm=(1,0))\n","        if top_k:\n","            item_indice = np.argsort(tf.transpose(tf.keras.backend.dot(items_ebs, action), perm=(1,0)))[0][-top_k:]\n","            return items_ids[item_indice]\n","        else:\n","            item_idx = np.argmax(tf.keras.backend.dot(items_ebs, action))\n","            return items_ids[item_idx]\n","        \n","    def train(self, max_episode_num, top_k=False, load_model=False):\n","        # 타겟 네트워크들 초기화\n","        self.actor.update_target_network()\n","        self.critic.update_target_network()\n","\n","        if load_model:\n","            self.load_model(\"save_weights/actor_50000.h5\", \"save_weights/critic_50000.h5\")\n","            print('Completely load weights!')\n","\n","        episodic_precision_history = []\n","\n","        for episode in range(max_episode_num):\n","            # episodic reward 리셋\n","            episode_reward = 0\n","            correct_count = 0\n","            steps = 0\n","            q_loss = 0\n","            mean_action = 0\n","            # Environment 리셋\n","            user_id, items_ids, done = self.env.reset()\n","            # print(f'user_id : {user_id}, rated_items_length:{len(self.env.user_items)}')\n","            # print('items : ', self.env.get_items_names(items_ids))\n","            while not done:\n","                \n","                # Observe current state & Find action\n","                ## Embedding 해주기\n","                user_eb = self.embedding_network.get_layer('user_embedding')(np.array(user_id))\n","                items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(items_ids))\n","                # items_eb = self.m_embedding_network.get_layer('movie_embedding')(np.array(items_ids))\n","                ## SRM으로 state 출력\n","                state = self.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(items_eb, axis=0)])\n","\n","                ## Action(ranking score) 출력\n","                action = self.actor.network(state)\n","\n","                ## ε-greedy exploration\n","                if self.epsilon > np.random.uniform() and not self.is_test:\n","                    self.epsilon -= self.epsilon_decay\n","                    action += np.random.normal(0,self.std,size=action.shape)\n","\n","                ## Item 추천\n","                recommended_item = self.recommend_item(action, self.env.recommended_items, top_k=top_k)\n","                \n","                # Calculate reward & observe new state (in env)\n","                ## Step\n","                next_items_ids, reward, done, _ = self.env.step(recommended_item, top_k=top_k)\n","                if top_k:\n","                    reward = np.sum(reward)\n","\n","                # get next_state\n","                next_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(next_items_ids))\n","                # next_items_eb = self.m_embedding_network.get_layer('movie_embedding')(np.array(next_items_ids))\n","                next_state = self.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(next_items_eb, axis=0)])\n","\n","                # buffer에 저장\n","                self.buffer.append(state, action, reward, next_state, done)\n","                \n","                if self.buffer.crt_idx > 1 or self.buffer.is_full:\n","                    # Sample a minibatch\n","                    batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones, weight_batch, index_batch = self.buffer.sample(self.batch_size)\n","\n","                    # Set TD targets\n","                    target_next_action= self.actor.target_network(batch_next_states)\n","                    qs = self.critic.network([target_next_action, batch_next_states])\n","                    target_qs = self.critic.target_network([target_next_action, batch_next_states])\n","                    min_qs = tf.raw_ops.Min(input=tf.concat([target_qs, qs], axis=1), axis=1, keep_dims=True) # Double Q method\n","                    td_targets = self.calculate_td_target(batch_rewards, min_qs, batch_dones)\n","        \n","                    # Update priority\n","                    for (p, i) in zip(td_targets, index_batch):\n","                        self.buffer.update_priority(abs(p[0]) + self.epsilon_for_priority, i)\n","\n","                    # print(weight_batch.shape)\n","                    # print(td_targets.shape)\n","                    # raise Exception\n","                    # Update critic network\n","                    q_loss += self.critic.train([batch_actions, batch_states], td_targets, weight_batch)\n","                    \n","                    # Update actor network\n","                    s_grads = self.critic.dq_da([batch_actions, batch_states])\n","                    self.actor.train(batch_states, s_grads)\n","                    self.actor.update_target_network()\n","                    self.critic.update_target_network()\n","\n","                items_ids = next_items_ids\n","                episode_reward += reward\n","                mean_action += np.sum(action[0])/(len(action[0]))\n","                steps += 1\n","\n","                if reward > 0:\n","                    correct_count += 1\n","                \n","                print(f'recommended items : {len(self.env.recommended_items)},  epsilon : {self.epsilon:0.3f}, reward : {reward:+}', end='\\r')\n","\n","                if done:\n","                    print()\n","                    precision = int(correct_count/steps * 100)\n","                    print(f'{episode}/{max_episode_num}, precision : {precision:2}%, total_reward:{episode_reward}, q_loss : {q_loss/steps}, mean_action : {mean_action/steps}')\n","                    if self.use_wandb:\n","                        wandb.log({'precision':precision, 'total_reward':episode_reward, 'epsilone': self.epsilon, 'q_loss' : q_loss/steps, 'mean_action' : mean_action/steps})\n","                    episodic_precision_history.append(precision)\n","             \n","            if (episode+1)%50 == 0:\n","                plt.plot(episodic_precision_history)\n","                plt.savefig(f'images/training_precision_%_top_5.png')\n","\n","            if (episode+1)%1000 == 0:\n","                self.save_model(f'save_weights/actor_{episode+1}_fixed.h5',\n","                                f'save_weights/critic_{episode+1}_fixed.h5')\n","\n","    def save_model(self, actor_path, critic_path):\n","        self.actor.save_weights(actor_path)\n","        self.critic.save_weights(critic_path)\n","        \n","    def load_model(self, actor_path, critic_path):\n","        self.actor.load_weights(actor_path)\n","        self.critic.load_weights(critic_path)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CmDzqkpk8ZLy"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ASRF1pBUA9hf","executionInfo":{"status":"error","timestamp":1634893830572,"user_tz":-330,"elapsed":9805,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d4526418-26cb-4f18-f004-fae1285238c8"},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","\n","MAX_EPISODE_NUM = 8000\n","\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n","\n","if __name__ == \"__main__\":\n","\n","    print('Data loading...')\n","\n","    #Loading datasets\n","    ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n","    users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n","    movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n","    ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n","    movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n","    movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n","\n","    print(\"Data loading complete!\")\n","    print(\"Data preprocessing...\")\n","\n","    # 영화 id를 영화 제목으로\n","    movies_id_to_movies = {movie[0]: movie[1:] for movie in movies_list}\n","    ratings_df = ratings_df.applymap(int)\n","\n","    # 유저별로 본 영화들 순서대로 정리\n","    users_dict = np.load('user_dict.npy', allow_pickle=True)\n","\n","    # 각 유저별 영화 히스토리 길이\n","    users_history_lens = np.load('users_histroy_len.npy')\n","\n","    users_num = max(ratings_df[\"UserID\"])+1\n","    items_num = max(ratings_df[\"MovieID\"])+1\n","\n","    # Training setting\n","    train_users_num = int(users_num * 0.8)\n","    train_items_num = items_num\n","    train_users_dict = {k:users_dict.item().get(k) for k in range(1, train_users_num+1)}\n","    train_users_history_lens = users_history_lens[:train_users_num]\n","    \n","    print('DONE!')\n","    time.sleep(2)\n","\n","    env = OfflineEnv(train_users_dict, train_users_history_lens, movies_id_to_movies, STATE_SIZE)\n","    recommender = DRRAgent(env, users_num, items_num, STATE_SIZE, use_wandb=False)\n","    recommender.actor.build_networks()\n","    recommender.critic.build_networks()\n","    recommender.train(MAX_EPISODE_NUM, load_model=False)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loading...\n","Data loading complete!\n","Data preprocessing...\n","DONE!\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-8cd4a079663a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_EPISODE_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-f62168ff6de8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_episode_num, top_k, load_model)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;31m# raise Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;31m# Update critic network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mq_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0;31m# Update actor network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-af6cb21a3d06>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, td_targets, weight_batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mweighted_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mdl_domega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_domega\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    528\u001b[0m   \"\"\"\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6235\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6236\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6238\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul]"]}]},{"cell_type":"markdown","metadata":{"id":"rgv0oXzeBE80"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"1ZsADhYBPHhK"},"source":["!pip install -q wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xHmoWGLPC4O","executionInfo":{"status":"ok","timestamp":1634893350496,"user_tz":-330,"elapsed":465,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["#Dependencies\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","\n","# from envs import OfflineEnv\n","# from recommender import DRRAgent\n","\n","import os\n","\n","ROOT_DIR = os.getcwd()\n","DATA_DIR = os.path.join(ROOT_DIR, 'ml-1m/')\n","STATE_SIZE = 10"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"BFkzwXrSPERC","executionInfo":{"status":"ok","timestamp":1634893401578,"user_tz":-330,"elapsed":3363,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0d2dabe4-679a-4f81-82f9-69ba5611f500"},"source":["#Loading datasets\n","ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n","users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n","movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n","ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n","movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n","movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n","movies_id_to_movies = {movie[0]: movie[1:] for movie in movies_list}\n","\n","movies_df.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MovieID</th>\n","      <th>Title</th>\n","      <th>Genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Animation|Children's|Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children's|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   MovieID                               Title                        Genres\n","0        1                    Toy Story (1995)   Animation|Children's|Comedy\n","1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n","2        3             Grumpier Old Men (1995)                Comedy|Romance\n","3        4            Waiting to Exhale (1995)                  Comedy|Drama\n","4        5  Father of the Bride Part II (1995)                        Comedy"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"qNNVg5zuPS__","executionInfo":{"status":"ok","timestamp":1634893434144,"user_tz":-330,"elapsed":2577,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"9a9b6adb-6ff3-46c7-e56f-07fe5899b1bc"},"source":["ratings_df = ratings_df.applymap(int)\n","users_dict = {user : [] for user in set(ratings_df[\"UserID\"])}\n","ratings_df = ratings_df.sort_values(by='Timestamp', ascending=True)\n","\n","ratings_df.head(5)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UserID</th>\n","      <th>MovieID</th>\n","      <th>Rating</th>\n","      <th>Timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1000138</th>\n","      <td>6040</td>\n","      <td>858</td>\n","      <td>4</td>\n","      <td>956703932</td>\n","    </tr>\n","    <tr>\n","      <th>1000153</th>\n","      <td>6040</td>\n","      <td>2384</td>\n","      <td>4</td>\n","      <td>956703954</td>\n","    </tr>\n","    <tr>\n","      <th>999873</th>\n","      <td>6040</td>\n","      <td>593</td>\n","      <td>5</td>\n","      <td>956703954</td>\n","    </tr>\n","    <tr>\n","      <th>1000007</th>\n","      <td>6040</td>\n","      <td>1961</td>\n","      <td>4</td>\n","      <td>956703977</td>\n","    </tr>\n","    <tr>\n","      <th>1000192</th>\n","      <td>6040</td>\n","      <td>2019</td>\n","      <td>5</td>\n","      <td>956703977</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         UserID  MovieID  Rating  Timestamp\n","1000138    6040      858       4  956703932\n","1000153    6040     2384       4  956703954\n","999873     6040      593       5  956703954\n","1000007    6040     1961       4  956703977\n","1000192    6040     2019       5  956703977"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"U_C3qq2_PgAB","executionInfo":{"status":"ok","timestamp":1634893600540,"user_tz":-330,"elapsed":92522,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["ratings_df_gen = ratings_df.iterrows()\n","users_dict_for_history_len = {user : [] for user in set(ratings_df[\"UserID\"])}\n","\n","for data in ratings_df_gen:\n","    users_dict[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n","    if data[1]['Rating'] >= 4:\n","        users_dict_for_history_len[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n","\n","users_history_lens = [len(users_dict_for_history_len[u]) for u in set(ratings_df[\"UserID\"])]\n","\n","users_num = max(ratings_df[\"UserID\"])+1\n","items_num = max(ratings_df[\"MovieID\"])+1\n","\n","train_users_num = int(users_num * 0.8)\n","train_items_num = items_num\n","train_users_dict = {k:users_dict[k] for k in range(1, train_users_num+1)}\n","train_users_history_lens = users_history_lens[:train_users_num]\n","\n","eval_users_num = int(users_num * 0.2)\n","eval_items_num = items_num\n","eval_users_dict = {k:users_dict[k] for k in range(users_num-eval_users_num, users_num)}\n","eval_users_history_lens = users_history_lens[-eval_users_num:]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoQLlDvGPyis","executionInfo":{"status":"ok","timestamp":1634893600546,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["def evaluate(recommender, env, check_movies = False, top_k=False):\n","\n","    # episodic reward 리셋\n","    episode_reward = 0\n","    steps = 0\n","    mean_precision = 0\n","    mean_ndcg = 0\n","    # Environment 리셋\n","    user_id, items_ids, done = env.reset()\n","    \n","    if check_movies:\n","        print(f'user_id : {user_id}, rated_items_length:{len(env.user_items)}')\n","        print('items : \\n', np.array(env.get_items_names(items_ids)))\n","\n","    while not done:\n","\n","        # Observe current state & Find action\n","        ## Embedding 해주기\n","        user_eb = recommender.embedding_network.get_layer('user_embedding')(np.array(user_id))\n","        items_eb = recommender.embedding_network.get_layer('movie_embedding')(np.array(items_ids))\n","        ## SRM으로 state 출력\n","        state = recommender.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(items_eb, axis=0)])\n","        ## Action(ranking score) 출력\n","        action = recommender.actor.network(state)\n","        ## Item 추천\n","        recommended_item = recommender.recommend_item(action, env.recommended_items, top_k=top_k)\n","        if check_movies:\n","            print(f'recommended items ids : {recommended_item}')\n","            print(f'recommened items : \\n {np.array(env.get_items_names(recommended_item), dtype=object)}')\n","        # Calculate reward & observe new state (in env)\n","        ## Step\n","        next_items_ids, reward, done, _ = env.step(recommended_item, top_k=top_k)\n","        if top_k:\n","            correct_list = [1 if r > 0 else 0 for r in reward]\n","            # ndcg\n","            dcg, idcg = calculate_ndcg(correct_list, [1 for _ in range(len(reward))])\n","            mean_ndcg += dcg/idcg\n","            \n","            #precision\n","            correct_num = top_k-correct_list.count(0)\n","            mean_precision += correct_num/top_k\n","            \n","        reward = np.sum(reward)\n","        items_ids = next_items_ids\n","        episode_reward += reward\n","        steps += 1\n","        \n","        if check_movies:\n","            print(f'precision : {correct_num/top_k}, dcg : {dcg:0.3f}, idcg : {idcg:0.3f}, ndcg : {dcg/idcg:0.3f}, reward : {reward}')\n","            print()\n","        break\n","    \n","    if check_movies:\n","        print(f'precision : {mean_precision/steps}, ngcg : {mean_ndcg/steps}, episode_reward : {episode_reward}')\n","        print()\n","    \n","    return mean_precision/steps, mean_ndcg/steps\n","\n","def calculate_ndcg(rel, irel):\n","    dcg = 0\n","    idcg = 0\n","    rel = [1 if r>0 else 0 for r in rel]\n","    for i, (r, ir) in enumerate(zip(rel, irel)):\n","        dcg += (r)/np.log2(i+2)\n","        idcg += (ir)/np.log2(i+2)\n","    return dcg, idcg"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"id":"Z2fj96xLP4be","executionInfo":{"status":"error","timestamp":1634893722396,"user_tz":-330,"elapsed":2777,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d368aa86-821a-4b7c-c729-ebf090278897"},"source":["tf.keras.backend.set_floatx('float64')\n","sum_precision = 0\n","sum_ndcg = 0\n","TOP_K = 10\n","\n","for user_id in eval_users_dict.keys():\n","    env = OfflineEnv(eval_users_dict, users_history_lens, movies_id_to_movies, STATE_SIZE, fix_user_id=user_id)\n","    recommender = DRRAgent(env, users_num, items_num, STATE_SIZE)\n","    recommender.actor.build_networks()\n","    recommender.critic.build_networks()\n","    recommender.load_model('save_weights/actor_10000.h5', \n","                           'save_weights/critic_10000.h5')\n","    precision, ndcg = evaluate(recommender, env, top_k=TOP_K)\n","    sum_precision += precision\n","    sum_ndcg += ndcg\n","    \n","print(f'precision@{TOP_K} : {sum_precision/len(eval_users_dict)}, ndcg@{TOP_K} : {sum_ndcg/len(eval_users_dict)}')"],"execution_count":27,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-b0b81122cb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     recommender.load_model('save_weights/actor_10000.h5', \n\u001b[0;32m---> 12\u001b[0;31m                            'save_weights/critic_10000.h5')\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOP_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msum_precision\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-f62168ff6de8>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, actor_path, critic_path)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-d4d46d027b6e>\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2352\u001b[0m             'first, then load the weights.')\n\u001b[1;32m   2353\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'save_weights/actor_10000.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"cell_type":"code","metadata":{"id":"Yyg5ciHvP7Y1","executionInfo":{"status":"aborted","timestamp":1634893603360,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}}},"source":["sum_precision = 0\n","sum_ndcg = 0\n","TOP_K = 10\n","\n","for user_id in eval_users_dict.keys():\n","    env = OfflineEnv(eval_users_dict, users_history_lens, movies_id_to_movies, STATE_SIZE, fix_user_id=user_id)\n","    recommender = DRRAgent(env, users_num, items_num, STATE_SIZE)\n","    recommender.actor.build_networks()\n","    recommender.critic.build_networks()\n","    recommender.load_model('save_weights/actor_8000.h5', \n","                           'save_weights/critic_8000.h5')\n","    precision, ndcg = evaluate(recommender, env, TOP_K=10)\n","    sum_precision += precision\n","    sum_ndcg += ndcg\n","    \n","print(f'precision@{TOP_K} : {sum_precision/len(eval_users_dict)}, ndcg@{TOP_K} : {sum_ndcg/len(eval_users_dict)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hMKrnTrtQCKi"},"source":[""],"execution_count":null,"outputs":[]}]}