{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-25-dqn-ieee.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T304746%20%7C%20DQN%20RL%20Model%20on%20IEEE%202021%20RecSys%20dataset.ipynb","timestamp":1644670582311}],"collapsed_sections":[],"mount_file_id":"1cSu_pJPPbjTHGZrqhIheo-p9qNroE5IX","authorship_tag":"ABX9TyPCdsWAtS9PFMaAWxtIo6zD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DQN RL Model on IEEE 2021 RecSys dataset"],"metadata":{"id":"cpAvJVlFATkd"}},{"cell_type":"markdown","metadata":{"id":"3GofkbEjwQCI"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaXpEKLdXNPa","executionInfo":{"status":"ok","timestamp":1636279874196,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"81c0ec32-7610-4cf3-e46f-12f54bdfc85e"},"source":["import os\n","project_name = \"ieee21cup-recsys\"; branch = \"main\"; account = \"sparsh-ai\"\n","project_path = os.path.join('/content', branch)\n","\n","if not os.path.exists(project_path):\n","    !cp -r /content/drive/MyDrive/git_credentials/. ~\n","    !mkdir \"{project_path}\"\n","    %cd \"{project_path}\"\n","    !git init\n","    !git remote add origin https://github.com/\"{account}\"/\"{project_name}\".git\n","    !git pull origin \"{branch}\"\n","    !git checkout -b \"{branch}\"\n","else:\n","    %cd \"{project_path}\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/main\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZvPHRyMXdlS","executionInfo":{"status":"ok","timestamp":1636279881076,"user_tz":-330,"elapsed":1014,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"4987f64f-cf0e-40d2-dafa-14b6d3a5e0c6"},"source":["%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"2eRcpGL6XfDs"},"source":["!cd /content/main && git add . && git commit -m 'commit' && git push origin main"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DctyNOSdx-7h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636277206359,"user_tz":-330,"elapsed":4288,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"28b72c68-ee59-4a95-b7ae-c1ea87509527"},"source":["!pip install -q wget"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"vrEmNkAAsQlM"},"source":["import io\n","import copy\n","import sys\n","import wget\n","import os\n","import random\n","import logging\n","import pandas as pd\n","from os import path as osp\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from pathlib import Path\n","import math\n","from copy import deepcopy\n","from collections import OrderedDict\n","\n","import multiprocessing as mp\n","import functools\n","from sklearn.preprocessing import MinMaxScaler\n","import pdb\n","\n","from prettytable import PrettyTable\n","\n","import bz2\n","import pickle\n","import _pickle as cPickle\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4swQxyAsQnj"},"source":["class Args:\n","\n","    # Paths\n","    datapath_bronze = '/content/main/data/bronze'\n","    datapath_silver = '/content/main/data/silver/T304746'\n","    datapath_gold = '/content/main/data/gold/T304746'\n","\n","    filename_trainset = 'train.csv'\n","    filename_iteminfo = 'item_info.csv'\n","    filename_track1_testset = 'track1_testset.csv'\n","    filename_track2_testset = 'track2_testset.csv'\n","\n","    data_sep = ' '\n","\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wIDRSKqOtEdb"},"source":["logging.basicConfig(stream=sys.stdout,\n","                    level = logging.INFO,\n","                    format='%(asctime)s [%(levelname)s] : %(message)s',\n","                    datefmt='%d-%b-%y %H:%M:%S')\n","\n","logger = logging.getLogger('IEEE21 Logger')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1bmqnvQv27E"},"source":["## Utilities"]},{"cell_type":"code","metadata":{"id":"tH7lmOJbAOIf"},"source":["def save_pickle(data, title):\n"," with bz2.BZ2File(title, 'w') as f: \n","    cPickle.dump(data, f)\n","\n","def load_pickle(path):\n","    data = bz2.BZ2File(path, 'rb')\n","    data = cPickle.load(data)\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AGTVUdmtwWgZ"},"source":["def download_dataset():\n","    # create bronze folder if not exist\n","    Path(args.datapath_bronze).mkdir(parents=True, exist_ok=True)\n","    # also creating silver and gold folder for later use\n","    Path(args.datapath_silver).mkdir(parents=True, exist_ok=True)\n","    Path(args.datapath_gold).mkdir(parents=True, exist_ok=True)\n","    # for each of the file, download if not exist\n","    datasets = ['train.parquet.snappy', 'item_info.parquet.snappy',\n","                'track1_testset.parquet.snappy', 'track2_testset.parquet.snappy']\n","    for filename in datasets:\n","        file_savepath = osp.join(args.datapath_bronze,filename)\n","        if not osp.exists(file_savepath):\n","            logger.info('Downloading {}'.format(filename))\n","            wget.download(url='https://github.com/sparsh-ai/ieee21cup-recsys/raw/main/data/bronze/{}'.format(filename),\n","                          out=file_savepath)\n","        else:\n","            logger.info('{} file already exists, skipping!'.format(filename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vk93jRMwtEWP"},"source":["def parquet_to_csv(path):\n","    savepath = osp.join(str(Path(path).parent),str(Path(path).name).split('.')[0]+'.csv')\n","    pd.read_parquet(path).to_csv(savepath, index=False, sep=args.data_sep)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_F4vRpFCzYsf"},"source":["def convert_dataset():\n","    # for each of the file, convert into csv, if csv not exist\n","    datasets = ['train.parquet.snappy', 'item_info.parquet.snappy',\n","                'track1_testset.parquet.snappy', 'track2_testset.parquet.snappy']\n","    datasets = {x:str(Path(x).name).split('.')[0]+'.csv' for x in datasets}\n","    for sfilename, tfilename in datasets.items():\n","        file_loadpath = osp.join(args.datapath_bronze,sfilename)\n","        file_savepath = osp.join(args.datapath_bronze,tfilename)\n","        if not osp.exists(file_savepath):\n","            logger.info('Converting {} to {}'.format(sfilename, tfilename))\n","            parquet_to_csv(file_loadpath)\n","        else:\n","            logger.info('{} file already exists, skipping!'.format(tfilename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_uT85xbufVi"},"source":["def normalize(array, axis=0):\n","    _min = array.min(axis=axis, keepdims=True)\n","    _max = array.max(axis=axis, keepdims=True)\n","    factor = _max - _min\n","    return (array - _min) / np.where(factor != 0, factor, 1)\n","\n","\n","def parse_click_history(history_list):\n","    clicks = list(map(lambda user_click: list(map(lambda item: item.split(':')[0],\n","                                                  user_click.split(','))),\n","                      history_list))\n","    _max_len = max(len(items) for items in clicks)\n","    clicks = [items + [0] * (_max_len - len(items)) for items in clicks]\n","    clicks = torch.tensor(np.array(clicks, dtype=np.long)) - 1\n","    return clicks\n","\n","\n","def parse_user_protrait(protrait_list):\n","    return torch.tensor(normalize(np.array(list(map(lambda x: x.split(','),\n","                                                    protrait_list)),\n","                                           dtype=np.float32)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2RIZ1rnugVW"},"source":["def process_item():\n","    readfilepath = osp.join(args.datapath_bronze,args.filename_iteminfo)\n","    outfilepath = osp.join(args.datapath_silver,'items_info.pt')\n","\n","    if not osp.exists(outfilepath):\n","        logger.info('processing items ...')\n","        item_info = pd.read_csv(readfilepath, sep=args.data_sep)\n","        item2id = np.array(item_info['item_id']) - 1\n","        item2loc = torch.tensor(np.array(item_info['location'], dtype=np.float32)[item2id])\n","        item2price = torch.tensor(normalize(np.array(item_info['price'], dtype=np.float32)[item2id]) * 10, dtype=torch.float32)\n","        item2feature = torch.tensor(normalize(np.array(list(map(lambda x: x.split(','),\n","                                                item_info['item_vec'])),\n","                                        dtype=np.float32)[item2id]))\n","        item2info = torch.cat([item2feature, item2price[:, None], item2loc[:, None]], dim=-1)\n","        torch.save([item2info, item2price, item2loc], outfilepath)\n","        logger.info('processed data saved at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} already exists, skipping ...'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngXkd__hvcRN"},"source":["def process_data(readfilepath, outfilepath):\n","    if not osp.exists(outfilepath):\n","        logger.info('processing data ...')\n","        logger.info('loading raw file {} ...'.format(readfilepath))\n","        dataset = pd.read_csv(readfilepath, sep=args.data_sep)\n","        click_items = parse_click_history(dataset['user_click_history'])\n","        user_protrait = parse_user_protrait(dataset['user_protrait'])\n","        exposed_items = None\n","        if 'exposed_items' in dataset.columns:\n","            exposed_items = torch.tensor(np.array(list(map(lambda x: x.split(','),\n","                                                        dataset['exposed_items'])),\n","                                                dtype=np.long) - 1)\n","        torch.save([user_protrait, click_items, exposed_items], outfilepath)\n","        logger.info('processed data saved at {}'.format(outfilepath))\n","    else:\n","        logger.info('{} already exists, skipping ...'.format(outfilepath))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7G5jruLvGDH"},"source":["def process_data_wrapper():\n","    ds = {\n","        args.filename_trainset:'train.pt',\n","        args.filename_track1_testset:'dev.pt',\n","        args.filename_track2_testset:'test.pt',\n","    }\n","    process_item()\n","    for k,v in ds.items():\n","        readfilepath = osp.join(args.datapath_bronze,k)\n","        outfilepath = osp.join(args.datapath_silver,v)\n","        process_data(readfilepath, outfilepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KB8J9nl1FzVm"},"source":["class Dataset:\n","    def __init__(self, filename, batch_size=1024):\n","        self.user_protrait, self.click_items, self.exposed_items \\\n","                = torch.load(filename)\n","        self.click_mask = self.click_items != -1\n","        self.click_items[self.click_items == -1] = 0\n","\n","        self.all_indexs = list(range(len(self.user_protrait)))\n","        self.cur_index = 0\n","        self.bz = batch_size\n","\n","    def reset(self):\n","        random.shuffle(self.all_indexs)\n","        self.cur_index = 0\n","\n","    def __len__(self):\n","        return len(self.all_indexs) // self.bz + int(bool(len(self.all_indexs) % self.bz))\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        if self.cur_index >= len(self.all_indexs):\n","            raise StopIteration\n","    \n","        i = self.all_indexs[self.cur_index:self.cur_index + self.bz]\n","        user, click_items, click_mask = \\\n","                self.user_protrait[i], self.click_items[i], self.click_mask[i]\n","        exposed_items = self.exposed_items[i] if self.exposed_items is not None else None\n","\n","        self.cur_index += self.bz\n","\n","        return user, click_items, click_mask, exposed_items if exposed_items is not None else None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1J1rPHpGBsm"},"source":["class Env:\n","    def __init__(self, value, K=3):\n","        self.K = K - 1\n","        self.value = np.asarray(value)\n","\n","    def done(self, obs):\n","        return obs[3] is not None and obs[3].size(1) == self.K\n","\n","    def __recall(self, s, t):\n","        return sum(i in t for i in s) / len(t)\n","\n","    def __reward(self, s, t):\n","        return self.__recall(s, t) * self.value[s].sum()\n","\n","    def new_obs(self, batch_obs, batch_actions):\n","        batch_users, batch_click_items, batch_click_mask, \\\n","                batch_exposed_items, batch_exposed_mask = batch_obs\n","        \n","        batch_new_exposed_items = torch.cat(\n","            [batch_exposed_items, batch_actions.unsqueeze(1)], dim=1\n","        ) if batch_exposed_items is not None else batch_actions.unsqueeze(1)\n","        \n","        _add_mask = torch.tensor([[True]]).expand(batch_users.size(0), -1)\n","        batch_new_exposed_mask = torch.cat(\n","            [batch_exposed_mask, _add_mask], dim=1\n","        ) if batch_exposed_mask is not None else _add_mask\n","        \n","        batch_new_obs = (batch_users, batch_click_items, batch_click_mask,\n","                         batch_new_exposed_items, batch_new_exposed_mask)\n","        return batch_new_obs\n","\n","    def step(self, batch_obs, batch_actions, batch_target_bundles, time):\n","        batch_rews = torch.tensor([self.__reward(action, bundle) \\\n","                                   for action, bundle in zip(batch_actions, batch_target_bundles[:, time])],\n","                                  dtype=torch.float32)\n","        batch_users, batch_click_items, batch_click_mask, \\\n","                batch_exposed_items, batch_exposed_mask = batch_obs\n","        done = batch_exposed_mask is not None and batch_exposed_mask[0].sum() == self.K\n","        if done:\n","            batch_new_obs = [None] * batch_users.size(0)\n","        else:\n","            batch_new_obs = self.new_obs(batch_obs, batch_actions)\n","        \n","        return batch_new_obs, batch_rews, torch.tensor([done] * batch_actions.size(0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKXTFUjOGJ8T"},"source":["def table_format(data, field_names=None, title=None):\n","    tb = PrettyTable()\n","    if field_names is not None:\n","        tb.field_names = field_names\n","        for i, name in enumerate(field_names):\n","            tb.align[name] = 'r' if i else 'l'\n","    if title is not None:\n","        tb.title = title\n","    tb.add_rows(data)\n","    return tb.get_string()\n","\n","\n","def recall(batch_pred_bundles, batch_target_bundles):\n","    rec, rec1, rec2, rec3 = [], [], [], []\n","    for pred_bundle, target_bundle in zip(batch_pred_bundles, batch_target_bundles):\n","        recs = []\n","        for bundle_a, bundle_b in zip(pred_bundle, target_bundle):\n","            recs.append(len(set(bundle_a.tolist()) & set(bundle_b.tolist())) / len(bundle_b))\n","        rec1.append(recs[0])\n","        rec2.append(recs[1])\n","        rec3.append(recs[2])\n","        rec.append((rec1[-1] + rec2[-1] + rec3[-1]) / 3)\n","    return np.mean(rec), np.mean(rec1), np.mean(rec2), np.mean(rec3)\n","\n","\n","def nan2num(tensor, num=0):\n","    tensor[tensor != tensor] = num\n","\n","\n","def inf2num(tensor, num=0):\n","    tensor[tensor == float('-inf')] = num\n","    tensor[tensor == float('inf')] = num\n","\n","\n","def tensor2device(tensors, device):\n","    return [tensor.to(device) if tensor is not None else None \\\n","            for tensor in tensors]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMZwihM7Gdzg"},"source":["def _calc_q_value(obs, net, act_mask, device):\n","    batch_users, batch_encoder_item_ids, encoder_mask, \\\n","            batch_decoder_item_ids, decoder_mask = tensor2device(obs, device)\n","    return net(batch_users,\n","               batch_encoder_item_ids,\n","               encoder_mask,\n","               batch_decoder_item_ids,\n","               decoder_mask,\n","               act_mask.unsqueeze(0).expand(batch_users.size(0), -1) if act_mask is not None else None)\n","\n","\n","def build_train(q_net,\n","                optimizer,\n","                grad_norm_clipping,\n","                act_mask,\n","                gamma=0.99,\n","                is_gpu=False):\n","    device = torch.device('cuda') if is_gpu else torch.device('cpu')\n","    q_net.to(device)\n","\n","    t_net = deepcopy(q_net)\n","    t_net.eval()\n","    t_net.to(device)\n","    optim = optimizer(q_net.parameters())\n","\n","    act_mask = act_mask.to(device)\n","\n","    if is_gpu and torch.cuda.device_count() > 1:\n","        q_net = torch.nn.DataParallel(q_net)\n","        t_net = torch.nn.DataParallel(t_net)\n","\n","    def save_model(filename,\n","                   epoch,\n","                   episode_rewards,\n","                   saved_mean_reward):\n","        torch.save({\n","            'epoch': epoch,\n","            'episode_rewards': episode_rewards,\n","            'saved_mean_reward': saved_mean_reward,\n","            'model': q_net.state_dict(),\n","            'optim': optim.state_dict()\n","        }, filename)\n","\n","    def load_model(filename):\n","        checkpoint = torch.load(filename,\n","                                map_location=torch.device('cpu'))\n","        #q_net.load_state_dict(checkpoint['model'])\n","        new_state_dict = OrderedDict()\n","        for k, v in checkpoint['model'].items():\n","            if k.find('module.') != -1:\n","                k = k[7:]\n","            new_state_dict[k] = v\n","        q_net.load_state_dict(new_state_dict)\n","        optim.load_state_dict(checkpoint['optim'])\n","        return checkpoint['epoch'], checkpoint['episode_rewards'], checkpoint['saved_mean_reward']\n","\n","    def train(obs,\n","              act,\n","              rew,\n","              next_obs,\n","              isweights,\n","              done_mask,\n","              topk=3):\n","        act, rew, isweights = act.to(device), rew.to(device), isweights.to(device)\n","        # q value at t+1 in double q\n","        with torch.no_grad():\n","            q_net.eval()\n","            next_q_val = _calc_q_value(next_obs, q_net, act_mask, device).detach()\n","            q_net.train()\n","            \n","            _next_mask = next_obs[4].to(device).sum(dim=1, keepdim=True) + 1 == act_mask.unsqueeze(0)\n","            assert next_q_val.size() == _next_mask.size()\n","\n","            next_q_val[_next_mask == False] = float('-inf')\n","\n","            next_action_max = next_q_val.argsort(dim=1, descending=True)[:, :topk]\n","            next_q_val_max = _calc_q_value(next_obs, t_net, act_mask, device) \\\n","                                   .detach() \\\n","                                   .gather(dim=1, index=next_action_max) \\\n","                                   .sum(dim=1)\n","\n","            _next_q_val_max = next_q_val_max.new_zeros(done_mask.size())\n","            _next_q_val_max[done_mask == False] = next_q_val_max\n","        # q value at t\n","        q_val = _calc_q_value(obs, q_net, act_mask, device)\n","        q_val_t = q_val.gather(dim=1, index=act.to(device)).sum(dim=1)\n","        assert q_val_t.size() == _next_q_val_max.size()\n","        #print('done')\n","        # Huber Loss\n","        loss = F.smooth_l1_loss(q_val_t,\n","                                rew + gamma * _next_q_val_max,\n","                                reduction='none')\n","        assert loss.size() == isweights.size()\n","        #wloss = (loss * isweights).mean()\n","        wloss = loss.mean()\n","        wloss.backward()\n","        torch.nn.utils.clip_grad_norm_(q_net.parameters(), grad_norm_clipping)\n","        optim.step()\n","        q_net.zero_grad()\n","\n","        return wloss.detach().data.item(), (loss.detach().mean().data.item()), loss.cpu().detach().abs()\n","\n","    def act(obs,\n","            eps_greedy,\n","            topk=3,\n","            is_greedy=False):\n","        return build_act(obs, act_mask, q_net, eps_greedy, topk,\n","                         is_greedy=is_greedy, device=device)\n","\n","    def update_target():\n","        for target_param, local_param in zip(t_net.parameters(), q_net.parameters()):\n","            target_param.data.copy_(local_param.data)\n","\n","    return q_net, act, train, update_target, save_model, load_model\n","\n","\n","def build_act(obs,\n","              act_mask,\n","              net,\n","              eps_greedy,\n","              topk=3,\n","              is_greedy=False,\n","              device=None):\n","    devcie = torch.device('cpu') if device is None else device\n","    act_mask = act_mask.to(device)\n","    def _epsilon_greedy(size):\n","        return torch.rand(size).to(device) < eps_greedy\n","    def _gen_act_mask():\n","        #if obs[3] is not None:\n","        if obs[4] is not None:\n","            #length = torch.tensor([len(o) + 1 if o is not None else 1 for o in obs[3]],\n","            #                      dtype=torch.float).view(-1, 1).to(device)\n","            length = obs[4].to(device).sum(dim=1, keepdim=True) + 1\n","        else:\n","            length = act_mask.new_ones((1,)).view(-1, 1)\n","        return act_mask.unsqueeze(0) == length\n","    net.eval()\n","    with torch.no_grad():\n","        q_val = _calc_q_value(obs, net, act_mask, device).detach()\n","        _act_mask = _gen_act_mask()\n","        if q_val.size() != _act_mask.size():\n","            assert _act_mask.size(0) == 1\n","            _act_mask = _act_mask.expand(q_val.size(0), -1)\n","        q_val[_act_mask == False] = float('-inf')\n","        _deterministic_acts = q_val.argsort(dim=1, descending=True)[:, :topk]\n","        if not is_greedy:\n","            _stochastic_acts = _deterministic_acts.new_empty(_deterministic_acts.size())\n","            chose_random = _epsilon_greedy(_stochastic_acts.size(0))\n","            _tmp = torch.arange(0, _act_mask.size(1), dtype=_deterministic_acts.dtype)\n","            for i in range(_act_mask.size(0)):\n","                _available_acts = _act_mask[i].nonzero().view(-1)\n","                _stochastic_acts[i] = _available_acts[torch.randperm(_available_acts.size(0))[:topk]]\n","            #if chose_random.sum() != len(chose_random):\n","            #    pdb.set_trace()\n","            _acts = torch.where(chose_random.unsqueeze(1).expand(-1, _stochastic_acts.size(1)),\n","                                _stochastic_acts,\n","                                _deterministic_acts)\n","            # TODO 去重       \n","        else:\n","            _acts = _deterministic_acts\n","            eps_greedy = 0.\n","    net.train()\n","    \n","    return _acts, eps_greedy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"koFQxtgos6gE"},"source":["## Jobs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2y8mdDjds6dr","executionInfo":{"status":"ok","timestamp":1636280333092,"user_tz":-330,"elapsed":578,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"d31698d0-83b0-4d1a-dae7-0697787c5c5f"},"source":["logger.info('JOB START: DOWNLOAD_RAW_DATASET')\n","download_dataset()\n","logger.info('JOB END: DOWNLOAD_RAW_DATASET')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["07-Nov-21 10:18:53 [INFO] : JOB START: DOWNLOAD_RAW_DATASET\n","07-Nov-21 10:18:53 [INFO] : train.parquet.snappy file already exists, skipping!\n","07-Nov-21 10:18:53 [INFO] : item_info.parquet.snappy file already exists, skipping!\n","07-Nov-21 10:18:53 [INFO] : track1_testset.parquet.snappy file already exists, skipping!\n","07-Nov-21 10:18:53 [INFO] : track2_testset.parquet.snappy file already exists, skipping!\n","07-Nov-21 10:18:53 [INFO] : JOB END: DOWNLOAD_RAW_DATASET\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ig3tPpB2Fx-","executionInfo":{"status":"ok","timestamp":1636277232354,"user_tz":-330,"elapsed":14778,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"1ba6042e-b8f6-4084-a1c3-69b7e0cefeaa"},"source":["logger.info('JOB START: DATASET_CONVERSION_PARQUET_TO_CSV')\n","convert_dataset()\n","logger.info('JOB END: DATASET_CONVERSION_PARQUET_TO_CSV')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["07-Nov-21 09:26:58 [INFO] : JOB START: DATASET_CONVERSION_PARQUET_TO_CSV\n","07-Nov-21 09:26:58 [INFO] : Converting train.parquet.snappy to train.csv\n","07-Nov-21 09:27:04 [INFO] : Converting item_info.parquet.snappy to item_info.csv\n","07-Nov-21 09:27:04 [INFO] : Converting track1_testset.parquet.snappy to track1_testset.csv\n","07-Nov-21 09:27:08 [INFO] : Converting track2_testset.parquet.snappy to track2_testset.csv\n","07-Nov-21 09:27:12 [INFO] : JOB END: DATASET_CONVERSION_PARQUET_TO_CSV\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kj4VvaPE7s4P","executionInfo":{"status":"ok","timestamp":1636283043925,"user_tz":-330,"elapsed":659,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3f057f8b-db97-4196-90f5-77e39351c32a"},"source":["logger.info('JOB START: DATASET_PREPROCESSING')\n","process_data_wrapper()\n","logger.info('JOB END: DATASET_PREPROCESSING')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["07-Nov-21 11:04:04 [INFO] : JOB START: DATASET_PREPROCESSING\n","07-Nov-21 11:04:04 [INFO] : /content/main/data/silver/T304746/items_info.pt already exists, skipping ...\n","07-Nov-21 11:04:04 [INFO] : /content/main/data/silver/T304746/train.pt already exists, skipping ...\n","07-Nov-21 11:04:04 [INFO] : /content/main/data/silver/T304746/dev.pt already exists, skipping ...\n","07-Nov-21 11:04:04 [INFO] : /content/main/data/silver/T304746/test.pt already exists, skipping ...\n","07-Nov-21 11:04:04 [INFO] : JOB END: DATASET_PREPROCESSING\n"]}]},{"cell_type":"code","metadata":{"id":"_8QpqVrsEcr5"},"source":[""],"execution_count":null,"outputs":[]}]}