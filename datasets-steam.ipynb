{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.steam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Dataset\n",
    "> Implementation of Steam games dataset.\n",
    "\n",
    "Steam is the world's most popular PC Gaming hub, with over 6,000 games and a community of millions of gamers. With a massive collection that includes everything from AAA blockbusters to small indie titles, great discovery tools are a highly valuable asset for Steam.\n",
    "\n",
    "Steam Video Game and Bundle Data\n",
    "\n",
    "These datasets contain reviews from the Steam video game platform, and information about which games were bundled together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from recohut.utils.common_utils import *\n",
    "from recohut.datasets.bases.common import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SteamDataset(Dataset):\n",
    "    games_url = 'https://github.com/RecoHut-Datasets/steam/raw/v1/steam_games.json.gz'\n",
    "    users_url = 'https://github.com/RecoHut-Datasets/steam/raw/v1/australian_users_items.json.gz'\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__(data_dir)\n",
    "        \n",
    "        self._process()\n",
    " \n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return ['steam_games.json', 'australian_users_items.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return ['gamesdata.parquet.snappy', 'mergeddata.parquet.snappy', \n",
    "                'numgames.parquet.snappy', 'recdata.parquet.snappy']\n",
    "\n",
    "    def download(self):\n",
    "        for url in [self.games_url, self.users_url]:\n",
    "            path = download_url(url, self.raw_dir)\n",
    "            extract_gz(path, self.raw_dir)\n",
    "            os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        with open(self.raw_paths[0]) as f:\n",
    "            lines = f.readlines()\n",
    "        lines_list = []\n",
    "        for l in lines:\n",
    "            _x = '[' + l + ']'\n",
    "            _x =  ast.literal_eval(_x)\n",
    "            lines_list.extend(_x)\n",
    "        temp_path = os.path.join(self.processed_dir, 'meta.json')\n",
    "        with open(temp_path, 'w') as json_file:\n",
    "            json.dump(lines_list, json_file)\n",
    "        df = pd.read_json(temp_path)\n",
    "        df.price = df.price.astype('str')\n",
    "        df.metascore = df.metascore.astype('str')\n",
    "        os.unlink(temp_path)\n",
    "\n",
    "        with open(self.raw_paths[1]) as f:\n",
    "            lines = f.readlines()\n",
    "        lines_list = []\n",
    "        for l in lines:\n",
    "            _x = '[' + l + ']'\n",
    "            _x =  ast.literal_eval(_x)\n",
    "            lines_list.extend(_x)\n",
    "        temp_path = os.path.join(self.processed_dir, 'data.json')\n",
    "        with open(temp_path, 'w') as json_file:\n",
    "            json.dump(lines_list, json_file)\n",
    "        useritems = pd.read_json(temp_path)\n",
    "        os.unlink(temp_path)\n",
    "\n",
    "        useritems['item_id'] = useritems['items'].apply(lambda x: [x [index]['item_id'] for index, _ in enumerate(x)])\n",
    "        # Add a column with substitute user_id, counter\n",
    "        useritems['uid'] = np.arange(len(useritems))\n",
    "        # numgames dataframe for later use\n",
    "        numgames = useritems[['user_id', 'items_count']]\n",
    "        # Take relevant columns\n",
    "        useritems = useritems[['uid', 'item_id']]\n",
    "        # Explode item_ids into seperate rows\n",
    "        lst_col = 'item_id'\n",
    "        useritems = pd.DataFrame({col:np.repeat(useritems[col].values, useritems[lst_col].str.len())\n",
    "                                    for col in useritems.columns.difference([lst_col])\n",
    "                                }).assign(**{lst_col:np.concatenate(useritems[lst_col].values)})[useritems.columns.tolist()]\n",
    "        # Add binary owned column\n",
    "        useritems['owned'] = np.ones(shape = useritems.shape[0])\n",
    "        # Change item_id to int\n",
    "        useritems['item_id'] = useritems['item_id'].astype(int)\n",
    "        # Rename column to match\n",
    "        useritems = useritems.rename(columns={'item_id': 'id'})\n",
    "        # Merge useritems and games data dataframes\n",
    "        alldata = pd.merge(useritems, df, on = 'id')\n",
    "        # Drop entries with no title\n",
    "        datawithnames = alldata.dropna(axis=0, subset=['title'])\n",
    "        # Get relevant columns for recommendation engine\n",
    "        recdata = datawithnames[['uid','id','owned']]\n",
    "\n",
    "        df.to_parquet(self.processed_paths[0], compression='snappy')\n",
    "        datawithnames.to_parquet(self.processed_paths[1], compression='snappy')\n",
    "        numgames.to_parquet(self.processed_paths[2], compression='snappy')\n",
    "        recdata.to_parquet(self.processed_paths[3], compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    }
   ],
   "source": [
    "ds = SteamDataset(data_dir='/content/data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
