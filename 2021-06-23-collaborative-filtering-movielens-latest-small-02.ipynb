{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "2.User-basedCollaborativeFiltering.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyPbyojOhURY"
      },
      "source": [
        "# CF Part 2 - User-based method\n",
        "> Collaborative Filtering on MovieLens Latest-small Part 2 - Finding recommendations using memory based user-user similarity method\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [movie, collaborative]\n",
        "- image:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE33o-Z1gB5y"
      },
      "source": [
        "### Download tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_11-qrsSgB51"
      },
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbwgznIgB57"
      },
      "source": [
        "### Import requirements\n",
        "```\n",
        "matplotlib==3.2.2\n",
        "numpy==1.19.2\n",
        "pandas==1.0.5\n",
        "python==3.7\n",
        "scikit-learn==0.24.1\n",
        "scikit-surprise==1.1.1\n",
        "scipy==1.6.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS_R1id1gB5-"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from recsys.datasets import ml100k\n",
        "from recsys.preprocessing import ids_encoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i95Dc1UUgB5_"
      },
      "source": [
        "### Load MovieLen ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g3RGJAmgB6B"
      },
      "source": [
        "ratings, movies = ml100k.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11V7xUSbgB6G"
      },
      "source": [
        "### userids and itemids encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPxE5jUkgB6M"
      },
      "source": [
        "# create the encoder\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jO1hP-7gB6O"
      },
      "source": [
        "### Transform rating dataframe to matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi_AduhbgB6T"
      },
      "source": [
        "def ratings_matrix(ratings):    \n",
        "    return csr_matrix(pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum).fillna(0).values)    \n",
        "\n",
        "R = ratings_matrix(ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rx37eszgB6W"
      },
      "source": [
        "Memory based collaborative filtering (CF) also known as nearest neighbors based CF makes recommendation based on similar behavious of users and items. There are two types of memory based CF : <b>user-based</b> and <b>item-based</b> CF. Both of these algorithm usually proceed in three stages :\n",
        "\n",
        "1. Similarity computation (between users or items)\n",
        "2. Rating prediction (using ratings of similar users or items)\n",
        "3. Top-N recommendation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hCnJQNbgB6f"
      },
      "source": [
        "## Idea\n",
        "\n",
        "Let $u$ be the user for which we plan to make recommendations. \n",
        "\n",
        "1. Find other users whose past rating behavior is similar to that of $u$\n",
        "2. Use their ratings on other items to predict what the current user will like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y4SvQ9ogB6h"
      },
      "source": [
        "## Algorithm : user-to-user collaborative filtering\n",
        "\n",
        "The entire process of user-to-user CF algorithm is described as follow <a href=\"https://romisatriawahono.net/lecture/rm/survey/information%20retrieval/Bobadilla%20-%20Recommender%20Systems%20-%202013.pdf\">(J. Bobadilla et al. 2013)</a>: For an active user $u$,\n",
        "\n",
        "<ol>\n",
        "    <li> First identify the set $G_u$ of $k$ most similar users. $G_u$ is the group users similar to the active user $u$. The similarity between two users $u$ and $v$ can be measured by the cosine similarity measure as follows :\n",
        "\n",
        "\\begin{equation}\n",
        " w_{u,v}=\\frac{\\vec{r}_u \\cdot \\vec{r}_v}{\\|\\vec{r}_u\\|_2 \\ast \\|\\vec{r}_v\\|_2} = \\frac{\\sum_{i\\in I}r_{u,i}r_{v,i}}{\\sqrt{\\sum_{i\\in I} (r_{u,i})^2}\\sqrt{\\sum_{i\\in I} (r_{v,i})^2}}\n",
        "\\end{equation}\n",
        "\n",
        "$w_{u,v}$ is the degree of similarity between users $u$ and $v$. This term is computed for all $v\\in U$, where $U$ is the set of all users. There remains the question of how many neighbors to select. As experimented by <a href=\"https://dl.acm.org/doi/10.1145/3130348.3130372\">(Herlocker et al. 1999)</a>, $k\\in [20,50]$ is a reasonable starting point in many domains.\n",
        "    </li>\n",
        "    <li> Find the set $C$ of candidate items, purchased by the group and not purchased by the active user $u$. Candidate items have to be the most frequent items purchased by the group.\n",
        "    </li>\n",
        "    <li>Aggregate ratings of users in $G_u$ to make predictions for user $u$ on items he has not already purchased. Several aggregation approaches are often used such as <b>average, weighted sum, ajusted weighted sum</b>. By using weighted sum, the predicted rating of user $u$ on item $i$ denoted by $\\hat{r}_{u,i}$ is computed as follow :\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\bar{r}_u + \\frac{\\sum_{v\\in G_u}(r_{v,i}-\\bar{r}_v)\\cdot w_{u,v}}{\\sum_{v\\in G_u}|w_{u,v}|}.\n",
        "\\end{equation}\n",
        "\n",
        "Ratings of similar users are weighted by the corresponding similarity with the active user. Summation are made over all the users who have rated item $i$. Subtracting the user’s mean rating $\\bar{r}_v$ compensates for differences in users’ use of the rating scale as some users will tend to give higher ratings than others <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>. This prediction is made for all items $i \\in C$ not purchased by user $u$.\n",
        "    </li>\n",
        "    <li>The Top-$N$ recommendations are obtained by choosing the $N$ items which provide most satisfaction to the user according to prediction.\n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9cuEYongB6j"
      },
      "source": [
        "### Step 1. Identify $G_u$, the set of $k$ users similar to an active user $u$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXPwjOm2gB6l"
      },
      "source": [
        "To find the $k$ most similar users to $u$, we use the cosine similarity and compute $w_{u,v}$ for all $v\\in U$. Fortunately, libraries such as <i>scikit-learn (sklearn)</i> are very useful for such tasks :\n",
        "\n",
        "1. First of all, we create a nearest neighbors model with sklearn through the function ```create_model()```. This function creates and fit a nearest neighbors model with user's ratings. We can choose ```cosine``` or ```euclidian``` based similarity metric. ```n_neighbors=21``` define the number of neighbors to return. With $k=20$ neighbors, $|G_u|=21$ as $G_u$ contains $20$ similar users added to the active user $u$. That is why ```n_neighbors=21```. Each row $r_u$ of the rating matrix $R$ represents ratings of user $u$ on all items of the database. Missing ratings are replaced with $0.0$. \n",
        "```python\n",
        "R[u,:] # uth row of the rating matrix R. Ratings of user u on all items in the database\n",
        "```\n",
        "2. Function ```nearest_neighbors()``` returns the knn users for each user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9x9jpDkgB6n"
      },
      "source": [
        "def create_model(rating_matrix, metric):\n",
        "    \"\"\"\n",
        "    - create the nearest neighbors model with the corresponding similarity metric\n",
        "    - fit the model\n",
        "    \"\"\"\n",
        "    model = NearestNeighbors(metric=metric, n_neighbors=21, algorithm='brute')\n",
        "    model.fit(rating_matrix)    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnSme27dgB6p"
      },
      "source": [
        "def nearest_neighbors(rating_matrix, model):\n",
        "    \"\"\"    \n",
        "    :param rating_matrix : rating matrix of shape (nb_users, nb_items)\n",
        "    :param model : nearest neighbors model    \n",
        "    :return\n",
        "        - similarities : distances of the neighbors from the referenced user\n",
        "        - neighbors : neighbors of the referenced user in decreasing order of similarities\n",
        "    \"\"\"    \n",
        "    similarities, neighbors = model.kneighbors(rating_matrix)        \n",
        "    return similarities[:, 1:], neighbors[:, 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXbvxzC8gB6q"
      },
      "source": [
        "Let's call functions ```create_model()``` and ```nearest_neighbors()``` to respectively create the $k$-NN model and compute the nearest neighbors for a given user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cqqDR_5gB6r"
      },
      "source": [
        "model = create_model(rating_matrix=R, metric='cosine') # we can also use the 'euclidian' distance\n",
        "similarities, neighbors = nearest_neighbors(R, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Gh_1bCgB6s"
      },
      "source": [
        "### Step 2. Find candidate items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mozg_Q3NgB6v"
      },
      "source": [
        "The set $C$ of candidate items are the most frequent ones purchased by users in $G_u$ for an active user $u$ and not purchased by $u$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeIcM33KgB6x"
      },
      "source": [
        "Function ```find_candidate_items()``` : find items purchased by these similar users as well as their frequency. Note that the frequency of the items in the set $C$ can be computed by just counting the actual occurrence frequency of that items.\n",
        "\n",
        "1. ```Gu_items``` : frequent items of $G_u$ in decreasing order of frequency.\n",
        "2. ```active_items``` : items already purchased by the active user\n",
        "3. ```candidates``` : frequent items of $G_u$ not purchased by the active user $u$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VvpeZcgB64"
      },
      "source": [
        "def find_candidate_items(userid):\n",
        "    \"\"\"\n",
        "    Find candidate items for an active user\n",
        "    \n",
        "    :param userid : active user\n",
        "    :param neighbors : users similar to the active user        \n",
        "    :return candidates : top 30 of candidate items\n",
        "    \"\"\"\n",
        "    user_neighbors = neighbors[userid]\n",
        "    activities = ratings.loc[ratings.userid.isin(user_neighbors)]\n",
        "    \n",
        "    # sort items in decreasing order of frequency\n",
        "    frequency = activities.groupby('itemid')['rating'].count().reset_index(name='count').sort_values(['count'],ascending=False)\n",
        "    Gu_items = frequency.itemid\n",
        "    active_items = ratings.loc[ratings.userid == userid].itemid.to_list()\n",
        "    candidates = np.setdiff1d(Gu_items, active_items, assume_unique=True)[:30]\n",
        "        \n",
        "    return candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr3w67zOgB69"
      },
      "source": [
        "### Step 3. Rating prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxnNDPLsgB7A"
      },
      "source": [
        "Now it's time to predict what score the active user $u$ would have given to each of the top-30 candidate items.\n",
        "\n",
        "To predict the score of $u$ on a candidate item $i$ ,we need :\n",
        "1. Similarities between $u$ and all his neighbors $v \\in G_u$ who rated item $i$ : function ```nearest_neighbors()``` returns similar users of a user as well as their corresponding similarities.\n",
        "2. Normalized ratings of all $v \\in G_u$ on item $i$. The normalized rating of user $v$ on item $i$ is defined by $r_{v,i}-\\bar{r}_v$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRT3d7BLgB7E"
      },
      "source": [
        "Next, let's compute the mean rating of each user and the normalized ratings for each item. The DataFrame ```mean``` contains mean rating for each user. With the mean rating of each user, we can add an extra column ```norm_rating``` to the ```ratings```'s DataFrame which can be accessed to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZ-DZN_gB7M"
      },
      "source": [
        "# mean ratings for each user\n",
        "mean = ratings.groupby(by='userid', as_index=False)['rating'].mean()\n",
        "mean_ratings = pd.merge(ratings, mean, suffixes=('','_mean'), on='userid')\n",
        "\n",
        "# normalized ratings for each items\n",
        "mean_ratings['norm_rating'] = mean_ratings['rating'] - mean_ratings['rating_mean']\n",
        "\n",
        "mean = mean.to_numpy()[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siSec0WkgB7R"
      },
      "source": [
        "np_ratings = mean_ratings.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UQduZpbgB7V"
      },
      "source": [
        "Let us define function ```predict``` that predict rating between user $u$ and item $i$. Recall that the prediction formula is defined as follow :\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\bar{r}_u + \\frac{\\sum_{v\\in G_u}(r_{v,i}-\\bar{r}_v)\\cdot w_{u,v}}{\\sum_{v\\in G_u}|w_{u,v}|}.\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f08b1FqvgB7W"
      },
      "source": [
        "def predict(userid, itemid):\n",
        "    \"\"\"\n",
        "    predict what score userid would have given to itemid.\n",
        "    \n",
        "    :param\n",
        "        - userid : user id for which we want to make prediction\n",
        "        - itemid : item id on which we want to make prediction\n",
        "        \n",
        "    :return\n",
        "        - r_hat : predicted rating of user userid on item itemid\n",
        "    \"\"\"\n",
        "    user_similarities = similarities[userid]\n",
        "    user_neighbors = neighbors[userid]\n",
        "    # get mean rating of user userid\n",
        "    user_mean = mean[userid]\n",
        "    \n",
        "    # find users who rated item 'itemid'\n",
        "    iratings = np_ratings[np_ratings[:, 1].astype('int') == itemid]\n",
        "    \n",
        "    # find similar users to 'userid' who rated item 'itemid'\n",
        "    suri = iratings[np.isin(iratings[:, 0], user_neighbors)]\n",
        "    \n",
        "    # similar users who rated current item (surci)\n",
        "    normalized_ratings = suri[:,4]\n",
        "    indexes = [np.where(user_neighbors == uid)[0][0] for uid in suri[:, 0].astype('int')]\n",
        "    sims = user_similarities[indexes]\n",
        "    \n",
        "    num = np.dot(normalized_ratings, sims)\n",
        "    den = np.sum(np.abs(sims))\n",
        "    \n",
        "    if num == 0 or den == 0:\n",
        "        return user_mean\n",
        "    \n",
        "    r_hat = user_mean + np.dot(normalized_ratings, sims) / np.sum(np.abs(sims))\n",
        "    \n",
        "    return r_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2cfxcs2gB7Y"
      },
      "source": [
        "Now, we can make rating prediction for a given user on each item in his set of candidate items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4vK7ulrgB7Z"
      },
      "source": [
        "def user2userPredictions(userid, pred_path):\n",
        "    \"\"\"\n",
        "    Make rating prediction for the active user on each candidate item and save in file prediction.csv\n",
        "    \n",
        "    :param\n",
        "        - userid : id of the active user\n",
        "        - pred_path : where to save predictions\n",
        "    \"\"\"    \n",
        "    # find candidate items for the active user\n",
        "    candidates = find_candidate_items(userid)\n",
        "    \n",
        "    # loop over candidates items to make predictions\n",
        "    for itemid in candidates:\n",
        "        \n",
        "        # prediction for userid on itemid\n",
        "        r_hat = predict(userid, itemid)\n",
        "        \n",
        "        # save predictions\n",
        "        with open(pred_path, 'a+') as file:\n",
        "            line = '{},{},{}\\n'.format(userid, itemid, r_hat)\n",
        "            file.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx4HN4kPgB7f"
      },
      "source": [
        "import sys\n",
        "\n",
        "def user2userCF():\n",
        "    \"\"\"\n",
        "    Make predictions for each user in the database.    \n",
        "    \"\"\"\n",
        "    # get list of users in the database\n",
        "    users = ratings.userid.unique()\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rRating predictions. Progress status : %.1f%%' % (float(count/len(users))*100.0))\n",
        "        sys.stdout.flush()\n",
        "    \n",
        "    saved_predictions = 'predictions.csv'    \n",
        "    if os.path.exists(saved_predictions):\n",
        "        os.remove(saved_predictions)\n",
        "    \n",
        "    for count, userid in enumerate(users):        \n",
        "        # make rating predictions for the current user\n",
        "        user2userPredictions(userid, saved_predictions)\n",
        "        _progress(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHW36qfgB7h",
        "outputId": "574b5a72-c43d-43b4-bc42-c140b5634039"
      },
      "source": [
        "user2userCF()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rating predictions. Progress status : 99.9%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLwR8O4OgB7r"
      },
      "source": [
        "### Step 4. Top-N recommendation\n",
        "\n",
        "Function ```user2userRecommendation()``` reads predictions for a given user and return the list of items in decreasing order of predicted rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc5hyq25gB7u"
      },
      "source": [
        "def user2userRecommendation(userid):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # encode the userid\n",
        "    uid = uencoder.transform([userid])[0]\n",
        "    saved_predictions = 'predictions.csv'\n",
        "    \n",
        "    predictions = pd.read_csv(saved_predictions, sep=',', names=['userid', 'itemid', 'predicted_rating'])\n",
        "    predictions = predictions[predictions.userid==uid]\n",
        "    List = predictions.sort_values(by=['predicted_rating'], ascending=False)\n",
        "    \n",
        "    List.userid = uencoder.inverse_transform(List.userid.tolist())\n",
        "    List.itemid = iencoder.inverse_transform(List.itemid.tolist())\n",
        "    \n",
        "    List = pd.merge(List, movies, on='itemid', how='inner')\n",
        "    \n",
        "    return List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID2YWpmSgB7v",
        "outputId": "ae336c38-04b3-474b-fcf2-b86eb8113b28"
      },
      "source": [
        "user2userRecommendation(212)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>predicted_rating</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>212</td>\n",
              "      <td>483</td>\n",
              "      <td>4.871495</td>\n",
              "      <td>Casablanca (1942)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>212</td>\n",
              "      <td>357</td>\n",
              "      <td>4.764547</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>212</td>\n",
              "      <td>50</td>\n",
              "      <td>4.660002</td>\n",
              "      <td>Star Wars (1977)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>212</td>\n",
              "      <td>98</td>\n",
              "      <td>4.613636</td>\n",
              "      <td>Silence of the Lambs, The (1991)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>212</td>\n",
              "      <td>64</td>\n",
              "      <td>4.550733</td>\n",
              "      <td>Shawshank Redemption, The (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>212</td>\n",
              "      <td>194</td>\n",
              "      <td>4.522336</td>\n",
              "      <td>Sting, The (1973)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>212</td>\n",
              "      <td>174</td>\n",
              "      <td>4.521300</td>\n",
              "      <td>Raiders of the Lost Ark (1981)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>212</td>\n",
              "      <td>134</td>\n",
              "      <td>4.414819</td>\n",
              "      <td>Citizen Kane (1941)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>212</td>\n",
              "      <td>187</td>\n",
              "      <td>4.344531</td>\n",
              "      <td>Godfather: Part II, The (1974)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>212</td>\n",
              "      <td>196</td>\n",
              "      <td>4.303696</td>\n",
              "      <td>Dead Poets Society (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>212</td>\n",
              "      <td>523</td>\n",
              "      <td>4.281802</td>\n",
              "      <td>Cool Hand Luke (1967)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>212</td>\n",
              "      <td>216</td>\n",
              "      <td>4.278246</td>\n",
              "      <td>When Harry Met Sally... (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>212</td>\n",
              "      <td>100</td>\n",
              "      <td>4.260087</td>\n",
              "      <td>Fargo (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>212</td>\n",
              "      <td>168</td>\n",
              "      <td>4.206139</td>\n",
              "      <td>Monty Python and the Holy Grail (1974)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>212</td>\n",
              "      <td>435</td>\n",
              "      <td>4.122984</td>\n",
              "      <td>Butch Cassidy and the Sundance Kid (1969)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>212</td>\n",
              "      <td>135</td>\n",
              "      <td>4.115228</td>\n",
              "      <td>2001: A Space Odyssey (1968)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>212</td>\n",
              "      <td>83</td>\n",
              "      <td>4.106995</td>\n",
              "      <td>Much Ado About Nothing (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>212</td>\n",
              "      <td>69</td>\n",
              "      <td>4.086366</td>\n",
              "      <td>Forrest Gump (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>212</td>\n",
              "      <td>70</td>\n",
              "      <td>4.086328</td>\n",
              "      <td>Four Weddings and a Funeral (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>212</td>\n",
              "      <td>275</td>\n",
              "      <td>3.985037</td>\n",
              "      <td>Sense and Sensibility (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>212</td>\n",
              "      <td>153</td>\n",
              "      <td>3.981619</td>\n",
              "      <td>Fish Called Wanda, A (1988)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>212</td>\n",
              "      <td>514</td>\n",
              "      <td>3.956640</td>\n",
              "      <td>Annie Hall (1977)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>212</td>\n",
              "      <td>521</td>\n",
              "      <td>3.937792</td>\n",
              "      <td>Deer Hunter, The (1978)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>212</td>\n",
              "      <td>97</td>\n",
              "      <td>3.906106</td>\n",
              "      <td>Dances with Wolves (1990)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>212</td>\n",
              "      <td>173</td>\n",
              "      <td>3.879325</td>\n",
              "      <td>Princess Bride, The (1987)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>212</td>\n",
              "      <td>660</td>\n",
              "      <td>3.847897</td>\n",
              "      <td>Fried Green Tomatoes (1991)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>212</td>\n",
              "      <td>215</td>\n",
              "      <td>3.709920</td>\n",
              "      <td>Field of Dreams (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>212</td>\n",
              "      <td>258</td>\n",
              "      <td>3.583718</td>\n",
              "      <td>Contact (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>212</td>\n",
              "      <td>202</td>\n",
              "      <td>3.508617</td>\n",
              "      <td>Groundhog Day (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>212</td>\n",
              "      <td>237</td>\n",
              "      <td>3.039041</td>\n",
              "      <td>Jerry Maguire (1996)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userid  itemid  predicted_rating  \\\n",
              "0      212     483          4.871495   \n",
              "1      212     357          4.764547   \n",
              "2      212      50          4.660002   \n",
              "3      212      98          4.613636   \n",
              "4      212      64          4.550733   \n",
              "5      212     194          4.522336   \n",
              "6      212     174          4.521300   \n",
              "7      212     134          4.414819   \n",
              "8      212     187          4.344531   \n",
              "9      212     196          4.303696   \n",
              "10     212     523          4.281802   \n",
              "11     212     216          4.278246   \n",
              "12     212     100          4.260087   \n",
              "13     212     168          4.206139   \n",
              "14     212     435          4.122984   \n",
              "15     212     135          4.115228   \n",
              "16     212      83          4.106995   \n",
              "17     212      69          4.086366   \n",
              "18     212      70          4.086328   \n",
              "19     212     275          3.985037   \n",
              "20     212     153          3.981619   \n",
              "21     212     514          3.956640   \n",
              "22     212     521          3.937792   \n",
              "23     212      97          3.906106   \n",
              "24     212     173          3.879325   \n",
              "25     212     660          3.847897   \n",
              "26     212     215          3.709920   \n",
              "27     212     258          3.583718   \n",
              "28     212     202          3.508617   \n",
              "29     212     237          3.039041   \n",
              "\n",
              "                                        title  \n",
              "0                           Casablanca (1942)  \n",
              "1      One Flew Over the Cuckoo's Nest (1975)  \n",
              "2                            Star Wars (1977)  \n",
              "3            Silence of the Lambs, The (1991)  \n",
              "4            Shawshank Redemption, The (1994)  \n",
              "5                           Sting, The (1973)  \n",
              "6              Raiders of the Lost Ark (1981)  \n",
              "7                         Citizen Kane (1941)  \n",
              "8              Godfather: Part II, The (1974)  \n",
              "9                   Dead Poets Society (1989)  \n",
              "10                      Cool Hand Luke (1967)  \n",
              "11             When Harry Met Sally... (1989)  \n",
              "12                               Fargo (1996)  \n",
              "13     Monty Python and the Holy Grail (1974)  \n",
              "14  Butch Cassidy and the Sundance Kid (1969)  \n",
              "15               2001: A Space Odyssey (1968)  \n",
              "16              Much Ado About Nothing (1993)  \n",
              "17                        Forrest Gump (1994)  \n",
              "18         Four Weddings and a Funeral (1994)  \n",
              "19               Sense and Sensibility (1995)  \n",
              "20                Fish Called Wanda, A (1988)  \n",
              "21                          Annie Hall (1977)  \n",
              "22                    Deer Hunter, The (1978)  \n",
              "23                  Dances with Wolves (1990)  \n",
              "24                 Princess Bride, The (1987)  \n",
              "25                Fried Green Tomatoes (1991)  \n",
              "26                     Field of Dreams (1989)  \n",
              "27                             Contact (1997)  \n",
              "28                       Groundhog Day (1993)  \n",
              "29                       Jerry Maguire (1996)  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhWlIKBHgB70"
      },
      "source": [
        "Let us make top n recommendation for a given user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OipwWHxgB71"
      },
      "source": [
        "## Evaluation with Mean Absolute Error (MAE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo0WXxvggB71"
      },
      "source": [
        "from recsys.preprocessing import train_test_split, get_examples\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "def evaluate(x_test, y_test):\n",
        "    print('Evaluate the model on {} test data ...'.format(x_test.shape[0]))\n",
        "    preds = list(predict(u,i) for (u,i) in x_test)\n",
        "    mae = np.sum(np.absolute(y_test - np.array(preds))) / x_test.shape[0]\n",
        "    print('\\nMAE :', mae)\n",
        "    return mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLsfKqFgB72",
        "outputId": "f43f3ecc-7f65-464b-b826-7e532e7cc9d0"
      },
      "source": [
        "evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.7505910931068639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7505910931068639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uf6TStwgB74"
      },
      "source": [
        "## Summary\n",
        "\n",
        "We have summarised all the steps of building the user-based collaborative filtering into a python class for further user. Click [UserToUser.py](https://github.com/nzhinusoftcm/review-on-collaborative-filtering/blob/master/recsys/memories/UserToUser.py) for more details on the **UserToUser** class definition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgVhH4HugB75"
      },
      "source": [
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "# load ml100k ratings\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBkpq1KvgB8E",
        "outputId": "095ed409-26e6-4cdf-fb21-8e637b4e010d"
      },
      "source": [
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, metric='cosine')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boR4DhcvgB8H",
        "outputId": "f3f8be18-5a77-4908-93e4-3655e215b2c5"
      },
      "source": [
        "# evaluate the user-based CF on the ml100k test data\n",
        "usertouser.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.7505910931068639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7505910931068639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKo-CUMtgB8L"
      },
      "source": [
        "## Evaluation on the ML-1M dataset (this may take some time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJRF3nrgB8M",
        "outputId": "2b1e4190-e225-4356-c736-f6096a216161"
      },
      "source": [
        "from recsys.datasets import ml1m\n",
        "from recsys.preprocessing import ids_encoder, get_examples, train_test_split\n",
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "# load ml100k ratings\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, k=20, metric='cosine')\n",
        "\n",
        "# evaluate the user-based CF on the ml1m test data\n",
        "print(\"==========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.732267005840993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.732267005840993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Krt6dqugB8N"
      },
      "source": [
        "## Limitations of user-based CF\n",
        "\n",
        "1. <b> Sparsity </b> : In general, users interact with less than 20% of items. This leads the rating matrix to be highly sparse. For example, the movielen-100k contains 100k ratings from 943 users on 1682 items. The pourcentage of sparsity in this case is around $94\\%$. A recommender system based on nearest neighbor algorithms may be unable to make any item recommendations for a particular user. As a result the accuracy of recommendations may be poor <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\">(Sarwar <i>et al.</i> 2001)</a>.\n",
        "\n",
        "2. <b> Stability of user's ratings </b> : As a user rates and re-rates items, their rating vector will change along with their similarity to other users. A user’s neighborhood is determined not only by their ratings but also by the ratings of other users, so their neighborhood can change as a result of new ratings supplied by any user in the system <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>.\n",
        "\n",
        "3. <b> Scalability </b> : Due to the non-stability of users ratings, finding similar users in advance is complicated. For this reason, most user-based CF systems find neighborhoods each time predictions or recommendations are needed. However, these are huge computations that grows with both the number of users and the number of items. With millions of users and items, a typical web-based recommender system running existing algorithms will suffer serious scalability concerns <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\">(Sarwar <i>et al.</i> 2001)</a>, <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWnqQ73OgB8Q"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Herlocker et al. (1999)<a href=\"https://dl.acm.org/doi/10.1145/3130348.3130372\"> An Algorithmic Framework for Performing Collaborative Filtering</a>\n",
        "2. Sarwar et al. (2001) <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\"> Item-based collaborative filtering recommendation algorithms</a> \n",
        "3. Michael D. Ekstrand, et al. (2011). <a href=\"https://dl.acm.org/doi/10.1561/1100000009\"> Collaborative Filtering Recommender Systems</a>\n",
        "4. J. Bobadilla et al. (2013)<a href=\"https://romisatriawahono.net/lecture/rm/survey/information%20retrieval/Bobadilla%20-%20Recommender%20Systems%20-%202013.pdf\"> Recommender systems survey</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mVbxsbdgB8R"
      },
      "source": [
        "## Author\n",
        "\n",
        "[Carmel WENGA](https://www.linkedin.com/in/carmel-wenga-871876178/), <br>\n",
        "PhD student at Université de la Polynésie Française, <br> \n",
        "Applied Machine Learning Research Engineer, <br>\n",
        "[ShoppingList](https://shoppinglist.cm), NzhinuSoft."
      ]
    }
  ]
}