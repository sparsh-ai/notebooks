{"cells":[{"cell_type":"markdown","source":["# MF on ML-100k in PyTorch"],"metadata":{"id":"OXuS4HHuT8wC"}},{"cell_type":"code","source":["!wget -q --show-progress https://files.grouplens.org/datasets/movielens/ml-100k.zip\n","!unzip ml-100k.zip\n","!mv ml-100k/u.data ."],"metadata":{"id":"AJhJHCd6TT-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.utils import shuffle\n","import numpy as np\n","\n","batch_size = 1024\n","device = torch.device('cpu')\n","learning_rate = 5e-4\n","weight_decay = 1e-5\n","epochs = 10\n","\n","\n","class MfDataset(Dataset):\n","    def __init__(self, u_id, i_id, rating):\n","        self.u_id = u_id\n","        self.i_id = i_id\n","        self.rating = rating\n","\n","    def __getitem__(self, index):\n","        return self.u_id[index], self.i_id[index], self.rating[index]\n","\n","    def __len__(self):\n","        return len(self.rating)\n","\n","\n","class MF(nn.Module):\n","    def __init__(self, num_users, num_items, mean, embedding_size=100):\n","        super(MF, self).__init__()\n","        self.user_emb = nn.Embedding(num_users, embedding_size)\n","        self.user_bias = nn.Embedding(num_users, 1)\n","        self.item_emb = nn.Embedding(num_items, embedding_size)\n","        self.item_bias = nn.Embedding(num_items, 1)\n","\n","        self.user_emb.weight.data.uniform_(0, 0.005)\n","        self.user_bias.weight.data.uniform_(-0.01, 0.01)\n","        self.item_emb.weight.data.uniform_(0, 0.005)\n","        self.item_bias.weight.data.uniform_(-0.01, 0.01)\n","\n","        # 全局bias\n","        self.mean = nn.Parameter(torch.FloatTensor([mean]), False)\n","\n","    def forward(self, u_id, i_id):\n","        U = self.user_emb(u_id)\n","        b_u = self.user_bias(u_id).squeeze()\n","        I = self.item_emb(i_id)\n","        b_i = self.item_bias(i_id).squeeze()\n","        return (U * I).sum(1) + b_u + b_i + self.mean\n","\n","\n","def main():\n","    df = pd.read_csv('u.data', header=None, delimiter='\\t')\n","    x, y = df.iloc[:, :2], df.iloc[:, 2]\n","    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=2020)\n","\n","    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n","\n","    # 需要将数据全部转化为np.array, 否则后面的dataloader会报错， pytorch与numpy之间转换较好，与pandas转化容易出错\n","    train_dataset = MfDataset(np.array(x_train[0]), np.array(x_train[1]), np.array(y_train).astype(np.float32)) # 将标签设为np.float32类型， 否则会报错\n","    test_dataset = MfDataset(np.array(x_test[0]), np.array(x_test[1]), np.array(y_test).astype(np.float32))\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","\n","    mean_rating = df.iloc[:, 2].mean()\n","    num_users, num_items = max(df[0]) + 1, max(df[1]) + 1\n","    model = MF(num_users, num_items, mean_rating).to(device)\n","    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    loss_func = torch.nn.MSELoss().to(device)\n","\n","    for epoch in range(epochs):\n","\n","        model.train()\n","        total_loss, total_len = 0, 0\n","        for x_u, x_i, y in train_dataloader:\n","            x_u, x_i, y = x_u.to(device), x_i.to(device), y.to(device)\n","            y_pre = model(x_u, x_i)\n","            loss = loss_func(y_pre, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item() * len(y)\n","            total_len += len(y)\n","        train_loss = total_loss / total_len\n","\n","        model.eval()\n","        labels, predicts = [], []\n","        with torch.no_grad():\n","            for x_u, x_i, y in test_dataloader:\n","                x_u, x_i, y = x_u.to(device), x_i.to(device), y.to(device)\n","                y_pre = model(x_u, x_i)\n","                labels.extend(y.tolist())\n","                predicts.extend(y_pre.tolist())\n","        mse = mean_squared_error(np.array(labels), np.array(predicts))\n","\n","        print(\"epoch {}, train loss is {}, val mse is {}\".format(epoch, train_loss, mse))\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8rEahLvTbqF","executionInfo":{"status":"ok","timestamp":1641538515085,"user_tz":-330,"elapsed":6939,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"b854993d-0408-4231-aa5c-6959c5c96731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(70000, 2) (30000, 2) (70000,) (30000,)\n","epoch 0, train loss is 1.2554658806119647, val mse is 1.2123010650286943\n","epoch 1, train loss is 1.1834860184533256, val mse is 1.1307691492157719\n","epoch 2, train loss is 1.0948329753603254, val mse is 1.0700546196805318\n","epoch 3, train loss is 1.038581883593968, val mse is 1.0412234145743122\n","epoch 4, train loss is 1.0069440517970494, val mse is 1.0237789366308847\n","epoch 5, train loss is 0.9844767317226955, val mse is 1.0099065085478796\n","epoch 6, train loss is 0.9659655159405299, val mse is 0.9978005986020112\n","epoch 7, train loss is 0.9496718340465, val mse is 0.9867652852654539\n","epoch 8, train loss is 0.9346688873972212, val mse is 0.9763544873696709\n","epoch 9, train loss is 0.9202980343273708, val mse is 0.9662312264539021\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"rsNyAAaUT5lA"}},{"cell_type":"code","source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -a \"Sparsh A.\" -m -iv -u -t -d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kk0V69zDT5lE","executionInfo":{"status":"ok","timestamp":1641538522889,"user_tz":-330,"elapsed":3633,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"0c39afbd-44e9-44a2-e30a-b72ffa1918d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author: Sparsh A.\n","\n","Last updated: 2022-01-07 06:55:23\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.144+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","torch  : 1.10.0+cu111\n","numpy  : 1.19.5\n","IPython: 5.5.0\n","pandas : 1.1.5\n","\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Nyd-d0uGT5lG"}},{"cell_type":"markdown","source":["**END**"],"metadata":{"id":"rVlR650LT5lG"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"name":"2022-01-11-mf-ml.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/P176240%20%7C%20MF%20on%20ML-100k%20in%20PyTorch.ipynb","timestamp":1644599014628},{"file_id":"1npp4hgFBQRflbqyRW4TayaUFIJJA_xHo","timestamp":1639737398037},{"file_id":"1vh6Mr1C7uh08K4zR4B2VIfqsK22pkraT","timestamp":1639730564985},{"file_id":"1F1wdk7jG5W0jbVM1nZBOPV0TYuSO7frV","timestamp":1639730030880},{"file_id":"https://github.com/RecoHut-Projects/recohut/blob/S394070/nbs/models/tensorflow/deepmf.ipynb","timestamp":1639729505410}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}