{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-22-pnn-criteo.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T161314%20%7C%20PNN%20on%20Criteo%20Ad%20Dataset%20in%20TF%202x.ipynb","timestamp":1644661241218},{"file_id":"1bhRkvGnfmxPWUPFRag57Dl6-4pl1ZEzm","timestamp":1637064112796}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1bhRkvGnfmxPWUPFRag57Dl6-4pl1ZEzm","authorship_tag":"ABX9TyN2IdOkQGtUh2CrUgkZVOZT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# PNN on Criteo Ad Dataset in TF 2.x"],"metadata":{"id":"7d6WNG88csfU"}},{"cell_type":"code","metadata":{"id":"0pxSU24FbSAy"},"source":["!pip install tensorflow==2.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnFg_wXiclo4","executionInfo":{"status":"ok","timestamp":1637061269255,"user_tz":-330,"elapsed":135691,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"6cc6fdd1-38da-459c-ea28-576e6c5492b1"},"source":["!pip install -q -U kaggle\n","!pip install --upgrade --force-reinstall --no-deps kaggle\n","!mkdir ~/.kaggle\n","!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download -d mrkmakr/criteo-dataset"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaggle\n","  Downloading kaggle-1.5.12.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 2.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=d0e4b97f111ac4c64a7c2fead5edb3baa0f1f4f21eca031e865b06b3f40f3bbb\n","  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n","Downloading criteo-dataset.zip to /content\n","100% 4.31G/4.31G [02:05<00:00, 44.7MB/s]\n","100% 4.31G/4.31G [02:05<00:00, 36.8MB/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZYBD38Ad5j2","executionInfo":{"status":"ok","timestamp":1637061804413,"user_tz":-330,"elapsed":325474,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"efff747a-58f1-49d5-bb09-51875616aaa0"},"source":["!unzip criteo-dataset.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  criteo-dataset.zip\n","  inflating: dac/readme.txt          \n","  inflating: dac/test.txt            \n","  inflating: dac/train.txt           \n"]}]},{"cell_type":"code","metadata":{"id":"BZwknC3Gd8Qg"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Layer, Input, ReLU\n","from tensorflow.keras.layers import Dense, Embedding, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import AUC"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDRfYvu4e4mO"},"source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","file = 'dac/train.txt'\n","read_part = True\n","sample_num = 10000\n","test_size = 0.2\n","\n","embed_dim = 8\n","dnn_dropout = 0.5\n","hidden_units = [256, 128, 64]\n","\n","learning_rate = 0.001\n","batch_size = 4096\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zzb1WXIet8A"},"source":["def sparseFeature(feat, feat_num, embed_dim=4):\n","    \"\"\"\n","    create dictionary for sparse feature\n","    :param feat: feature name\n","    :param feat_num: the total number of sparse features that do not repeat\n","    :param embed_dim: embedding dimension\n","    :return:\n","    \"\"\"\n","    return {'feat_name': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n","\n","\n","def denseFeature(feat):\n","    \"\"\"\n","    create dictionary for dense feature\n","    :param feat: dense feature name\n","    :return:\n","    \"\"\"\n","    return {'feat_name': feat}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NnOfRIQerQh"},"source":["def create_criteo_dataset(file, embed_dim=8, read_part=True, sample_num=100000, test_size=0.2):\n","    \"\"\"\n","    a example about creating criteo dataset\n","    :param file: dataset's path\n","    :param embed_dim: the embedding dimension of sparse features\n","    :param read_part: whether to read part of it\n","    :param sample_num: the number of instances if read_part is True\n","    :param test_size: ratio of test dataset\n","    :return: feature columns, train, test\n","    \"\"\"\n","    names = ['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11',\n","             'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n","             'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22',\n","             'C23', 'C24', 'C25', 'C26']\n","\n","    if read_part:\n","        data_df = pd.read_csv(file, sep='\\t', iterator=True, header=None,\n","                          names=names)\n","        data_df = data_df.get_chunk(sample_num)\n","\n","    else:\n","        data_df = pd.read_csv(file, sep='\\t', header=None, names=names)\n","\n","    sparse_features = ['C' + str(i) for i in range(1, 27)]\n","    dense_features = ['I' + str(i) for i in range(1, 14)]\n","    features = sparse_features + dense_features\n","\n","    data_df[sparse_features] = data_df[sparse_features].fillna('-1')\n","    data_df[dense_features] = data_df[dense_features].fillna(0)\n","\n","    # Bin continuous data into intervals.\n","    est = KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='uniform')\n","    data_df[dense_features] = est.fit_transform(data_df[dense_features])\n","\n","    for feat in sparse_features:\n","        le = LabelEncoder()\n","        data_df[feat] = le.fit_transform(data_df[feat])\n","\n","    # ==============Feature Engineering===================\n","\n","    # ====================================================\n","    feature_columns = [sparseFeature(feat, int(data_df[feat].max()) + 1, embed_dim=embed_dim)\n","                        for feat in features]\n","    train, test = train_test_split(data_df, test_size=test_size)\n","\n","    train_X = train[features].values.astype('int32')\n","    train_y = train['label'].values.astype('int32')\n","    test_X = test[features].values.astype('int32')\n","    test_y = test['label'].values.astype('int32')\n","\n","    return feature_columns, (train_X, train_y), (test_X, test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6L1wMGGeCGE"},"source":["class DNN(Layer):\n","    def __init__(self, hidden_units, activation='relu', dropout=0.):\n","        \"\"\"Deep Neural Network\n","\t\t:param hidden_units: A list. Neural network hidden units.\n","\t\t:param activation: A string. Activation function of dnn.\n","\t\t:param dropout: A scalar. Dropout number.\n","\t\t\"\"\"\n","        super(DNN, self).__init__()\n","        self.dnn_network = [Dense(units=unit, activation=activation) for unit in hidden_units]\n","        self.dropout = Dropout(dropout)\n","\n","    def call(self, inputs, **kwargs):\n","        x = inputs\n","        for dnn in self.dnn_network:\n","            x = dnn(x)\n","        x = self.dropout(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K09g18Cmgxrf"},"source":["class PNN(Model):\n","    def __init__(self, feature_columns, hidden_units, mode='in', dnn_dropout=0.,\n","                 activation='relu', embed_reg=1e-6, w_z_reg=1e-6, w_p_reg=1e-6, l_b_reg=1e-6):\n","        \"\"\"\n","        Product-based Neural Networks\n","        :param feature_columns: A list. sparse column feature information.\n","        :param hidden_units: A list. Neural network hidden units.\n","        :param mode: A string. 'in' IPNN or 'out'OPNN.\n","        :param activation: A string. Activation function of dnn.\n","        :param dnn_dropout: A scalar. Dropout of dnn.\n","        :param embed_reg: A scalar. The regularizer of embedding.\n","        :param w_z_reg: A scalar. The regularizer of w_z_ in product layer\n","        :param w_p_reg: A scalar. The regularizer of w_p in product layer\n","        :param l_b_reg: A scalar. The regularizer of l_b in product layer\n","        \"\"\"\n","        super(PNN, self).__init__()\n","        # inner product or outer product\n","        self.mode = mode\n","        self.sparse_feature_columns = feature_columns\n","        # the number of feature fields\n","        self.field_num = len(self.sparse_feature_columns)\n","        self.embed_dim = self.sparse_feature_columns[0]['embed_dim']\n","        # The embedding dimension of each feature field must be the same\n","        self.embed_layers = {\n","            'embed_' + str(i): Embedding(input_dim=feat['feat_num'],\n","                                         input_length=1,\n","                                         output_dim=feat['embed_dim'],\n","                                         embeddings_initializer='random_uniform',\n","                                         embeddings_regularizer=l2(embed_reg))\n","            for i, feat in enumerate(self.sparse_feature_columns)\n","        }\n","        # parameters\n","        self.w_z = self.add_weight(name='w_z',\n","                                   shape=(self.field_num, self.embed_dim, hidden_units[0]),\n","                                   initializer='random_uniform',\n","                                   regularizer=l2(w_z_reg),\n","                                   trainable=True\n","                                   )\n","        if mode == 'in':\n","            self.w_p = self.add_weight(name='w_p',\n","                                       shape=(self.field_num * (self.field_num - 1) // 2, self.embed_dim,\n","                                              hidden_units[0]),\n","                                       initializer='random_uniform',\n","                                       reguarizer=l2(w_p_reg),\n","                                       trainable=True)\n","        # out\n","        else:\n","            self.w_p = self.add_weight(name='w_p',\n","                                       shape=(self.field_num * (self.field_num - 1) // 2, self.embed_dim,\n","                                              self.embed_dim, hidden_units[0]),\n","                                       initializer='random_uniform',\n","                                       regularizer=l2(w_p_reg),\n","                                       trainable=True)\n","        self.l_b = self.add_weight(name='l_b', shape=(hidden_units[0], ),\n","                                   initializer='random_uniform',\n","                                   regularizer=l2(l_b_reg),\n","                                   trainable=True)\n","        # dnn\n","        self.dnn_network = DNN(hidden_units[1:], activation, dnn_dropout)\n","        self.dense_final = Dense(1)\n","\n","    def call(self, inputs):\n","        sparse_inputs = inputs\n","        sparse_embed = [self.embed_layers['embed_{}'.format(i)](sparse_inputs[:, i])\n","                 for i in range(sparse_inputs.shape[1])]\n","        sparse_embed = tf.transpose(tf.convert_to_tensor(sparse_embed), [1, 0, 2])  # (None, field_num, embed_dim)\n","        # product layer\n","        row = []\n","        col = []\n","        for i in range(len(self.sparse_feature_columns) - 1):\n","            for j in range(i + 1, len(self.sparse_feature_columns)):\n","                row.append(i)\n","                col.append(j)\n","        p = tf.gather(sparse_embed, row, axis=1)\n","        q = tf.gather(sparse_embed, col, axis=1)\n","        if self.mode == 'in':\n","            l_p = tf.tensordot(p*q, self.w_p, axes=2)  # (None, hidden[0])\n","        else:  # out\n","            u = tf.expand_dims(q, 2)  # (None, field_num(field_num-1)/2, 1, emb_dim)\n","            v = tf.expand_dims(p, 2)  # (None, field_num(field_num-1)/2, 1, emb_dim)\n","            l_p = tf.tensordot(tf.matmul(tf.transpose(u, [0, 1, 3, 2]), v), self.w_p, axes=3)  # (None, hidden[0])\n","\n","        l_z = tf.tensordot(sparse_embed, self.w_z, axes=2)  # (None, hidden[0])\n","        l_1 = tf.nn.relu(tf.concat([l_z + l_p + self.l_b], axis=-1))\n","        # dnn layer\n","        dnn_x = self.dnn_network(l_1)\n","        outputs = tf.nn.sigmoid(self.dense_final(dnn_x))\n","        return outputs\n","\n","    def summary(self):\n","        sparse_inputs = Input(shape=(len(self.sparse_feature_columns),), dtype=tf.int32)\n","        Model(inputs=sparse_inputs, outputs=self.call(sparse_inputs)).summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHIfDXsXePmP","executionInfo":{"status":"ok","timestamp":1637064104041,"user_tz":-330,"elapsed":126683,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"bf3b2c23-c835-482e-dbce-4509747130f6"},"source":["# ========================== Create dataset =======================\n","feature_columns, train, test = create_criteo_dataset(file=file,\n","                                                        embed_dim=embed_dim,\n","                                                        read_part=read_part,\n","                                                        sample_num=sample_num,\n","                                                        test_size=test_size)\n","train_X, train_y = train\n","test_X, test_y = test\n","# ============================Build Model==========================\n","mirrored_strategy = tf.distribute.MirroredStrategy()\n","with mirrored_strategy.scope():\n","    model = PNN(feature_columns, hidden_units, dnn_dropout)\n","    model.summary()\n","    # =========================Compile============================\n","    model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=learning_rate),\n","                    metrics=[AUC()])\n","# ============================model checkpoint======================\n","# check_path = 'save/pnn_weights.epoch_{epoch:04d}.val_loss_{val_loss:.4f}.ckpt'\n","# checkpoint = tf.keras.callbacks.ModelCheckpoint(check_path, save_weights_only=True,\n","#                                                 verbose=1, period=5)\n","# ===========================Fit==============================\n","model.fit(\n","    train_X,\n","    train_y,\n","    epochs=epochs,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)],  # checkpoint\n","    batch_size=batch_size,\n","    validation_split=0.1\n",")\n","# ===========================Test==============================\n","print('test AUC: %f' % model.evaluate(test_X, test_y, batch_size=batch_size)[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","WARNING:tensorflow:\n","The following Variables were used a Lambda layer's call (tf.tensordot), but\n","are not present in its tracked objects:\n","  <tf.Variable 'w_p:0' shape=(741, 8, 8, 256) dtype=float32>\n","It is possible that this is intended behavior, but it is more likely\n","an omission. This is a strong indication that this layer should be\n","formulated as a subclassed Layer rather than a Lambda layer.\n","WARNING:tensorflow:\n","The following Variables were used a Lambda layer's call (tf.tensordot_1), but\n","are not present in its tracked objects:\n","  <tf.Variable 'w_z:0' shape=(39, 8, 256) dtype=float32>\n","It is possible that this is intended behavior, but it is more likely\n","an omission. This is a strong indication that this layer should be\n","formulated as a subclassed Layer rather than a Lambda layer.\n","WARNING:tensorflow:\n","The following Variables were used a Lambda layer's call (tf.__operators__.add_1), but\n","are not present in its tracked objects:\n","  <tf.Variable 'l_b:0' shape=(256,) dtype=float32>\n","It is possible that this is intended behavior, but it is more likely\n","an omission. This is a strong indication that this layer should be\n","formulated as a subclassed Layer rather than a Lambda layer.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 39)]         0                                            \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem (Slici (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_1 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_2 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_3 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_4 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_5 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_6 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_7 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_8 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_9 (Sli (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_10 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_11 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_12 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_13 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_14 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_15 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_16 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_17 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_18 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_19 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_20 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_21 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_22 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_23 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_24 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_25 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_26 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_27 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_28 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_29 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_30 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_31 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_32 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_33 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_34 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_35 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_36 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_37 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_38 (Sl (None,)              0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 8)            1400        tf.__operators__.getitem[0][0]   \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 8)            3088        tf.__operators__.getitem_1[0][0] \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 8)            44168       tf.__operators__.getitem_2[0][0] \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 8)            32264       tf.__operators__.getitem_3[0][0] \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 8)            448         tf.__operators__.getitem_4[0][0] \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, 8)            64          tf.__operators__.getitem_5[0][0] \n","__________________________________________________________________________________________________\n","embedding_6 (Embedding)         (None, 8)            25472       tf.__operators__.getitem_6[0][0] \n","__________________________________________________________________________________________________\n","embedding_7 (Embedding)         (None, 8)            744         tf.__operators__.getitem_7[0][0] \n","__________________________________________________________________________________________________\n","embedding_8 (Embedding)         (None, 8)            24          tf.__operators__.getitem_8[0][0] \n","__________________________________________________________________________________________________\n","embedding_9 (Embedding)         (None, 8)            23888       tf.__operators__.getitem_9[0][0] \n","__________________________________________________________________________________________________\n","embedding_10 (Embedding)        (None, 8)            16672       tf.__operators__.getitem_10[0][0]\n","__________________________________________________________________________________________________\n","embedding_11 (Embedding)        (None, 8)            42272       tf.__operators__.getitem_11[0][0]\n","__________________________________________________________________________________________________\n","embedding_12 (Embedding)        (None, 8)            13800       tf.__operators__.getitem_12[0][0]\n","__________________________________________________________________________________________________\n","embedding_13 (Embedding)        (None, 8)            192         tf.__operators__.getitem_13[0][0]\n","__________________________________________________________________________________________________\n","embedding_14 (Embedding)        (None, 8)            16280       tf.__operators__.getitem_14[0][0]\n","__________________________________________________________________________________________________\n","embedding_15 (Embedding)        (None, 8)            37792       tf.__operators__.getitem_15[0][0]\n","__________________________________________________________________________________________________\n","embedding_16 (Embedding)        (None, 8)            72          tf.__operators__.getitem_16[0][0]\n","__________________________________________________________________________________________________\n","embedding_17 (Embedding)        (None, 8)            9192        tf.__operators__.getitem_17[0][0]\n","__________________________________________________________________________________________________\n","embedding_18 (Embedding)        (None, 8)            4376        tf.__operators__.getitem_18[0][0]\n","__________________________________________________________________________________________________\n","embedding_19 (Embedding)        (None, 8)            32          tf.__operators__.getitem_19[0][0]\n","__________________________________________________________________________________________________\n","embedding_20 (Embedding)        (None, 8)            40296       tf.__operators__.getitem_20[0][0]\n","__________________________________________________________________________________________________\n","embedding_21 (Embedding)        (None, 8)            64          tf.__operators__.getitem_21[0][0]\n","__________________________________________________________________________________________________\n","embedding_22 (Embedding)        (None, 8)            96          tf.__operators__.getitem_22[0][0]\n","__________________________________________________________________________________________________\n","embedding_23 (Embedding)        (None, 8)            20200       tf.__operators__.getitem_23[0][0]\n","__________________________________________________________________________________________________\n","embedding_24 (Embedding)        (None, 8)            320         tf.__operators__.getitem_24[0][0]\n","__________________________________________________________________________________________________\n","embedding_25 (Embedding)        (None, 8)            15512       tf.__operators__.getitem_25[0][0]\n","__________________________________________________________________________________________________\n","embedding_26 (Embedding)        (None, 8)            800         tf.__operators__.getitem_26[0][0]\n","__________________________________________________________________________________________________\n","embedding_27 (Embedding)        (None, 8)            800         tf.__operators__.getitem_27[0][0]\n","__________________________________________________________________________________________________\n","embedding_28 (Embedding)        (None, 8)            800         tf.__operators__.getitem_28[0][0]\n","__________________________________________________________________________________________________\n","embedding_29 (Embedding)        (None, 8)            800         tf.__operators__.getitem_29[0][0]\n","__________________________________________________________________________________________________\n","embedding_30 (Embedding)        (None, 8)            800         tf.__operators__.getitem_30[0][0]\n","__________________________________________________________________________________________________\n","embedding_31 (Embedding)        (None, 8)            800         tf.__operators__.getitem_31[0][0]\n","__________________________________________________________________________________________________\n","embedding_32 (Embedding)        (None, 8)            800         tf.__operators__.getitem_32[0][0]\n","__________________________________________________________________________________________________\n","embedding_33 (Embedding)        (None, 8)            800         tf.__operators__.getitem_33[0][0]\n","__________________________________________________________________________________________________\n","embedding_34 (Embedding)        (None, 8)            800         tf.__operators__.getitem_34[0][0]\n","__________________________________________________________________________________________________\n","embedding_35 (Embedding)        (None, 8)            800         tf.__operators__.getitem_35[0][0]\n","__________________________________________________________________________________________________\n","embedding_36 (Embedding)        (None, 8)            800         tf.__operators__.getitem_36[0][0]\n","__________________________________________________________________________________________________\n","embedding_37 (Embedding)        (None, 8)            800         tf.__operators__.getitem_37[0][0]\n","__________________________________________________________________________________________________\n","embedding_38 (Embedding)        (None, 8)            800         tf.__operators__.getitem_38[0][0]\n","__________________________________________________________________________________________________\n","tf.convert_to_tensor (TFOpLambd (39, None, 8)        0           embedding[0][0]                  \n","                                                                 embedding_1[0][0]                \n","                                                                 embedding_2[0][0]                \n","                                                                 embedding_3[0][0]                \n","                                                                 embedding_4[0][0]                \n","                                                                 embedding_5[0][0]                \n","                                                                 embedding_6[0][0]                \n","                                                                 embedding_7[0][0]                \n","                                                                 embedding_8[0][0]                \n","                                                                 embedding_9[0][0]                \n","                                                                 embedding_10[0][0]               \n","                                                                 embedding_11[0][0]               \n","                                                                 embedding_12[0][0]               \n","                                                                 embedding_13[0][0]               \n","                                                                 embedding_14[0][0]               \n","                                                                 embedding_15[0][0]               \n","                                                                 embedding_16[0][0]               \n","                                                                 embedding_17[0][0]               \n","                                                                 embedding_18[0][0]               \n","                                                                 embedding_19[0][0]               \n","                                                                 embedding_20[0][0]               \n","                                                                 embedding_21[0][0]               \n","                                                                 embedding_22[0][0]               \n","                                                                 embedding_23[0][0]               \n","                                                                 embedding_24[0][0]               \n","                                                                 embedding_25[0][0]               \n","                                                                 embedding_26[0][0]               \n","                                                                 embedding_27[0][0]               \n","                                                                 embedding_28[0][0]               \n","                                                                 embedding_29[0][0]               \n","                                                                 embedding_30[0][0]               \n","                                                                 embedding_31[0][0]               \n","                                                                 embedding_32[0][0]               \n","                                                                 embedding_33[0][0]               \n","                                                                 embedding_34[0][0]               \n","                                                                 embedding_35[0][0]               \n","                                                                 embedding_36[0][0]               \n","                                                                 embedding_37[0][0]               \n","                                                                 embedding_38[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 39, 8)        0           tf.convert_to_tensor[0][0]       \n","__________________________________________________________________________________________________\n","tf.compat.v1.gather_1 (TFOpLamb (None, 741, 8)       0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.expand_dims (TFOpLambda)     (None, 741, 1, 8)    0           tf.compat.v1.gather_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.compat.v1.gather (TFOpLambda (None, 741, 8)       0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 741, 8, 1)    0           tf.expand_dims[0][0]             \n","__________________________________________________________________________________________________\n","tf.expand_dims_1 (TFOpLambda)   (None, 741, 1, 8)    0           tf.compat.v1.gather[0][0]        \n","__________________________________________________________________________________________________\n","tf.linalg.matmul (TFOpLambda)   (None, 741, 8, 8)    0           tf.compat.v1.transpose_1[0][0]   \n","                                                                 tf.expand_dims_1[0][0]           \n","__________________________________________________________________________________________________\n","tf.tensordot_1 (TFOpLambda)     (None, 256)          0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.tensordot (TFOpLambda)       (None, 256)          0           tf.linalg.matmul[0][0]           \n","__________________________________________________________________________________________________\n","tf.__operators__.add (TFOpLambd (None, 256)          0           tf.tensordot_1[0][0]             \n","                                                                 tf.tensordot[0][0]               \n","__________________________________________________________________________________________________\n","tf.__operators__.add_1 (TFOpLam (None, 256)          0           tf.__operators__.add[0][0]       \n","__________________________________________________________________________________________________\n","tf.identity (TFOpLambda)        (None, 256)          0           tf.__operators__.add_1[0][0]     \n","__________________________________________________________________________________________________\n","tf.nn.relu (TFOpLambda)         (None, 256)          0           tf.identity[0][0]                \n","__________________________________________________________________________________________________\n","dnn (DNN)                       (None, 64)           41152       tf.nn.relu[0][0]                 \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            65          dnn[0][0]                        \n","__________________________________________________________________________________________________\n","tf.math.sigmoid (TFOpLambda)    (None, 1)            0           dense_2[0][0]                    \n","==================================================================================================\n","Total params: 400,345\n","Trainable params: 400,345\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","2/2 [==============================] - 23s 8s/step - loss: 0.7048 - auc: 0.5076 - val_loss: 0.6895 - val_auc: 0.5886\n","Epoch 2/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.6856 - auc: 0.5387 - val_loss: 0.6731 - val_auc: 0.5862\n","Epoch 3/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.6673 - auc: 0.5539 - val_loss: 0.6502 - val_auc: 0.6061\n","Epoch 4/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.6414 - auc: 0.5672 - val_loss: 0.6176 - val_auc: 0.6159\n","Epoch 5/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.6046 - auc: 0.5819 - val_loss: 0.5768 - val_auc: 0.6244\n","Epoch 6/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.5597 - auc: 0.6090 - val_loss: 0.5405 - val_auc: 0.6272\n","Epoch 7/10\n","2/2 [==============================] - 13s 6s/step - loss: 0.5208 - auc: 0.6418 - val_loss: 0.5361 - val_auc: 0.6410\n","Epoch 8/10\n","2/2 [==============================] - 13s 6s/step - loss: 0.5131 - auc: 0.7008 - val_loss: 0.5553 - val_auc: 0.6626\n","Epoch 9/10\n","2/2 [==============================] - 12s 6s/step - loss: 0.5164 - auc: 0.7653 - val_loss: 0.5487 - val_auc: 0.6825\n","1/1 [==============================] - 1s 1s/step - loss: 0.5333 - auc: 0.5909\n","test AUC: 0.590887\n"]}]},{"cell_type":"code","metadata":{"id":"UKnzXHU2k0Bt"},"source":[""],"execution_count":null,"outputs":[]}]}