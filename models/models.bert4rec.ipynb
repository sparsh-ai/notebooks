{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.bert4rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT4Rec\n",
    "> Implementation of BERT4Rec transformer-based recommender model in Pytorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Any, Iterable, List, Optional, Tuple, Union, Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "\n",
    "from recohut.models.bases.sequential import SequentialModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BERT4Rec(SequentialModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.item_embeddings = torch.nn.Embedding(\n",
    "            self.vocab_size, embedding_dim=self.channels\n",
    "        )\n",
    "        self.input_pos_embedding = torch.nn.Embedding(512, embedding_dim=self.channels)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.channels, nhead=4, dropout=self.dropout\n",
    "        )\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.linear_out = Linear(self.channels, self.vocab_size)\n",
    "        self.do = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def forward(self, src_items):\n",
    "        src = self.encode_src(src_items)\n",
    "        out = self.linear_out(src)\n",
    "        return out\n",
    "\n",
    "    def encode_src(self, src_items):\n",
    "        src_items = self.item_embeddings(src_items)\n",
    "        batch_size, in_sequence_len = src_items.size(0), src_items.size(1)\n",
    "        pos_encoder = (\n",
    "            torch.arange(0, in_sequence_len, device=src_items.device)\n",
    "            .unsqueeze(0)\n",
    "            .repeat(batch_size, 1)\n",
    "        )\n",
    "        pos_encoder = self.input_pos_embedding(pos_encoder)\n",
    "        src_items += pos_encoder\n",
    "        src = src_items.permute(1, 0, 2)\n",
    "        src = self.encoder(src)\n",
    "        return src.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.pad = 0\n",
    "        self.mask = 1\n",
    "        self.cap = 0\n",
    "        self.seed = 42\n",
    "        self.vocab_size = 10000\n",
    "        self.channels = 128\n",
    "        self.dropout = 0.4\n",
    "        self.learning_rate = 1e-4\n",
    "        self.history_size = 30\n",
    "        self.data_dir = '/content/data'\n",
    "        self.log_dir = '/content/recommender_logs'\n",
    "        self.model_dir = '/content/recommender_models'\n",
    "        self.batch_size = 32\n",
    "        self.shuffle = True\n",
    "        self.max_epochs = 2\n",
    "        self.val_epoch = 1\n",
    "        self.gpus = None\n",
    "        self.monitor = 'valid_loss'\n",
    "        self.mode = 'min'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_trainer(model, datamodule, max_epochs=10, val_epoch=5, gpus=None, log_dir=None,\n",
    "               model_dir=None, monitor='val_loss', mode='min', *args, **kwargs):\n",
    "    log_dir = log_dir if log_dir is not None else os.getcwd()\n",
    "    model_dir = model_dir if model_dir is not None else os.getcwd()\n",
    "\n",
    "    logger = TensorBoardLogger(save_dir=log_dir)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=monitor,\n",
    "        mode=mode,\n",
    "        dirpath=model_dir,\n",
    "        filename=\"recommender\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    logger=logger,\n",
    "    check_val_every_n_epoch=val_epoch,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    num_sanity_val_steps=0,\n",
    "    gradient_clip_val=1,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    gpus=gpus\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    test_result = trainer.test(model, datamodule=datamodule)\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | item_embeddings     | Embedding          | 474 K \n",
      "1 | input_pos_embedding | Embedding          | 65.5 K\n",
      "2 | encoder             | TransformerEncoder | 3.6 M \n",
      "3 | linear_out          | Linear             | 478 K \n",
      "4 | do                  | Dropout            | 0     \n",
      "-----------------------------------------------------------\n",
      "4.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 M     Total params\n",
      "18.307    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content/recommender_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e273ffc12ee24598acacf43a452e081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4696e991ccca4bd3ae49462d76b2490e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f478384a312b48bb90d2a7cc42c97f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ceca8ef10946ee850c1ac38d23d8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.0032284767366945744, 'test_loss': 7.648849010467529}\n",
      "--------------------------------------------------------------------------------\n",
      "{'val_loss': 7.648849010467529, 'best_model_path': '/content/recommender_models/recommender.ckpt'}\n"
     ]
    }
   ],
   "source": [
    "ds = ML1mDataModule(data_sir=args.data_dir, **args.__dict__)\n",
    "ds.prepare_data()\n",
    "\n",
    "args.vocab_size = len(ds.data.mapping) + 2\n",
    "\n",
    "model = BERT4Rec(**args.__dict__)\n",
    "\n",
    "result_val = pl_trainer(model, ds, **args.__dict__)\n",
    "\n",
    "output_json = {\n",
    "    \"val_loss\": result_val[0][\"test_loss\"],\n",
    "    \"best_model_path\": checkpoint_callback.best_model_path,\n",
    "}\n",
    "\n",
    "print(output_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
