{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-01-26-tfrs-olist.ipynb","provenance":[{"file_id":"https://github.com/recohut/nbs/blob/main/raw/T368830%20%7C%20Multi-Task%20Recommender%20on%20Olist%20dataset%20using%20TFRS%20Library.ipynb","timestamp":1644674008768},{"file_id":"https://github.com/recohut/notebooks/blob/master/_notebooks/2021-07-04-tfrs-recommenders-olist.ipynb","timestamp":1635312785561}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Pl4AgHqYUUqw9nBrE3n12SkQI3qT4pN8","authorship_tag":"ABX9TyNlTdxYeg/gziUwGaF2PmAf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NzKpIG2P7rCx"},"source":["# Multi-Task Recommender on Olist dataset using TFRS Library\n","\n","> TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset."]},{"cell_type":"markdown","metadata":{"id":"73ngMKyL8ehG"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"QXhSHSjTPfoB"},"source":["### Overview\n","- Objective: To demonstrate TensorFlow 2.0 TFRS recommenders library to build a recommendation system on a customer retail data.\n","- Data source: https://www.kaggle.com/olistbr/brazilian-ecommerce/home/\n","- Benefit: Flexible model, ability to add different features and specify and adjust model complexity easily."]},{"cell_type":"markdown","metadata":{"id":"yyOZelCuPg1q"},"source":["### Theory\n","Two types of recommendation model-- Retrieval and Ranking.\n","- Retrieval: The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient. Retrieval can be computationally more efficient because it only returns smaller set of items a user would strongly interested.\n","- Ranking: The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates."]},{"cell_type":"markdown","metadata":{"id":"p1rpU624hKri"},"source":["Built with TensorFlow 2.x, TFRS makes it possible to:\n","\n","- Build and evaluate flexible **[candidate nomination models](https://research.google/pubs/pub48840/)**;\n","- Freely incorporate item, user, and context **[information](https://tensorflow.org/recommenders/examples/featurization)** into recommendation models;\n","- Train **[multi-task models](https://tensorflow.org/recommenders/examples/multitask)** that jointly optimize multiple recommendation objectives;\n","- Efficiently serve the resulting models using **[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)**.\n","- [Multi-task learning](https://research.google/pubs/pub47842/), [feature cross modeling](https://arxiv.org/abs/1708.05123), [self-supervised learning](https://arxiv.org/abs/2007.12865), and state-of-the-art efficient [approximate nearest neighbours computation](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html)."]},{"cell_type":"markdown","metadata":{"id":"DOxZmD-VaEdu"},"source":["### Outline\n","1. Retrieval model\n","2. Ranking model\n","3. Adding text and timestamp embedding\n","4. Multitask recommendation, combining retrieval and ranking\n","5. Add more features using Cross Network."]},{"cell_type":"markdown","metadata":{"id":"Ge2APNZwbHF1"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOL4L1OCyjTj","executionInfo":{"status":"ok","timestamp":1635313245771,"user_tz":-330,"elapsed":4977,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"9ce1483b-dc99-43e9-ab8c-912502390662"},"source":["!pip install -q tensorflow-recommenders"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 85 kB 2.5 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"AOf0GG14ZoDX"},"source":["import os\n","import pprint\n","import tempfile\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from typing import Dict, Text\n","\n","import tensorflow as tf\n","import tensorflow_recommenders as tfrs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSHqwMCyRhTw","executionInfo":{"status":"ok","timestamp":1635313510867,"user_tz":-330,"elapsed":3407,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"748d5948-93c9-4f5c-d364-3a390c625157"},"source":["!pip install -q watermark\n","%reload_ext watermark\n","%watermark -m -iv -u -t -d"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Last updated: 2021-10-27 05:45:19\n","\n","Compiler    : GCC 7.5.0\n","OS          : Linux\n","Release     : 5.4.104+\n","Machine     : x86_64\n","Processor   : x86_64\n","CPU cores   : 2\n","Architecture: 64bit\n","\n","seaborn                : 0.11.2\n","pandas                 : 1.1.5\n","numpy                  : 1.19.5\n","matplotlib             : 3.2.2\n","tensorflow_recommenders: 0.6.0\n","IPython                : 5.5.0\n","tensorflow             : 2.6.0\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"UosmyIAPbIS1"},"source":["## Data Loading"]},{"cell_type":"code","metadata":{"id":"uORj0Lar5hrG"},"source":["# !pip install -q -U kaggle\n","# !pip install --upgrade --force-reinstall --no-deps kaggle\n","# !mkdir ~/.kaggle\n","# !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json\n","# !kaggle datasets download -d olistbr/brazilian-ecommerce"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HL5StgSQQ6vK","executionInfo":{"status":"ok","timestamp":1635313298784,"user_tz":-330,"elapsed":1663,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3e6a7fde-1c4b-4e9e-ab46-391375bd8bb2"},"source":["!git clone -q https://github.com/sparsh-ai/multiobjective-optimizations.git\n","!cp multiobjective-optimizations/data/brazilian-ecommerce.zip .\n","!unzip brazilian-ecommerce.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  brazilian-ecommerce.zip\n","  inflating: olist_customers_dataset.csv  \n","  inflating: olist_geolocation_dataset.csv  \n","  inflating: olist_order_items_dataset.csv  \n","  inflating: olist_order_payments_dataset.csv  \n","  inflating: olist_order_reviews_dataset.csv  \n","  inflating: olist_orders_dataset.csv  \n","  inflating: olist_products_dataset.csv  \n","  inflating: olist_sellers_dataset.csv  \n","  inflating: product_category_name_translation.csv  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4kzXioHdedga","executionInfo":{"status":"ok","timestamp":1635313309276,"user_tz":-330,"elapsed":2488,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"1eef39ad-27bd-4abe-ac01-5f1ee403eae0"},"source":["import glob\n","files = sorted(glob.glob('/content/*.csv'))\n","dfs = [pd.read_csv(data) for data in files]\n","for i, x in enumerate(dfs):\n","  print(f\"\\n\\ndfs {i}: {files[i].split('/')[-1].split('.')[0]}\\n\")\n","  display(x.head())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 0: olist_customers_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>customer_unique_id</th>\n","      <th>customer_zip_code_prefix</th>\n","      <th>customer_city</th>\n","      <th>customer_state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n","      <td>861eff4711a542e4b93843c6dd7febb0</td>\n","      <td>14409</td>\n","      <td>franca</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18955e83d337fd6b2def6b18a428ac77</td>\n","      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n","      <td>9790</td>\n","      <td>sao bernardo do campo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n","      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n","      <td>1151</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n","      <td>259dac757896d24d7702b9acbbff3f3c</td>\n","      <td>8775</td>\n","      <td>mogi das cruzes</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n","      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n","      <td>13056</td>\n","      <td>campinas</td>\n","      <td>SP</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        customer_id  ... customer_state\n","0  06b8999e2fba1a1fbc88172c00ba8bc7  ...             SP\n","1  18955e83d337fd6b2def6b18a428ac77  ...             SP\n","2  4e7b3e00288586ebd08712fdd0374a03  ...             SP\n","3  b2b6027bc5c5109e529d4dc6358b12c3  ...             SP\n","4  4f2d8ab171c80ec8364f7c12e35b23ad  ...             SP\n","\n","[5 rows x 5 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 1: olist_geolocation_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geolocation_zip_code_prefix</th>\n","      <th>geolocation_lat</th>\n","      <th>geolocation_lng</th>\n","      <th>geolocation_city</th>\n","      <th>geolocation_state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1037</td>\n","      <td>-23.545621</td>\n","      <td>-46.639292</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1046</td>\n","      <td>-23.546081</td>\n","      <td>-46.644820</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1046</td>\n","      <td>-23.546129</td>\n","      <td>-46.642951</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1041</td>\n","      <td>-23.544392</td>\n","      <td>-46.639499</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1035</td>\n","      <td>-23.541578</td>\n","      <td>-46.641607</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   geolocation_zip_code_prefix  ...  geolocation_state\n","0                         1037  ...                 SP\n","1                         1046  ...                 SP\n","2                         1046  ...                 SP\n","3                         1041  ...                 SP\n","4                         1035  ...                 SP\n","\n","[5 rows x 5 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 2: olist_order_items_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>order_item_id</th>\n","      <th>product_id</th>\n","      <th>seller_id</th>\n","      <th>shipping_limit_date</th>\n","      <th>price</th>\n","      <th>freight_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n","      <td>1</td>\n","      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n","      <td>48436dade18ac8b2bce089ec2a041202</td>\n","      <td>2017-09-19 09:45:35</td>\n","      <td>58.90</td>\n","      <td>13.29</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00018f77f2f0320c557190d7a144bdd3</td>\n","      <td>1</td>\n","      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n","      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n","      <td>2017-05-03 11:05:13</td>\n","      <td>239.90</td>\n","      <td>19.93</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000229ec398224ef6ca0657da4fc703e</td>\n","      <td>1</td>\n","      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n","      <td>5b51032eddd242adc84c38acab88f23d</td>\n","      <td>2018-01-18 14:48:30</td>\n","      <td>199.00</td>\n","      <td>17.87</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00024acbcdf0a6daa1e931b038114c75</td>\n","      <td>1</td>\n","      <td>7634da152a4610f1595efa32f14722fc</td>\n","      <td>9d7a1d34a5052409006425275ba1c2b4</td>\n","      <td>2018-08-15 10:10:18</td>\n","      <td>12.99</td>\n","      <td>12.79</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n","      <td>1</td>\n","      <td>ac6c3623068f30de03045865e4e10089</td>\n","      <td>df560393f3a51e74553ab94004ba5c87</td>\n","      <td>2017-02-13 13:57:51</td>\n","      <td>199.90</td>\n","      <td>18.14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           order_id  order_item_id  ...   price freight_value\n","0  00010242fe8c5a6d1ba2dd792cb16214              1  ...   58.90         13.29\n","1  00018f77f2f0320c557190d7a144bdd3              1  ...  239.90         19.93\n","2  000229ec398224ef6ca0657da4fc703e              1  ...  199.00         17.87\n","3  00024acbcdf0a6daa1e931b038114c75              1  ...   12.99         12.79\n","4  00042b26cf59d7ce69dfabb4e55b4fd9              1  ...  199.90         18.14\n","\n","[5 rows x 7 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 3: olist_order_payments_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>payment_sequential</th>\n","      <th>payment_type</th>\n","      <th>payment_installments</th>\n","      <th>payment_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n","      <td>1</td>\n","      <td>credit_card</td>\n","      <td>8</td>\n","      <td>99.33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n","      <td>1</td>\n","      <td>credit_card</td>\n","      <td>1</td>\n","      <td>24.39</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n","      <td>1</td>\n","      <td>credit_card</td>\n","      <td>1</td>\n","      <td>65.71</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ba78997921bbcdc1373bb41e913ab953</td>\n","      <td>1</td>\n","      <td>credit_card</td>\n","      <td>8</td>\n","      <td>107.78</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>42fdf880ba16b47b59251dd489d4441a</td>\n","      <td>1</td>\n","      <td>credit_card</td>\n","      <td>2</td>\n","      <td>128.45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           order_id  ...  payment_value\n","0  b81ef226f3fe1789b1e8b2acac839d17  ...          99.33\n","1  a9810da82917af2d9aefd1278f1dcfa0  ...          24.39\n","2  25e8ea4e93396b6fa0d3dd708e76c1bd  ...          65.71\n","3  ba78997921bbcdc1373bb41e913ab953  ...         107.78\n","4  42fdf880ba16b47b59251dd489d4441a  ...         128.45\n","\n","[5 rows x 5 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 4: olist_order_reviews_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>order_id</th>\n","      <th>review_score</th>\n","      <th>review_comment_title</th>\n","      <th>review_comment_message</th>\n","      <th>review_creation_date</th>\n","      <th>review_answer_timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7bc2406110b926393aa56f80a40eba40</td>\n","      <td>73fc7af87114b39712e6da79b0a377eb</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2018-01-18 00:00:00</td>\n","      <td>2018-01-18 21:46:59</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n","      <td>a548910a1c6147796b98fdf73dbeba33</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2018-03-10 00:00:00</td>\n","      <td>2018-03-11 03:05:13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n","      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2018-02-17 00:00:00</td>\n","      <td>2018-02-18 14:36:24</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n","      <td>658677c97b385a9be170737859d3511b</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>Recebi bem antes do prazo estipulado.</td>\n","      <td>2017-04-21 00:00:00</td>\n","      <td>2017-04-21 22:02:06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n","      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n","      <td>2018-03-01 00:00:00</td>\n","      <td>2018-03-02 10:26:53</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          review_id  ... review_answer_timestamp\n","0  7bc2406110b926393aa56f80a40eba40  ...     2018-01-18 21:46:59\n","1  80e641a11e56f04c1ad469d5645fdfde  ...     2018-03-11 03:05:13\n","2  228ce5500dc1d8e020d8d1322874b6f0  ...     2018-02-18 14:36:24\n","3  e64fb393e7b32834bb789ff8bb30750e  ...     2017-04-21 22:02:06\n","4  f7c4243c7fe1938f181bec41a392bdeb  ...     2018-03-02 10:26:53\n","\n","[5 rows x 7 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 5: olist_orders_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>customer_id</th>\n","      <th>order_status</th>\n","      <th>order_purchase_timestamp</th>\n","      <th>order_approved_at</th>\n","      <th>order_delivered_carrier_date</th>\n","      <th>order_delivered_customer_date</th>\n","      <th>order_estimated_delivery_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n","      <td>9ef432eb6251297304e76186b10a928d</td>\n","      <td>delivered</td>\n","      <td>2017-10-02 10:56:33</td>\n","      <td>2017-10-02 11:07:15</td>\n","      <td>2017-10-04 19:55:00</td>\n","      <td>2017-10-10 21:25:13</td>\n","      <td>2017-10-18 00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n","      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n","      <td>delivered</td>\n","      <td>2018-07-24 20:41:37</td>\n","      <td>2018-07-26 03:24:27</td>\n","      <td>2018-07-26 14:31:00</td>\n","      <td>2018-08-07 15:27:45</td>\n","      <td>2018-08-13 00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n","      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n","      <td>delivered</td>\n","      <td>2018-08-08 08:38:49</td>\n","      <td>2018-08-08 08:55:23</td>\n","      <td>2018-08-08 13:50:00</td>\n","      <td>2018-08-17 18:06:29</td>\n","      <td>2018-09-04 00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n","      <td>f88197465ea7920adcdbec7375364d82</td>\n","      <td>delivered</td>\n","      <td>2017-11-18 19:28:06</td>\n","      <td>2017-11-18 19:45:59</td>\n","      <td>2017-11-22 13:39:59</td>\n","      <td>2017-12-02 00:28:42</td>\n","      <td>2017-12-15 00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n","      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n","      <td>delivered</td>\n","      <td>2018-02-13 21:18:39</td>\n","      <td>2018-02-13 22:20:29</td>\n","      <td>2018-02-14 19:46:34</td>\n","      <td>2018-02-16 18:17:02</td>\n","      <td>2018-02-26 00:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           order_id  ... order_estimated_delivery_date\n","0  e481f51cbdc54678b7cc49136f2d6af7  ...           2017-10-18 00:00:00\n","1  53cdb2fc8bc7dce0b6741e2150273451  ...           2018-08-13 00:00:00\n","2  47770eb9100c2d0c44946d9cf07ec65d  ...           2018-09-04 00:00:00\n","3  949d5b44dbf5de918fe9c16f97b45f8a  ...           2017-12-15 00:00:00\n","4  ad21c59c0840e6cb83a9ceb5573f8159  ...           2018-02-26 00:00:00\n","\n","[5 rows x 8 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 6: olist_products_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>product_category_name</th>\n","      <th>product_name_lenght</th>\n","      <th>product_description_lenght</th>\n","      <th>product_photos_qty</th>\n","      <th>product_weight_g</th>\n","      <th>product_length_cm</th>\n","      <th>product_height_cm</th>\n","      <th>product_width_cm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n","      <td>perfumaria</td>\n","      <td>40.0</td>\n","      <td>287.0</td>\n","      <td>1.0</td>\n","      <td>225.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n","      <td>artes</td>\n","      <td>44.0</td>\n","      <td>276.0</td>\n","      <td>1.0</td>\n","      <td>1000.0</td>\n","      <td>30.0</td>\n","      <td>18.0</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>96bd76ec8810374ed1b65e291975717f</td>\n","      <td>esporte_lazer</td>\n","      <td>46.0</td>\n","      <td>250.0</td>\n","      <td>1.0</td>\n","      <td>154.0</td>\n","      <td>18.0</td>\n","      <td>9.0</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cef67bcfe19066a932b7673e239eb23d</td>\n","      <td>bebes</td>\n","      <td>27.0</td>\n","      <td>261.0</td>\n","      <td>1.0</td>\n","      <td>371.0</td>\n","      <td>26.0</td>\n","      <td>4.0</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9dc1a7de274444849c219cff195d0b71</td>\n","      <td>utilidades_domesticas</td>\n","      <td>37.0</td>\n","      <td>402.0</td>\n","      <td>4.0</td>\n","      <td>625.0</td>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         product_id  ... product_width_cm\n","0  1e9e8ef04dbcff4541ed26657ea517e5  ...             14.0\n","1  3aa071139cb16b67ca9e5dea641aaa2f  ...             20.0\n","2  96bd76ec8810374ed1b65e291975717f  ...             15.0\n","3  cef67bcfe19066a932b7673e239eb23d  ...             26.0\n","4  9dc1a7de274444849c219cff195d0b71  ...             13.0\n","\n","[5 rows x 9 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 7: olist_sellers_dataset\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>seller_id</th>\n","      <th>seller_zip_code_prefix</th>\n","      <th>seller_city</th>\n","      <th>seller_state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3442f8959a84dea7ee197c632cb2df15</td>\n","      <td>13023</td>\n","      <td>campinas</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n","      <td>13844</td>\n","      <td>mogi guacu</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n","      <td>20031</td>\n","      <td>rio de janeiro</td>\n","      <td>RJ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n","      <td>4195</td>\n","      <td>sao paulo</td>\n","      <td>SP</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n","      <td>12914</td>\n","      <td>braganca paulista</td>\n","      <td>SP</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          seller_id  ...  seller_state\n","0  3442f8959a84dea7ee197c632cb2df15  ...            SP\n","1  d1b65fc7debc3361ea86b5f14c68d2e2  ...            SP\n","2  ce3ad9de960102d0677a81f5d0bb7b2d  ...            RJ\n","3  c0f3eea2e14555b6faeea3dd58c1b1c3  ...            SP\n","4  51a04a8a6bdcb23deccc82b0b80742cf  ...            SP\n","\n","[5 rows x 4 columns]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","dfs 8: product_category_name_translation\n","\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_category_name</th>\n","      <th>product_category_name_english</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>beleza_saude</td>\n","      <td>health_beauty</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>informatica_acessorios</td>\n","      <td>computers_accessories</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>automotivo</td>\n","      <td>auto</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cama_mesa_banho</td>\n","      <td>bed_bath_table</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>moveis_decoracao</td>\n","      <td>furniture_decor</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    product_category_name product_category_name_english\n","0            beleza_saude                 health_beauty\n","1  informatica_acessorios         computers_accessories\n","2              automotivo                          auto\n","3         cama_mesa_banho                bed_bath_table\n","4        moveis_decoracao               furniture_decor"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"uRci8wzMNOPT"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"_GCUFv9reddm","executionInfo":{"status":"ok","timestamp":1635313330731,"user_tz":-330,"elapsed":16718,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"a4c59161-d33a-4cde-92bb-ce316d20d558"},"source":["df11 = pd.merge(dfs[2], dfs[5], how='outer', on='order_id')[['product_id','customer_id','order_purchase_timestamp']]\n","df12 = pd.merge(dfs[6], dfs[8], how='left', on='product_category_name')[['product_id','product_category_name_english']]\n","df1 = pd.merge(df11, df12, how='left', on='product_id')\n","df1['sku'] = df1.groupby(['product_category_name_english']).cumcount().astype('str')\n","df1['product_id'] = df1['product_category_name_english'] + '_' + df1['sku']\n","df1['implicit_interaction_weight'] = 1\n","df1['order_purchase_timestamp'] = df1['order_purchase_timestamp'].map(lambda x: pd.to_datetime(x).timestamp())\n","df1 = df1[['customer_id', 'product_id', 'implicit_interaction_weight', 'order_purchase_timestamp']]\n","df1.columns = ['USERID','ITEMID','RATING','TIMESTAMP']\n","df1.dropna(inplace=True)\n","df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>USERID</th>\n","      <th>ITEMID</th>\n","      <th>RATING</th>\n","      <th>TIMESTAMP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3ce436f183e68e07877b285a838db11a</td>\n","      <td>cool_stuff_0</td>\n","      <td>1</td>\n","      <td>1.505293e+09</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>f6dd3ec061db4e3987629fe6b26e5cce</td>\n","      <td>pet_shop_0</td>\n","      <td>1</td>\n","      <td>1.493204e+09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6489ae5e4333f3693df5ad4372dab6d3</td>\n","      <td>furniture_decor_0</td>\n","      <td>1</td>\n","      <td>1.515940e+09</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d4eb9395c8c0431ee92fce09860c5a06</td>\n","      <td>perfumery_0</td>\n","      <td>1</td>\n","      <td>1.533722e+09</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58dbd0b2d70206bf40e62cd34e84d795</td>\n","      <td>garden_tools_0</td>\n","      <td>1</td>\n","      <td>1.486217e+09</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>112645</th>\n","      <td>b51593916b4b8e0d6f66f2ae24f2673d</td>\n","      <td>housewares_6963</td>\n","      <td>1</td>\n","      <td>1.524492e+09</td>\n","    </tr>\n","    <tr>\n","      <th>112646</th>\n","      <td>84c5d4fbaf120aae381fad077416eaa0</td>\n","      <td>computers_accessories_7825</td>\n","      <td>1</td>\n","      <td>1.531564e+09</td>\n","    </tr>\n","    <tr>\n","      <th>112647</th>\n","      <td>29309aa813182aaddc9b259e31b870e6</td>\n","      <td>sports_leisure_8640</td>\n","      <td>1</td>\n","      <td>1.508778e+09</td>\n","    </tr>\n","    <tr>\n","      <th>112648</th>\n","      <td>b5e6afd5a41800fdf401e0272ca74655</td>\n","      <td>computers_accessories_7826</td>\n","      <td>1</td>\n","      <td>1.502752e+09</td>\n","    </tr>\n","    <tr>\n","      <th>112649</th>\n","      <td>96d649da0cc4ff33bb408b199d4c7dcf</td>\n","      <td>bed_bath_table_11114</td>\n","      <td>1</td>\n","      <td>1.528564e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>111023 rows × 4 columns</p>\n","</div>"],"text/plain":["                                  USERID  ...     TIMESTAMP\n","0       3ce436f183e68e07877b285a838db11a  ...  1.505293e+09\n","1       f6dd3ec061db4e3987629fe6b26e5cce  ...  1.493204e+09\n","2       6489ae5e4333f3693df5ad4372dab6d3  ...  1.515940e+09\n","3       d4eb9395c8c0431ee92fce09860c5a06  ...  1.533722e+09\n","4       58dbd0b2d70206bf40e62cd34e84d795  ...  1.486217e+09\n","...                                  ...  ...           ...\n","112645  b51593916b4b8e0d6f66f2ae24f2673d  ...  1.524492e+09\n","112646  84c5d4fbaf120aae381fad077416eaa0  ...  1.531564e+09\n","112647  29309aa813182aaddc9b259e31b870e6  ...  1.508778e+09\n","112648  b5e6afd5a41800fdf401e0272ca74655  ...  1.502752e+09\n","112649  96d649da0cc4ff33bb408b199d4c7dcf  ...  1.528564e+09\n","\n","[111023 rows x 4 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MtcW265zt0r","executionInfo":{"status":"ok","timestamp":1635313337786,"user_tz":-330,"elapsed":7077,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"2a47d117-23a7-4466-8bce-9b2880908063"},"source":["interactions_dict = df1.groupby(['USERID', 'ITEMID'])['RATING'].count().reset_index()\n","interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n","interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n","\n","for x in interactions.take(5): print(x)\n","\n","interactions = interactions.map(lambda x: {\n","    'USERID' : x['USERID'], \n","    'ITEMID' : x['ITEMID'], \n","    'RATING' : float(x['RATING']),\n","})"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'00012a2ce6f8dcda20d059ce98491703'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'toys_1531'>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'000161a058600d5901f007fab4c27140'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'health_beauty_6074'>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'0001fd6190edaaf884bcaf3d49edf079'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'baby_571'>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'0002414f95344307404f0ace7a26f1d5'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'cool_stuff_1263'>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'000379cdec625522490c315e70c7a9fb'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'bed_bath_table_483'>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n"]}]},{"cell_type":"code","metadata":{"id":"xaDMgvUWeYwm"},"source":["items_dict = df1[['ITEMID']].drop_duplicates()\n","items_dict = {name: np.array(value) for name, value in items_dict.items()}\n","items = tf.data.Dataset.from_tensor_slices(items_dict)\n","\n","items = items.map(lambda x: x['ITEMID'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKxYOXCzrea5"},"source":["### get unique item and user id's as a lookup table\n","unique_item_titles = np.unique(np.concatenate(list(items.batch(1000))))\n","unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"USERID\"]))))\n","\n","# Randomly shuffle data and split between train and test.\n","tf.random.set_seed(42)\n","shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n","\n","train = shuffled.take(60_000)\n","test = shuffled.skip(60_000).take(20_000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44S48b-H3ewY"},"source":["## Retrieval Model"]},{"cell_type":"markdown","metadata":{"id":"a8ESTThw7Kse"},"source":["There are five important component of the query and candicate tower: candidate model (item_model), querty model (user_model), metrics, task, and compute loss."]},{"cell_type":"code","metadata":{"id":"qfcgl8Vj3dTm"},"source":["class RetailModel(tfrs.Model):\n","\n","    def __init__(self, user_model, item_model):\n","      super().__init__()\n","      \n","      ### Candidate model (item)\n","      ### This is Keras preprocessing layers to first convert user ids to integers, \n","      ### and then convert those to user embeddings via an Embedding layer. \n","      ### We use the list of unique user ids we computed earlier as a vocabulary:\n","      item_model = tf.keras.Sequential([\n","                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n","                                      vocabulary=unique_item_titles, mask_token=None),\n","                                      tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n","                                      ])\n","      ### we pass the embedding layer into item model\n","      self.item_model: tf.keras.Model = item_model\n","          \n","      ### Query model (users)    \n","      user_model = tf.keras.Sequential([\n","                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n","                                      vocabulary=unique_user_ids, mask_token=None),\n","                                      # We add an additional embedding to account for unknown tokens.\n","                                      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n","                                      ])\n","      self.user_model: tf.keras.Model = user_model\n","      \n","      ### for retrieval model. we take top-k accuracy as metrics\n","      metrics = tfrs.metrics.FactorizedTopK(candidates=items.batch(128).map(item_model))\n","      \n","      # define the task, which is retrieval\n","      task = tfrs.tasks.Retrieval(metrics=metrics)\n","      \n","      self.task: tf.keras.layers.Layer = task\n","\n","    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","      # We pick out the user features and pass them into the user model.\n","      user_embeddings = self.user_model(features[\"USERID\"])\n","      # And pick out the movie features and pass them into the movie model,\n","      # getting embeddings back.\n","      positive_movie_embeddings = self.item_model(features[\"ITEMID\"])\n","\n","      # The task computes the loss and the metrics.\n","      return self.task(user_embeddings, positive_movie_embeddings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBYnb5F1R2P1","outputId":"0a519872-eb30-4613-bfbc-9fc003fdcbcd"},"source":["### Fitting and evaluating\n","\n","### we choose the dimensionality of the query and candicate representation.\n","embedding_dimension = 32\n","\n","## we pass the model, which is the same model we created in the query and candidate tower, into the model\n","item_model = tf.keras.Sequential([\n","                                tf.keras.layers.experimental.preprocessing.StringLookup(\n","                                vocabulary=unique_item_titles, mask_token=None),\n","                                tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n","                                ])\n","\n","user_model = tf.keras.Sequential([\n","                                tf.keras.layers.experimental.preprocessing.StringLookup(\n","                                vocabulary=unique_user_ids, mask_token=None),\n","                                # We add an additional embedding to account for unknown tokens.\n","                                tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n","                                ])\n","\n","model = RetailModel(user_model, item_model)\n","\n","# a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1\n","# other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n","\n","cached_train = train.shuffle(100_000).batch(8192).cache()\n","cached_test = test.batch(4096).cache()\n","\n","## fit the model with ten epochs\n","model_hist = model.fit(cached_train, epochs=10)\n","\n","#evaluate the model\n","model.evaluate(cached_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","8/8 [==============================] - 400s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.6667e-04 - loss: 62067.0734 - regularization_loss: 0.0000e+00 - total_loss: 62067.0734\n","Epoch 2/10\n","8/8 [==============================] - 396s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0935 - factorized_top_k/top_10_categorical_accuracy: 0.1493 - factorized_top_k/top_50_categorical_accuracy: 0.3334 - factorized_top_k/top_100_categorical_accuracy: 0.4331 - loss: 61949.0182 - regularization_loss: 0.0000e+00 - total_loss: 61949.0182\n","Epoch 3/10\n","8/8 [==============================] - 392s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5566 - factorized_top_k/top_10_categorical_accuracy: 0.7027 - factorized_top_k/top_50_categorical_accuracy: 0.9107 - factorized_top_k/top_100_categorical_accuracy: 0.9537 - loss: 61799.8203 - regularization_loss: 0.0000e+00 - total_loss: 61799.8203\n","Epoch 4/10\n","8/8 [==============================] - 391s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6852 - factorized_top_k/top_10_categorical_accuracy: 0.8421 - factorized_top_k/top_50_categorical_accuracy: 0.9835 - factorized_top_k/top_100_categorical_accuracy: 0.9948 - loss: 61557.9358 - regularization_loss: 0.0000e+00 - total_loss: 61557.9358\n","Epoch 5/10\n","8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6006 - factorized_top_k/top_10_categorical_accuracy: 0.7915 - factorized_top_k/top_50_categorical_accuracy: 0.9886 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 61139.4262 - regularization_loss: 0.0000e+00 - total_loss: 61139.4262\n","Epoch 6/10\n","8/8 [==============================] - 389s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5041 - factorized_top_k/top_10_categorical_accuracy: 0.7085 - factorized_top_k/top_50_categorical_accuracy: 0.9848 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 60430.4431 - regularization_loss: 0.0000e+00 - total_loss: 60430.4431\n","Epoch 7/10\n","8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4606 - factorized_top_k/top_10_categorical_accuracy: 0.6669 - factorized_top_k/top_50_categorical_accuracy: 0.9832 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 59296.1063 - regularization_loss: 0.0000e+00 - total_loss: 59296.1063\n","Epoch 8/10\n","8/8 [==============================] - 384s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4800 - factorized_top_k/top_10_categorical_accuracy: 0.6913 - factorized_top_k/top_50_categorical_accuracy: 0.9875 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 57606.5898 - regularization_loss: 0.0000e+00 - total_loss: 57606.5898\n","Epoch 9/10\n","8/8 [==============================] - 387s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5498 - factorized_top_k/top_10_categorical_accuracy: 0.7657 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 55261.9683 - regularization_loss: 0.0000e+00 - total_loss: 55261.9683\n","Epoch 10/10\n","8/8 [==============================] - 385s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6651 - factorized_top_k/top_10_categorical_accuracy: 0.8625 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9997 - loss: 52214.9371 - regularization_loss: 0.0000e+00 - total_loss: 52214.9371\n","5/5 [==============================] - 132s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_100_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n"," 'loss': 29625.80078125,\n"," 'regularization_loss': 0,\n"," 'total_loss': 29625.80078125}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yvfAWTa5OJ6","outputId":"cb2ef58c-7ae9-41d8-c553-8ef9f19bc140"},"source":["model.evaluate(cached_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5/5 [==============================] - 130s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_100_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n"," 'loss': 29625.80078125,\n"," 'regularization_loss': 0,\n"," 'total_loss': 29625.80078125}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"T48UBb5A6Zv2","outputId":"2e231d6d-711e-45a3-c9ee-112b45bd080b"},"source":["# num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n","epochs = [i for i in range(10)]\n","\n","plt.plot(epochs, model_hist.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"accuracy\")\n","plt.title(\"Accuracy vs epoch\")\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"Top-100 accuracy\");\n","plt.legend()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f289dc49790>"]},"metadata":{"tags":[]},"execution_count":16},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKCDYWVO6dnG","outputId":"d5161d99-f90b-460f-d7eb-4f44ddc7601d"},"source":["# Create a model that takes in raw query features, and\n","index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n","# recommends items out of the entire dataset.\n","index.index(items.batch(100).map(model.item_model), items)\n","\n","# Get recommendations.\n","j = str(40)\n","_, items = index(tf.constant([j]))\n","print(f\"Recommendations for user %s: {items[0]}\" %(j))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Recommendations for user 40: [b'housewares_1189' b'housewares_1181' b'housewares_1186'\n"," b'housewares_1188' b'electronics_1206' b'housewares_1185'\n"," b'housewares_1190' b'electronics_1205' b'housewares_1182'\n"," b'housewares_1184']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y09nBvYJ7CLQ"},"source":["There you are, our first simple yet effective recommendation engine using retrieval task. But what about ranking? can we rank all the items for best to worst, only then run retrieval task to retrieve selected items from the short list? Now we can explore another type of recommendation task: ranking."]},{"cell_type":"markdown","metadata":{"id":"C_IBmLuxC-x2"},"source":["## Ranking Model"]},{"cell_type":"markdown","metadata":{"id":"XMDlO4aKDFSL"},"source":["Ranking model is able to assist retrieval by ranking all the items from highest to lowest, predcting a probablity that a user may or may not like it. Ranking model is useful to filter out items that are not relevant for the user before retrieval task, making retrieval task much more accurate and efficient.\n","\n","Here, many embedding layers works similarly with retrieval model, with addition of multiple hidden layers under Sequential latyers, where we can stack multiple dense layers. We split the query and candidate tower separately, and call them later into the model."]},{"cell_type":"code","metadata":{"id":"nqsYVhXZDAm2"},"source":["class RankingModel(tf.keras.Model):\n","\n","    def __init__(self):\n","        super().__init__()\n","        embedding_dimension = 32\n","\n","        # Compute embeddings for users.\n","        self.user_embeddings = tf.keras.Sequential([\n","          tf.keras.layers.experimental.preprocessing.StringLookup(\n","            vocabulary=unique_user_ids, mask_token=None),\n","          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n","        ])\n","\n","        # Compute embeddings for movies.\n","        self.item_embeddings = tf.keras.Sequential([\n","          tf.keras.layers.experimental.preprocessing.StringLookup(\n","            vocabulary=unique_item_titles, mask_token=None),\n","          tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n","        ])\n","\n","        # Compute predictions.\n","        self.ratings = tf.keras.Sequential([\n","          # Learn multiple dense layers.\n","          tf.keras.layers.Dense(256, activation=\"relu\"),\n","          tf.keras.layers.Dense(64, activation=\"relu\"),\n","          # Make rating predictions in the final layer.\n","          tf.keras.layers.Dense(1)\n","  ])\n","\n","    def call(self, inputs):\n","\n","        user_id, item_id = inputs\n","\n","        user_embedding = self.user_embeddings(user_id)\n","        item_embedding = self.item_embeddings(item_id)\n","\n","        return self.ratings(tf.concat([user_embedding, item_embedding], axis=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQ6uPSZ0DpvA"},"source":["This model takes user ids and item ids, and outputs a predicted rating, for example:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HkN_XVoDqPE","outputId":"b5cabe5b-8dff-4600-cdd1-07de58bb1132"},"source":["RankingModel()(([\"f6dd3ec061db4e3987629fe6b26e5cce\"], [\"pet_shop_0\"]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['f6dd3ec061db4e3987629fe6b26e5cce']\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['pet_shop_0']\n","Consider rewriting this model with the Functional API.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01409375]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"HUQ1uAWHEJve"},"source":["class RetailModel(tfrs.models.Model):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.ranking_model: tf.keras.Model = RankingModel()\n","        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n","          loss = tf.keras.losses.MeanSquaredError(),\n","          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n","        )\n","\n","    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","        rating_predictions = self.ranking_model(\n","            (features[\"USERID\"], features[\"ITEMID\"]))\n","\n","        # The task computes the loss and the metrics.\n","        return self.task(labels=features[\"RATING\"], predictions=rating_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InDnIB3JEUdV","outputId":"3415ad4e-662c-41a0-a137-46a36e3d38c7"},"source":["model = RetailModel()\n","\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5))\n","\n","cached_train = train.shuffle(100_000).batch(8192).cache()\n","cached_test = test.batch(4096).cache()\n","\n","model.fit(cached_train, epochs=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","8/8 [==============================] - 3s 31ms/step - root_mean_squared_error: 0.9951 - loss: 0.8617 - regularization_loss: 0.0000e+00 - total_loss: 0.8617\n","Epoch 2/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.2813 - loss: 0.0668 - regularization_loss: 0.0000e+00 - total_loss: 0.0668\n","Epoch 3/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 0.0593 - loss: 0.0030 - regularization_loss: 0.0000e+00 - total_loss: 0.0030\n","Epoch 4/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0126 - loss: 1.3481e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3481e-04\n","Epoch 5/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0027 - loss: 6.1202e-06 - regularization_loss: 0.0000e+00 - total_loss: 6.1202e-06\n","Epoch 6/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 5.7347e-04 - loss: 2.7786e-07 - regularization_loss: 0.0000e+00 - total_loss: 2.7786e-07\n","Epoch 7/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.2221e-04 - loss: 1.2619e-08 - regularization_loss: 0.0000e+00 - total_loss: 1.2619e-08\n","Epoch 8/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6041e-05 - loss: 5.7305e-10 - regularization_loss: 0.0000e+00 - total_loss: 5.7305e-10\n","Epoch 9/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 5.5814e-06 - loss: 2.6307e-11 - regularization_loss: 0.0000e+00 - total_loss: 2.6307e-11\n","Epoch 10/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1712e-06 - loss: 1.1586e-12 - regularization_loss: 0.0000e+00 - total_loss: 1.1586e-12\n","Epoch 11/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6456e-07 - loss: 5.9607e-14 - regularization_loss: 0.0000e+00 - total_loss: 5.9607e-14\n","Epoch 12/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 13/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 14/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 15/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 16/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 17/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 18/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 19/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 20/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 21/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 22/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 23/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 24/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 25/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 26/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 27/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 28/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 29/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 30/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 31/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 32/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 33/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 34/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 35/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 36/100\n","8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 37/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 38/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 39/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 40/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 41/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 42/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 43/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 44/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 45/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 46/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 47/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 48/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 49/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 50/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 51/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 52/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 53/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 54/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 55/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 56/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 57/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 58/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 59/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 60/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 61/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 62/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 63/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 64/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 65/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 66/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 67/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 68/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 69/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 70/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 71/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 72/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 73/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 74/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 75/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 76/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 77/100\n","8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 78/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 79/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 80/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 81/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 82/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 83/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 84/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 85/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 86/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 87/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 88/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 89/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 90/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 91/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 92/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 93/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 94/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 95/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 96/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 97/100\n","8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 98/100\n","8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 99/100\n","8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n","Epoch 100/100\n","8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f28a37c5d90>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2FSXa6fEUZk","outputId":"fb0c87aa-9652-4545-e1a4-abc14dc86b23"},"source":["model.evaluate(cached_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5/5 [==============================] - 2s 22ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'loss': 1.4210854715202004e-14,\n"," 'regularization_loss': 0,\n"," 'root_mean_squared_error': 1.1920928955078125e-07,\n"," 'total_loss': 1.4210854715202004e-14}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"hvjpk_oyEcfF"},"source":["The RMSE is not very good, which we shall see how we can improve it by adding more features and combining ranking and retrieval model together."]},{"cell_type":"markdown","metadata":{"id":"iOl88rdWMqtd"},"source":["## Adding Context\n","Adding Timestamp and Text embeddings"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_93rwbdCEUVL","outputId":"9853264f-70e8-4d87-e31a-a729d4723292"},"source":["interactions_dict = df1.groupby(['USERID', 'ITEMID', 'TIMESTAMP'])['RATING'].count().reset_index()\n","interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n","interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n","\n","for x in interactions.take(5): print(x)\n","\n","interactions = interactions.map(lambda x: {\n","    'USERID' : x['USERID'], \n","    'ITEMID' : x['ITEMID'], \n","    'RATING' : float(x['RATING']),\n","    'TIMESTAMP' : x['TIMESTAMP'],\n","})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'00012a2ce6f8dcda20d059ce98491703'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'toys_1531'>, 'TIMESTAMP': <tf.Tensor: shape=(), dtype=float64, numpy=1510675706.0>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'000161a058600d5901f007fab4c27140'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'health_beauty_6074'>, 'TIMESTAMP': <tf.Tensor: shape=(), dtype=float64, numpy=1500198032.0>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'0001fd6190edaaf884bcaf3d49edf079'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'baby_571'>, 'TIMESTAMP': <tf.Tensor: shape=(), dtype=float64, numpy=1488280003.0>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'0002414f95344307404f0ace7a26f1d5'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'cool_stuff_1263'>, 'TIMESTAMP': <tf.Tensor: shape=(), dtype=float64, numpy=1502888960.0>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n","{'USERID': <tf.Tensor: shape=(), dtype=string, numpy=b'000379cdec625522490c315e70c7a9fb'>, 'ITEMID': <tf.Tensor: shape=(), dtype=string, numpy=b'bed_bath_table_483'>, 'TIMESTAMP': <tf.Tensor: shape=(), dtype=float64, numpy=1522676537.0>, 'RATING': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KbfzbgIbNVtB"},"source":["items_dict = df1[['ITEMID']].drop_duplicates()\n","items_dict = {name: np.array(value) for name, value in items_dict.items()}\n","items = tf.data.Dataset.from_tensor_slices(items_dict)\n","\n","items = items.map(lambda x: x['ITEMID'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHRL37wANiXV"},"source":["timestamp is an exmaple of continuous features, which needs to be rescaled, or otherwise it will be too large for the model. there are other methods to reduce the size of the timestamp, ,such as standardization and normalization here we use discretization, which puts them into buckets of categorical features,"]},{"cell_type":"code","metadata":{"id":"32XGSiMdNbWS"},"source":["timestamps = np.concatenate(list(interactions.map(lambda x: x[\"TIMESTAMP\"]).batch(100)))\n","max_timestamp = timestamps.max()\n","min_timestamp = timestamps.min()\n","timestamp_buckets = np.linspace(\n","    min_timestamp, max_timestamp, num=1000,)\n","\n","item_ids = interactions.batch(10_000).map(lambda x: x[\"ITEMID\"])\n","user_ids = interactions.batch(10_000).map(lambda x: x[\"USERID\"])\n","\n","unique_item_ids = np.unique(np.concatenate(list(item_ids)))\n","unique_user_ids = np.unique(np.concatenate(list(user_ids)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5qEXLMUN9R9"},"source":["tf.random.set_seed(42)\n","shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n","\n","train = shuffled.take(60_000)\n","test = shuffled.skip(60_000).take(20_000)\n","\n","cached_train = train.shuffle(100_000).batch(2048)\n","cached_test = test.batch(4096).cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"enlr1TvoPw3-"},"source":["We split the query and candidate model separately to allow more stacked embedding layers before we pass it into the model. In the user model (query model), in addition to user embedding, we also add timestamp embedding."]},{"cell_type":"code","metadata":{"id":"EzLslJVrPp5a"},"source":["### user model\n","\n","class UserModel(tf.keras.Model):\n","\n","    def __init__(self, use_timestamps):\n","        super().__init__()\n","\n","        self._use_timestamps = use_timestamps\n","\n","        ## embed user id from unique_user_ids\n","        self.user_embedding = tf.keras.Sequential([\n","            tf.keras.layers.experimental.preprocessing.StringLookup(\n","                vocabulary=unique_user_ids, mask_token=None),\n","            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n","        ])\n","\n","        ## embed timestamp\n","        if use_timestamps:\n","            self.timestamp_embedding = tf.keras.Sequential([\n","              tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n","              tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n","            ])\n","            self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n","\n","            self.normalized_timestamp.adapt(timestamps)\n","\n","    def call(self, inputs):\n","        if not self._use_timestamps:\n","              return self.user_embedding(inputs[\"USERID\"])\n","\n","        ## all features here\n","        return tf.concat([\n","            self.user_embedding(inputs[\"USERID\"]),\n","            self.timestamp_embedding(inputs[\"TIMESTAMP\"]),\n","            self.normalized_timestamp(inputs[\"TIMESTAMP\"]),\n","        ], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z5wg7SVAQGKZ"},"source":["For the candidate model, we want the model to learn from the text features too by processing the text features that is able to learn words that are similar to each other. It can also identify OOV (out of Vocabulary) word, so if we are predicing a new item, the model can calculate them appropriately.\n","\n","Below, the item name will be transformated by tokenization (splitting into constituent words or word-pieces), followed by vocabulary learning, then followed by an embedding.\n","\n"]},{"cell_type":"code","metadata":{"id":"ADFkvoNtPp15"},"source":["### candidate model\n","\n","class ItemModel(tf.keras.Model):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        max_tokens = 10_000\n","\n","        ## embed title from unique_item_ids\n","        self.title_embedding = tf.keras.Sequential([\n","          tf.keras.layers.experimental.preprocessing.StringLookup(\n","              vocabulary=unique_item_ids, mask_token=None),\n","          tf.keras.layers.Embedding(len(unique_item_ids) + 1, 32)\n","        ])\n","\n","        ## processing text features: item title vectorizer (see self.title_vectorizer)\n","        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n","            max_tokens=max_tokens)\n","\n","        ## we apply title vectorizer to items\n","        self.title_text_embedding = tf.keras.Sequential([\n","          self.title_vectorizer,\n","          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n","          tf.keras.layers.GlobalAveragePooling1D(),\n","        ])\n","\n","        self.title_vectorizer.adapt(items)\n","\n","    def call(self, titles):\n","        return tf.concat([\n","            self.title_embedding(titles),\n","            self.title_text_embedding(titles),\n","        ], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN7GQh_FQpbM"},"source":["With both UserModel and ItemModel defined, we can put together a combined model and implement our loss and metrics logic.\n","\n","Note that we also need to make sure that the query model and candidate model output embeddings of compatible size. Because we'll be varying their sizes by adding more features, the easiest way to accomplish this is to use a dense projection layer after each model:"]},{"cell_type":"code","metadata":{"id":"52mV0P7vPpyN"},"source":["class RetailModel(tfrs.models.Model):\n","\n","    def __init__(self, use_timestamps):\n","        super().__init__()\n","        \n","        ## query model is user model\n","        self.query_model = tf.keras.Sequential([\n","          UserModel(use_timestamps),\n","          tf.keras.layers.Dense(32)\n","        ])\n","        \n","        ## candidate model is the item model\n","        self.candidate_model = tf.keras.Sequential([\n","          ItemModel(),\n","          tf.keras.layers.Dense(32)\n","        ])\n","        \n","        ## retrieval task, choose metrics\n","        self.task = tfrs.tasks.Retrieval(\n","            metrics=tfrs.metrics.FactorizedTopK(\n","                candidates=items.batch(128).map(self.candidate_model),\n","            ),\n","        )\n","\n","    def compute_loss(self, features, training=False):\n","        # We only pass the user id and timestamp features into the query model. This\n","        # is to ensure that the training inputs would have the same keys as the\n","        # query inputs. Otherwise the discrepancy in input structure would cause an\n","        # error when loading the query model after saving it.\n","        \n","        query_embeddings = self.query_model({\n","            \"USERID\": features[\"USERID\"],\n","            \"TIMESTAMP\": features[\"TIMESTAMP\"],\n","        })\n","        \n","        item_embeddings = self.candidate_model(features[\"ITEMID\"])\n","\n","        return self.task(query_embeddings, item_embeddings)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_c_3EzxbQ6ne"},"source":["> Note: Baseline is with no timestamp feature."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBhWoMJtQ4gc","outputId":"a2c73265-8f61-4c34-c30d-11ebcfc24c54"},"source":["model = RetailModel(use_timestamps=False)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n","model.fit(cached_train, epochs=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0564 - factorized_top_k/top_5_categorical_accuracy: 0.0614 - factorized_top_k/top_10_categorical_accuracy: 0.0640 - factorized_top_k/top_50_categorical_accuracy: 0.0715 - factorized_top_k/top_100_categorical_accuracy: 0.0752 - loss: 14855.2315 - regularization_loss: 0.0000e+00 - total_loss: 14855.2315\n","Epoch 2/3\n","30/30 [==============================] - 420s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0479 - factorized_top_k/top_5_categorical_accuracy: 0.0490 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.0508 - factorized_top_k/top_100_categorical_accuracy: 0.0516 - loss: 14047.4312 - regularization_loss: 0.0000e+00 - total_loss: 14047.4312\n","Epoch 3/3\n","30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 5.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0026 - factorized_top_k/top_50_categorical_accuracy: 0.0101 - factorized_top_k/top_100_categorical_accuracy: 0.0195 - loss: 11625.8452 - regularization_loss: 0.0000e+00 - total_loss: 11625.8452\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2837bac9d0>"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_LGm5ZJRXsB","outputId":"b081514d-ee96-4562-c431-18aedcde18c3"},"source":["model.evaluate(cached_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","5/5 [==============================] - 137s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33116.2435 - regularization_loss: 0.0000e+00 - total_loss: 33116.2435\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_100_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n"," 'loss': 30138.40234375,\n"," 'regularization_loss': 0,\n"," 'total_loss': 30138.40234375}"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"CL-lraRjRPki"},"source":["Including time into the model:\n","\n","Do the result change if we add time features?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hP5JGQXRRMx7","outputId":"8c5f421b-1da1-49cf-f83b-424cb9525c46"},"source":["model =x RetailModel(use_timestamps=True)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n","model.fit(cached_train, epochs=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n","WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n","30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0077 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.0459 - factorized_top_k/top_100_categorical_accuracy: 0.0664 - loss: 14859.7737 - regularization_loss: 0.0000e+00 - total_loss: 14859.7737\n","Epoch 2/3\n","30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 2.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0011 - factorized_top_k/top_50_categorical_accuracy: 0.0032 - factorized_top_k/top_100_categorical_accuracy: 0.0051 - loss: 12473.8825 - regularization_loss: 0.0000e+00 - total_loss: 12473.8825\n","Epoch 3/3\n","30/30 [==============================] - 432s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0070 - factorized_top_k/top_10_categorical_accuracy: 0.0132 - factorized_top_k/top_50_categorical_accuracy: 0.0543 - factorized_top_k/top_100_categorical_accuracy: 0.1117 - loss: 8039.4111 - regularization_loss: 0.0000e+00 - total_loss: 8039.4111\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f27e41ea250>"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wb9rJdWMRaQY","outputId":"19a3faeb-56b5-4401-f717-cf44107b603a"},"source":["model.evaluate(cached_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'USERID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'TIMESTAMP': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n","5/5 [==============================] - 138s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33796.7786 - regularization_loss: 0.0000e+00 - total_loss: 33796.7786\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_100_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n"," 'loss': 30721.021484375,\n"," 'regularization_loss': 0,\n"," 'total_loss': 30721.021484375}"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"MmPAVEhVRexT"},"source":["> Note: Eventhough we only run it at three epochs, we can see accuracy increase as we add time into the model."]},{"cell_type":"markdown","metadata":{"id":"hNd03e3Qc_P2"},"source":["## Multi-Task Model with ReLU-based DNN"]},{"cell_type":"markdown","metadata":{"id":"cTkDkTyWdKnN"},"source":["The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."]},{"cell_type":"code","metadata":{"id":"XcipDXldRg2a"},"source":["class Model(tfrs.models.Model):\n","\n","    def __init__(self,\n","                 rating_weight: float, retrieval_weight: float) -> None:\n","        # We take the loss weights in the constructor: this allows us to instantiate\n","        # several model objects with different loss weights.\n","\n","        super().__init__()\n","\n","        embedding_dimension = 32\n","\n","        # item models.\n","        self.item_model: tf.keras.layers.Layer = tf.keras.Sequential([\n","          tf.keras.layers.experimental.preprocessing.StringLookup(\n","            vocabulary=unique_item_ids, mask_token=None),\n","          tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension)\n","        ])\n","            \n","        ## user model    \n","        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n","          tf.keras.layers.experimental.preprocessing.StringLookup(\n","            vocabulary=unique_user_ids, mask_token=None),\n","          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n","        ])\n","\n","        # A small model to take in user and item embeddings and predict ratings.\n","        # We can make this as complicated as we want as long as we output a scalar\n","        # as our prediction.\n","        \n","        ## this is Relu-Based DNN\n","        self.rating_model = tf.keras.Sequential([\n","            tf.keras.layers.Dense(256, activation=\"relu\"),\n","            tf.keras.layers.Dense(128, activation=\"relu\"),\n","            tf.keras.layers.Dense(64, activation=\"relu\"),\n","            tf.keras.layers.Dense(1),\n","        ])\n","\n","        # rating and retrieval task.\n","        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n","            loss=tf.keras.losses.MeanSquaredError(),\n","            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n","        )\n","            \n","        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n","            metrics=tfrs.metrics.FactorizedTopK(\n","                candidates=items.batch(128).map(self.item_model)\n","            )\n","        )\n","\n","        # The loss weights.\n","        self.rating_weight = rating_weight\n","        self.retrieval_weight = retrieval_weight\n","\n","    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n","        # We pick out the user features and pass them into the user model.\n","        user_embeddings = self.user_model(features[\"USERID\"])\n","        \n","        # And pick out the item features and pass them into the item model.\n","        item_embeddings = self.item_model(features[\"ITEMID\"])\n","\n","        return (\n","            user_embeddings,\n","            item_embeddings,\n","            # We apply the multi-layered rating model to a concatentation of\n","            # user and item embeddings.\n","            self.rating_model(\n","                tf.concat([user_embeddings, item_embeddings], axis=1)\n","            ),\n","        )\n","\n","    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","\n","        ## ratings go here as a method to compute loss\n","        ratings = features.pop(\"RATING\")\n","\n","        user_embeddings, item_embeddings, rating_predictions = self(features)\n","\n","        # We compute the loss for each task.\n","        rating_loss = self.rating_task(\n","            labels=ratings,\n","            predictions=rating_predictions,\n","        )\n","        retrieval_loss = self.retrieval_task(user_embeddings, item_embeddings)\n","\n","        # And combine them using the loss weights.\n","        return (self.rating_weight * rating_loss\n","                + self.retrieval_weight * retrieval_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mFPyxPmYdtio"},"source":["### Rating-specialized model\n","Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yRty3OOdqEh","outputId":"d800cc38-0313-4c34-e438-bc09b56599d9"},"source":["model = Model(rating_weight=1.0, retrieval_weight=0.0)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n","\n","cached_train = train.shuffle(100_000).batch(8192).cache()\n","cached_test = test.batch(4096).cache()\n","\n","model.fit(cached_train, epochs=3)\n","metrics = model.evaluate(cached_test, return_dict=True)\n","\n","print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n","print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","8/8 [==============================] - 388s 48s/step - root_mean_squared_error: 0.4401 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 7.8333e-04 - loss: 0.1581 - regularization_loss: 0.0000e+00 - total_loss: 0.1581\n","Epoch 2/3\n","8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.0205 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 3.7047e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.7047e-04\n","Epoch 3/3\n","8/8 [==============================] - 386s 48s/step - root_mean_squared_error: 0.0125 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 1.5387e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5387e-04\n","5/5 [==============================] - 133s 26s/step - root_mean_squared_error: 0.0123 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 9.0000e-04 - loss: 1.5055e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5055e-04\n","Retrieval top-100 accuracy: 0.001.\n","Ranking RMSE: 0.012.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RS-P_DJLd-UE"},"source":["### Retrieval-specialized model\n","Let's now try a model that focuses on retrieval only."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VazdjAAudzpX","outputId":"8bbf4321-2cfe-46c8-fe20-1ea305d08042"},"source":["model = Model(rating_weight=0.0, retrieval_weight=1.0)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n","\n","model.fit(cached_train, epochs=3)\n","metrics = model.evaluate(cached_test, return_dict=True)\n","\n","print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n","print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.9892 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 3.8333e-04 - factorized_top_k/top_100_categorical_accuracy: 7.0000e-04 - loss: 62067.1797 - regularization_loss: 0.0000e+00 - total_loss: 62067.1797\n","Epoch 2/3\n","8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9881 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0918 - factorized_top_k/top_10_categorical_accuracy: 0.1484 - factorized_top_k/top_50_categorical_accuracy: 0.3325 - factorized_top_k/top_100_categorical_accuracy: 0.4333 - loss: 61949.0569 - regularization_loss: 0.0000e+00 - total_loss: 61949.0569\n","Epoch 3/3\n","8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9851 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5590 - factorized_top_k/top_10_categorical_accuracy: 0.7058 - factorized_top_k/top_50_categorical_accuracy: 0.9094 - factorized_top_k/top_100_categorical_accuracy: 0.9534 - loss: 61799.7860 - regularization_loss: 0.0000e+00 - total_loss: 61799.7860\n","5/5 [==============================] - 130s 26s/step - root_mean_squared_error: 0.9883 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.8281 - regularization_loss: 0.0000e+00 - total_loss: 32588.8281\n","Retrieval top-100 accuracy: 0.000.\n","Ranking RMSE: 0.988.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dT9KY_YreDZh"},"source":["### Joint model\n","Let's now train a model that assigns positive weights to both tasks."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAy8T18LeE9R","outputId":"3cea02f2-6f91-4dc4-aa93-f6f76f32e27c"},"source":["model = Model(rating_weight=0.5, retrieval_weight=0.5)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n","\n","model.fit(cached_train, epochs=3)\n","metrics = model.evaluate(cached_test, return_dict=True)\n","\n","print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n","print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","8/8 [==============================] - 383s 47s/step - root_mean_squared_error: 0.4693 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_50_categorical_accuracy: 2.6667e-04 - factorized_top_k/top_100_categorical_accuracy: 7.5000e-04 - loss: 31033.7246 - regularization_loss: 0.0000e+00 - total_loss: 31033.7246\n","Epoch 2/3\n","8/8 [==============================] - 387s 48s/step - root_mean_squared_error: 0.0133 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0084 - factorized_top_k/top_10_categorical_accuracy: 0.0152 - factorized_top_k/top_50_categorical_accuracy: 0.0466 - factorized_top_k/top_100_categorical_accuracy: 0.0706 - loss: 31004.2229 - regularization_loss: 0.0000e+00 - total_loss: 31004.2229\n","Epoch 3/3\n","8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.0138 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1620 - factorized_top_k/top_10_categorical_accuracy: 0.2301 - factorized_top_k/top_50_categorical_accuracy: 0.4188 - factorized_top_k/top_100_categorical_accuracy: 0.5109 - loss: 30972.8370 - regularization_loss: 0.0000e+00 - total_loss: 30972.8370\n","5/5 [==============================] - 131s 26s/step - root_mean_squared_error: 0.0136 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_100_categorical_accuracy: 1.5000e-04 - loss: 16294.1732 - regularization_loss: 0.0000e+00 - total_loss: 16294.1732\n","Retrieval top-100 accuracy: 0.000.\n","Ranking RMSE: 0.014.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oEQF2KeJeKha"},"source":["We can see that accuracy is highest and RMSE is lowest when we combine both ranking and retrieval together."]}]}