{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Song Recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FobpPeUT1JU",
        "outputId": "e7a9d8aa-a992-4132-faf2-c2c98f488efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 11.8 MB 52 kB/s \n",
            "\u001b[?25h  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttIbHs9jRPjP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import logging\n",
        "import sys\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import seaborn as sns\n",
        "\n",
        "from surprise import SVD, SlopeOne, NMF, KNNBaseline\n",
        "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
        "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
        "from surprise.prediction_algorithms.random_pred import NormalPredictor\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rcParams.update({'font.size': 18})\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkpER4magJ4o"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAJEi7PxSr5w",
        "outputId": "fe013bc4-93f5-4919-dc0e-ac15ba4c7ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset downloaded: ./data/bronze/interactions.parquet.gz\n"
          ]
        }
      ],
      "source": [
        "# download data\n",
        "!python ./code/load_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RE32q3AhTJPG",
        "outputId": "02c27621-af42-4c84-d7f7-01bb3759e994"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>track_id</th>\n",
              "      <th>plays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>732659</td>\n",
              "      <td>6347</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>732659</td>\n",
              "      <td>9365</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>732659</td>\n",
              "      <td>16962</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>732659</td>\n",
              "      <td>19513</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>732659</td>\n",
              "      <td>19536</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  track_id  plays\n",
              "0   732659      6347      1\n",
              "1   732659      9365      1\n",
              "2   732659     16962      2\n",
              "3   732659     19513      1\n",
              "4   732659     19536      1"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_parquet('./data/bronze/interactions.parquet.gz')\n",
        "data.columns = ['user_id', 'track_id','plays']\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YC1rn4_TU8h",
        "outputId": "fd61d689-181f-4d04-9cb0-1a87729a3255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48373586 entries, 0 to 48373585\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Dtype\n",
            "---  ------    -----\n",
            " 0   user_id   int64\n",
            " 1   track_id  int64\n",
            " 2   plays     int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 1.1 GB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4zLi5SRTrD-"
      },
      "outputs": [],
      "source": [
        "# data_small = data.head(1000).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy985iL8gNQq"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OojYxl_JTXlh"
      },
      "outputs": [],
      "source": [
        "def tt_preprocess(tt):\n",
        "    # Saturate top 1% of plays, where 24 is 99th percentile of plays\n",
        "    tt.plays = tt.plays.transform(lambda x: 24 if x > 24 else x)\n",
        "    # Create 'rating' column based on log(plays/max_plays) transformed to 1-5 scale\n",
        "    tt['rating'] = np.log10(tt.plays)/np.log10(tt['plays'].max())*5+1\n",
        "    # Include only top 250 tracks (11% of total data, ~4.8 millions entries)\n",
        "    top_tracks = tt['track_id'].value_counts()[:250].index.tolist()\n",
        "    tt = tt[tt['track_id'].isin(top_tracks)]\n",
        "    # Drop plays\n",
        "    tt = tt.drop(columns='plays')\n",
        "    # Create dummy column, timestamp, to fit Surprise format\n",
        "    tt['timestamp'] = 0\n",
        "    return tt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN6ASKtjVzVt"
      },
      "outputs": [],
      "source": [
        "# load preprocessed tt data\n",
        "data = tt_preprocess(data)\n",
        "\n",
        "# Split into train/validation data \n",
        "frac = 0.8\n",
        "train = data.sample(frac=frac,random_state=0)\n",
        "test = data.drop(train.index)\n",
        "# test = test.set_index('user_id')\n",
        "\n",
        "# Save training data\n",
        "train_path = './data/silver/train.parquet.gz'\n",
        "train.to_parquet(train_path, compression='gzip')\n",
        "\n",
        "# Save testing data\n",
        "test_path = './data/silver/test.parquet.gz'\n",
        "test.to_parquet(test_path, compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw35zEjIg8Ws"
      },
      "source": [
        "## User Profile Recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYN96WOCUNps"
      },
      "outputs": [],
      "source": [
        "class SongRecommender():\n",
        "    \"\"\"Basic song recommender system.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name='svd'):\n",
        "        \"\"\"Constructs a SongRecommender\"\"\"\n",
        "        self.logger = logging.getLogger('reco-cs')\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def fit(self, ratings):\n",
        "        \"\"\"\n",
        "        Trains the recommender on a given set of ratings.\n",
        "        Parameters\n",
        "        ----------\n",
        "        ratings : pandas dataframe, shape = (n_ratings, 4)\n",
        "                  with columns 'user_id', 'track_id', 'likes', 'timestamp'\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        self.logger.debug(\"starting fit\")\n",
        "        # processing for Surprise\n",
        "        ratings = ratings.sample(frac=1)\n",
        "        ratings = Dataset.load_from_df(ratings[['user_id', 'track_id', 'rating']],\n",
        "                                       reader=Reader(rating_scale = (1,5)))\n",
        "        self.trainset = ratings.build_full_trainset()\n",
        "        # Choose model class based on model_name\n",
        "        if self.model_name == 'svd':\n",
        "            self.algo = SVD(lr_all=0.001,n_epochs=125)\n",
        "        elif self.model_name == 'slopeone':\n",
        "            self.algo = SlopeOne()\n",
        "        elif self.model_name == 'nmf':\n",
        "            self.algo = NMF()\n",
        "        elif self.model_name == 'knnbaseline':\n",
        "            self.algo = KNNBaseline() \n",
        "        elif self.model_name == 'cocluster':\n",
        "            self.algo = CoClustering() \n",
        "        elif self.model_name == 'baseline':\n",
        "            self.algo = BaselineOnly()\n",
        "        elif self.model_name == 'normal':\n",
        "            self.algo = NormalPredictor()            \n",
        "        self.algo.fit(self.trainset)\n",
        "        self.logger.debug(\"finishing fit\")\n",
        "        return(self)\n",
        "\n",
        "    def transform(self, requests):\n",
        "        \"\"\"\n",
        "        Predicts the ratings for a given set of requests.\n",
        "        Parameters\n",
        "        ----------\n",
        "        requests : pandas dataframe, shape = (n_ratings, 4)\n",
        "                  with columns 'user_id', 'track_id', 'rating', 'timestamp'\n",
        "        Returns\n",
        "        -------\n",
        "        dataframe : a pandas dataframe with columns 'user_id', 'track_id', 'rating'\n",
        "                    column 'rating' contains the predicted rating\n",
        "        \"\"\"\n",
        "        self.logger.debug(\"starting predict\")\n",
        "        self.logger.debug(\"request count: {}\".format(requests.shape[0]))\n",
        "        testset = Dataset(reader=Reader()).construct_testset(raw_testset = requests.values)\n",
        "        predictions = self.algo.test(testset)\n",
        "        pred_base = [(pred.uid,pred.iid,pred.est) for pred in predictions]\n",
        "        predictions = pd.DataFrame(pred_base,columns=['user_id', 'track_id', 'rating'])\n",
        "        self.logger.debug(\"finishing predict\")\n",
        "        return(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_-zAIB8hBtV"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1-0EG54cYhq"
      },
      "outputs": [],
      "source": [
        "# set list of models to train\n",
        "model_name_ = [\"svd\", \"cocluster\", \"nmf\"]\n",
        "\n",
        "# set TRAIN SET path\n",
        "path_train_ = \"./data/silver/train.parquet.gz\"\n",
        "\n",
        "# Reading TRAIN SET from input file into pandas\n",
        "train_data = pd.read_parquet(path_train_)\n",
        "\n",
        "for model_name in model_name_:\n",
        "    # Creating an instance of your recommender with the right parameters\n",
        "    reco = SongRecommender(model_name)\n",
        "    # fits on training data, returns a SongRecommender object\n",
        "    model = reco.fit(train_data)\n",
        "    # save model to pickle file\n",
        "    pickle.dump(model, open(f\"./artifacts/models/model_{model_name}.p\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXJpsjxYigko"
      },
      "source": [
        "## Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AP6ZAOpXqaS"
      },
      "outputs": [],
      "source": [
        "path_requests_ = \"./data/silver/test.parquet.gz\"\n",
        "result_path_ = \"./outputs/model_result_ensemble.csv\"\n",
        "\n",
        "model_paths_ = ['./artifacts/models/model_cocluster.p',\n",
        "                './artifacts/models/model_svd.p',\n",
        "                './artifacts/models/model_nmf.p']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDKSkHY9Uplo"
      },
      "outputs": [],
      "source": [
        "# Reading REQUEST SET from input file into pandas\n",
        "request_data = pd.read_parquet(path_requests_)\n",
        "\n",
        "if model_paths_ == 'default':\n",
        "    global_mean = train_data['rating'].mean()\n",
        "    result_data = request_data.drop(columns=['timestamp'])\n",
        "    result_data['rating'] = global_mean\n",
        "else:\n",
        "    # Creating an instance of your recommender with the right parameters\n",
        "    # reco_instance = SongRecommender(model_paths_)\n",
        "    if len(model_paths_)>1:\n",
        "        result_dfs = []\n",
        "        for path in model_paths_:\n",
        "            model = pickle.load(open(path, \"rb\"))\n",
        "            result_dfs.append(model.transform(request_data))\n",
        "        # Designate weights based on val set RMSE relative to\n",
        "        # global mean RMSE, and normalize\n",
        "        global_mean_rmse = 1.3706\n",
        "        cocluster_weight = 1.3706 - 1.255\n",
        "        nmf_weight = 1.3706 - 1.2716\n",
        "        svd_weight = 1.3706 - 1.1934\n",
        "        result_dfs[0]['rating'] = \\\n",
        "            (result_dfs[0]['rating']*cocluster_weight + \\\n",
        "                result_dfs[1]['rating']*nmf_weight + \\\n",
        "                    result_dfs[2]['rating']*svd_weight)/ \\\n",
        "                        (cocluster_weight + nmf_weight + svd_weight)\n",
        "        result_data = result_dfs[0]\n",
        "    else:\n",
        "        # load the model\n",
        "        model = pickle.load(open(model_paths_[0], \"rb\"))\n",
        "        # apply predict on request_data, returns a dataframe\n",
        "        result_data = model.transform(request_data)\n",
        "\n",
        "result_data.to_csv(result_path_, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAzKEuxcv05-"
      },
      "outputs": [],
      "source": [
        "# !echo *.p >> .gitignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fs4Og2Fowe6Z",
        "outputId": "ece45af9-fb6a-41c7-ec19-7c982b3431ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>track_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>732659.0</td>\n",
              "      <td>191611.0</td>\n",
              "      <td>1.344042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>891958.0</td>\n",
              "      <td>54149.0</td>\n",
              "      <td>1.386490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>891958.0</td>\n",
              "      <td>90798.0</td>\n",
              "      <td>1.699234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>891958.0</td>\n",
              "      <td>176425.0</td>\n",
              "      <td>1.614198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>891958.0</td>\n",
              "      <td>314455.0</td>\n",
              "      <td>1.401167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id  track_id    rating\n",
              "0  732659.0  191611.0  1.344042\n",
              "1  891958.0   54149.0  1.386490\n",
              "2  891958.0   90798.0  1.699234\n",
              "3  891958.0  176425.0  1.614198\n",
              "4  891958.0  314455.0  1.401167"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bJMtJwFf-12"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_SeDs2Uiyy5"
      },
      "outputs": [],
      "source": [
        "def compute_score(predictions, actual):\n",
        "    \"\"\"Look at 5% of most highly predicted songs for each user.\n",
        "    Return the average actual rating of those songs.\n",
        "    \"\"\"\n",
        "    actual.drop(columns=['timestamp'],inplace=True)\n",
        "    df = pd.merge(predictions, actual.rename(columns={'rating':'actualrating'}), on=['user_id','track_id']).fillna(1.0)\n",
        "    # for each user\n",
        "    g = df.groupby('user_id')\n",
        "    # detect the top 5% songs as predicted by your algorithm\n",
        "    top_5 = g.rating.transform(\n",
        "        lambda x: x >= x.quantile(.95))\n",
        "    # return the mean of the actual score on those\n",
        "    return df.actualrating[top_5==1].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an-9RrKEiz5V"
      },
      "outputs": [],
      "source": [
        "def compute_rmse(predictions, actual):\n",
        "    # RMSE between predictions and actual ratings\n",
        "    rmse = ((predictions.rating - actual.rating) ** 2).mean() ** .5\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igm2YT3HjgWS"
      },
      "outputs": [],
      "source": [
        "path_testing_ = \"./data/silver/test.parquet.gz\" # groundtruth\n",
        "result_path_ = \"./outputs/model_result_ensemble.csv\" # predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAOT7lthf8j9",
        "outputId": "0a19039e-ee50-4abc-8473-72116f7b439e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2370072780573707\n",
            "1.579932687440548\n"
          ]
        }
      ],
      "source": [
        "# Load predictions data\n",
        "prediction_data = pd.read_csv(result_path_)\n",
        "\n",
        "# Load actual validation data\n",
        "actual_data = pd.read_parquet(path_testing_)\n",
        "\n",
        "# Compute score based on mean of top 5% of each users song rankings\n",
        "score = compute_score(prediction_data, actual_data)\n",
        "print(score)\n",
        "\n",
        "# Compute RMSE between prediction and actual data\n",
        "rmse = compute_rmse(prediction_data, actual_data)\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB4dlyq61UmV"
      },
      "outputs": [],
      "source": [
        "# Save results to csv file\n",
        "fields=[result_path_,round(score,4),round(rmse,4)]\n",
        "with open(r'./outputs/eval_results.csv', 'a') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trxJL3Mej_R5"
      },
      "source": [
        "## Results Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaJPGMQ7kAnG"
      },
      "outputs": [],
      "source": [
        "# # Load results.csv file\n",
        "# results = pd.read_csv('./outputs/results.csv')\n",
        "\n",
        "# # If hyperparameters = True, generate SVD hyperparameters bar plot\n",
        "# # If hyperparameters = False, generate model comparison bar plot\n",
        "# hyperparameters = False\n",
        "\n",
        "# if hyperparameters == False:\n",
        "#     model_labels = ['SVD', 'NMF','KNN',\n",
        "#                         'Co-cluster','ALS Base','Normal','Global Mean']\n",
        "\n",
        "#     models_names = results.name[results.name.str.contains(\n",
        "#         'svd_default|nmf|knn|cocluster|baseline|normal|global_mean')]\n",
        "\n",
        "#     xlabel = 'Model Name'\n",
        "    \n",
        "#     comparison = results[results.name.isin(models_names)]\n",
        "\n",
        "#     comparison['label'] = model_labels\n",
        "#     comparison.sort_values(by='rmse',ascending=False,inplace=True)\n",
        "\n",
        "#     fig,ax = plt.subplots(figsize=(13,6))\n",
        "#     plt.bar(comparison['label'],comparison['rmse'],color = sns.color_palette(\"husl\", 7))\n",
        "#     plt.xlabel('Model Type')\n",
        "#     plt.ylabel('RMSE')\n",
        "\n",
        "#     plt.show(block=False)\n",
        "#     plt.savefig('./outputs/rmse_comparison_no_ensemble.jpg')\n",
        "#     plt.close('all')\n",
        "\n",
        "#     # comparison = comparison.iloc[:,[3,2]]\n",
        "#     # comparison.to_csv('data/results/comparison_results.csv',index=False)\n",
        "# else:\n",
        "#     hyp_names = results.name[results.name.str.contains(\n",
        "#         'svd|pred.csv')]\n",
        "    \n",
        "#     hyp_df = results[results.name.isin(hyp_names)]\n",
        "    \n",
        "#     hyp_df.drop(index=[9,10],inplace=True)\n",
        "    \n",
        "#     hyp_df['lr'] = [.01, .005, .001, .001, .001, .001, .005, .005, .005, .005]\n",
        "#     hyp_df['epochs'] = [20, 20, 20, 50, 75, 125, 10, 50, 125, 75]\n",
        "    \n",
        "#     print(hyp_df)\n",
        "\n",
        "#     fig,ax = plt.subplots(figsize=(8,5))\n",
        "#     plt.scatter(x=hyp_df['lr'], y=hyp_df['epochs'], s=400, \n",
        "#                 c=hyp_df['rmse'], cmap=sns.color_palette('plasma', as_cmap=True))\n",
        "#     plt.xlabel('Learning Rate')\n",
        "#     plt.ylabel('Number of Epochs')\n",
        "\n",
        "#     cb = plt.colorbar()\n",
        "#     cb.ax.set_title('RMSE')\n",
        "    \n",
        "#     fig.tight_layout()\n",
        "#     plt.show(block=False)\n",
        "#     plt.savefig('./outputs/rmse_svd_hyp.jpg')\n",
        "#     plt.close('all')\n",
        "\n",
        "#     hyp_df = hyp_df.iloc[:,[3,4,2]]\n",
        "#     hyp_df.to_csv('./outputs/results/hyp_results.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_n6lr7Rf5-b"
      },
      "source": [
        "## Group Recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htCfj2Hx4m_o"
      },
      "outputs": [],
      "source": [
        "with open('./artifacts/le_user.pkl', 'rb') as f:\n",
        "    le_user = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vucf-bjlRdh5"
      },
      "outputs": [],
      "source": [
        "class GroupRecommender():\n",
        "    \"\"\"Playlist recommender system for groups.\"\"\"\n",
        "\n",
        "    def __init__(self,user_ids,num_songs=5,ensemble=True):\n",
        "        \"\"\"Constructs a GroupRecommender\"\"\"\n",
        "        self.user_ids = user_ids\n",
        "        self.num_songs = num_songs\n",
        "        self.ensemble = ensemble\n",
        "\n",
        "    def score_for_users(self,train_path):\n",
        "        \"\"\"Loads a trained model and predicts ratings for all tracks for given users\n",
        "        Args:\n",
        "            train_path (str): path to training data csv file\n",
        "        Returns:\n",
        "            self: GroupRecommender class instance\n",
        "        \"\"\"        \n",
        "        self.train = pd.read_parquet(train_path)\n",
        "        self.train.loc[:,'user_id'] = le_user.inverse_transform(self.train.user_id.values)\n",
        "        \n",
        "        track_list = self.train['track_id'].unique()\n",
        "        \n",
        "        df = pd.DataFrame(columns = self.user_ids, index = track_list).reset_index()\n",
        "        \n",
        "        request_data = pd.melt(df, id_vars = 'index', value_vars=self.user_ids)\n",
        "        request_data.rename(columns={'index': 'track_id', 'variable': 'user_id', 'value': 'rating'},inplace=True)\n",
        "        request_data = request_data[['user_id', 'track_id', 'rating']]\n",
        "        request_data['timestamp'] = 0\n",
        "        \n",
        "        if self.ensemble:\n",
        "            # Load ensemble of models for predictions\n",
        "            model_paths = ['./artifacts/models/model_cocluster.p',\n",
        "                           './artifacts/models/model_svd.p',\n",
        "                           './artifacts/models/model_nmf.p']\n",
        "            result_dfs = []\n",
        "            for path in model_paths:\n",
        "                model = pickle.load( open( path, \"rb\" ) )\n",
        "                result_dfs.append(model.transform(request_data))\n",
        "                \n",
        "            global_mean_rmse = 1.3706\n",
        "            cocluster_weight = global_mean_rmse - 1.255\n",
        "            nmf_weight = global_mean_rmse - 1.2716\n",
        "            svd_weight = global_mean_rmse - 1.1934\n",
        "            result_dfs[0]['rating'] = \\\n",
        "                (result_dfs[0]['rating']*cocluster_weight + \\\n",
        "                    result_dfs[1]['rating']*nmf_weight + \\\n",
        "                        result_dfs[2]['rating']*svd_weight)/ \\\n",
        "                            (cocluster_weight + nmf_weight + svd_weight)\n",
        "                            \n",
        "            self.predictions = result_dfs[0]\n",
        "        else:\n",
        "            # Use best SVD model\n",
        "            model = pickle.load(open(\"./artifacts/models/model_svd.p\", \"rb\"))\n",
        "\n",
        "            # Predict for request_data, returns a dataframe\n",
        "            self.predictions = model.transform(request_data)\n",
        "        \n",
        "        return self\n",
        "        \n",
        "    def impute_knowns(self):\n",
        "        \"\"\"Imputes actual ratings into prediction ratings for known entries\n",
        "        Returns:\n",
        "            self: GroupRecommender class instance\n",
        "        \"\"\"        \n",
        "        updated = self.predictions.merge(self.train, how='left', on=['user_id', 'track_id'],\n",
        "                            suffixes=('', '_new'))\n",
        "        # updated.drop(columns = ['Unnamed: 0','timestamp'],inplace=True)\n",
        "\n",
        "        updated['rating'] = np.where(pd.notnull(updated['rating_new']), updated['rating_new'], updated['rating'])\n",
        "        # # # Modify here\n",
        "        # updated['known'] = np.where(pd.notnull(updated['rating_new']), updated['rating_new'], updated['rating'])\n",
        "        updated.drop('rating_new', axis=1, inplace=True)\n",
        "        \n",
        "        self.predictions = updated\n",
        "        \n",
        "        return self\n",
        "        \n",
        "    def create_rankings(self):\n",
        "        \"\"\"For each user, sorts the ratings column, and replaces it with indices\n",
        "            indicating the ranking of the entries\n",
        "        Returns:\n",
        "            self: GroupRecommender class instance\n",
        "        \"\"\"        \n",
        "        dfs = []\n",
        "        for idx, user_id in enumerate(self.user_ids):\n",
        "            sorted_by_rating = self.predictions[self.predictions['user_id'] == user_id].sort_values(\n",
        "                by='rating',ascending=False).reset_index().drop(\n",
        "                columns=['user_id','index']).reset_index().set_index('track_id')\n",
        "            dfs.append(sorted_by_rating.rename(columns={'index':'rank'},inplace=True))\n",
        "            if idx == 0:\n",
        "                rankings = sorted_by_rating\n",
        "            else:\n",
        "                rankings = rankings.join(sorted_by_rating,rsuffix=str(idx+1))\n",
        "\n",
        "        self.rankings = rankings\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    # def track_artist_names(self,df):\n",
        "    #     \"\"\"Extract song_title and artist_name for tracks in given DataFrame\n",
        "    #     Args:\n",
        "    #         df (pandas DataFrame): DataFrame of top recommended songs\n",
        "    #     Returns:\n",
        "    #         pandas DataFrame: Initial DataFrame with additional song_title, artist_name columns\n",
        "    #     \"\"\"    \n",
        "        \n",
        "    #     # read in map of track_id to artist_name and song_title\n",
        "    #     names = pd.read_csv('data/track_artist_names.txt',sep = '<SEP>',header=None)\n",
        "        \n",
        "    #     # drop unnecessary column and rename columns\n",
        "    #     names.drop(columns = [0], inplace = True)\n",
        "    #     names.rename(columns={1: \"track_id\", 2: \"artist_name\", 3: \"song_title\"},inplace=True)\n",
        "        \n",
        "    #     # Merge on track id to add new columns\n",
        "    #     df = pd.merge(df, names, on = 'track_id',how='left')\n",
        "        \n",
        "    #     return df\n",
        "\n",
        "    def rec_group_playlist(self,strategy='lm'):\n",
        "        \"\"\"Applies a strategy to generate group rankings using the individual rankings\n",
        "        Args:\n",
        "            strategy (str, optional): Name of group ranking strategy. Defaults to 'lm'.\n",
        "        Returns:\n",
        "            pandas DataFrame: DataFrame of recommended songs with rankings\n",
        "        \"\"\"        \n",
        "        rankings = self.rankings\n",
        "        \n",
        "        rank_cols = [col for col in rankings.columns if 'rank' in col]\n",
        "\n",
        "        if strategy == 'mp':\n",
        "             # Most pleasure strategy\n",
        "            rankings['best_rnk'] = rankings[rank_cols].min(axis=1)\n",
        "            strat_col = 'best_rnk'\n",
        "        elif strategy == 'avg':\n",
        "            # Average rank strategy\n",
        "            rankings['avg_rnk'] = rankings[rank_cols].mean(axis=1)\n",
        "            strat_col = 'avg_rnk'\n",
        "        else:\n",
        "            # Least misery strategy\n",
        "            rankings['worst_rnk'] = rankings[rank_cols].max(axis=1)\n",
        "            strat_col = 'worst_rnk' # default is least misery strategy\n",
        "        \n",
        "        top_songs = rankings.sort_values(strat_col)[:self.num_songs]\n",
        "        # top_songs = self.track_artist_names(top_songs)\n",
        "        \n",
        "        # Rearrange dataframe to be presentable\n",
        "        # top_songs.insert(0, 'artist_name', top_songs.pop('artist_name'))\n",
        "        # top_songs.insert(1, 'song_title', top_songs.pop('song_title'))\n",
        "        # top_songs.drop(columns=['track_id'],inplace=True)\n",
        "        # rating_cols = [col for col in rankings.columns if 'rating' in col]\n",
        "        # top_songs.drop(columns=rating_cols,inplace=True)\n",
        "        # char_lim = 30\n",
        "        # top_songs['artist_name'] = top_songs['artist_name'].transform(lambda x: \n",
        "        #             x[:char_lim] + '...' \n",
        "        #             if len(x) > char_lim+1 else x)\n",
        "        # top_songs['song_title'] = top_songs['song_title'].transform(lambda x: \n",
        "        #             x[:char_lim] + '...' \n",
        "        #             if len(x) > char_lim+1 else x)\n",
        "        # print(top_songs)\n",
        "        \n",
        "        return top_songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdJtaBwEjUkD"
      },
      "outputs": [],
      "source": [
        "# Initial parameters\n",
        "user_ids = ['d1ca8b3e78811238cf94ee7caa1868d7ae9e908a',\n",
        "        '621659a10f52dc4f8b50f205ab85b6d6b7d1b0dc',\n",
        "        '257fc9ff00cd0ac79f53c7d65510b2ebba0c6b8e']\n",
        "\n",
        "num_songs = 5\n",
        "train_path = './data/silver/train.parquet.gz'\n",
        "strategy = 'avg'\n",
        "save_path = './outputs/rankings_avg.csv'\n",
        "ensemble = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkEKlobqOKOZ"
      },
      "outputs": [],
      "source": [
        "reco = GroupRecommender(user_ids,num_songs,ensemble)\n",
        "reco.score_for_users(train_path)\n",
        "reco.impute_knowns()\n",
        "reco.create_rankings()\n",
        "top_songs = reco.rec_group_playlist(strategy)\n",
        "top_songs.to_csv(save_path,index='False')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Bg0FveyN3bhr",
        "outputId": "acc00d8c-54f0-43eb-fe99-f642ddbfcfd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rank2</th>\n",
              "      <th>rating2</th>\n",
              "      <th>timestamp2</th>\n",
              "      <th>rank3</th>\n",
              "      <th>rating3</th>\n",
              "      <th>timestamp3</th>\n",
              "      <th>avg_rnk</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>track_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25043</th>\n",
              "      <td>6</td>\n",
              "      <td>5.035409</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.532112</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67917</th>\n",
              "      <td>2</td>\n",
              "      <td>5.632456</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>2.728436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216543</th>\n",
              "      <td>18</td>\n",
              "      <td>4.271564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.818957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5.863106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247548</th>\n",
              "      <td>1</td>\n",
              "      <td>5.789916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28</td>\n",
              "      <td>2.555950</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>5.789916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191902</th>\n",
              "      <td>5</td>\n",
              "      <td>5.152002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38</td>\n",
              "      <td>2.409702</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          rank    rating  timestamp  ...   rating3  timestamp3    avg_rnk\n",
              "track_id                             ...                                 \n",
              "25043        6  5.035409        0.0  ...  6.000000         0.0   5.000000\n",
              "67917        2  5.632456        0.0  ...  6.000000         0.0   8.666667\n",
              "216543      18  4.271564        0.0  ...  5.863106         0.0  10.333333\n",
              "247548       1  5.789916        0.0  ...  5.789916         0.0  14.000000\n",
              "191902       5  5.152002        0.0  ...  6.000000         0.0  14.333333\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4QWPRDE-zjK"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEIqfuVG-8ca",
        "outputId": "865e3539-db76-4df4-8111-a86cc95e1900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\n",
            "├── artifacts\n",
            "│   ├── le_item.pkl\n",
            "│   ├── le_user.pkl\n",
            "│   └── models\n",
            "│       ├── model_cocluster.p\n",
            "│       ├── model_nmf.p\n",
            "│       └── model_svd.p\n",
            "├── code\n",
            "│   ├── __init__.py\n",
            "│   └── load_data.py\n",
            "├── data\n",
            "│   ├── bronze\n",
            "│   │   └── interactions.parquet.gz\n",
            "│   └── silver\n",
            "│       ├── test.parquet.gz\n",
            "│       └── train.parquet.gz\n",
            "├── docs\n",
            "├── extras\n",
            "├── LICENSE\n",
            "├── notebooks\n",
            "├── outputs\n",
            "│   ├── eval_results.csv\n",
            "│   ├── model_result_ensemble.csv\n",
            "│   ├── rankings_avg.csv\n",
            "│   └── results.csv\n",
            "├── README.md\n",
            "├── requirements.txt\n",
            "└── setup.py\n",
            "\n",
            "10 directories, 18 files\n"
          ]
        }
      ],
      "source": [
        "!tree -L 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdRM66_YOdo8"
      },
      "source": [
        "## App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Gvk7rpk-11"
      },
      "outputs": [],
      "source": [
        "# from flask import Flask, render_template, flash, request\n",
        "# from wtforms import Form, TextField, TextAreaField, validators, StringField, SubmitField\n",
        "# from group_rec import GroupRecommender\n",
        "\n",
        "# DEBUG = True\n",
        "# app = Flask(__name__)\n",
        "# app.config.from_object(__name__)\n",
        "# app.config['SECRET_KEY'] = '<redacted>'\n",
        "\n",
        "# class ReusableForm(Form):\n",
        "#     user1 = TextField('user1:', validators=[validators.required()])\n",
        "#     user2 = TextField('user2:', validators=[validators.required()])\n",
        "#     user3 = TextField('user3:', validators=[validators.required()])\n",
        "\n",
        "# @app.route(\"/\", methods=['GET', 'POST'])\n",
        "# def hello():\n",
        "#     # Generate playlist recommendations based on user ids\n",
        "#     form = ReusableForm(request.form)\n",
        "\n",
        "#     if request.method == 'POST':\n",
        "#         user1=request.form['user1']\n",
        "#         user2=request.form['user2']\n",
        "#         user3=request.form['user3']\n",
        "\n",
        "#         if form.validate():\n",
        "#             flash('Generating playlist...')\n",
        "#             user_ids = [user1,user2,user3]\n",
        "        \n",
        "#             num_songs = 5\n",
        "#             train_path = 'data/train.csv'\n",
        "#             strategy = 'lm'\n",
        "\n",
        "#             ensemble = False\n",
        "            \n",
        "#             reco = GroupRecommender(user_ids,num_songs,ensemble)\n",
        "            \n",
        "#             reco.score_for_users(train_path)\n",
        "            \n",
        "#             reco.impute_knowns()\n",
        "\n",
        "#             reco.create_rankings()\n",
        "            \n",
        "#             top_songs = reco.rec_group_playlist(strategy)\n",
        "            \n",
        "#             top_songs = top_songs.loc[:,['artist_name','song_title']]\n",
        "            \n",
        "#             top_songs.rename(columns = {'artist_name': 'Artist', \n",
        "#                                         'song_title':'Song Title'},inplace=True)\n",
        "            \n",
        "#             top_songs['Track Number'] = range(1,6)\n",
        "#             top_songs.set_index('Track Number', drop=True, inplace=True)\n",
        "#             top_songs.index.name = None\n",
        "            \n",
        "#             return render_template('view.html',tables=[top_songs.to_html(classes='songs')],titles=[''])\n",
        "#         else:\n",
        "#             flash('Error: All Fields are Required')\n",
        "\n",
        "#     return render_template('index.html', form=form)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPBpyxJjMT/2sp/xmgPzs82",
      "collapsed_sections": [],
      "mount_file_id": "1Cy-U9kQbMTIs1BDwqYOA2DdU3xg1YpEv",
      "name": "reco-tut-gpr-t1-02-notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
