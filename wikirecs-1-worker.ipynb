{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wikirecs-1.worker","provenance":[{"file_id":"1KDUlGmiF0QDqDEriKYiAn9i5Xhxtpy10","timestamp":1625763528590}],"collapsed_sections":[],"mount_file_id":"1oar0IIoKvzlao9331q0pCluMvDwhaJh4","authorship_tag":"ABX9TyNtsJtttXDGAHT85bDLW6zS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Jep4VQyz3ZzE","executionInfo":{"status":"ok","timestamp":1625763697015,"user_tz":-330,"elapsed":908,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["project_name=\"reco-wikirecs\"; branch=\"master\"; account=\"sparsh-ai\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ailHP5gi3ZzP","executionInfo":{"status":"ok","timestamp":1625763724038,"user_tz":-330,"elapsed":6338,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"e864fccf-5896-4abb-9f02-88c73ea22bb4"},"source":["!cp /content/drive/MyDrive/mykeys.py /content\n","import mykeys\n","!rm /content/mykeys.py\n","path = \"/content/\" + project_name; \n","!mkdir \"{path}\"\n","%cd \"{path}\"\n","import sys; sys.path.append(path)\n","!git config --global user.email \"sparsh@recohut.com\"\n","!git config --global user.name  \"colab-sparsh\"\n","!git init\n","!git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n","!git pull origin \"{branch}\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/reco-wikirecs\n","Initialized empty Git repository in /content/reco-wikirecs/.git/\n","remote: Enumerating objects: 35, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 35 (delta 10), reused 32 (delta 7), pack-reused 0\u001b[K\n","Unpacking objects: 100% (35/35), done.\n","From https://github.com/sparsh-ai/reco-wikirecs\n"," * branch            master     -> FETCH_HEAD\n"," * [new branch]      master     -> origin/master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWDDXhuK9klF","executionInfo":{"status":"ok","timestamp":1625729526223,"user_tz":-330,"elapsed":743,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"b18d4705-83dd-402c-a6fc-3f3461c92d5b"},"source":["%cd /content/reco-wikirecs/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/reco-wikirecs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6HVnZkVW3ZzQ","executionInfo":{"status":"ok","timestamp":1625762573026,"user_tz":-330,"elapsed":10791,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"84c27b46-9194-4aa6-8f63-90317b2a696c"},"source":["!git status\n","!git add . && git commit -m 'commit' && git push origin \"{branch}\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Compressing objects: 100% (10/10), done.\n","Writing objects: 100% (10/10), 37.57 MiB | 4.78 MiB/s, done.\n","Total 10 (delta 3), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n","To https://github.com/sparsh-ai/reco-wikirecs.git\n","   033f9d1..e673d03  master -> master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LLMOakVK7lZg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763802144,"user_tz":-330,"elapsed":75926,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"3272b0d6-ba68-4434-fd90-528e9ed01c06"},"source":["!pip install -r requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting implicit\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/07/c0121884722d16e2c5beeb815f6b84b41cbf22e738e4075f1475be2791bc/implicit-0.4.4.tar.gz (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 25.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 31.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 20.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 14.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 11.9MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 634kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 665kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 757kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 778kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 788kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 808kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 819kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 839kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 849kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 931kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 962kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 993kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 10.9MB/s \n","\u001b[?25hCollecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Collecting umap\n","  Downloading https://files.pythonhosted.org/packages/4b/46/08ab68936625400fe690684428d4db4764f49b406782cc133df1d0299d06/umap-0.1.1.tar.gz\n","Collecting itables\n","  Downloading https://files.pythonhosted.org/packages/f4/29/501d21d839a2ea3bbd5821e0c7b228db2b281d06b577971dd97f8d340a41/itables-0.3.0-py3-none-any.whl\n","Collecting PyYAML>=5.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 60.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from implicit->-r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from implicit->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from implicit->-r requirements.txt (line 1)) (4.41.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia->-r requirements.txt (line 2)) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from itables->-r requirements.txt (line 4)) (1.1.5)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from itables->-r requirements.txt (line 4)) (5.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia->-r requirements.txt (line 2)) (2021.5.30)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->itables->-r requirements.txt (line 4)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->itables->-r requirements.txt (line 4)) (2.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (57.0.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (5.0.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->itables->-r requirements.txt (line 4)) (4.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->itables->-r requirements.txt (line 4)) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->itables->-r requirements.txt (line 4)) (0.7.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython->itables->-r requirements.txt (line 4)) (0.2.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->itables->-r requirements.txt (line 4)) (0.2.5)\n","Building wheels for collected packages: implicit, wikipedia, umap\n","  Building wheel for implicit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for implicit: filename=implicit-0.4.4-cp37-cp37m-linux_x86_64.whl size=3406369 sha256=f7e45ff8baf9f950e0d98c698c08708f18fac0dd4a6772a8278acbb15d93580b\n","  Stored in directory: /root/.cache/pip/wheels/bf/d4/ec/fd4f622fcbefb7521f149905295b2c26adecb23af38aa28217\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp37-none-any.whl size=11697 sha256=df1c53cfa57c864d0e29222418e06ef99e867215c132297f248242abcd537277\n","  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-cp37-none-any.whl size=3568 sha256=70b174712717dc017c68f312de3ec7f9a47c1e7467c8ea417999d2b068122d9e\n","  Stored in directory: /root/.cache/pip/wheels/7b/29/33/b4d917dc95f69c0a060e2ab012d95e15db9ed4cc0b94ccac26\n","Successfully built implicit wikipedia umap\n","Installing collected packages: implicit, wikipedia, umap, itables, PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.4.1 implicit-0.4.4 itables-0.3.0 umap-0.1.1 wikipedia-1.4.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wlWx6OrY3n_A"},"source":["---"]},{"cell_type":"code","metadata":{"id":"c_uAz5OS4sm3","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1625763803215,"user_tz":-330,"elapsed":1077,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"d0464559-970d-4d7e-b0d6-69df582dcd5f"},"source":["import yaml\n","import os\n","\n","from wiki_pull import *\n","\n","%matplotlib inline\n","%reload_ext autoreload\n","%autoreload 2\n","\n","from itables.javascript import load_datatables\n","load_datatables()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/javascript":["require.config({\n","    paths: {\n","        datatables: 'https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min',\n","    }\n","});\n","\n","$('head').append('<link rel=\"stylesheet\" type=\"text/css\" \\\n","                href = \"https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\" > ');\n","\n","$('head').append('<style> table td { text-overflow: ellipsis; overflow: hidden; } </style>');\n","\n","$('head').append(`<script>\n","function eval_functions(map_or_text) {\n","    if (typeof map_or_text === \"string\") {\n","        if (map_or_text.startsWith(\"function\")) {\n","            try {\n","                // Note: parenthesis are required around the whole expression for eval to return a value!\n","                // See https://stackoverflow.com/a/7399078/911298.\n","                //\n","                // eval(\"local_fun = \" + map_or_text) would fail because local_fun is not declared\n","                // (using var, let or const would work, but it would only be declared in the local scope\n","                // and therefore the value could not be retrieved).\n","                const func = eval(\"(\" + map_or_text + \")\");\n","                if (typeof func !== \"function\") {\n","                    // Note: backquotes are super convenient!\n","                    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\n","                    console.error(\"Evaluated expression \" + map_or_text + \" is not a function (type is \" + typeof func + \")\");\n","                    return map_or_text;\n","                }\n","                // Return the function\n","                return func;\n","            } catch (e) {\n","                // Make sure to print the error with a second argument to console.error().\n","                console.error(\"itables was not able to parse \" + map_or_text, e);\n","            }\n","        }\n","    } else if (typeof map_or_text === \"object\") {\n","        if (map_or_text instanceof Array) {\n","            // Note: \"var\" is now superseded by \"let\" and \"const\".\n","            // https://medium.com/javascript-scene/javascript-es6-var-let-or-const-ba58b8dcde75\n","            const result = [];\n","            // Note: \"for of\" is the best way to iterate through an iterable.\n","            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for...of\n","            for (const item of map_or_text) {\n","                result.push(eval_functions(item));\n","            }\n","            return result;\n","\n","            // Alternatively, more functional approach in one line:\n","            // return map_or_text.map(eval_functions);\n","        } else {\n","            const result = {};\n","            // Object.keys() is safer than \"for in\" because otherwise you might have keys\n","            // that aren't defined in the object itself.\n","            //\n","            // See https://stackoverflow.com/a/684692/911298.\n","            for (const item of Object.keys(map_or_text)) {\n","                result[item] = eval_functions(map_or_text[item]);\n","            }\n","            return result;\n","        }\n","    }\n","\n","    return map_or_text;\n","}\n","\n","</` + 'script>');"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"iT-JOJiF3G8M","executionInfo":{"status":"ok","timestamp":1625763803216,"user_tz":-330,"elapsed":23,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["with open('config.yaml') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"tQPeT_sk7Mud","executionInfo":{"status":"ok","timestamp":1625755605162,"user_tz":-330,"elapsed":432198,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"a248ea52-7dd1-4633-bd10-bc24d0201250"},"source":["get_sample_of_users(config['edit_lookback'], config['outfile'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000500it [07:04, 2379.90it/s]                             "],"name":"stderr"},{"output_type":"stream","text":["Earliest timestamp: 2021-06-21T19:22:49Z\n","Latest timestamp: 2021-07-08T14:39:42Z\n","Number of distinct users: 54355\n","Mean number of edits per user in timeframe: 18.40\n","Number of distinct pages edited: 401926\n","Mean number of edits per page in timeframe: 2.49\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>userid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Rodimus Rhyme</td>\n","      <td>7021208.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Asarlaí</td>\n","      <td>3215664.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Frank Anchor</td>\n","      <td>4659544.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MAHosieAPS</td>\n","      <td>40684241.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Aranya</td>\n","      <td>35393771.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54349</th>\n","      <td>Penwhale</td>\n","      <td>125125.0</td>\n","    </tr>\n","    <tr>\n","      <th>54350</th>\n","      <td>Htetrasme</td>\n","      <td>174367.0</td>\n","    </tr>\n","    <tr>\n","      <th>54351</th>\n","      <td>LarTram</td>\n","      <td>39905917.0</td>\n","    </tr>\n","    <tr>\n","      <th>54352</th>\n","      <td>Etan J. Tal</td>\n","      <td>7706243.0</td>\n","    </tr>\n","    <tr>\n","      <th>54353</th>\n","      <td>Charlton.austin</td>\n","      <td>26706343.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54354 rows × 2 columns</p>\n","</div>"],"text/plain":["                  user      userid\n","0        Rodimus Rhyme   7021208.0\n","1              Asarlaí   3215664.0\n","2         Frank Anchor   4659544.0\n","3           MAHosieAPS  40684241.0\n","4               Aranya  35393771.0\n","...                ...         ...\n","54349         Penwhale    125125.0\n","54350        Htetrasme    174367.0\n","54351          LarTram  39905917.0\n","54352      Etan J. Tal   7706243.0\n","54353  Charlton.austin  26706343.0\n","\n","[54354 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzPsvEDtEgwm","executionInfo":{"status":"ok","timestamp":1625763805196,"user_tz":-330,"elapsed":578,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"05c3d3b1-1bbf-4d24-ce7c-de272597b734"},"source":["!wget https://github.com/sparsh-ai/reco-wikirecs/raw/033f9d18a9a791b5ffa173b6dda9a2e0ac76e311/sampled_users_2021_07_08.csv"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2021-07-08 17:03:39--  https://github.com/sparsh-ai/reco-wikirecs/raw/033f9d18a9a791b5ffa173b6dda9a2e0ac76e311/sampled_users_2021_07_08.csv\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/sparsh-ai/reco-wikirecs/033f9d18a9a791b5ffa173b6dda9a2e0ac76e311/sampled_users_2021_07_08.csv [following]\n","--2021-07-08 17:03:39--  https://raw.githubusercontent.com/sparsh-ai/reco-wikirecs/033f9d18a9a791b5ffa173b6dda9a2e0ac76e311/sampled_users_2021_07_08.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1226906 (1.2M) [text/plain]\n","Saving to: ‘sampled_users_2021_07_08.csv.1’\n","\n","sampled_users_2021_ 100%[===================>]   1.17M  --.-KB/s    in 0.04s   \n","\n","2021-07-08 17:03:40 (29.5 MB/s) - ‘sampled_users_2021_07_08.csv.1’ saved [1226906/1226906]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iRqIusXhEsUJ","executionInfo":{"status":"ok","timestamp":1625763939656,"user_tz":-330,"elapsed":665,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import pandas as pd\n","import numpy as np\n","import requests\n","import time\n","import os\n","from tqdm import tqdm\n","from pyarrow import feather\n","\n","\n","def get_recent_changes(N):\n","    S = requests.Session()\n","\n","    t = tqdm(total=N, position=0, leave=True)\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"format\": \"json\",\n","        \"rcprop\": \"title|ids|sizes|flags|user|userid|timestamp\",\n","        \"rcshow\": \"!bot|!anon|!minor\",\n","        \"rctype\": \"edit\",\n","        \"rcnamespace\": \"0\",\n","        \"list\": \"recentchanges\",\n","        \"action\": \"query\",\n","        \"rclimit\": \"500\",\n","    }\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","    all_rc = RECENTCHANGES\n","\n","    i = 500\n","    t.update(500)\n","    while i <= N:\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","        all_rc.extend(RECENTCHANGES)\n","        i = i + 500\n","        t.update(500)\n","\n","    if len(all_rc) > N:\n","        all_rc = all_rc[:N]\n","\n","    return all_rc\n","\n","\n","def get_sample_of_users(edit_lookback, outfile=None):\n","    \"\"\"Get a sample of recently active users by pulling the most recent N edits\n","    Note that this will be biased towards highly active users.\n","    Args:\n","        edit_lookback: The number of edits to go back.\n","        outfile: Pickle file path to write the user list to\n","    Returns:\n","        Dataframe with user and user id columns\n","    \"\"\"\n","    df = get_recent_changes(edit_lookback)\n","\n","    # Drop missing userid entries\n","    df = pd.DataFrame(df).dropna(subset=[\"userid\"])\n","\n","    print(\"Earliest timestamp: {}\".format(df.timestamp.min()))\n","    print(\"Latest timestamp: {}\".format(df.timestamp.max()))\n","    print(\"Number of distinct users: {}\".format(len(df.user.unique())))\n","    print(\n","        \"Mean number of edits per user in timeframe: %.2f\"\n","        % (len(df) / len(df.user.unique()))\n","    )\n","    print(\"Number of distinct pages edited: {}\".format(len(df.pageid.unique())))\n","    print(\n","        \"Mean number of edits per page in timeframe: %.2f\"\n","        % (len(df) / len(df.pageid.unique()))\n","    )\n","\n","    # Deduplicate to get\n","    sampled_users = df.loc[:, [\"user\", \"userid\"]].drop_duplicates()\n","\n","    # Remove RFD\n","    sampled_users = sampled_users[np.invert(sampled_users.user == \"RFD\")]\n","    sampled_users = sampled_users.reset_index(drop=True)\n","\n","    if outfile:\n","        sampled_users.to_csv(outfile, index=False)\n","\n","    return sampled_users\n","\n","\n","def get_edit_history(\n","    userid=None, user=None, latest_timestamp=None, earliest_timestamp=None, limit=None):\n","    \"\"\"For a particular user, pull their whole history of edits.\n","    Args:\n","        param1 (int): The first parameter.\n","        param2 (str): The second parameter.\n","    Returns:\n","        bool: The return value. True for success, False otherwise.\n","    \"\"\"\n","\n","    S = requests.Session()\n","    S.headers.update(\n","        {\"User-Agent\": \"WikiRecs (danielrsaunders@gmail.com) One-time pull\"}\n","    )\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"action\": \"query\",\n","        \"format\": \"json\",\n","        \"ucnamespace\": \"0\",\n","        \"list\": \"usercontribs\",\n","        \"ucuserids\": userid,\n","        \"ucprop\": \"title|ids|sizediff|flags|comment|timestamp\",\n","        \"ucshow=\": \"!minor|!new\",\n","    }\n","    if latest_timestamp is not None:\n","        PARAMS[\"ucstart\"] = latest_timestamp\n","    if earliest_timestamp is not None:\n","        PARAMS[\"ucend\"] = earliest_timestamp\n","    if user is not None:\n","        PARAMS[\"ucuser\"] = user\n","    if userid is not None:\n","        PARAMS[\"ucuserid\"] = userid\n","\n","    PARAMS[\"uclimit\"] = 500\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    if \"query\" not in DATA:\n","        print(DATA)\n","        raise ValueError\n","\n","    USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","    all_ucs = USERCONTRIBS\n","    i = 500\n","    while i < 100000:\n","        if \"continue\" not in DATA:\n","            break\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","        all_ucs.extend(USERCONTRIBS)\n","        i = i + 500\n","\n","    return all_ucs\n","\n","\n","def pull_edit_histories(\n","    sampled_users_file,\n","    edit_histories_file_pattern,\n","    users_per_chunk,\n","    earliest_timestamp,\n","    start=0):\n","    histories = []\n","    cols = [\"userid\", \"user\", \"pageid\", \"title\", \"timestamp\", \"sizediff\"]\n","    sampled_users = pd.read_csv(sampled_users_file)\n","    sampled_users.loc[:, \"userid\"].astype(int)\n","\n","    sampled_users = sampled_users.reset_index()\n","\n","    # Iterate through all the users in the list\n","    for i, (user, userid) in tqdm(\n","        iterable=enumerate(\n","            zip(sampled_users[\"user\"][start:], sampled_users[\"userid\"][start:]),\n","            start=start),\n","        total=len(sampled_users)): \n","\n","        # Get the history of edits for this userid\n","        thehistory = get_edit_history(\n","            userid=int(userid), earliest_timestamp=earliest_timestamp\n","        )\n","\n","        # If no edits, skip\n","        if len(thehistory) == 0:\n","            continue\n","\n","        thehistory = pd.DataFrame(thehistory)\n","\n","        # Remove edits using automated tools by looking for the word \"using\" in the comments\n","        try:\n","            thehistory = thehistory[\n","                np.invert(thehistory.comment.astype(str).str.contains(\"using\"))\n","            ]\n","        except AttributeError:\n","            continue\n","\n","        if len(thehistory) == 0:\n","            continue\n","\n","        histories.append(thehistory.loc[:, cols])\n","\n","        # if np.mod(i, 50) == 0:\n","        #     print(\n","        #         \"Most recent: {}/{} {} ({}) has {} edits\".format(\n","        #             i, len(sampled_users), user, int(userid), len(thehistory)\n","        #         )\n","        #     )\n","\n","        # Every x users save it out, for the sake of ram limitations\n","        if np.mod(i, users_per_chunk) == 0:\n","            feather.write_feather(\n","                pd.concat(histories), edit_histories_file_pattern.format(i)\n","            )\n","\n","            histories = []\n","      \n","    # Get the last few users that don't make up a full chunk\n","    feather.write_feather(pd.concat(histories), edit_histories_file_pattern.format(i))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vNLJxSLB2m8","outputId":"f87e9c2d-a0f7-4a45-e9d4-807f85bc07eb"},"source":["pull_edit_histories(\n","    config['outfile'],\n","    os.path.join(config['file_save_path'],config['edit_histories_file_pattern']),\n","    config['users_per_chunk'],\n","    config['earliest_timestamp'],\n","    start=10000,\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  9%|▉         | 4974/54339 [46:00<5:18:32,  2.58it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EwuprV5I3MIw"},"source":["!rm -r /content/drive/MyDrive/TempData/WikiRecs/edit_histories_2021_07_08_9*.feather"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VjRxyUhCePFT"},"source":["### Baseline models\n","\n","| Model | Type | Description |\n","| - | -:| ---:|\n","| Popularity | Rule-based | Most popular over the past year |\n","| Recent | Rule-based | Most recently edited by this user |\n","| Frequent | Rule-based | Most frequently edited by this user in the last year |\n","| BM25 | Collaborative-filtering | Okapi BM25, a simple variation on Jaccard similarity with TF-IDF that often has much better results |\n","| ALS | Collaborative-filtering | Alternating Least Squares matrix factorization of implicit training data, with BM25 pre-scaling |"]},{"cell_type":"code","metadata":{"id":"3g07BOYfbSUl"},"source":[""],"execution_count":null,"outputs":[]}]}